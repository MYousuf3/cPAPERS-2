[
  {
    "paper_id": "2306.17464v1",
    "submission_id": "yCA2i3bGbfC",
    "submission_title": "Identification of Partially Observed Linear Causal Models: Graphical Conditions for the Non-Gaussian and Heterogeneous Cases",
    "review_id": "Yoetz5inmJf",
    "input": {
      "title": "Identification of Partially Observed Linear Causal Models: Graphical Conditions for the Non-Gaussian and Heterogeneous Cases",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I enjoyed the idea and I think the main problem of learning latent causal graphical models is very important; however, this paper should clarify some necessary definitions, concepts and examples; otherwise I cannot properly evaluate its originality and contribution.\n- line 41/43/84: It is unclear that '\\epsilon is a vector of independent noise variables', '\\epsilon_i are uncorrelated within each domain, ...', and '\\epsilon_i are not necessarily mutually independent...'\n- In the linear structural equation models (SEM) settings, is independence of \\epilson_i required? Otherwise it may violate the markov condition and it seems to be a mixture of directed and undirected graphical model.\n- (1) line 55: definition of the directed path says that (V_i) is a directed path from V_i to itself. Then, Pa(V_i) should include V_i.\n- line 91, the conditions in Theorem 1 is not clear. It should clarify that 'Suppose we have observed X generated according to the mixing procedure (4) in a number of domains, t = 1, 2, T'\n- If T =2, then is the considered model is X = Y M \\epsilon_1 + (1- Y) M \\epsilon_2 where Y is Bernoulli distribution with known/unknown probabilities?, X_j = \\beta X_{Pa(j)} + Y_{1j} \\epsilon_{j1} + (1 - Y_{1j}) \\epsilon_{j2} where (Y_{1j}) are independent Bernoulli distribution with known/unknown probabilities, or X = M (p \\epsilon_1 + (1- p) M \\epsilon_2)?\n- In the finite sample setting, is it assumed to be known what distribution of error (\\epsilon_t) the sample follows?\n- line 116, the definition of the bottleneck should be clarified when J and K are sets of nodes.\n- We say that a set B is a bottleneck from J to K if every directed path from J to K includes some b \\in B.\n- line 121 From the definition, for each Vi, Ch(Vi) is a bottleneck from Ch(Vi) to X.\n- If J includes two nodes, saying J = {1, 2}, and K = {3}, the directed path from J to K is not defined.\n- e.g., I at first conjecture that it means that the directed path from j to k, for all j \\in J and k \\in K.\n- Then, all directed paths are (1,3), (2,3). Hence, {3} is only bottleneck.\n- However, then, it is contradictory to line 121.\n- line 160, it is also unclear that 'Rank(M_K^J) = 0 is a violation of classical faithfulness if there...'.\n- It is in fact not true that without considering the error variances of (\\epsilon).\n- The statement is true if all error variances are the same, otherwise there is no guarantees that 'there is a path from J to K but the path coefficients cancel out so that the net effect of J on K is 0'.\n- In addition, the term 'bottleneck faithfulness' might better to be modified, because it is completely based on the graph, the original faithfulness assumption is based on the graph and its probability distribution.\n- Hence, the name 'bottleneck faithfulness' might lead to incorrect understanding of the concept of the bottleneck faithfulness.\n- line 179, it should be clarified that 'Let V_k \\to V denote the variables whose longest path to X has fewer than k nodes.'\n- For example, 1->2->3<-4.\n- Then, by the definition of V_k, we can see V_1 = {3}, V_2 = {2,3,4}, V_3 = {1,2,3,4}, while the longest path is 1->2->3.\n- Hence, it should be the variables whose paths to X has fewer than k nodes.\n- Figure 4, it is unclear that how Desc(X_2) = Desc(L_1) in all graphs.\n- For instance, in G_1, Desc(X_2) = (X_2, X_3) and L_1 does not exist.\n- line 285, it should be clarified that the expectation of the variable corresponding to a node is zero, somewhere in Section 2.\n- I agree that learning a SEM with latent variables is very difficult, and hence, it is worthy to investigate the necessary and sufficient condition for the identifiability.\n- In addition, it is possible that I do not understand some parts of the paper and I amy not be familiar with the line of works.\n- However, without the concrete defintion of the model and concepts, I am pretty sure that common readers cannot understand the part that I fail to understand.\n- Hence, it should clarify the model the paper focuses and it would be better to provide how to check the proposed conditions are satisfied from finite samples or prior information.\n- Minor:\n- line 29 not not\n- line 82 matrix \\mathcal{X}\n- line 173 equation (8) and does (8)\n- line 287 d-th domain might be t-th domain",
    "review_points_list": [
      "I enjoyed the idea and I think the main problem of learning latent causal graphical models is very important; however, this paper should clarify some necessary definitions, concepts and examples; otherwise I cannot properly evaluate its originality and contribution.",
      "line 41/43/84: It is unclear that '\\epsilon is a vector of independent noise variables', '\\epsilon_i are uncorrelated within each domain, ...', and '\\epsilon_i are not necessarily mutually independent...'",
      "In the linear structural equation models (SEM) settings, is independence of \\epilson_i required? Otherwise it may violate the markov condition and it seems to be a mixture of directed and undirected graphical model.",
      "(1) line 55: definition of the directed path says that (V_i) is a directed path from V_i to itself. Then, Pa(V_i) should include V_i.",
      "line 91, the conditions in Theorem 1 is not clear. It should clarify that 'Suppose we have observed X generated according to the mixing procedure (4) in a number of domains, t = 1, 2, T'",
      "If T =2, then is the considered model is X = Y M \\epsilon_1 + (1- Y) M \\epsilon_2 where Y is Bernoulli distribution with known/unknown probabilities?, X_j = \\beta X_{Pa(j)} + Y_{1j} \\epsilon_{j1} + (1 - Y_{1j}) \\epsilon_{j2} where (Y_{1j}) are independent Bernoulli distribution with known/unknown probabilities, or X = M (p \\epsilon_1 + (1- p) M \\epsilon_2)?",
      "In the finite sample setting, is it assumed to be known what distribution of error (\\epsilon_t) the sample follows?",
      "line 116, the definition of the bottleneck should be clarified when J and K are sets of nodes.",
      "We say that a set B is a bottleneck from J to K if every directed path from J to K includes some b \\in B.",
      "line 121 From the definition, for each Vi, Ch(Vi) is a bottleneck from Ch(Vi) to X.",
      "If J includes two nodes, saying J = {1, 2}, and K = {3}, the directed path from J to K is not defined.",
      "e.g., I at first conjecture that it means that the directed path from j to k, for all j \\in J and k \\in K.",
      "Then, all directed paths are (1,3), (2,3). Hence, {3} is only bottleneck.",
      "However, then, it is contradictory to line 121.",
      "line 160, it is also unclear that 'Rank(M_K^J) = 0 is a violation of classical faithfulness if there...'.",
      "It is in fact not true that without considering the error variances of (\\epsilon).",
      "The statement is true if all error variances are the same, otherwise there is no guarantees that 'there is a path from J to K but the path coefficients cancel out so that the net effect of J on K is 0'.",
      "In addition, the term 'bottleneck faithfulness' might better to be modified, because it is completely based on the graph, the original faithfulness assumption is based on the graph and its probability distribution.",
      "Hence, the name 'bottleneck faithfulness' might lead to incorrect understanding of the concept of the bottleneck faithfulness.",
      "line 179, it should be clarified that 'Let V_k \\to V denote the variables whose longest path to X has fewer than k nodes.'",
      "For example, 1->2->3<-4.",
      "Then, by the definition of V_k, we can see V_1 = {3}, V_2 = {2,3,4}, V_3 = {1,2,3,4}, while the longest path is 1->2->3.",
      "Hence, it should be the variables whose paths to X has fewer than k nodes.",
      "Figure 4, it is unclear that how Desc(X_2) = Desc(L_1) in all graphs.",
      "For instance, in G_1, Desc(X_2) = (X_2, X_3) and L_1 does not exist.",
      "line 285, it should be clarified that the expectation of the variable corresponding to a node is zero, somewhere in Section 2.",
      "I agree that learning a SEM with latent variables is very difficult, and hence, it is worthy to investigate the necessary and sufficient condition for the identifiability.",
      "In addition, it is possible that I do not understand some parts of the paper and I amy not be familiar with the line of works.",
      "However, without the concrete defintion of the model and concepts, I am pretty sure that common readers cannot understand the part that I fail to understand.",
      "Hence, it should clarify the model the paper focuses and it would be better to provide how to check the proposed conditions are satisfied from finite samples or prior information.",
      "Minor:",
      "line 29 not not",
      "line 82 matrix \\mathcal{X}",
      "line 173 equation (8) and does (8)",
      "line 287 d-th domain might be t-th domain"
    ]
  },
  {
    "paper_id": "2306.17464v1",
    "submission_id": "yCA2i3bGbfC",
    "submission_title": "Identification of Partially Observed Linear Causal Models: Graphical Conditions for the Non-Gaussian and Heterogeneous Cases",
    "review_id": "dEgKNnY19Ow",
    "input": {
      "title": "Identification of Partially Observed Linear Causal Models: Graphical Conditions for the Non-Gaussian and Heterogeneous Cases",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper tries to investigate the sufficient and necessary conditions for linear causal models with hidden variables, including linear causal models with hidden common causes and those with latent factors being causally related.\n- This general framework would be new because those models have been investigated separately.\n- The estimation method based on exhaustive search in Section 3 looks a na\u00efve method.\n- Another proposed estimation based on sparse regularization is proposed. The idea seems not so new.\n- I'm not sure if the assumption on the sparseness on lines 106-111 is reasonable or effective in which application domains.\n- I wonder if there is a reasonable scientific reason to think that the sparsest models are the truth.\n- Further, I'm interested in how the identifiability results change if the sparsest model assumption has been removed.\n- I thought previous works [17-22] do not make this assumption.\n- I would appreciate it if the authors make these points above clear.\n- The proposed estimation methods look not very fresh or very solid. One is a simple exhaustive search. It is not clear if the other regularization method is consistent or consistently selects the truth.\n- In fact, they say this regularization method did not work well (lines 317-324).\n- I was not sure if an underdetermined version of [16] has been already considered in the literature of independent component analysis or signal processing.\n- There are several unclear things.\n- Line 116: A set B. Is B a set of what?\n- Line 29: might not not -> might not.\n- Line 133: Bottleneck faithfulness. Bottleneck faithfulness has not been defined at this point.\n- Figure 2: \u201cis not a redundancy\u201d What would be the definition of this?\n- Figure 3: Co-parental non-redundancy, parental non-redundancy. I couldn\u2019t find their definitions in the paper. Ah, I see. I found them in the supplement.\n- Line 192: at least one? What is this ? here?\n- In the supplement, on page 11, what Times of Times (i) means?\n- In 6.1, were the artificial data generated under the assumption that the underlying model is the sparsest.\n- How is the number of hidden variables selected?\n- This work could contribute to a deeper theoretical understanding of causal discovery methods in the presence of hidden variables, including hidden common causes and latent factors, by considering a general framework includes both classes of linear causal models with hidden common causes and latent factors.\n- Relating to this, I have a question. Previous works [17-22] gave sufficient conditions. Did the authors of this submission find some other sufficient conditions for any of the models considered in [17-22]? If there are no other sufficient conditions, does this mean that the conditions given by [17-22] turned out to be also necessary?",
    "review_points_list": [
      "The paper tries to investigate the sufficient and necessary conditions for linear causal models with hidden variables, including linear causal models with hidden common causes and those with latent factors being causally related.",
      "This general framework would be new because those models have been investigated separately.",
      "The estimation method based on exhaustive search in Section 3 looks a na\u00efve method.",
      "Another proposed estimation based on sparse regularization is proposed. The idea seems not so new.",
      "I'm not sure if the assumption on the sparseness on lines 106-111 is reasonable or effective in which application domains.",
      "I wonder if there is a reasonable scientific reason to think that the sparsest models are the truth.",
      "Further, I'm interested in how the identifiability results change if the sparsest model assumption has been removed.",
      "I thought previous works [17-22] do not make this assumption.",
      "I would appreciate it if the authors make these points above clear.",
      "The proposed estimation methods look not very fresh or very solid. One is a simple exhaustive search. It is not clear if the other regularization method is consistent or consistently selects the truth.",
      "In fact, they say this regularization method did not work well (lines 317-324).",
      "I was not sure if an underdetermined version of [16] has been already considered in the literature of independent component analysis or signal processing.",
      "There are several unclear things.",
      "Line 116: A set B. Is B a set of what?",
      "Line 29: might not not -> might not.",
      "Line 133: Bottleneck faithfulness. Bottleneck faithfulness has not been defined at this point.",
      "Figure 2: \u201cis not a redundancy\u201d What would be the definition of this?",
      "Figure 3: Co-parental non-redundancy, parental non-redundancy. I couldn\u2019t find their definitions in the paper. Ah, I see. I found them in the supplement.",
      "Line 192: at least one? What is this ? here?",
      "In the supplement, on page 11, what Times of Times (i) means?",
      "In 6.1, were the artificial data generated under the assumption that the underlying model is the sparsest.",
      "How is the number of hidden variables selected?",
      "This work could contribute to a deeper theoretical understanding of causal discovery methods in the presence of hidden variables, including hidden common causes and latent factors, by considering a general framework includes both classes of linear causal models with hidden common causes and latent factors.",
      "Relating to this, I have a question. Previous works [17-22] gave sufficient conditions. Did the authors of this submission find some other sufficient conditions for any of the models considered in [17-22]? If there are no other sufficient conditions, does this mean that the conditions given by [17-22] turned out to be also necessary?"
    ]
  },
  {
    "paper_id": "2306.17464v1",
    "submission_id": "yCA2i3bGbfC",
    "submission_title": "Identification of Partially Observed Linear Causal Models: Graphical Conditions for the Non-Gaussian and Heterogeneous Cases",
    "review_id": "K8OPSUDxRI1",
    "input": {
      "title": "Identification of Partially Observed Linear Causal Models: Graphical Conditions for the Non-Gaussian and Heterogeneous Cases",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is original. The related work section is comprehensive enough to appreciate the original contributions of this paper.\n- Considering the readability, I was pleased to read the paper. Notations, texts, theorems, and explanations are all placed perfectly. Sections are organized coherently. Figures are simple yet informative. Technically, the authors made progress in identifiability via graphical and matrix-related understanding, connecting other existing conditions (as demonstrated in the related work section).\n- Is theorem 1 if and only if condition? It is currently written like sufficiency. Given that some of the space is left, it would be helpful if Section 4.2 contains figures that can explain the Lemmas in the section. Similarly, the section may have an algorithm (pseudocode?).\n- This paper provides necessity, sufficiency, and identification results (in addition to estimation). Since (theoretical) causality research focuses on the existence of clearly defined estimands, such conditions will be valuable resources to develop the causal theory further.\n- Although linearity is a strong assumption over the functions of causal models, since it allows us to study a class of causal models in depth, I would not consider the assumption restrictive. In the future, it would be desirable to provide some details about the estimation procedure for overcomplete ICA.",
    "review_points_list": [
      "The paper is original. The related work section is comprehensive enough to appreciate the original contributions of this paper.",
      "Considering the readability, I was pleased to read the paper. Notations, texts, theorems, and explanations are all placed perfectly. Sections are organized coherently. Figures are simple yet informative. Technically, the authors made progress in identifiability via graphical and matrix-related understanding, connecting other existing conditions (as demonstrated in the related work section).",
      "Is theorem 1 if and only if condition? It is currently written like sufficiency. Given that some of the space is left, it would be helpful if Section 4.2 contains figures that can explain the Lemmas in the section. Similarly, the section may have an algorithm (pseudocode?).",
      "This paper provides necessity, sufficiency, and identification results (in addition to estimation). Since (theoretical) causality research focuses on the existence of clearly defined estimands, such conditions will be valuable resources to develop the causal theory further.",
      "Although linearity is a strong assumption over the functions of causal models, since it allows us to study a class of causal models in depth, I would not consider the assumption restrictive. In the future, it would be desirable to provide some details about the estimation procedure for overcomplete ICA."
    ]
  },
  {
    "paper_id": "2306.17464v1",
    "submission_id": "yCA2i3bGbfC",
    "submission_title": "Identification of Partially Observed Linear Causal Models: Graphical Conditions for the Non-Gaussian and Heterogeneous Cases",
    "review_id": "duy4ia4JVkG",
    "input": {
      "title": "Identification of Partially Observed Linear Causal Models: Graphical Conditions for the Non-Gaussian and Heterogeneous Cases",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Challenging and relevant problem that has been studied in many versions before.\n- The main contribution of this paper is that it provides some generic graphical criteria that determine whether or not this identification problem is uniquely solvable, thereby bringing together several other approaches.\n- Drawback is that it is hard to assess to what extent the accompanying assumptions apply in practice or whether they are very restrictive or not.\n- Naturally \u2018linear\u2019 is often assumed but not always valid.\n- Also the need to know the number of latents beforehand makes it harder to apply in real-world scenarios.\n- Often the goal is to infer what latent variables / constructs can be recognised/identified from the observed distribution.\n- Similarly, on applying the reconstruction estimation described in section 6, it is not easy to verify from the output obtained whether the assumptions actually did hold or not.\n- And actually determining the full model F itself may involve an exhaustive search over graphs, or hope that a penalised log-likelihood approach will converge to the true optimum quickly \u2026 which is by no means guaranteed either.\n- Perhaps the \u2018full identifiability\u2019 is more than what is actually needed.\n- For example, a model with subpath Li -> Lj -> Xk would not satisfy the conditions, but the marginal over Li -> Xk would, and still be equally informative or useful to have.\n- And for the reconstruction problem based on available X that would be perfectly fine.\n- Technical quality is good, with attention to detail and good efforts to interpret the sometimes quite abstract theoretical results.\n- Clarity can be improved at some points where concepts are used before they are actually defined, but overall very readable for a challenging subject like this.\n- Experimental evaluation could be a bit more extensive but is ok to illustrate some of the remaining challenges.\n- Originality: well-known problem, but interesting and original approach.\n- Quality: high quality.\n- Clarity: ok with minor suggestions for improvement below.\n- Significance: not directly applicable as an off-the-shelf algorithm, but certainly a meaningful theoretical contribution that provides new insights.\n- Minor comment: p3.82: typo \u2018the the\u2019.\n- p3.93: \u2018uncorrelated in each domain\u2019 => does this mean they all *have* to change between domains? if so, then that is a rather strong and unrealistic setting, as in most cases only a subset of noise terms is likely to differ between domains / over time\n- p3.116: can the nodes in J and K themselves be part of the bottleneck from J to K? (ok later becomes clear)\n- p4,123-8: These two assumptions are at first sight quite artificial and hard to parse in terms of what graphs are excluded and what not.\n- In other words, it is not easy to see how restrictive / realistic these assumptions are in practice.\n- It would be helpful to give some hints/pointers to see what types of graphs generally satisfy these conditions. For example if the variables can be separated so that there are no directed paths from X to L, does the causal structure between the X influence the \u2018unique minimal bottleneck condition\u2019?\n- p4.133: explain/define \u2018bottleneck faithful\u2019 \u2026 (ok later found at p5.156, just refer here)\n- p6.192: weird character \u2018one?\u2019 in the pdf (or perhaps just my reader)\n- p6.213: \u2018only recover limited information about the causal structure\u2019 => true, but it would be interesting to see if starting from these to reduce the full search space to \u2018local latent structure discovery\u2019 would make the assumptions provided here much less restrictive in practice \u2026 and with it greatly enhance the applicability\n- p9.321-324: doesn\u2019t L1 typically induce sparsity by driving certain small coefficients to zero?",
    "review_points_list": [
      "Challenging and relevant problem that has been studied in many versions before.",
      "The main contribution of this paper is that it provides some generic graphical criteria that determine whether or not this identification problem is uniquely solvable, thereby bringing together several other approaches.",
      "Drawback is that it is hard to assess to what extent the accompanying assumptions apply in practice or whether they are very restrictive or not.",
      "Naturally \u2018linear\u2019 is often assumed but not always valid.",
      "Also the need to know the number of latents beforehand makes it harder to apply in real-world scenarios.",
      "Often the goal is to infer what latent variables / constructs can be recognised/identified from the observed distribution.",
      "Similarly, on applying the reconstruction estimation described in section 6, it is not easy to verify from the output obtained whether the assumptions actually did hold or not.",
      "And actually determining the full model F itself may involve an exhaustive search over graphs, or hope that a penalised log-likelihood approach will converge to the true optimum quickly \u2026 which is by no means guaranteed either.",
      "Perhaps the \u2018full identifiability\u2019 is more than what is actually needed.",
      "For example, a model with subpath Li -> Lj -> Xk would not satisfy the conditions, but the marginal over Li -> Xk would, and still be equally informative or useful to have.",
      "And for the reconstruction problem based on available X that would be perfectly fine.",
      "Technical quality is good, with attention to detail and good efforts to interpret the sometimes quite abstract theoretical results.",
      "Clarity can be improved at some points where concepts are used before they are actually defined, but overall very readable for a challenging subject like this.",
      "Experimental evaluation could be a bit more extensive but is ok to illustrate some of the remaining challenges.",
      "Originality: well-known problem, but interesting and original approach.",
      "Quality: high quality.",
      "Clarity: ok with minor suggestions for improvement below.",
      "Significance: not directly applicable as an off-the-shelf algorithm, but certainly a meaningful theoretical contribution that provides new insights.",
      "Minor comment: p3.82: typo \u2018the the\u2019.",
      "p3.93: \u2018uncorrelated in each domain\u2019 => does this mean they all *have* to change between domains? if so, then that is a rather strong and unrealistic setting, as in most cases only a subset of noise terms is likely to differ between domains / over time",
      "p3.116: can the nodes in J and K themselves be part of the bottleneck from J to K? (ok later becomes clear)",
      "p4,123-8: These two assumptions are at first sight quite artificial and hard to parse in terms of what graphs are excluded and what not.",
      "In other words, it is not easy to see how restrictive / realistic these assumptions are in practice.",
      "It would be helpful to give some hints/pointers to see what types of graphs generally satisfy these conditions. For example if the variables can be separated so that there are no directed paths from X to L, does the causal structure between the X influence the \u2018unique minimal bottleneck condition\u2019?",
      "p4.133: explain/define \u2018bottleneck faithful\u2019 \u2026 (ok later found at p5.156, just refer here)",
      "p6.192: weird character \u2018one?\u2019 in the pdf (or perhaps just my reader)",
      "p6.213: \u2018only recover limited information about the causal structure\u2019 => true, but it would be interesting to see if starting from these to reduce the full search space to \u2018local latent structure discovery\u2019 would make the assumptions provided here much less restrictive in practice \u2026 and with it greatly enhance the applicability",
      "p9.321-324: doesn\u2019t L1 typically induce sparsity by driving certain small coefficients to zero?"
    ]
  },
  {
    "paper_id": "2102.13088v2",
    "submission_id": "yTJtgA1Gh2",
    "submission_title": "Even your Teacher Needs Guidance: Ground-Truth Targets Dampen Regularization Imposed by Self-Distillation",
    "review_id": "MDkas_8BcYG",
    "input": {
      "title": "Even your Teacher Needs Guidance: Ground-Truth Targets Dampen Regularization Imposed by Self-Distillation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper provides closed-form solutions of self-distillation in the kernel ridge regression setting.\n- Overall, the entire paper is mostly well-written and easy to follow.\n- It is a natural extension of the theoretical results in Mobahi et al. (2020), though the theoretical novelty is limited given the prior works.\n- After reading the paper, I am not convinced that incorporating the ground-truth label is essential during the self-distillation step to overcome underfitting.\n- As you show in Theorem 4.5, the weighting parameter \u03b1 turns out to amplify the regularization parameter \u03bb.\n- We can also smartly tune \u03bb on the validation set to achieve the same effect as tuning \u03b1.\n- Therefore, I don't think that incorporating the ground-truth labels of training data are necessary.\n- The way to estimate the value of \u03b1 in section 4.3 is not globally optimal, as it does not account for the future steps of self-distillation.\n- I would instead call it a greedy estimation of \u03b1.\n- For ResNet-50 on CIFAR-10, why are the best training accuracy only 88% and the best test accuracy only 94%?\n- In my experience, the training accuracy can always reach very close to 100%, and the test accuracy is around ~94%.\n- Please check out this GitHub: https://github.com/kuangliu/pytorch-cifar.\n- For Line 239-240, you mentioned that 'As illustrated in Figure 2a for case (a), the regularization imposed by self-distillation initially improves the quality of the solution'.\n- To me, I don't see such a trend in Figure 2(a).\n- The curves corresponding to f1, ..., f\u221e become more underfitting as the index value increases.\n- To better illustrate your argument, I would suggest the authors provide a figure of '\u03c4 vs. training loss' (similar to Figure 5).\n- It would be better to state the contribution in the introduction rather than in related works (Line 84-93).\n- Also, the introductions to the notation (Line 96-101) are well-suited to be at the beginning of Section 3 Problem Setup.\n- One minor correction to footnote 4, for some cases (e.g., using Adam optimizer), the equivalence between L2 regularization and weight decay does not hold.\n- See Loshchilov et al. (2017) and Zhang et al. (2018).\n- Overall, I think this paper is well-written and studies a critical problem in machine learning, considering that there are still relatively few works exploring the theories of knowledge distillation.\n- However, the theoretical novelty is very limited as most of the theorems are very natural extensions from the results in Mobahi et al. (2020).\n- Also, I am not very convinced that incorporating the ground-truth label is necessary for self-distillation.\n- Therefore, I vote for a weak rejection at the current stage.\n- I am happy to increase my ratings if the authors can address my concerns properly.\n- The authors' response resolved my concern. I will increase my score from 5 to 6.",
    "review_points_list": [
      "This paper provides closed-form solutions of self-distillation in the kernel ridge regression setting.",
      "Overall, the entire paper is mostly well-written and easy to follow.",
      "It is a natural extension of the theoretical results in Mobahi et al. (2020), though the theoretical novelty is limited given the prior works.",
      "After reading the paper, I am not convinced that incorporating the ground-truth label is essential during the self-distillation step to overcome underfitting.",
      "As you show in Theorem 4.5, the weighting parameter \u03b1 turns out to amplify the regularization parameter \u03bb.",
      "We can also smartly tune \u03bb on the validation set to achieve the same effect as tuning \u03b1.",
      "Therefore, I don't think that incorporating the ground-truth labels of training data are necessary.",
      "The way to estimate the value of \u03b1 in section 4.3 is not globally optimal, as it does not account for the future steps of self-distillation.",
      "I would instead call it a greedy estimation of \u03b1.",
      "For ResNet-50 on CIFAR-10, why are the best training accuracy only 88% and the best test accuracy only 94%?",
      "In my experience, the training accuracy can always reach very close to 100%, and the test accuracy is around ~94%.",
      "Please check out this GitHub: https://github.com/kuangliu/pytorch-cifar.",
      "For Line 239-240, you mentioned that 'As illustrated in Figure 2a for case (a), the regularization imposed by self-distillation initially improves the quality of the solution'.",
      "To me, I don't see such a trend in Figure 2(a).",
      "The curves corresponding to f1, ..., f\u221e become more underfitting as the index value increases.",
      "To better illustrate your argument, I would suggest the authors provide a figure of '\u03c4 vs. training loss' (similar to Figure 5).",
      "It would be better to state the contribution in the introduction rather than in related works (Line 84-93).",
      "Also, the introductions to the notation (Line 96-101) are well-suited to be at the beginning of Section 3 Problem Setup.",
      "One minor correction to footnote 4, for some cases (e.g., using Adam optimizer), the equivalence between L2 regularization and weight decay does not hold.",
      "See Loshchilov et al. (2017) and Zhang et al. (2018).",
      "Overall, I think this paper is well-written and studies a critical problem in machine learning, considering that there are still relatively few works exploring the theories of knowledge distillation.",
      "However, the theoretical novelty is very limited as most of the theorems are very natural extensions from the results in Mobahi et al. (2020).",
      "Also, I am not very convinced that incorporating the ground-truth label is necessary for self-distillation.",
      "Therefore, I vote for a weak rejection at the current stage.",
      "I am happy to increase my ratings if the authors can address my concerns properly.",
      "The authors' response resolved my concern. I will increase my score from 5 to 6."
    ]
  },
  {
    "paper_id": "2102.13088v2",
    "submission_id": "yTJtgA1Gh2",
    "submission_title": "Even your Teacher Needs Guidance: Ground-Truth Targets Dampen Regularization Imposed by Self-Distillation",
    "review_id": "B11UN3Zn57Q",
    "input": {
      "title": "Even your Teacher Needs Guidance: Ground-Truth Targets Dampen Regularization Imposed by Self-Distillation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The existing theory behind distillation is thin, and this paper makes a step toward a better grasp of it.\n- The claims are well supported by experiments and well explained in the text.\n- I have not thoroughly checked the proofs in the supplementary material.\n- I found the writing quality high and the exposition clear.\n- The findings and theory presented is likely significant in the community's effort to deepen our understanding of distillation.",
    "review_points_list": [
      "The existing theory behind distillation is thin, and this paper makes a step toward a better grasp of it.",
      "The claims are well supported by experiments and well explained in the text.",
      "I have not thoroughly checked the proofs in the supplementary material.",
      "I found the writing quality high and the exposition clear.",
      "The findings and theory presented is likely significant in the community's effort to deepen our understanding of distillation."
    ]
  },
  {
    "paper_id": "2102.13088v2",
    "submission_id": "yTJtgA1Gh2",
    "submission_title": "Even your Teacher Needs Guidance: Ground-Truth Targets Dampen Regularization Imposed by Self-Distillation",
    "review_id": "oK_cTA5MmSs",
    "input": {
      "title": "Even your Teacher Needs Guidance: Ground-Truth Targets Dampen Regularization Imposed by Self-Distillation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper clearly stated the motivation of introducing a weighted ground truth target while self distillation.\n- Theoretical results (Theorem 4.3, 4.5) supported the argument.\n- The author also provided a close form solution for setting the step wise weight other than a fixed weight for all steps.\n- The estimation of the optimal weight provided practical usefulness for this method and guidance on how to adjust this hyperparameter efficiently other than grid search.\n- However, my minor concern about this work are:\n- The main theoretical results are all derived under the setting of fixed weight for all distillation steps. While in practice the optimal weights are calculated at each step.\n- In section 4.2, the author argued by introducing the weight parameter, the self distillation process can potentially do not sparsify the basis. According to theorem 4.3, this potential heavily depends on the value of the weights and the weights are derived in a closed form manner at each step.\n- It would be more rigorous if the author could provide some guarantees with probability of theorem 4.3 to show how likely the basis will not sparsify.\n- Overall, I think this work proposed an inspiring potential method on addressing the evolution of basis problem carried out by Mobahi et al.(2020), along with some practical usage.",
    "review_points_list": [
      "The paper clearly stated the motivation of introducing a weighted ground truth target while self distillation.",
      "Theoretical results (Theorem 4.3, 4.5) supported the argument.",
      "The author also provided a close form solution for setting the step wise weight other than a fixed weight for all steps.",
      "The estimation of the optimal weight provided practical usefulness for this method and guidance on how to adjust this hyperparameter efficiently other than grid search.",
      "However, my minor concern about this work are:",
      "The main theoretical results are all derived under the setting of fixed weight for all distillation steps. While in practice the optimal weights are calculated at each step.",
      "In section 4.2, the author argued by introducing the weight parameter, the self distillation process can potentially do not sparsify the basis. According to theorem 4.3, this potential heavily depends on the value of the weights and the weights are derived in a closed form manner at each step.",
      "It would be more rigorous if the author could provide some guarantees with probability of theorem 4.3 to show how likely the basis will not sparsify.",
      "Overall, I think this work proposed an inspiring potential method on addressing the evolution of basis problem carried out by Mobahi et al.(2020), along with some practical usage."
    ]
  },
  {
    "paper_id": "2110.13986v1",
    "submission_id": "w-EabDtADg",
    "submission_title": "Fair Sequential Selection Using Supervised Learning Models",
    "review_id": "IQWlEUrfFW1",
    "input": {
      "title": "Fair Sequential Selection Using Supervised Learning Models",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper studies a novel setting in fair machine learning.\n- I can see that there are a lot of theoretical works done by this paper.\n- However, I feel that this paper is not quite well-written as some key points are not explained or missing.\n- In addition, how each section in the appendix is responding to each part in the main paper is not explicit (the authors should refer to the appendix sections in the main paper).\n- These factors lower my score.\n- Theorem 1 and A.1 need more explanations in the paper.\n- The derivation of the first equation to Theorem 1 and the equation between Eq. (18) and (19) could show the key difference between the sequential selection setting and traditional supervised learning setting.\n- In the proof to Theorem 2, how the second constraint in Eq. (5) is used?\n- I believe that it is hidden somewhere in the proof but the authors should explicitly show that.\n- The paper defines accuracy as Pr{Y=1}.\n- But to me this is just the true positive rate, not the accuracy, since it only considers the case where the individual is predicted positive.\n- Could the authors clarify this?\n- The logic of Sections 4.1 and 3.1 are not consistent.\n- In Section 3.1, the paper defines a probability to flit the decision of the pre-trained model.\n- But in Section 4.1, the paper \u201ctrust\u201d the score made by the pre-trained model and only aims to learn a threshold for making decisions.\n- I don\u2019t have the expertise to check the differential privacy part of this paper.",
    "review_points_list": [
      "The paper studies a novel setting in fair machine learning.",
      "I can see that there are a lot of theoretical works done by this paper.",
      "However, I feel that this paper is not quite well-written as some key points are not explained or missing.",
      "In addition, how each section in the appendix is responding to each part in the main paper is not explicit (the authors should refer to the appendix sections in the main paper).",
      "These factors lower my score.",
      "Theorem 1 and A.1 need more explanations in the paper.",
      "The derivation of the first equation to Theorem 1 and the equation between Eq. (18) and (19) could show the key difference between the sequential selection setting and traditional supervised learning setting.",
      "In the proof to Theorem 2, how the second constraint in Eq. (5) is used?",
      "I believe that it is hidden somewhere in the proof but the authors should explicitly show that.",
      "The paper defines accuracy as Pr{Y=1}.",
      "But to me this is just the true positive rate, not the accuracy, since it only considers the case where the individual is predicted positive.",
      "Could the authors clarify this?",
      "The logic of Sections 4.1 and 3.1 are not consistent.",
      "In Section 3.1, the paper defines a probability to flit the decision of the pre-trained model.",
      "But in Section 4.1, the paper \u201ctrust\u201d the score made by the pre-trained model and only aims to learn a threshold for making decisions.",
      "I don\u2019t have the expertise to check the differential privacy part of this paper."
    ]
  },
  {
    "paper_id": "2110.13986v1",
    "submission_id": "w-EabDtADg",
    "submission_title": "Fair Sequential Selection Using Supervised Learning Models",
    "review_id": "-iSOW-7FohG",
    "input": {
      "title": "Fair Sequential Selection Using Supervised Learning Models",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper considers a new fairness criterion for selection problems of finite resources.\n- The fairness notion is similar to existing notions and has the same form of equality of group wise probabilities.\n- Fairness in selection problems has previously been studied.\n- Guaranteeing fairness when only privatized attributes are available has been studied in classification.\n- The novelty in this paper is studying this new fairness notion in the selection setting (repeated i.i.d. classification) with private attributes (only at test time).\n- The postprocessing approach is a very interesting technical result and approach, and not obvious.\n- However, the selection setting considered is only studied for a single selection, does not study dynamics of selections on each other (because it studies single selections) and only studies the setting for binary sensitive attributes (but I understand this may only complicate theory but not the approach).\n- The theorems and technical details are sound and complete.\n- Some crucial experimental details are missing especially how 1) they simulated selection problems from the static datasets and 2) how the optimization was performed and thresholds chosen for EO and the baselines and 3) how exactly they computed the statistics.\n- Furthermore, I am unsure about one of the results in table 1.\n- The paper is clearly written and easy to follow.\n- The basis of the paper is the following sentence  \u201cdecisions are fair if the (qualified) applicants from different groups are  selected at the same rate.\u201d,  this implies in classification that P(R=1|Y=1,A=0)=P(R=1|Y=1,A=1) (EO) but Theorem 1 says otherwise, what the authors actually mean is that decisions are fair if we select the same number of qualified individuals from different groups and not \u201crates\u201d.\n- I think the proposed notion (ESR) is fundamentally very very different from EO as it is not a conditional statement .\n- I think this paper misses out an incredible opportunity to study selection problems by only focusing on the m=1 case and assumes i.i.d. selections and no impact of previous selections on the following ones.\n- Due to this, I feel the selection aspect of the paper is not that novel and so it goes back to studying the ESR notion in classification problems and trying to argue for it (from theorem 1).\n- However, the paper does not attempt to justify ESR in the classification  from an ethical perspective or long term perspective but only cites the EEOC.\n- 1) studying binary attributes,\n- 2) m=1 setting 'single selection',\n- 3) i.i.d. between selections which is not a reasonable assumption in reality",
    "review_points_list": [
      "The paper considers a new fairness criterion for selection problems of finite resources.",
      "The fairness notion is similar to existing notions and has the same form of equality of group wise probabilities.",
      "Fairness in selection problems has previously been studied.",
      "Guaranteeing fairness when only privatized attributes are available has been studied in classification.",
      "The novelty in this paper is studying this new fairness notion in the selection setting (repeated i.i.d. classification) with private attributes (only at test time).",
      "The postprocessing approach is a very interesting technical result and approach, and not obvious.",
      "However, the selection setting considered is only studied for a single selection, does not study dynamics of selections on each other (because it studies single selections) and only studies the setting for binary sensitive attributes (but I understand this may only complicate theory but not the approach).",
      "The theorems and technical details are sound and complete.",
      "Some crucial experimental details are missing especially how 1) they simulated selection problems from the static datasets and 2) how the optimization was performed and thresholds chosen for EO and the baselines and 3) how exactly they computed the statistics.",
      "Furthermore, I am unsure about one of the results in table 1.",
      "The paper is clearly written and easy to follow.",
      "The basis of the paper is the following sentence  \u201cdecisions are fair if the (qualified) applicants from different groups are  selected at the same rate.\u201d,  this implies in classification that P(R=1|Y=1,A=0)=P(R=1|Y=1,A=1) (EO) but Theorem 1 says otherwise, what the authors actually mean is that decisions are fair if we select the same number of qualified individuals from different groups and not \u201crates\u201d.",
      "I think the proposed notion (ESR) is fundamentally very very different from EO as it is not a conditional statement .",
      "I think this paper misses out an incredible opportunity to study selection problems by only focusing on the m=1 case and assumes i.i.d. selections and no impact of previous selections on the following ones.",
      "Due to this, I feel the selection aspect of the paper is not that novel and so it goes back to studying the ESR notion in classification problems and trying to argue for it (from theorem 1).",
      "However, the paper does not attempt to justify ESR in the classification  from an ethical perspective or long term perspective but only cites the EEOC.",
      "1) studying binary attributes,",
      "2) m=1 setting 'single selection',",
      "3) i.i.d. between selections which is not a reasonable assumption in reality"
    ]
  },
  {
    "paper_id": "2110.13986v1",
    "submission_id": "w-EabDtADg",
    "submission_title": "Fair Sequential Selection Using Supervised Learning Models",
    "review_id": "5RFQX7ebn_u",
    "input": {
      "title": "Fair Sequential Selection Using Supervised Learning Models",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I thank the authors for the extensive related work section---related work in classification fairness, selection, and differential privacy is discussed.\n- Work related to sequential decision making is briefly mentioned (a single RL algorithm).\n- To add, the bandit literature is another large area in sequential decision making with numerous works in fairness, e.g., Joseph et al. Fairness in Learning: Classic and Contextual Bandits, which focuses on individual fairness.\n- More closely related to the classification setting (does not deal w/ exploration problem) might be batch bandit/RL algorithms that enforce fairness, e.g., Metevier et al. Bandits with High Prob. Guarantees.\n- ESR is a fairness notion based on predicted outcome and not actual outcome (the selection made and not the 'selection that should have been made'), and can be thought of as the action taken by the bandit.\n- To summarize, along with reinforcement learning, I suggest mentioning bandit literature in the related work, as it is another important area in sequential decision making.\n- Discussing the differences in the RL/bandit settings and the one being considered in this work can also strengthen the related work section.\n- The paper is readable, but there is some room for improvement.\n- In line 183 'It shows that even with the seemingly fair...' this requires more explanation, e.g., an example or intuition.\n- Line 147 offers good motivation for the need of a fairness definition for the sequential setting.\n- Also, notation for probabilities seem to change in Theorem 2 (from brackets to parentheses).\n- I did not view the supplementary material but looked at the work in the main text.\n- Is there a reason the authors switch between parens and bracket notation for probability?\n- The authors assert in the introduction that they show that models enforcing statistical parity / equal opportunity may still be fair in the sequential setting they consider.\n- I only see this in (1) after Corollary 1, line 183, 'Note that he condition in Corollary 1 generally does not hold. It shows that...we may still be discriminatory,' and (2) the comparison to equal opportunity in the experimental section.\n- A comparison to statistical parity seems to be missing entirely in the empirical section of the main text, although it is listed as a contribution.\n- Otherwise, the empirical analysis seems to support the claims made by the paper.",
    "review_points_list": [
      "I thank the authors for the extensive related work section---related work in classification fairness, selection, and differential privacy is discussed.",
      "Work related to sequential decision making is briefly mentioned (a single RL algorithm).",
      "To add, the bandit literature is another large area in sequential decision making with numerous works in fairness, e.g., Joseph et al. Fairness in Learning: Classic and Contextual Bandits, which focuses on individual fairness.",
      "More closely related to the classification setting (does not deal w/ exploration problem) might be batch bandit/RL algorithms that enforce fairness, e.g., Metevier et al. Bandits with High Prob. Guarantees.",
      "ESR is a fairness notion based on predicted outcome and not actual outcome (the selection made and not the 'selection that should have been made'), and can be thought of as the action taken by the bandit.",
      "To summarize, along with reinforcement learning, I suggest mentioning bandit literature in the related work, as it is another important area in sequential decision making.",
      "Discussing the differences in the RL/bandit settings and the one being considered in this work can also strengthen the related work section.",
      "The paper is readable, but there is some room for improvement.",
      "In line 183 'It shows that even with the seemingly fair...' this requires more explanation, e.g., an example or intuition.",
      "Line 147 offers good motivation for the need of a fairness definition for the sequential setting.",
      "Also, notation for probabilities seem to change in Theorem 2 (from brackets to parentheses).",
      "I did not view the supplementary material but looked at the work in the main text.",
      "Is there a reason the authors switch between parens and bracket notation for probability?",
      "The authors assert in the introduction that they show that models enforcing statistical parity / equal opportunity may still be fair in the sequential setting they consider.",
      "I only see this in (1) after Corollary 1, line 183, 'Note that he condition in Corollary 1 generally does not hold. It shows that...we may still be discriminatory,' and (2) the comparison to equal opportunity in the experimental section.",
      "A comparison to statistical parity seems to be missing entirely in the empirical section of the main text, although it is listed as a contribution.",
      "Otherwise, the empirical analysis seems to support the claims made by the paper."
    ]
  },
  {
    "paper_id": "2107.07994v3",
    "submission_id": "vGjTOxss-Dl",
    "submission_title": "Property-Aware Relation Networks for Few-Shot Molecular Property Prediction",
    "review_id": "KqyWGmPs9wb",
    "input": {
      "title": "Property-Aware Relation Networks for Few-Shot Molecular Property Prediction",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The Major strengths: Strong motivation for property-specific adaptation + adaptive relation graph learning is presented.\n- This is done via examples (Fig1), comparisons to works without property-specific adaptation, and examples of how learned relation graphs differ greatly across tasks.\n- The proposed model (PAR), though complex, seems to appropriately address the problem setup.\n- Strong results (only on 1-shot and 10-shot classification) + comparison to multiple baselines, for each of PAR's major dimensions.\n- Comprehensive ablations of contributions and analysis of their effects.\n- Somewhat unclear writing.\n- High overall complexity of the approach, adding elements to already-complex IterRefLSTM and Meta-MGNN.\n- Results only on artificial few-shot settings.\n- Can the adjacency matrix be estimated directly from cosine similarity of embeddings, rather than doing the iterative estimation?\n- Appendix Figure 8 row order doesn\u2019t seem to match caption?\n- Figure 4 - these adjacency matrices are the same but according to Fig9 and caption they should be different.\n- Figure 3 - please label the variants with a short summary to avoid having to cross-reference the text.\n- The ablations are strong.\n- The three main contributions (beyond results) are ablated, and show large degradations when removed:\n- Property-aware embedding\n- Fine-tuning of all parameters degrades wrt only final layers.\n- Comparison to existing work is thorough.\n- 10 seeds for confidence intervals.\n- Proper comparison to several lines of work which were the basis for PAR.\n- Overall this paper addresses a difficult task in a better way, with strong motivation and appropriate novel methods.\n- It would be helpful to see a section on limitations.\n- It would be interesting to see results on full tox21 / other moleculenet datasets, without artificially constraining to 1 or 10-shot classification.\n- See suggested ablation above: \u201cCan the adjacency matrix be estimated directly from cosine similarity of embeddings, rather than doing the iterative estimation?\u201d\n- Overall the paper is thorough, well-motivated and contains necessary detail.\n- The **clarity of the paper could be improved**:\n- Some concepts should be high-level described (relation graph / property-aware embedding) when the terms are introduced.\n- Some heavy notation can be reduced and gets in the way of understanding.\n- It would be helpful to be more explicit where the aggregation (GNN node embeddings -> single vector) happens, versus where is task-specific adaptation.\n- Please move description of g, p, r, c superscripts to the front of [Section 3 - Proposed Method].\n- What is the $e^p_{x_{Tj}}$ initialization value for equation (2)?\n- Several grammatical errors (eg: \u201cwhile fine-tune theta\u201d, \u201ctaking a few gradient descents\u201d)\n- Figure 4: (d) 12th task instead of 11th task?\n- Parameterize MLP in eq (3) by $\theta^r$ ?\n- Also see comments about figures above",
    "review_points_list": [
      "The Major strengths: Strong motivation for property-specific adaptation + adaptive relation graph learning is presented.",
      "This is done via examples (Fig1), comparisons to works without property-specific adaptation, and examples of how learned relation graphs differ greatly across tasks.",
      "The proposed model (PAR), though complex, seems to appropriately address the problem setup.",
      "Strong results (only on 1-shot and 10-shot classification) + comparison to multiple baselines, for each of PAR's major dimensions.",
      "Comprehensive ablations of contributions and analysis of their effects.",
      "Somewhat unclear writing.",
      "High overall complexity of the approach, adding elements to already-complex IterRefLSTM and Meta-MGNN.",
      "Results only on artificial few-shot settings.",
      "Can the adjacency matrix be estimated directly from cosine similarity of embeddings, rather than doing the iterative estimation?",
      "Appendix Figure 8 row order doesn\u2019t seem to match caption?",
      "Figure 4 - these adjacency matrices are the same but according to Fig9 and caption they should be different.",
      "Figure 3 - please label the variants with a short summary to avoid having to cross-reference the text.",
      "The ablations are strong.",
      "The three main contributions (beyond results) are ablated, and show large degradations when removed:",
      "Property-aware embedding",
      "Fine-tuning of all parameters degrades wrt only final layers.",
      "Comparison to existing work is thorough.",
      "10 seeds for confidence intervals.",
      "Proper comparison to several lines of work which were the basis for PAR.",
      "Overall this paper addresses a difficult task in a better way, with strong motivation and appropriate novel methods.",
      "It would be helpful to see a section on limitations.",
      "It would be interesting to see results on full tox21 / other moleculenet datasets, without artificially constraining to 1 or 10-shot classification.",
      "See suggested ablation above: \u201cCan the adjacency matrix be estimated directly from cosine similarity of embeddings, rather than doing the iterative estimation?\u201d",
      "Overall the paper is thorough, well-motivated and contains necessary detail.",
      "The **clarity of the paper could be improved**:",
      "Some concepts should be high-level described (relation graph / property-aware embedding) when the terms are introduced.",
      "Some heavy notation can be reduced and gets in the way of understanding.",
      "It would be helpful to be more explicit where the aggregation (GNN node embeddings -> single vector) happens, versus where is task-specific adaptation.",
      "Please move description of g, p, r, c superscripts to the front of [Section 3 - Proposed Method].",
      "What is the $e^p_{x_{Tj}}$ initialization value for equation (2)?",
      "Several grammatical errors (eg: \u201cwhile fine-tune theta\u201d, \u201ctaking a few gradient descents\u201d)",
      "Figure 4: (d) 12th task instead of 11th task?",
      "Parameterize MLP in eq (3) by $\theta^r$ ?",
      "Also see comments about figures above"
    ]
  },
  {
    "paper_id": "2107.00644v2",
    "submission_id": "zQvxc8ul2rR",
    "submission_title": "Stabilizing Deep Q-Learning with ConvNets and Vision Transformers under Data Augmentation",
    "review_id": "kH_8QIb005l",
    "input": {
      "title": "Stabilizing Deep Q-Learning with ConvNets and Vision Transformers under Data Augmentation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper identifies an issue with the increased variance of the target estimation in DrQ (image-based RL with data augmentation).\n- The authors conjecture two root causes for the increased variance: non-deterministic Q-targets and over-regularization.\n- To remedy these issues they propose to apply data augmentation more carefully.\n- Specifically, the authors suggest to mix augmented and un-augmented inputs to the critic and stop augmenting of the actor's inputs.\n- This method is then empirically justified in a series of experiment on tasks from the DeepMind Control Suite.\n- The author investigate an interesting question of an effect of data augmentation on generalization in image-based RL.\n- The method is thoroughly verified in different settings.\n- The paper is clearly written and easy to follow.\n- The exploration of alternative architecture, such as ViT.\n- The paper proposes a small trick that lacks in novelty.\n- The impact of data-augmentation on the estimation variance was also studied in the original DrQ paper (Kostrikov et. al), where a very similar technique was proposed -- the target estimation was done over 2 different augmentations.\n- This work introduces a tiny modification of the DrQ's variance reduction approach, that just combines one augmented and one un-augmented observation instead of combining two augmented observations.\n- Furthermore, the authors fail to mention this prior result in their paper and compare to it.\n- From the paper it is not clear what hyper-parameters are used for the baselines, specifically for DrQ.\n- If the authors use the original DrQ's parameters, then I see several major issues with the empirical results:\n- 1) SVEA uses encoder arch that consists of 11 conv layers, while DrQ only uses 4.\n- 2) The size of replay buffer of SVEA is 500K, while DrQ's 100K.\n- 3) SVEA virtually increases the batch size by factor of 2, which usually leads to better performance on the DeepMind Control Suite tasks, it is not clear if the authors increase batch size for DrQ or not.\n- These discrepancies alone could result in a drastic difference in performance and can render the empirical study to be invalid.\n- There is no experiments that compare individual components of SVEA to verify is that the improved performance comes from the proposed method or better/different hyper-parameters.\n- The authors claim in line 30 that they 'theoretically ground' their findings, but this is not the case as there is no theoretical results presented.\n- In general, the authors don't do a good job justifying that the two pitfalls are real.\n- Their argument is hand-wavy and is based on a series of indirect comparisons to the baseline (DrQ).\n- Unfortunately, there are too many moving parts in those comparisons that make it virtually impossible to validate the claim (see also the point above about the hyper-parameter discrepancies).\n- Given the very limited scope of novelty and technical contribution, the failure to mention the prior work that is almost identical, and the inconclusive empirical study I recommend to reject this paper from a high-profile venue of NeurIPS.",
    "review_points_list": [
      "The paper identifies an issue with the increased variance of the target estimation in DrQ (image-based RL with data augmentation).",
      "The authors conjecture two root causes for the increased variance: non-deterministic Q-targets and over-regularization.",
      "To remedy these issues they propose to apply data augmentation more carefully.",
      "Specifically, the authors suggest to mix augmented and un-augmented inputs to the critic and stop augmenting of the actor's inputs.",
      "This method is then empirically justified in a series of experiment on tasks from the DeepMind Control Suite.",
      "The author investigate an interesting question of an effect of data augmentation on generalization in image-based RL.",
      "The method is thoroughly verified in different settings.",
      "The paper is clearly written and easy to follow.",
      "The exploration of alternative architecture, such as ViT.",
      "The paper proposes a small trick that lacks in novelty.",
      "The impact of data-augmentation on the estimation variance was also studied in the original DrQ paper (Kostrikov et. al), where a very similar technique was proposed -- the target estimation was done over 2 different augmentations.",
      "This work introduces a tiny modification of the DrQ's variance reduction approach, that just combines one augmented and one un-augmented observation instead of combining two augmented observations.",
      "Furthermore, the authors fail to mention this prior result in their paper and compare to it.",
      "From the paper it is not clear what hyper-parameters are used for the baselines, specifically for DrQ.",
      "If the authors use the original DrQ's parameters, then I see several major issues with the empirical results:",
      "1) SVEA uses encoder arch that consists of 11 conv layers, while DrQ only uses 4.",
      "2) The size of replay buffer of SVEA is 500K, while DrQ's 100K.",
      "3) SVEA virtually increases the batch size by factor of 2, which usually leads to better performance on the DeepMind Control Suite tasks, it is not clear if the authors increase batch size for DrQ or not.",
      "These discrepancies alone could result in a drastic difference in performance and can render the empirical study to be invalid.",
      "There is no experiments that compare individual components of SVEA to verify is that the improved performance comes from the proposed method or better/different hyper-parameters.",
      "The authors claim in line 30 that they 'theoretically ground' their findings, but this is not the case as there is no theoretical results presented.",
      "In general, the authors don't do a good job justifying that the two pitfalls are real.",
      "Their argument is hand-wavy and is based on a series of indirect comparisons to the baseline (DrQ).",
      "Unfortunately, there are too many moving parts in those comparisons that make it virtually impossible to validate the claim (see also the point above about the hyper-parameter discrepancies).",
      "Given the very limited scope of novelty and technical contribution, the failure to mention the prior work that is almost identical, and the inconclusive empirical study I recommend to reject this paper from a high-profile venue of NeurIPS."
    ]
  },
  {
    "paper_id": "2107.00644v2",
    "submission_id": "zQvxc8ul2rR",
    "submission_title": "Stabilizing Deep Q-Learning with ConvNets and Vision Transformers under Data Augmentation",
    "review_id": "SsnCSOo29O8",
    "input": {
      "title": "Stabilizing Deep Q-Learning with ConvNets and Vision Transformers under Data Augmentation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- the idea of data-augmentation has been extensively used in both supervised and reinforcement learning, this paper proposes an approach that in some ways generalizes the DrQ approach, and in others simplifies it.\n- In my view the modifications, though subtle, are novel.\n- The work produces an extensive array of empirical results showing reobust generalization and impressive sample-efficiency.\n- The comparisons to DrQ lack specification of the hyperparamters K and M, which can easily be added.\n- If, as I suspect, the comparison is with DrQ[K=1, M=1], it would be nice to see a comparison to the default DrQ[K=2, M=2] and/or at the very least DrQ[K=2, M=1], which matches the number of forward passes through the Q-network.\n- it would be nice to see the equivalent plot for various values of K.\n- I would slightly quibble with the claim of 'theoretically grounded' on line 30, as this paper does not feature any rigorous theoretical statements.\n- Overall the paper is very clearly and well written.\n- DrQ is parameterized by a K and M which control how many samples the target Q-values and TD loss, respectively, are averaged over.\n- It would be good to specify which is being used here.\n- It sounds like [K=1, M=1] (?) but I would think the fairest comparison would be [K=2, M=1].\n- The targets on line 215 and line 9 of Algorithm 1 presumably look different in continuous control cases, which is the main focus of the experimental section.\n- would the expressions not be equivalent but simpler if the trade-off was simply alpha and (1 - alpha), instead of beta?\n- The experimental setup is slightly unclear in the text, copying the caption of Figure 3 into the main body would help.\n- The sentence 'all methods are trained for 500k frames and evaluated on the full set of tasks' could be clarified.\n- Figure 6 (left) needs error-bars.\n- Data-augmentation seems to be a very simple technique for improving the sample-efficiency and generalizability of RL agents.\n- This is particularly important for real-world applications where interactions with the environment can be expensive and the sim-to-real gap can be prohibitive.",
    "review_points_list": [
      "the idea of data-augmentation has been extensively used in both supervised and reinforcement learning, this paper proposes an approach that in some ways generalizes the DrQ approach, and in others simplifies it.",
      "In my view the modifications, though subtle, are novel.",
      "The work produces an extensive array of empirical results showing reobust generalization and impressive sample-efficiency.",
      "The comparisons to DrQ lack specification of the hyperparamters K and M, which can easily be added.",
      "If, as I suspect, the comparison is with DrQ[K=1, M=1], it would be nice to see a comparison to the default DrQ[K=2, M=2] and/or at the very least DrQ[K=2, M=1], which matches the number of forward passes through the Q-network.",
      "it would be nice to see the equivalent plot for various values of K.",
      "I would slightly quibble with the claim of 'theoretically grounded' on line 30, as this paper does not feature any rigorous theoretical statements.",
      "Overall the paper is very clearly and well written.",
      "DrQ is parameterized by a K and M which control how many samples the target Q-values and TD loss, respectively, are averaged over.",
      "It would be good to specify which is being used here.",
      "It sounds like [K=1, M=1] (?) but I would think the fairest comparison would be [K=2, M=1].",
      "The targets on line 215 and line 9 of Algorithm 1 presumably look different in continuous control cases, which is the main focus of the experimental section.",
      "would the expressions not be equivalent but simpler if the trade-off was simply alpha and (1 - alpha), instead of beta?",
      "The experimental setup is slightly unclear in the text, copying the caption of Figure 3 into the main body would help.",
      "The sentence 'all methods are trained for 500k frames and evaluated on the full set of tasks' could be clarified.",
      "Figure 6 (left) needs error-bars.",
      "Data-augmentation seems to be a very simple technique for improving the sample-efficiency and generalizability of RL agents.",
      "This is particularly important for real-world applications where interactions with the environment can be expensive and the sim-to-real gap can be prohibitive."
    ]
  },
  {
    "paper_id": "2107.00644v2",
    "submission_id": "zQvxc8ul2rR",
    "submission_title": "Stabilizing Deep Q-Learning with ConvNets and Vision Transformers under Data Augmentation",
    "review_id": "TAJ3pE4xjjQ",
    "input": {
      "title": "Stabilizing Deep Q-Learning with ConvNets and Vision Transformers under Data Augmentation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well-written, clear and provides a good description of the experiments.\n- It clearly sets up the problem that standard data augmentation methods suffer from.\n- It also provides empirical solutions to these problems and backs up these claims with experimental results.\n- Even though the paper justifies the claims only empirically based on experimentation, the ideas proposed here have made simple and easily extendable modifications, which can be very useful in complex state action spaces when RL+Data augmentation is employed.\n- The ideas proposed here are pretty simple and straightforward, but I am not convinced these methods alone provide us a full-fledged framework for data augmentation as claimed.\n- Any theoretical justification provided with this work is not rigorous enough to demonstrate that these methods are universal for all data augmentation problems.\n- On the novelty front, the paper's key contribution seems to be the idea of using un-augmented inputs to the targets.\n- There are two ways to look at this -- just as a simple innovation being not novel enough on its own or trying to understand how the work arrives at this simple innovation and whether the innovation helps improve the algorithm performance over a wide variety of tasks.\n- I am more inclined towards the latter.\n- I believe this is still a useful enough contribution to practitioners and researchers alike, where a few simple modifications help greatly stabilize performance.\n- My major concern with the paper was the hyper-parameters and architectures used for the baselines.\n- It looks like the adapted baselines were handicapped a bit by architectural changes and these baselines were not tuned to optimality, or at least it was not very evident that this was done thoroughly.\n- This takes a bit of the shine off the impressive results presented by the paper and I am not sure if tuning the parameters would change any relative comparison between those baselines and this method.\n- The paper's proposed methods are good and the results are useful on their own to the community.\n- Having said that, because of the other minor issues mentioned earlier, I am not able to give a higher score than 6 for this paper.",
    "review_points_list": [
      "The paper is well-written, clear and provides a good description of the experiments.",
      "It clearly sets up the problem that standard data augmentation methods suffer from.",
      "It also provides empirical solutions to these problems and backs up these claims with experimental results.",
      "Even though the paper justifies the claims only empirically based on experimentation, the ideas proposed here have made simple and easily extendable modifications, which can be very useful in complex state action spaces when RL+Data augmentation is employed.",
      "The ideas proposed here are pretty simple and straightforward, but I am not convinced these methods alone provide us a full-fledged framework for data augmentation as claimed.",
      "Any theoretical justification provided with this work is not rigorous enough to demonstrate that these methods are universal for all data augmentation problems.",
      "On the novelty front, the paper's key contribution seems to be the idea of using un-augmented inputs to the targets.",
      "There are two ways to look at this -- just as a simple innovation being not novel enough on its own or trying to understand how the work arrives at this simple innovation and whether the innovation helps improve the algorithm performance over a wide variety of tasks.",
      "I am more inclined towards the latter.",
      "I believe this is still a useful enough contribution to practitioners and researchers alike, where a few simple modifications help greatly stabilize performance.",
      "My major concern with the paper was the hyper-parameters and architectures used for the baselines.",
      "It looks like the adapted baselines were handicapped a bit by architectural changes and these baselines were not tuned to optimality, or at least it was not very evident that this was done thoroughly.",
      "This takes a bit of the shine off the impressive results presented by the paper and I am not sure if tuning the parameters would change any relative comparison between those baselines and this method.",
      "The paper's proposed methods are good and the results are useful on their own to the community.",
      "Having said that, because of the other minor issues mentioned earlier, I am not able to give a higher score than 6 for this paper."
    ]
  },
  {
    "paper_id": "2008.08032v4",
    "submission_id": "vh7qBSDZW3G",
    "submission_title": "Efficient constrained sampling via the mirror-Langevin algorithm",
    "review_id": "el-rX1JN3Hm",
    "input": {
      "title": "Efficient constrained sampling via the mirror-Langevin algorithm",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Interesting theoretical result, showing that the convergence issue in [ZPFP20] can be solved by a better approximation of the diffusion step.\n- Relaxes the assumptions made in [ZPFP20], in particular the commutation conditions for Hessians.\n- The paper would greatly improve by analyzing the impact of approximate, which would provide a more correct description of the practical convergence rate.\n- The claim in the abstract that \u201cUnlike prior work, our result has vanishing bias as the step size goes to zero\u201d is not fair, since including a discretization of the diffusion will most probably involve a similar bias.\n- The practical usefulness of the algorithm seems limited. Based on Figure 4, it is not clear whether a better diffusion discretization truly yields a better solution.\n- The algorithm is only compared to PLA, which has the worst convergence rate, and is known to perform rather badly in practice.\n- It may be interesting to compare against MYULA [BDMP17], MLD (asymmetric discretization [HKRC18], or [REKV20] (the latter also being worth mentioning in Table 1).",
    "review_points_list": [
      "Interesting theoretical result, showing that the convergence issue in [ZPFP20] can be solved by a better approximation of the diffusion step.",
      "Relaxes the assumptions made in [ZPFP20], in particular the commutation conditions for Hessians.",
      "The paper would greatly improve by analyzing the impact of approximate, which would provide a more correct description of the practical convergence rate.",
      "The claim in the abstract that \u201cUnlike prior work, our result has vanishing bias as the step size goes to zero\u201d is not fair, since including a discretization of the diffusion will most probably involve a similar bias.",
      "The practical usefulness of the algorithm seems limited. Based on Figure 4, it is not clear whether a better diffusion discretization truly yields a better solution.",
      "The algorithm is only compared to PLA, which has the worst convergence rate, and is known to perform rather badly in practice.",
      "It may be interesting to compare against MYULA [BDMP17], MLD (asymmetric discretization [HKRC18], or [REKV20] (the latter also being worth mentioning in Table 1)."
    ]
  },
  {
    "paper_id": "2008.08032v4",
    "submission_id": "vh7qBSDZW3G",
    "submission_title": "Efficient constrained sampling via the mirror-Langevin algorithm",
    "review_id": "n1POnmFj8Iw",
    "input": {
      "title": "Efficient constrained sampling via the mirror-Langevin algorithm",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper extends the approach of [DMM19] to handle a mirror descent like Langevin algorithm.\n- The authors define a Bregman optimal transport cost that will induce the natural geometry of the algorithm.\n- The algorithm is designed as a \"Forward Flow\" algorithm [Wib18], so that the convergence proof of [DMM19] can be extended to mirror descent.\n- The algorithm has two steps.\n- The first step is like a mirror descent descent and the second one introduces randomness following a mirror flow (instead of a Gaussian noise in ULA).\n- On the practical side, unlike ULA, this mirror flow step cannot be implemented in closed form.\n- The implementation of MLD2 should be discussed further. Can we implement it in closed form for some \\phi (other than the square norm)?\n- On the theoretical side, this paper is quite rich mathematically with several interesting ideas that extend those of DMM19 and can be used beyond the scope of this paper.\n- The authors extend the approach of [DMM19] to handle a mirror descent like Langevin algorithm.\n- The convergence rate is provided in terms of the Bregman cost if V is relatively strongly convex and in terms of KL else.\n- The algorithm has a natural geometry induced by the Bregman optimal transport cost.\n- The authors use Ito calculus to show the convergence of the algorithm.\n- The entropy is (sub)differentiable at \\pi, and this requires implicitly the density of \\pi to be an element of S_{loc}^{1,1}(R^d) (see [AGS08, Th 10.4.13])\n- The paper is well-written. Even the appendix is of high quality.\n- The authors assume simultaneously Ass. 2 and Ass. 3 with \\alpha > 0 in Theorem 2?\n- The algorithm has a warm start assumption in Th 2 (convergence in KL divergence).\n- The velocity field of the algorithm is not explained in detail.\n- The simulations are a bit lightweight. I understand this work is theoretical.\n- Why not plot the ergodic means of the \\theta_k along the algorithm?\n- Some cleaning is needed in the references.",
    "review_points_list": [
      "The paper extends the approach of [DMM19] to handle a mirror descent like Langevin algorithm.",
      "The authors define a Bregman optimal transport cost that will induce the natural geometry of the algorithm.",
      "The algorithm is designed as a \"Forward Flow\" algorithm [Wib18], so that the convergence proof of [DMM19] can be extended to mirror descent.",
      "The algorithm has two steps.",
      "The first step is like a mirror descent descent and the second one introduces randomness following a mirror flow (instead of a Gaussian noise in ULA).",
      "On the practical side, unlike ULA, this mirror flow step cannot be implemented in closed form.",
      "The implementation of MLD2 should be discussed further. Can we implement it in closed form for some \\phi (other than the square norm)?",
      "On the theoretical side, this paper is quite rich mathematically with several interesting ideas that extend those of DMM19 and can be used beyond the scope of this paper.",
      "The authors extend the approach of [DMM19] to handle a mirror descent like Langevin algorithm.",
      "The convergence rate is provided in terms of the Bregman cost if V is relatively strongly convex and in terms of KL else.",
      "The algorithm has a natural geometry induced by the Bregman optimal transport cost.",
      "The authors use Ito calculus to show the convergence of the algorithm.",
      "The entropy is (sub)differentiable at \\pi, and this requires implicitly the density of \\pi to be an element of S_{loc}^{1,1}(R^d) (see [AGS08, Th 10.4.13])",
      "The paper is well-written. Even the appendix is of high quality.",
      "The authors assume simultaneously Ass. 2 and Ass. 3 with \\alpha > 0 in Theorem 2?",
      "The algorithm has a warm start assumption in Th 2 (convergence in KL divergence).",
      "The velocity field of the algorithm is not explained in detail.",
      "The simulations are a bit lightweight. I understand this work is theoretical.",
      "Why not plot the ergodic means of the \\theta_k along the algorithm?",
      "Some cleaning is needed in the references."
    ]
  },
  {
    "paper_id": "2008.08032v4",
    "submission_id": "vh7qBSDZW3G",
    "submission_title": "Efficient constrained sampling via the mirror-Langevin algorithm",
    "review_id": "OShD6pB2bHT",
    "input": {
      "title": "Efficient constrained sampling via the mirror-Langevin algorithm",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The motivation is strong --- correcting bias in the Euler-Maruyama discretization of Zhang et al.\n- The proof looks correct to me. It is also easy to follow and the results are neat.\n- The biggest concern for me is that the proposed algorithm is not really a discretization since the diffusion step is still in continuous time and the proof relies on Ito's formula.\n- This obviously makes a big difference and it is unclear what a proper discretization of it is.\n- I noticed that this has been the concern for reviewers of COLT. However, I don't think it is now addressed up to satisfactory.\n- I wonder how the proposed algorithm compare to running LD in the mirrored space, which was shown in Ya-Ping Hsieh et al. (2018) to have O(d/eps^2) convergence.\n- For optimization this would not be a concern since the optimum need not match under transformation of the mirror map, but since now we are dealing with sampling, there is no obvious reason that one should prefer MLA over LD in the mirrored space.\n- The empirical result (Figure 2), if the authors decide to include any, does not provide strong evidence supporting the theoretical argument.\n- PLA seems to converge much faster, although MLA lead to better results but there is still a large gap from the target distribution.\n- How strong is the self-concordance assumption on mirror maps? Does it apply to choices other than barriers?",
    "review_points_list": [
      "The motivation is strong --- correcting bias in the Euler-Maruyama discretization of Zhang et al.",
      "The proof looks correct to me. It is also easy to follow and the results are neat.",
      "The biggest concern for me is that the proposed algorithm is not really a discretization since the diffusion step is still in continuous time and the proof relies on Ito's formula.",
      "This obviously makes a big difference and it is unclear what a proper discretization of it is.",
      "I noticed that this has been the concern for reviewers of COLT. However, I don't think it is now addressed up to satisfactory.",
      "I wonder how the proposed algorithm compare to running LD in the mirrored space, which was shown in Ya-Ping Hsieh et al. (2018) to have O(d/eps^2) convergence.",
      "For optimization this would not be a concern since the optimum need not match under transformation of the mirror map, but since now we are dealing with sampling, there is no obvious reason that one should prefer MLA over LD in the mirrored space.",
      "The empirical result (Figure 2), if the authors decide to include any, does not provide strong evidence supporting the theoretical argument.",
      "PLA seems to converge much faster, although MLA lead to better results but there is still a large gap from the target distribution.",
      "How strong is the self-concordance assumption on mirror maps? Does it apply to choices other than barriers?"
    ]
  },
  {
    "paper_id": "2110.04202v3",
    "submission_id": "yhjpeuWepoj",
    "submission_title": "Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation",
    "review_id": "UelqsZH8Lfe",
    "input": {
      "title": "Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The study is well-motivated and tackles an important problem, which is unsupervised domain adaptation without access to the source data.\n- The proposed method is carefully designed to solve this problem and works well in several benchmark datasets, while there are some concerns on hyper-parameter setting and scalability.\n- I vote for 'weak accept'.\n- This paper is well-written and easy-to-follow.\n- This study tackles an important and challenging problem, which is source-free UDA. The source-free UDA should be beneficial in many practical situations where domain adaptation is needed.\n- The experimental results show that the proposed method works well in several benchmark datasets. In addition, rigorous ablation studies validate the design of the proposed method.\n- Scalability to the number of target data. Since we need to store and continuously update the extracted features of all target data, it should spend a lot of memory, when the number of target data is large.\n- In addition, computational cost can be also prohibitively large due to the nearest-neighbor search process in each iteration.\n- Although small-scale target data can be expected in some situations where domain adaptation is required, this point should be discussed in the paper.\n- How to optimally set the number of nearest/expanded neighbors. Although Fig. 4 shows some robustness of the proposed method against suboptimal setting of K and M, this robustness may heavily depend on both the dimensionality of the features and the number of target data.\n- Since it is difficult to tune hyper-parameters in the adaptation phase under the source-free setting, this point should be carefully analyzed/discussed.\n- It is not clear to see whether the final objective function is minimized if and only if all p_i are one-hot vectors with ground-truth labels.\n- Showing loss curve with error curve may help.\n- Something wrong in Eq. (7). I think both \\bar{p}_c and q_c cannot be label distribution but scalar.\n- Please check it.",
    "review_points_list": [
      "The study is well-motivated and tackles an important problem, which is unsupervised domain adaptation without access to the source data.",
      "The proposed method is carefully designed to solve this problem and works well in several benchmark datasets, while there are some concerns on hyper-parameter setting and scalability.",
      "I vote for 'weak accept'.",
      "This paper is well-written and easy-to-follow.",
      "This study tackles an important and challenging problem, which is source-free UDA. The source-free UDA should be beneficial in many practical situations where domain adaptation is needed.",
      "The experimental results show that the proposed method works well in several benchmark datasets. In addition, rigorous ablation studies validate the design of the proposed method.",
      "Scalability to the number of target data. Since we need to store and continuously update the extracted features of all target data, it should spend a lot of memory, when the number of target data is large.",
      "In addition, computational cost can be also prohibitively large due to the nearest-neighbor search process in each iteration.",
      "Although small-scale target data can be expected in some situations where domain adaptation is required, this point should be discussed in the paper.",
      "How to optimally set the number of nearest/expanded neighbors. Although Fig. 4 shows some robustness of the proposed method against suboptimal setting of K and M, this robustness may heavily depend on both the dimensionality of the features and the number of target data.",
      "Since it is difficult to tune hyper-parameters in the adaptation phase under the source-free setting, this point should be carefully analyzed/discussed.",
      "It is not clear to see whether the final objective function is minimized if and only if all p_i are one-hot vectors with ground-truth labels.",
      "Showing loss curve with error curve may help.",
      "Something wrong in Eq. (7). I think both \\bar{p}_c and q_c cannot be label distribution but scalar.",
      "Please check it."
    ]
  },
  {
    "paper_id": "2110.04202v3",
    "submission_id": "yhjpeuWepoj",
    "submission_title": "Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation",
    "review_id": "1f3evwOrabB",
    "input": {
      "title": "Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Nearest Neighbour (NN) based techniques have been used extensively in DA literature to structural properties of the target domain.\n- The paper finds that using Reciprocal NN (RNN) instead of NN provides an improvement in the performance of the model.\n- The ideas described in this paper are novel and have been presented well.\n- The results are significant and demonstrate promising accuracy for 2D and 3D computer vision tasks.\n- The top K/M RNN points are shown to have a higher correct ratio percentage compared to the top K/M NN points.\n- However, the performance of the source-free model really depends on the points that lie in low confidence regions (which are typically not present in the top K) because they contribute to the majority of the samples.\n- So even if the extended neighbourhood is considered, it is not clear how RNN could perform better than NN since the most confident samples are classified correctly anyway.\n- On Eq. 1 ($\text{L}_{\text{N}}$), each of the terms on the right-hand side ($A, \text{S}, p$) are always positive.\n- So the dot product of these vectors will be limited to a positive regime.\n- Wouldn't it be ideal to choose a negative $A$ value for the nRNN data point (consider it as a highly dissimilar point) that needs to be 'pushed away' instead of $r=0.1$ (L143)?\n- Also, in Fig. 3, a value of $r$ that lies in between -1 and 0 has not been shown.\n- For e.g., a $r= -0.1$.\n- Training the model in a curriculum fashion could boost the performance of your method since the model has the flexibility to learn the signal from beyond the data points present at the top-K.\n- Minor typos: 1. L136: 'non-reciprocal neighbors neighbors' .. repeated words.\n- 2. L143: 'If not specified otherwise r is set to 0.1.' .. remove otherwise here?\n- Consider including the following references in your paper as they are closely related to your method.[Ref 1] Yuang Liu, Wei Zhang, Jun Wang, 'Source-Free Domain Adaptation for Semantic Segmentation', CVPR'21\n- [Ref 2] Venkat N, Kundu JN, Singh DK, Revanur A, Babu RV, 'Your Classifier can Secretly Suffice Multi-Source Domain Adaptation', NeurIPS'20",
    "review_points_list": [
      "Nearest Neighbour (NN) based techniques have been used extensively in DA literature to structural properties of the target domain.",
      "The paper finds that using Reciprocal NN (RNN) instead of NN provides an improvement in the performance of the model.",
      "The ideas described in this paper are novel and have been presented well.",
      "The results are significant and demonstrate promising accuracy for 2D and 3D computer vision tasks.",
      "The top K/M RNN points are shown to have a higher correct ratio percentage compared to the top K/M NN points.",
      "However, the performance of the source-free model really depends on the points that lie in low confidence regions (which are typically not present in the top K) because they contribute to the majority of the samples.",
      "So even if the extended neighbourhood is considered, it is not clear how RNN could perform better than NN since the most confident samples are classified correctly anyway.",
      "On Eq. 1 ($\text{L}_{\text{N}}$), each of the terms on the right-hand side ($A, \text{S}, p$) are always positive.",
      "So the dot product of these vectors will be limited to a positive regime.",
      "Wouldn't it be ideal to choose a negative $A$ value for the nRNN data point (consider it as a highly dissimilar point) that needs to be 'pushed away' instead of $r=0.1$ (L143)?",
      "Also, in Fig. 3, a value of $r$ that lies in between -1 and 0 has not been shown.",
      "For e.g., a $r= -0.1$.",
      "Training the model in a curriculum fashion could boost the performance of your method since the model has the flexibility to learn the signal from beyond the data points present at the top-K.",
      "Minor typos: 1. L136: 'non-reciprocal neighbors neighbors' .. repeated words.",
      "2. L143: 'If not specified otherwise r is set to 0.1.' .. remove otherwise here?",
      "Consider including the following references in your paper as they are closely related to your method.[Ref 1] Yuang Liu, Wei Zhang, Jun Wang, 'Source-Free Domain Adaptation for Semantic Segmentation', CVPR'21",
      "[Ref 2] Venkat N, Kundu JN, Singh DK, Revanur A, Babu RV, 'Your Classifier can Secretly Suffice Multi-Source Domain Adaptation', NeurIPS'20"
    ]
  },
  {
    "paper_id": "2110.04202v3",
    "submission_id": "yhjpeuWepoj",
    "submission_title": "Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation",
    "review_id": "KF5Y6TmFE9P",
    "input": {
      "title": "Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.\n- The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.\n- The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset. The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP). Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.\n- The authors also establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.\n- The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.\n- This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.\n- The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.\n- log(k) is an upper bound on the improvement of query complexity for any sampler.\n- The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.\n- The paper is very clear and well organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.\n- The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.",
    "review_points_list": [
      "The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.",
      "The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.",
      "The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset. The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP). Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.",
      "The authors also establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.",
      "The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.",
      "This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.",
      "The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.",
      "log(k) is an upper bound on the improvement of query complexity for any sampler.",
      "The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.",
      "The paper is very clear and well organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.",
      "The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm."
    ]
  },
  {
    "paper_id": "2110.04202v3",
    "submission_id": "yhjpeuWepoj",
    "submission_title": "Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation",
    "review_id": "tSRw9Hfs3Sm",
    "input": {
      "title": "Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- In Section 5, the authors insist, 'To the best of our knowledge, existing works on DA do not explicitly exploit this source of information, and they could be combined with our method.' However, the use of local structure in the target domain is pretty well-known.\n- [a] Pan et al., Exploring Category-Agnostic Clusters for Open-Set Domain Adaptation. CVPR, 2020\n- The papers below have a similar problem definition to that in this paper.\n- [b] Li et al., Source-free domain adaptation for semantic segmentation. CVPR, 2021.\n- [c] Kurmi et al., Domain Impression: A Source Data Free Domain Adaptation Method. WACV, 2021.\n- [d] Yeh et al., SoFA: Source-data-free Feature Alignment for Unsupervised Domain Adaptation. WACV, 2021.\n- Figure (c) shows that the samples misclassified once can be pushed toward a cluster for each class. However, it is unclear why the proposed method can form completely clean clusters.\n- In Section 5, the authors insist, 'To the best of our knowledge, existing works on DA do not explicitly exploit this source of information, and they could be combined with our method.' The former is already addressed in the originality part. If the authors insist that the proposed method can be combined with their method, they could have shown some results.\n- The performance gain is sometimes very moderate. For example, results of Office-31 and Office-Home are very close to those by SHOT [21] and ModelAdaptation [20]. By the way, the authors of [20] have named their method not as ModelAdaptation but as Collaborative Class Conditional GAN (3C-GAN).",
    "review_points_list": [
      "In Section 5, the authors insist, 'To the best of our knowledge, existing works on DA do not explicitly exploit this source of information, and they could be combined with our method.' However, the use of local structure in the target domain is pretty well-known.",
      "[a] Pan et al., Exploring Category-Agnostic Clusters for Open-Set Domain Adaptation. CVPR, 2020",
      "The papers below have a similar problem definition to that in this paper.",
      "[b] Li et al., Source-free domain adaptation for semantic segmentation. CVPR, 2021.",
      "[c] Kurmi et al., Domain Impression: A Source Data Free Domain Adaptation Method. WACV, 2021.",
      "[d] Yeh et al., SoFA: Source-data-free Feature Alignment for Unsupervised Domain Adaptation. WACV, 2021.",
      "Figure (c) shows that the samples misclassified once can be pushed toward a cluster for each class. However, it is unclear why the proposed method can form completely clean clusters.",
      "In Section 5, the authors insist, 'To the best of our knowledge, existing works on DA do not explicitly exploit this source of information, and they could be combined with our method.' The former is already addressed in the originality part. If the authors insist that the proposed method can be combined with their method, they could have shown some results.",
      "The performance gain is sometimes very moderate. For example, results of Office-31 and Office-Home are very close to those by SHOT [21] and ModelAdaptation [20]. By the way, the authors of [20] have named their method not as ModelAdaptation but as Collaborative Class Conditional GAN (3C-GAN)."
    ]
  },
  {
    "paper_id": "2110.04202v3",
    "submission_id": "ueGDv64HmO",
    "submission_title": "Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation",
    "review_id": "imicABBW4Hf",
    "input": {
      "title": "Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed framework is technically sound, which can exploit the local representation structure from various granularities.\n- The paper is well written, and it's easy to capture the gist of this work.\n- Sufficient experiments are conducted to evaluate the whole model and various model components.\n- Technically, I'm convinced that the proposed method is able to promote the feature compactness within some feature cluster. However, except for the feature compactness, it is also important to constrain the inter-cluster feature separability so as to guarantee the good performance on target domain. How can the proposed model achieves this important property?\n- In Eq. 1, authors use the distance towards query sample to depict semantics. Considering the representation bias of each specific instance, why not use the distance towards the cluster center associated to the query sample? This scheme may capture semantics more precisely.\n- The objectives in Eq. 9 are composed of a diversity term, two neighborhood semantic similarity terms and a self-regularization term. There should be a trade-off among these three kinds of objectives, such that some trade-off parameters might further promote the performance of this model.\n- I am convinced by the technical merit of this paper, and think it as a well-suited framework for Source-free Domain Adaptation.\n- Though there are some points needed to be further clarified, this work is decent enough as a whole.",
    "review_points_list": [
      "The proposed framework is technically sound, which can exploit the local representation structure from various granularities.",
      "The paper is well written, and it's easy to capture the gist of this work.",
      "Sufficient experiments are conducted to evaluate the whole model and various model components.",
      "Technically, I'm convinced that the proposed method is able to promote the feature compactness within some feature cluster. However, except for the feature compactness, it is also important to constrain the inter-cluster feature separability so as to guarantee the good performance on target domain. How can the proposed model achieves this important property?",
      "In Eq. 1, authors use the distance towards query sample to depict semantics. Considering the representation bias of each specific instance, why not use the distance towards the cluster center associated to the query sample? This scheme may capture semantics more precisely.",
      "The objectives in Eq. 9 are composed of a diversity term, two neighborhood semantic similarity terms and a self-regularization term. There should be a trade-off among these three kinds of objectives, such that some trade-off parameters might further promote the performance of this model.",
      "I am convinced by the technical merit of this paper, and think it as a well-suited framework for Source-free Domain Adaptation.",
      "Though there are some points needed to be further clarified, this work is decent enough as a whole."
    ]
  },
  {
    "paper_id": "2110.04202v3",
    "submission_id": "ueGDv64HmO",
    "submission_title": "Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation",
    "review_id": "W97qac31Mzh",
    "input": {
      "title": "Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The motivation of utilizing the memory bank to retrieve nearest neighbors should be given more explanations and discussions.\n- The hyperparameter r used in Eq.5 and Eq.9: Is it the same? If not, why not choose different hyperparameters for these two parts?\n- Comparative experiments with more source-free domain adaptation (SFDA) methods, such as [1] [2] [3], should be provided.\n- It\u2019s recommended to provide visualization of target features before adaptation in Fig.5 for better comparison.\n- Does the performance improve significantly at the expense of consuming large computational time cost? Time complexity analysis of the proposed method should be provided.\n- The current manuscript should be carefully polished, e.g., some grammar errors, the layout of Figures and Tables.\n- The submitted code cannot re-implement the results in this paper, and there is a large performance gap. So I recommend to reject this paper.",
    "review_points_list": [
      "The motivation of utilizing the memory bank to retrieve nearest neighbors should be given more explanations and discussions.",
      "The hyperparameter r used in Eq.5 and Eq.9: Is it the same? If not, why not choose different hyperparameters for these two parts?",
      "Comparative experiments with more source-free domain adaptation (SFDA) methods, such as [1] [2] [3], should be provided.",
      "It\u2019s recommended to provide visualization of target features before adaptation in Fig.5 for better comparison.",
      "Does the performance improve significantly at the expense of consuming large computational time cost? Time complexity analysis of the proposed method should be provided.",
      "The current manuscript should be carefully polished, e.g., some grammar errors, the layout of Figures and Tables.",
      "The submitted code cannot re-implement the results in this paper, and there is a large performance gap. So I recommend to reject this paper."
    ]
  },
  {
    "paper_id": "2110.04202v3",
    "submission_id": "ueGDv64HmO",
    "submission_title": "Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation",
    "review_id": "vLCOtruRYs",
    "input": {
      "title": "Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors introduce a source-free domain adaptation method by using the intrinsic data structures\n- The authors propose a method for adaptation by encouraging label consistency among local target features\n- The approach achieves significant improvement on VisDA-C (3%)  and marginal improvement (0.4%) over the prior-art [21] on the Office-Home dataset\n- The minibatch update of $p_i$\u2019s coupled with the self-regularization loss $L_{self}$ seems similar to an mommnetum update of $S=[p_1, p_2,..., p_{n_t}]\n- Any comments on what would be the behavior if such momentum update is applied while updating $F\n- The proposed approach does not employ any pseudo-label-based loss as used in other prior arts\n- I am curious about the importance of the diversity loss, $L_{div\n- The authors claim that \u201csource-free methods outperform methods that have access to source data during adaptation\u201d\n- The authors have set the affinity value for the expanded neighbors to an arbitrary value of 0.1\n- I thank the authors for the detailed rebuttal\n- In presence of source data the performance of the method degrades\n- Without diversity loss performance degrades significantly\n- The significance of setting different affinities for the expanded neighbors and nRNNs must be clarified thoroughly\n- I hope that the authors would include a thorough discussion on the limitations of this approach in their revised draft\n- I'd like to raise the score to '6: Marginally above the acceptance threshold\u2019",
    "review_points_list": [
      "The authors introduce a source-free domain adaptation method by using the intrinsic data structures",
      "The authors propose a method for adaptation by encouraging label consistency among local target features",
      "The approach achieves significant improvement on VisDA-C (3%)  and marginal improvement (0.4%) over the prior-art [21] on the Office-Home dataset",
      "The minibatch update of $p_i$\u2019s coupled with the self-regularization loss $L_{self}$ seems similar to an mommnetum update of $S=[p_1, p_2,..., p_{n_t}]",
      "Any comments on what would be the behavior if such momentum update is applied while updating $F",
      "The proposed approach does not employ any pseudo-label-based loss as used in other prior arts",
      "I am curious about the importance of the diversity loss, $L_{div",
      "The authors claim that \u201csource-free methods outperform methods that have access to source data during adaptation\u201d",
      "The authors have set the affinity value for the expanded neighbors to an arbitrary value of 0.1",
      "I thank the authors for the detailed rebuttal",
      "In presence of source data the performance of the method degrades",
      "Without diversity loss performance degrades significantly",
      "The significance of setting different affinities for the expanded neighbors and nRNNs must be clarified thoroughly",
      "I hope that the authors would include a thorough discussion on the limitations of this approach in their revised draft",
      "I'd like to raise the score to '6: Marginally above the acceptance threshold\u2019"
    ]
  },
  {
    "paper_id": "2110.04202v3",
    "submission_id": "ueGDv64HmO",
    "submission_title": "Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation",
    "review_id": "d5sa51SZxYO",
    "input": {
      "title": "Exploiting the Intrinsic Neighborhood Structure for Source-free Domain Adaptation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The motivation for various nearest neighbor strategies is clear (L42-51). The proposed reciprocal nearest neighbor approach is intuitive and makes sense.\n- The simplicity of the approach is a key highlight of this work.\n- Good work on the analysis. The figures are helpful in understanding the effectiveness of the approach.\n- Figure 4 (Left) presents another interesting observation where per-shared fraction (measured without using target labels) converges with target accuracy (more details in the next section).\n- The ablation study is detailed and supports the claims made in the paper.\n- Moreover, the insights presented in this work would be highly useful for research in Source-Free Domain Adaptation.\n- The manuscript is mostly easy to follow (though some clarifications and typographical fixes are required).\n- Overall, it is a good read.\n- The inclusion of code is appreciated.\n- Scalability: The requirement of a memory bank and nearest neighbor computation seems like a large overhead (e.g. consider large scale datasets like ImageNet).\n- The authors should investigate the effect of reducing the space and computational overhead.\n- A runtime analysis (training time, FLOPS / epoch etc.) is required to understand the scalability of the proposed framework.\n- Could the authors provide a runtime comparison against the prior state-of-the-art methods?\n- Could the authors provide more details on how the nearest neighbors are computed?\n- The nearest neighbor computation would entail O(n_t * n_t) operations (quadratic) for each epoch (every target feature is compared with every other feature to obtain the list of nearest neighbors).\n- This is a huge overhead considering that most adaptation algorithms require O(n_t) operations (linear).\n- Consider the following approach: Suppose the target training dataset is split into, say, 10 mutually exclusive and exhaustive folds.\n- Each fold pertains to 10% of the data (call this, one mini-epoch) and is trained upon sequentially.\n- This approach reduces the memory bank to 10% of the data and ensures that samples in this mini-epoch pertain to the corresponding fold.\n- After one epoch on the entire dataset is completed (i.e. after 10 mini-epochs), the data is randomly shuffled to create the next 10 folds.\n- The model is trained on the entire dataset, however, would require 10 times less overhead for memoization and NN-computation.\n- This could reveal that perhaps only a fraction of the dataset in-memory is sufficient and the performance gain saturates with an increase in samples.\n- If this works, then one of a major drawback of the proposed framework could be solved.\n- Could the authors verify this and comment on the efficacy of this approach?\n- The requirement of a memory bank and nearest neighbor computation seems like a large overhead (e.g. consider large scale datasets like ImageNet).\n- The nearest neighbor computation would entail O(n_t * n_t) operations (quadratic) for each epoch (every target feature is compared with every other feature to obtain the list of nearest neighbors).\n- This is a huge overhead considering that most adaptation algorithms require O(n_t) operations (linear).\n- Consider the following approach: Suppose the target training dataset is split into, say, 10 mutually exclusive and exhaustive folds.\n- This approach reduces the memory bank to 10% of the data and ensures that samples in this mini-epoch pertain to the corresponding fold.\n- After one epoch on the entire dataset is completed (i.e. after 10 mini-epochs), the data is randomly shuffled to create the next 10 folds.\n- The model is trained on the entire dataset, however, would require 10 times less overhead for memoization and NN-computation.\n- This could reveal that perhaps only a fraction of the dataset in-memory is sufficient and the performance gain saturates with an increase in samples.\n- If this works, then one of a major drawback of the proposed framework could be solved.\n- Could the authors verify this and comment on the efficacy of this approach?\n- L147-149: This part is confusing.\n- My understanding is that $\text{S}_{i}^{T}$ is a constant vector (not \"scalar\", L147) containing the prediction scores of $x_i^t$.\n- The loss $\text{L}_{self}$ essentially computes a weighted sum (weights = $\text{S}_i$) of the class probabilities ($p_i$).\n- The expression is written like so (and not $p_i^T \times p_i$) because the loss $\text{L}_{self}$ is assumed to back-propagate only through the variable $p_i$ and not through the weights ($\text{S}_i$).\n- If this is the case, please consider paraphrasing this part to clarify the same.\n- Affinity measure: In the current formulation, affinity is a hyperparameter ($A = 1$ or $r<=1$).\n- Thus, affinity is assigning discrete weights to the similarity between pairs of samples in Eq. 1.\n- Did the authors consider using continuous affinity values to obtain a \u201cdegree of connectivity\u201d (L55), for e.g. using feature distance $D_{dis} = || z_i - z_j ||$?\n- The observation in Figure 4 (left) could potentially lead to a reliable convergence criterion.\n- The usual practice in Unsupervised DA is to consider a labeled validation set for determining training convergence / selecting maximum epochs etc.\n- A recent work [P1] presents an approach to determine training convergence without using target labels.\n- In the proposed framework, the per-shared plot in Figure 4 (left) seems to correlate with the target accuracy.\n- This could potentially be used as a convergence criterion.\n- Could the authors provide more insights on this aspect?\n- Minor Comments: A recent work by Wang et al., \u201cTent: Fully Test-Time Adaptation by Entropy Minimization\u201d, ICLR 2021 also performs source-free adaptation using entropy minimization which results in a simple approach.\n- It would be interesting to compare the runtime vs. performance trade-off between Tent and the proposed neighborhood approach.\n- Typos: L273 (consistence -> consistency), L217 (date -> data), L145 (simple -> simply), L115 (weight -> weigh), L103, 232 (discusses -> discussed), Fig. 1 caption (pushed -> pushing), L34 (vary -> very).\n- L90, L149, L270: Avoid 1-3 worded lines to save space (paraphrase the sentence).\n- L45-51: Here, it would be a good idea to introduce / define RNN and nRNN so that the figure 1(c) is comprehensible.\n- Also, in Fig. 1(c) left, consider showing nearest neighbors connectivity on the left and the RNN/nRNN plot on the right (i.e. swap the two diagrams).\n- This would enhance readability.",
    "review_points_list": [
      "The motivation for various nearest neighbor strategies is clear (L42-51). The proposed reciprocal nearest neighbor approach is intuitive and makes sense.",
      "The simplicity of the approach is a key highlight of this work.",
      "Good work on the analysis. The figures are helpful in understanding the effectiveness of the approach.",
      "Figure 4 (Left) presents another interesting observation where per-shared fraction (measured without using target labels) converges with target accuracy (more details in the next section).",
      "The ablation study is detailed and supports the claims made in the paper.",
      "Moreover, the insights presented in this work would be highly useful for research in Source-Free Domain Adaptation.",
      "The manuscript is mostly easy to follow (though some clarifications and typographical fixes are required).",
      "Overall, it is a good read.",
      "The inclusion of code is appreciated.",
      "Scalability: The requirement of a memory bank and nearest neighbor computation seems like a large overhead (e.g. consider large scale datasets like ImageNet).",
      "The authors should investigate the effect of reducing the space and computational overhead.",
      "A runtime analysis (training time, FLOPS / epoch etc.) is required to understand the scalability of the proposed framework.",
      "Could the authors provide a runtime comparison against the prior state-of-the-art methods?",
      "Could the authors provide more details on how the nearest neighbors are computed?",
      "The nearest neighbor computation would entail O(n_t * n_t) operations (quadratic) for each epoch (every target feature is compared with every other feature to obtain the list of nearest neighbors).",
      "This is a huge overhead considering that most adaptation algorithms require O(n_t) operations (linear).",
      "Consider the following approach: Suppose the target training dataset is split into, say, 10 mutually exclusive and exhaustive folds.",
      "Each fold pertains to 10% of the data (call this, one mini-epoch) and is trained upon sequentially.",
      "This approach reduces the memory bank to 10% of the data and ensures that samples in this mini-epoch pertain to the corresponding fold.",
      "After one epoch on the entire dataset is completed (i.e. after 10 mini-epochs), the data is randomly shuffled to create the next 10 folds.",
      "The model is trained on the entire dataset, however, would require 10 times less overhead for memoization and NN-computation.",
      "This could reveal that perhaps only a fraction of the dataset in-memory is sufficient and the performance gain saturates with an increase in samples.",
      "If this works, then one of a major drawback of the proposed framework could be solved.",
      "Could the authors verify this and comment on the efficacy of this approach?",
      "The requirement of a memory bank and nearest neighbor computation seems like a large overhead (e.g. consider large scale datasets like ImageNet).",
      "The nearest neighbor computation would entail O(n_t * n_t) operations (quadratic) for each epoch (every target feature is compared with every other feature to obtain the list of nearest neighbors).",
      "This is a huge overhead considering that most adaptation algorithms require O(n_t) operations (linear).",
      "Consider the following approach: Suppose the target training dataset is split into, say, 10 mutually exclusive and exhaustive folds.",
      "This approach reduces the memory bank to 10% of the data and ensures that samples in this mini-epoch pertain to the corresponding fold.",
      "After one epoch on the entire dataset is completed (i.e. after 10 mini-epochs), the data is randomly shuffled to create the next 10 folds.",
      "The model is trained on the entire dataset, however, would require 10 times less overhead for memoization and NN-computation.",
      "This could reveal that perhaps only a fraction of the dataset in-memory is sufficient and the performance gain saturates with an increase in samples.",
      "If this works, then one of a major drawback of the proposed framework could be solved.",
      "Could the authors verify this and comment on the efficacy of this approach?",
      "L147-149: This part is confusing.",
      "My understanding is that $\text{S}_{i}^{T}$ is a constant vector (not \"scalar\", L147) containing the prediction scores of $x_i^t$.",
      "The loss $\text{L}_{self}$ essentially computes a weighted sum (weights = $\text{S}_i$) of the class probabilities ($p_i$).",
      "The expression is written like so (and not $p_i^T \times p_i$) because the loss $\text{L}_{self}$ is assumed to back-propagate only through the variable $p_i$ and not through the weights ($\text{S}_i$).",
      "If this is the case, please consider paraphrasing this part to clarify the same.",
      "Affinity measure: In the current formulation, affinity is a hyperparameter ($A = 1$ or $r<=1$).",
      "Thus, affinity is assigning discrete weights to the similarity between pairs of samples in Eq. 1.",
      "Did the authors consider using continuous affinity values to obtain a \u201cdegree of connectivity\u201d (L55), for e.g. using feature distance $D_{dis} = || z_i - z_j ||$?",
      "The observation in Figure 4 (left) could potentially lead to a reliable convergence criterion.",
      "The usual practice in Unsupervised DA is to consider a labeled validation set for determining training convergence / selecting maximum epochs etc.",
      "A recent work [P1] presents an approach to determine training convergence without using target labels.",
      "In the proposed framework, the per-shared plot in Figure 4 (left) seems to correlate with the target accuracy.",
      "This could potentially be used as a convergence criterion.",
      "Could the authors provide more insights on this aspect?",
      "Minor Comments: A recent work by Wang et al., \u201cTent: Fully Test-Time Adaptation by Entropy Minimization\u201d, ICLR 2021 also performs source-free adaptation using entropy minimization which results in a simple approach.",
      "It would be interesting to compare the runtime vs. performance trade-off between Tent and the proposed neighborhood approach.",
      "Typos: L273 (consistence -> consistency), L217 (date -> data), L145 (simple -> simply), L115 (weight -> weigh), L103, 232 (discusses -> discussed), Fig. 1 caption (pushed -> pushing), L34 (vary -> very).",
      "L90, L149, L270: Avoid 1-3 worded lines to save space (paraphrase the sentence).",
      "L45-51: Here, it would be a good idea to introduce / define RNN and nRNN so that the figure 1(c) is comprehensible.",
      "Also, in Fig. 1(c) left, consider showing nearest neighbors connectivity on the left and the RNN/nRNN plot on the right (i.e. swap the two diagrams).",
      "This would enhance readability."
    ]
  },
  {
    "paper_id": "2108.13643v4",
    "submission_id": "wP9twkexC3V",
    "submission_title": "Learning to Synthesize Programs as Interpretable and Generalizable Policies",
    "review_id": "P3T_CAC-mqw",
    "input": {
      "title": "Learning to Synthesize Programs as Interpretable and Generalizable Policies",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I find the approach to be novel, creatively designing loss functions ensuring quality latent space representation of programs.\n- Program synthesis is an important and challenging research area, and thus I find the problem being solved important.\n- Technique is illustrated on a simple (Karel) tasks which might seem insufficient, but the program synthesis field is still at the stage where small problems are hard to solve, thus I find the choice appropriate.\n- Paper is well written and easy to follow. In addition, authors provide extensive appendix and accompanying web page with useful information.\n- Figure 2 is very informative. I would suggest extending the caption of the figure so it is more self-contained.\n- I understood different parts of the figure only when I thoroughly read the paper.\n- In the future, it would be good to evaluate the approach on tasks that are outside of the Karel domain.\n- I do not have a good track of other approaches that can be used for synthesizing Karel programs, and thus am not certain if all relevant approaches are included in the comparison.\n- Have you considered different ways of generating programs than pure random generation? Are there many programs that are 'not interesting' when performing random generation?\n- Program Embedding Space Smoothness. Is there a specific reason why embedding space search is performed on the train/val set, vs test set? Does the same trend apply to the test set?\n- In Table 2, do results represent percent of times that execution traces of two programs match (averaged across program pairs)? I understand that Rmat is defined as number of times traces match, not percent of times.\n- equation 4 (latent behavior reconstruction loss): Loss is referred to as a cross entropy loss. However, EXECt(ro) seems incorrect as it's constant in the inner sum. I assume it should be 1 in a case of the executed action, and 0 otherwise?\n- Line 233: 'shown in Figure 6'. This figure is not in the main text.",
    "review_points_list": [
      "I find the approach to be novel, creatively designing loss functions ensuring quality latent space representation of programs.",
      "Program synthesis is an important and challenging research area, and thus I find the problem being solved important.",
      "Technique is illustrated on a simple (Karel) tasks which might seem insufficient, but the program synthesis field is still at the stage where small problems are hard to solve, thus I find the choice appropriate.",
      "Paper is well written and easy to follow. In addition, authors provide extensive appendix and accompanying web page with useful information.",
      "Figure 2 is very informative. I would suggest extending the caption of the figure so it is more self-contained.",
      "I understood different parts of the figure only when I thoroughly read the paper.",
      "In the future, it would be good to evaluate the approach on tasks that are outside of the Karel domain.",
      "I do not have a good track of other approaches that can be used for synthesizing Karel programs, and thus am not certain if all relevant approaches are included in the comparison.",
      "Have you considered different ways of generating programs than pure random generation? Are there many programs that are 'not interesting' when performing random generation?",
      "Program Embedding Space Smoothness. Is there a specific reason why embedding space search is performed on the train/val set, vs test set? Does the same trend apply to the test set?",
      "In Table 2, do results represent percent of times that execution traces of two programs match (averaged across program pairs)? I understand that Rmat is defined as number of times traces match, not percent of times.",
      "equation 4 (latent behavior reconstruction loss): Loss is referred to as a cross entropy loss. However, EXECt(ro) seems incorrect as it's constant in the inner sum. I assume it should be 1 in a case of the executed action, and 0 otherwise?",
      "Line 233: 'shown in Figure 6'. This figure is not in the main text."
    ]
  },
  {
    "paper_id": "2108.13643v4",
    "submission_id": "wP9twkexC3V",
    "submission_title": "Learning to Synthesize Programs as Interpretable and Generalizable Policies",
    "review_id": "aOmBPgXfdp",
    "input": {
      "title": "Learning to Synthesize Programs as Interpretable and Generalizable Policies",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper's pros (thoroughly done scientific experiments, a different perspective on how to build generalizable policies for MDPs, and considered framing and discussion pointing out its own limitations) slightly outweigh its cons (missing related work from classical planning, confusion about the possibility for loops in decision trees, and statistically borderline results in some experiments)\n- and I believe this paper presents a reasonable scientific effort that will be interesting for a subset of the NeurIPS community.\n- The authors do a reasonable job of situating the work with respect to other efforts to synthesize programmatic policies from deep RL agents, program synthesis approaches, and limitations of finite state machines\n- The authors make statements about decision trees not handling loops several times in the paper, but that is a somewhat misleading statement.\n- It is possible to include loops in decision trees, but these loops must be encapsulated differently within the DSL (see Silver et al, AAAI 2020 for an example where they use a \u201cscanning\u201d function that operates like a while loop within a decision tree context).\n- There is a missing body of work from classical planning on synthesizing policies as programs in these same structures, two references below\n- I appreciated the thoroughness of ablations covering all main aspects of the program embedding learning, and the method was (mostly) explained clearly\n- I would have liked to see a little more discussion on why programs specifically vs. hierarchical policies vs. abstract action spaces, and how this kind of approach would be expected to work for problems that are not specifically designed for program synthesis techniques\n- However I recognize there isn\u2019t too much space and the authors alluded to this in the results sections.\n- many of the results are statistically insignificant given the enormous standard deviations in the tables, especially in the program reconstruction\n- It would have been nice to get some insight for why DRL-abs does not always perform better than DRL, as well as how these models were trained/how their parameters were validated\n- Why can VIPER not solve the generalization task? If it\u2019s also operating on the abstract space, I would have thought it should be invariant to the grid size since it will only have information about objects in the environment?\n- A simple way to keep the observation size the same for DRL between different problem sizes, which would also be a more fair comparison to the LEAPS model, would be to use a fully connected network (Long* et al., 2015) as the policy\n- The authors included exceptionally extensive supplementary material (31 pages!) with some nice visualizations of the learned program embeddings, extra details needed to reproduce the main experiments, extra experiments on transfer to unseen configurations of KAREL tasks, and code\n- I think details about the RL aspect of the test tasks needs to be made very clear\n- Why did the authors only evaluate generalization on StairClimber and Maze?\n- It should be trivial to expand all of the problems to larger grids and it seems a bit weird to pick only 2",
    "review_points_list": [
      "The paper's pros (thoroughly done scientific experiments, a different perspective on how to build generalizable policies for MDPs, and considered framing and discussion pointing out its own limitations) slightly outweigh its cons (missing related work from classical planning, confusion about the possibility for loops in decision trees, and statistically borderline results in some experiments)",
      "and I believe this paper presents a reasonable scientific effort that will be interesting for a subset of the NeurIPS community.",
      "The authors do a reasonable job of situating the work with respect to other efforts to synthesize programmatic policies from deep RL agents, program synthesis approaches, and limitations of finite state machines",
      "The authors make statements about decision trees not handling loops several times in the paper, but that is a somewhat misleading statement.",
      "It is possible to include loops in decision trees, but these loops must be encapsulated differently within the DSL (see Silver et al, AAAI 2020 for an example where they use a \u201cscanning\u201d function that operates like a while loop within a decision tree context).",
      "There is a missing body of work from classical planning on synthesizing policies as programs in these same structures, two references below",
      "I appreciated the thoroughness of ablations covering all main aspects of the program embedding learning, and the method was (mostly) explained clearly",
      "I would have liked to see a little more discussion on why programs specifically vs. hierarchical policies vs. abstract action spaces, and how this kind of approach would be expected to work for problems that are not specifically designed for program synthesis techniques",
      "However I recognize there isn\u2019t too much space and the authors alluded to this in the results sections.",
      "many of the results are statistically insignificant given the enormous standard deviations in the tables, especially in the program reconstruction",
      "It would have been nice to get some insight for why DRL-abs does not always perform better than DRL, as well as how these models were trained/how their parameters were validated",
      "Why can VIPER not solve the generalization task? If it\u2019s also operating on the abstract space, I would have thought it should be invariant to the grid size since it will only have information about objects in the environment?",
      "A simple way to keep the observation size the same for DRL between different problem sizes, which would also be a more fair comparison to the LEAPS model, would be to use a fully connected network (Long* et al., 2015) as the policy",
      "The authors included exceptionally extensive supplementary material (31 pages!) with some nice visualizations of the learned program embeddings, extra details needed to reproduce the main experiments, extra experiments on transfer to unseen configurations of KAREL tasks, and code",
      "I think details about the RL aspect of the test tasks needs to be made very clear",
      "Why did the authors only evaluate generalization on StairClimber and Maze?",
      "It should be trivial to expand all of the problems to larger grids and it seems a bit weird to pick only 2"
    ]
  },
  {
    "paper_id": "2108.13643v4",
    "submission_id": "wP9twkexC3V",
    "submission_title": "Learning to Synthesize Programs as Interpretable and Generalizable Policies",
    "review_id": "NeTLmY8v8Pi",
    "input": {
      "title": "Learning to Synthesize Programs as Interpretable and Generalizable Policies",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This is a very substantial and impressive piece of work.\n- Program synthesis is a very promising avenue for building RL agents that achieve better generalisation, and whose representations are humanly interpretable.\n- A major accomplishment of this paper is to learn embeddings of programs (in a variant of the Karel language) using a VAE with a recurrent encoder and decoder and three different losses.\n- The authors carry out an extensive evaluation, with careful ablations, and show the effectiveness of the approach on a number of (admittedly quite simple) RL tasks.\n- The most important result, to my mind, comes towards the end of the main text, which is to show that learned programs generalise to out-of-distribution grid sizes, where other approaches fail.\n- The paper is clearly written and logically organised, although the method is complex, which means that a lot of referring to the Appendix is needed to follow it.\n- Extensive material is supplied in the Appendix to back up the main paper.\n- There are quite a few issues in the definition of the DSL in Figure 1.\n- \u201cwhile(b)\u201d should be \u201cwhile(b): s\u201d.\n- the definition of \u201cPerception\u201d is, at present, unused.\n- I suspect the authors meant to write \u201cPercept h\u201d rather than \u201cPerception h\u201d, and to write \u201cpercept h\u201d in the definition of a \u201cCondition\u201d.\n- the definition of  \u201cCondition\u201d should perhaps be simply \u201cpercept | not percept\u201d.\n- Don\u2019t you need some brackets in the grammar?\n- Otherwise how do you distinguish \u201cwhile(B): (S1 ; S2)\u201d from \u201c(while(B): S1) ; S2\u201d?\n- It\u2019s a minor thing, but I feel the DSL grammar in Fig. 1 should be made to match this.\n- It\u2019s really a syntactic variant of Karel.\n- Section 4.1: I was very curious, at this point, to know what the architecture of q_phi and p_theta was.\n- It took me a while to hunt them down in the Appendix (Section F6).\n- A pointer to this material in the main text (Section 4.1) would be helpful.\n- In the Appendix (Section F6), you state \u201cwe utilize a syntax checker \u2026 at the output of the decoder to limit predictions to syntactically valid tokens\u201d.\n- How do you do this? Does the training loop just skip to the next sample if a syntactically incorrect program is generated?\n- This can\u2019t be right? How do you use the syntax check?\n- How do you sample from the set of possible programs in order to learn the program embedding?\n- Do they all carry out meaningful behaviours?\n- Do they all terminate?\n- Lines 81-82: \u201cThis limit the set of synthesizable programs\u201d -> \u201cThis limits the set of synthesizable programs\u201d.\n- Lines 108-109: \u201cview this objective is a special case\u201d -> \u201cview this objective as a special case\u201d.\n- Figure 3 caption: \u201ctasks that demands certain behaviors\u201d -> \u201ctasks that demand certain behaviors\u201d.\n- Line 166: \u201c through supervised instead of RL gradients\u201d -> \u201c through supervised learning instead of RL gradients\u201d (presumably)",
    "review_points_list": [
      "This is a very substantial and impressive piece of work.",
      "Program synthesis is a very promising avenue for building RL agents that achieve better generalisation, and whose representations are humanly interpretable.",
      "A major accomplishment of this paper is to learn embeddings of programs (in a variant of the Karel language) using a VAE with a recurrent encoder and decoder and three different losses.",
      "The authors carry out an extensive evaluation, with careful ablations, and show the effectiveness of the approach on a number of (admittedly quite simple) RL tasks.",
      "The most important result, to my mind, comes towards the end of the main text, which is to show that learned programs generalise to out-of-distribution grid sizes, where other approaches fail.",
      "The paper is clearly written and logically organised, although the method is complex, which means that a lot of referring to the Appendix is needed to follow it.",
      "Extensive material is supplied in the Appendix to back up the main paper.",
      "There are quite a few issues in the definition of the DSL in Figure 1.",
      "\u201cwhile(b)\u201d should be \u201cwhile(b): s\u201d.",
      "the definition of \u201cPerception\u201d is, at present, unused.",
      "I suspect the authors meant to write \u201cPercept h\u201d rather than \u201cPerception h\u201d, and to write \u201cpercept h\u201d in the definition of a \u201cCondition\u201d.",
      "the definition of  \u201cCondition\u201d should perhaps be simply \u201cpercept | not percept\u201d.",
      "Don\u2019t you need some brackets in the grammar?",
      "Otherwise how do you distinguish \u201cwhile(B): (S1 ; S2)\u201d from \u201c(while(B): S1) ; S2\u201d?",
      "It\u2019s a minor thing, but I feel the DSL grammar in Fig. 1 should be made to match this.",
      "It\u2019s really a syntactic variant of Karel.",
      "Section 4.1: I was very curious, at this point, to know what the architecture of q_phi and p_theta was.",
      "It took me a while to hunt them down in the Appendix (Section F6).",
      "A pointer to this material in the main text (Section 4.1) would be helpful.",
      "In the Appendix (Section F6), you state \u201cwe utilize a syntax checker \u2026 at the output of the decoder to limit predictions to syntactically valid tokens\u201d.",
      "How do you do this? Does the training loop just skip to the next sample if a syntactically incorrect program is generated?",
      "This can\u2019t be right? How do you use the syntax check?",
      "How do you sample from the set of possible programs in order to learn the program embedding?",
      "Do they all carry out meaningful behaviours?",
      "Do they all terminate?",
      "Lines 81-82: \u201cThis limit the set of synthesizable programs\u201d -> \u201cThis limits the set of synthesizable programs\u201d.",
      "Lines 108-109: \u201cview this objective is a special case\u201d -> \u201cview this objective as a special case\u201d.",
      "Figure 3 caption: \u201ctasks that demands certain behaviors\u201d -> \u201ctasks that demand certain behaviors\u201d.",
      "Line 166: \u201c through supervised instead of RL gradients\u201d -> \u201c through supervised learning instead of RL gradients\u201d (presumably)"
    ]
  },
  {
    "paper_id": "2108.13643v4",
    "submission_id": "wP9twkexC3V",
    "submission_title": "Learning to Synthesize Programs as Interpretable and Generalizable Policies",
    "review_id": "sQhjVkaEI9A",
    "input": {
      "title": "Learning to Synthesize Programs as Interpretable and Generalizable Policies",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I enjoyed reading the manuscript and found some of the presented ideas quite interesting.\n- The proposed approach is capable of synthesizing programs from the ground up using a predefined DSL that contains loops, conditional statements and domain dependent actions and perceptions.\n- At the core of this novel capability is the set of behavioural losses used to train a variational autoencoder resulting in a latent space where programs with similar behaviors are grouped closer to each other.\n- The proposed program behavior loss is an obvious step towards building a program autoencoder, the latent behavior loss is a non-trivial addition which according to the ablation studies makes a sizeable contribution to the performance of the model.\n- How did you choose the architecture of the neural program executor module and were there any special considerations driven by the DSL and family of supported programs?\n- Once trained how closely did the neural program executor can actually match the execution of the ground truth program?\n- Why did you decide to use just actions? Wouldn't action-state sequences provide a stronger supervision signal especially when only fragments of the execution of the reconstructed program semantically match the ground truth trace?\n- The analyses, experiments and reported results clearly demonstrate that LEAPS does provide RL agents with the capability to learn programmatic policies that can even generalize to larger worlds.\n- However, there are a few more results which may be reported that I think would increase the quality of the paper:\n- Traversals of the program latent space and visualizing interpolations between different programs.\n- More explicit information about the computational resources and time needed to run the various experiments.\n- At least one plot showing how the best-found program evolves over the course of searching - complexity and losses.\n- In figure 15 in the appendix the CEM search is described as converging to the ground truth solution, but the population of candidate solutions in fact passes right by the ground truth and never actually returns to it.\n- Can you explain this phenomena?",
    "review_points_list": [
      "I enjoyed reading the manuscript and found some of the presented ideas quite interesting.",
      "The proposed approach is capable of synthesizing programs from the ground up using a predefined DSL that contains loops, conditional statements and domain dependent actions and perceptions.",
      "At the core of this novel capability is the set of behavioural losses used to train a variational autoencoder resulting in a latent space where programs with similar behaviors are grouped closer to each other.",
      "The proposed program behavior loss is an obvious step towards building a program autoencoder, the latent behavior loss is a non-trivial addition which according to the ablation studies makes a sizeable contribution to the performance of the model.",
      "How did you choose the architecture of the neural program executor module and were there any special considerations driven by the DSL and family of supported programs?",
      "Once trained how closely did the neural program executor can actually match the execution of the ground truth program?",
      "Why did you decide to use just actions? Wouldn't action-state sequences provide a stronger supervision signal especially when only fragments of the execution of the reconstructed program semantically match the ground truth trace?",
      "The analyses, experiments and reported results clearly demonstrate that LEAPS does provide RL agents with the capability to learn programmatic policies that can even generalize to larger worlds.",
      "However, there are a few more results which may be reported that I think would increase the quality of the paper:",
      "Traversals of the program latent space and visualizing interpolations between different programs.",
      "More explicit information about the computational resources and time needed to run the various experiments.",
      "At least one plot showing how the best-found program evolves over the course of searching - complexity and losses.",
      "In figure 15 in the appendix the CEM search is described as converging to the ground truth solution, but the population of candidate solutions in fact passes right by the ground truth and never actually returns to it.",
      "Can you explain this phenomena?"
    ]
  },
  {
    "paper_id": "2106.13021v1",
    "submission_id": "x_sdq4ZYSOl",
    "submission_title": "Improved Regret Bounds for Tracking Experts with Memory",
    "review_id": "94tdQ_Vl5hb",
    "input": {
      "title": "Improved Regret Bounds for Tracking Experts with Memory",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well-written and easy to read.\n- The main concerns I have are about originality and result' significance.\n- 1. The contribution for the linear-time projection algorithm 3. As the paper points out, it is based on the prior work when the box constraint lower bound is universal over different experts.\n- But for this paper's algorithm, it needs to have different lower bounds for different experts.\n- Algorithm 3 modifies the prior work and solve this problem.\n- But the difficulty of it is debatable.\n- Also, I don't see any new insights from Algorithm 3 as well.\n- 2. The contribution for the Algorithm 1&2.\n- As pointed out in the paper, this algorithm is based on prior works ideas in Eq.(12) and the partition specialists Markov chain update in [26].\n- The update rule in Algorithm 1&2 step 9 seems to be from the [26]'s Markov chain update and just generalizes the chain update.\n- Because the original inefficient algorithm from [4] has the observations of Eq.(12) (which is the kind of box constraint projection), and the follow-up work [26] proposed an efficient algorithm with the Markov chain update (which is the Markov chain update rule idea for Algorithm 1&2 step 9).\n- Based on the above arguments, there is no surprise that the algorithm 1&2 could have a mixing scheme MPP explanation in Section 4.\n- 3. The comparison in Figure 1 is unfair.\n- For the result in this paper, it depends on the tuning parameters m (the number of unique experts) and the k (the number of switches).\n- And this paper's result in Figure 1 depends on this prior knowledge, while the prior work [26] does not need such information, which explains the reason to have increasing values for MPP and Partition Specialists.\n- In other words, this paper's claim on having better theoretical results out of the range m<k is not accurate.\n- If we only consider the m<k case, the theoretical improvement is really minimal, only a constant term improvement.\n- Thanks the author/s for the detailed explanation on my initial reviews.\n- After checking the work [26] more carefully, I agree with the author/s that the comparison in Figure 1 is fair.\n- However, for Algorithm 3's contribution on the efficient linear-time projection, I am not convinced that its contribution is significant enough given the prior work's efficient algorithm.\n- For my second concern on Algorithm 1&2 and the reply from the author/s, I totally agree that Algorithm 1&2 are not directly from [26].\n- Although we could put the correspondence between P (P_ww, P_ws, P_sw, P_ss) from [26] and \\theta, \\alpha from this paper, and we will at least achieve the performance guarantee from [26], the paper's contribution about the revelation of the Markov prior over partition specialists corresponding to a geometrically-decaying mixing scheme is not trivial.",
    "review_points_list": [
      "The paper is well-written and easy to read.",
      "The main concerns I have are about originality and result' significance.",
      "1. The contribution for the linear-time projection algorithm 3. As the paper points out, it is based on the prior work when the box constraint lower bound is universal over different experts.",
      "But for this paper's algorithm, it needs to have different lower bounds for different experts.",
      "Algorithm 3 modifies the prior work and solve this problem.",
      "But the difficulty of it is debatable.",
      "Also, I don't see any new insights from Algorithm 3 as well.",
      "2. The contribution for the Algorithm 1&2.",
      "As pointed out in the paper, this algorithm is based on prior works ideas in Eq.(12) and the partition specialists Markov chain update in [26].",
      "The update rule in Algorithm 1&2 step 9 seems to be from the [26]'s Markov chain update and just generalizes the chain update.",
      "Because the original inefficient algorithm from [4] has the observations of Eq.(12) (which is the kind of box constraint projection), and the follow-up work [26] proposed an efficient algorithm with the Markov chain update (which is the Markov chain update rule idea for Algorithm 1&2 step 9).",
      "Based on the above arguments, there is no surprise that the algorithm 1&2 could have a mixing scheme MPP explanation in Section 4.",
      "3. The comparison in Figure 1 is unfair.",
      "For the result in this paper, it depends on the tuning parameters m (the number of unique experts) and the k (the number of switches).",
      "And this paper's result in Figure 1 depends on this prior knowledge, while the prior work [26] does not need such information, which explains the reason to have increasing values for MPP and Partition Specialists.",
      "In other words, this paper's claim on having better theoretical results out of the range m<k is not accurate.",
      "If we only consider the m<k case, the theoretical improvement is really minimal, only a constant term improvement.",
      "Thanks the author/s for the detailed explanation on my initial reviews.",
      "After checking the work [26] more carefully, I agree with the author/s that the comparison in Figure 1 is fair.",
      "However, for Algorithm 3's contribution on the efficient linear-time projection, I am not convinced that its contribution is significant enough given the prior work's efficient algorithm.",
      "For my second concern on Algorithm 1&2 and the reply from the author/s, I totally agree that Algorithm 1&2 are not directly from [26].",
      "Although we could put the correspondence between P (P_ww, P_ws, P_sw, P_ss) from [26] and \\theta, \\alpha from this paper, and we will at least achieve the performance guarantee from [26], the paper's contribution about the revelation of the Markov prior over partition specialists corresponding to a geometrically-decaying mixing scheme is not trivial."
    ]
  },
  {
    "paper_id": "2106.13021v1",
    "submission_id": "x_sdq4ZYSOl",
    "submission_title": "Improved Regret Bounds for Tracking Experts with Memory",
    "review_id": "GrVrbnWq9Q",
    "input": {
      "title": "Improved Regret Bounds for Tracking Experts with Memory",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper discusses fundamental questions in Online Learning.\n- The suggested algorithm improves upon previous results while introducing new techniques that seem to be useful in other contexts as well.\n- The paper is very clear and easy to follow.\n- The authors described thoroughly previous results and their connection to their paper.\n- who is H in (3) and (9)?",
    "review_points_list": [
      "The paper discusses fundamental questions in Online Learning.",
      "The suggested algorithm improves upon previous results while introducing new techniques that seem to be useful in other contexts as well.",
      "The paper is very clear and easy to follow.",
      "The authors described thoroughly previous results and their connection to their paper.",
      "who is H in (3) and (9)?"
    ]
  },
  {
    "paper_id": "2106.13021v1",
    "submission_id": "x_sdq4ZYSOl",
    "submission_title": "Improved Regret Bounds for Tracking Experts with Memory",
    "review_id": "4AEkbWNjpjC",
    "input": {
      "title": "Improved Regret Bounds for Tracking Experts with Memory",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The significance of the paper is mainly in introducing the first efficient MPP algorithm to match (actually improve) the state of the art regret bound for the setting of switching experts with memory.\n- It also introduces an efficient algorithm for computing exact relative-entropy projections into entry-wise non-uniform lower-constrained simplex, that is then used as part of an new efficient projection-based algorithm for the setting, achieving (actually improving) the SOTA regret bound.\n- The paper also suggests (Theorem 4) the advantage of the projections-based algorithm over the MPP variant for settings with switching costs.\n- The presentation of the material is clear and the paper is easy to follow.\n- Relevant references are provided and the contributions of the paper over the state of the art and related results from relevant domains are explicitly stated.\n- I do have a couple of comments/questions nevertheless:\n- To assess the significance of the improvement in the regret bound (the discussion around line 250) it would be helpful to also refer to a relevant lower bound on the achievable regret.\n- The way I see the flow of ideas in the paper, it is first established that for a projections-based algorithm to be efficient two elements are needed - an efficient computation of the projection, and an efficient computation of $\beta_i$ (line 176).\n- The paper then proceeds to implement an efficient projections-based scheme, and its (efficient) MPP equivalent (section 4) having an explicit formulation of the $\beta$ updates.\n- My question is going back to (12), and comparing it to the PoDS-$\theta$ rule (15).\n- This should 'close the loop' in a sense, providing an efficient formulation of a solution to (12) (which is impossible in general) for the structure introduced by the PoDS-$\theta$ algorithm, and using the explicit form of (20).\n- Finally, a few suggestions/typos:\n- Typo: replace $v_i$ in line 67.\n- Clarify what is meant by 'absolute loss' in line 70.\n- Should be $\text{ln} nT$ in line 79.\n- Include $k=40$ in the plot of Figure 1, not only at the caption.",
    "review_points_list": [
      "The significance of the paper is mainly in introducing the first efficient MPP algorithm to match (actually improve) the state of the art regret bound for the setting of switching experts with memory.",
      "It also introduces an efficient algorithm for computing exact relative-entropy projections into entry-wise non-uniform lower-constrained simplex, that is then used as part of an new efficient projection-based algorithm for the setting, achieving (actually improving) the SOTA regret bound.",
      "The paper also suggests (Theorem 4) the advantage of the projections-based algorithm over the MPP variant for settings with switching costs.",
      "The presentation of the material is clear and the paper is easy to follow.",
      "Relevant references are provided and the contributions of the paper over the state of the art and related results from relevant domains are explicitly stated.",
      "I do have a couple of comments/questions nevertheless:",
      "To assess the significance of the improvement in the regret bound (the discussion around line 250) it would be helpful to also refer to a relevant lower bound on the achievable regret.",
      "The way I see the flow of ideas in the paper, it is first established that for a projections-based algorithm to be efficient two elements are needed - an efficient computation of the projection, and an efficient computation of $\beta_i$ (line 176).",
      "The paper then proceeds to implement an efficient projections-based scheme, and its (efficient) MPP equivalent (section 4) having an explicit formulation of the $\beta$ updates.",
      "My question is going back to (12), and comparing it to the PoDS-$\theta$ rule (15).",
      "This should 'close the loop' in a sense, providing an efficient formulation of a solution to (12) (which is impossible in general) for the structure introduced by the PoDS-$\theta$ algorithm, and using the explicit form of (20).",
      "Finally, a few suggestions/typos:",
      "Typo: replace $v_i$ in line 67.",
      "Clarify what is meant by 'absolute loss' in line 70.",
      "Should be $\text{ln} nT$ in line 79.",
      "Include $k=40$ in the plot of Figure 1, not only at the caption."
    ]
  },
  {
    "paper_id": "2005.03084v1",
    "submission_id": "wEOlVzVhMW_",
    "submission_title": "Beware of the Simulated DAG! Causal Discovery Benchmarks May Be Easy to Game",
    "review_id": "n-KxnUDOp8H",
    "input": {
      "title": "Beware of the Simulated DAG! Causal Discovery Benchmarks May Be Easy to Game",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is very well written and a pleasure to read.\n- The authors shed some new light on current causal structure learning algorithms by introducing the intuitive concept of varsortability.\n- They show that varsortability is high in common simulation schemes used for benchmarking causal structure learning algorithms.\n- Interestingly, they show that high varsortability may still be exploited after data standardization and may explain why certain continuous structure learning algorithms work so well.\n- They motivate this possible explanation by matching the performance of their algorithm sortnregres to other algorithms.\n- These results, however, do not imply, or proof, that varsortability is a 'causal' explanation of why other continuous learning algorithms work so well in the presence of high varsortability.\n- In Section 3.4 the authors give a heuristic argument why this is the case, but the paper would be much stronger if the authors could actually proof this, and state precisely under which circumstances this would hold.\n- Part of the arguments of this section could I think be improved upon.\n- For example, the authors state that: - line 239: 'We expect the residuals after the first gradient step ... to be larger ...'\n- line 254: 'b) why performance changes once data is standardized ... causal order.' without further explanation.\n- It would be helpful if the authors could elaborate more on this.\n- Nevertheless, the concept of varsortability and the benchmarking results will still be a valuable contribution to NeurIPS.\n- Minor comments: - line 217-221: 'In general, ... causal order.': What motivates these claims? I think a reference would be appropriate.\n- line 226-229: 'We do not expect combinatorial ... to be dependent on data scale.'  Why is that?\n- line 310: 'are driven by': Really? Or should this read as 'may be driven by'?\n- line 292 'sortnregress': Why not emphasize more that this is a novel contribution?\n- Why Figure 1 only for ER-2 graphs and Table 2 only for ER-4 and SF-4 graphs?",
    "review_points_list": [
      "The paper is very well written and a pleasure to read.",
      "The authors shed some new light on current causal structure learning algorithms by introducing the intuitive concept of varsortability.",
      "They show that varsortability is high in common simulation schemes used for benchmarking causal structure learning algorithms.",
      "Interestingly, they show that high varsortability may still be exploited after data standardization and may explain why certain continuous structure learning algorithms work so well.",
      "They motivate this possible explanation by matching the performance of their algorithm sortnregres to other algorithms.",
      "These results, however, do not imply, or proof, that varsortability is a 'causal' explanation of why other continuous learning algorithms work so well in the presence of high varsortability.",
      "In Section 3.4 the authors give a heuristic argument why this is the case, but the paper would be much stronger if the authors could actually proof this, and state precisely under which circumstances this would hold.",
      "Part of the arguments of this section could I think be improved upon.",
      "For example, the authors state that: - line 239: 'We expect the residuals after the first gradient step ... to be larger ...'",
      "line 254: 'b) why performance changes once data is standardized ... causal order.' without further explanation.",
      "It would be helpful if the authors could elaborate more on this.",
      "Nevertheless, the concept of varsortability and the benchmarking results will still be a valuable contribution to NeurIPS.",
      "Minor comments: - line 217-221: 'In general, ... causal order.': What motivates these claims? I think a reference would be appropriate.",
      "line 226-229: 'We do not expect combinatorial ... to be dependent on data scale.'  Why is that?",
      "line 310: 'are driven by': Really? Or should this read as 'may be driven by'?",
      "line 292 'sortnregress': Why not emphasize more that this is a novel contribution?",
      "Why Figure 1 only for ER-2 graphs and Table 2 only for ER-4 and SF-4 graphs?"
    ]
  },
  {
    "paper_id": "2005.03084v1",
    "submission_id": "wEOlVzVhMW_",
    "submission_title": "Beware of the Simulated DAG! Causal Discovery Benchmarks May Be Easy to Game",
    "review_id": "xWd2uHmIRu",
    "input": {
      "title": "Beware of the Simulated DAG! Causal Discovery Benchmarks May Be Easy to Game",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Split the review into individual points or pieces\n- Each point should be a distinct comment, observation, strength, weakness or question",
    "review_points_list": [
      "Split the review into individual points or pieces",
      "Each point should be a distinct comment, observation, strength, weakness or question"
    ]
  },
  {
    "paper_id": "2009.09197v2",
    "submission_id": "wDJUUcCTNI2",
    "submission_title": "Weak-shot Fine-grained Classification via Similarity Transfer",
    "review_id": "VDoIQcuhBQ9",
    "input": {
      "title": "Weak-shot Fine-grained Classification via Similarity Transfer",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper proposes to utilize the easily available web data to learn novel fine-grained categories by transferring the pairwise semantic similarity from clean data to web data.\n- My concerns are as follows:\n- This paper holds the premise that most web images are with correct labels and utilize the proposed SimNet trained on clean data to filter out the noisy web data.\n- Does the proposed method still work when the crawled web data are very dirty? Corresponding experiments or theoretical analyses should be added.\n- When the training set is composed of the base training set and the novel training set, the classification accuracy drops a lot in section 5.10.\n- Respective classification results in the base test set and the novel test set should be given. Corresponding experiments and analyses should be added, which is essential for verifying the effectiveness of the proposed method in the real-world applications.\n- The authors should describe the difference between weak-shot learning and zero/few-shot learning more clearly.\n- Respective training and test stages should be presented for better understanding of readers.\n- More qualitative results about finding the outliers among the web data should be added to prove the effectiveness of the proposed method visually.\n- The layout of this paper should be carefully designed. For example, Figure 3, Figure 4 and their surrounding text should be reset for better readability.",
    "review_points_list": [
      "The paper proposes to utilize the easily available web data to learn novel fine-grained categories by transferring the pairwise semantic similarity from clean data to web data.",
      "My concerns are as follows:",
      "This paper holds the premise that most web images are with correct labels and utilize the proposed SimNet trained on clean data to filter out the noisy web data.",
      "Does the proposed method still work when the crawled web data are very dirty? Corresponding experiments or theoretical analyses should be added.",
      "When the training set is composed of the base training set and the novel training set, the classification accuracy drops a lot in section 5.10.",
      "Respective classification results in the base test set and the novel test set should be given. Corresponding experiments and analyses should be added, which is essential for verifying the effectiveness of the proposed method in the real-world applications.",
      "The authors should describe the difference between weak-shot learning and zero/few-shot learning more clearly.",
      "Respective training and test stages should be presented for better understanding of readers.",
      "More qualitative results about finding the outliers among the web data should be added to prove the effectiveness of the proposed method visually.",
      "The layout of this paper should be carefully designed. For example, Figure 3, Figure 4 and their surrounding text should be reset for better readability."
    ]
  },
  {
    "paper_id": "2009.09197v2",
    "submission_id": "wDJUUcCTNI2",
    "submission_title": "Weak-shot Fine-grained Classification via Similarity Transfer",
    "review_id": "LWYrhlBGzEz",
    "input": {
      "title": "Weak-shot Fine-grained Classification via Similarity Transfer",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors propose an interesting and practical task, and the authors present good baseline to address the problem.\n- The idea of similarity transfer is good and reasonable.\n- The use of SimNet, and the construction of the relation features is interesting.\n- Large number of experiments are conducted to verify different factors in the proposed method.\n- It is a complicated paper. The paper seems revised many times, but the presentation is not very effective in my point of view.\n- The main goal is to train a novel-category classifier using the regularizations obtained from clean base categories.\n- The presentation can be improved by first presenting the overall pipeline and then talk about Sec 4.2.\n- The regularizations terms should be discussed, such as how to obtain the similarity matrix.\n- The paper is more relevant to web supervision but not zero/few-shot learning.\n- The term 'weak-shot learning' is somehow confusing.\n- The proposed idea fundamentally work for general image classification problem but is restricted to fine-grained image classification.\n- It is suggested to first address a simple, general problem (general image classification), and then extend it to a more complicated task (fine-grained image classification).\n- The similarity transfer method can be applied to real-world problems, but is there any restriction?\n- The base and novel sets are disjoint in the experiments, but it implies there are requirements for the base and novel sets.\n- The base and novel sets must belong to the same meta-category, such as bird.\n- If we would like to train a novel bird classifier, but only CompCars dataset is available as the clean base set, the transferability may not hold.\n- The proposed task is too complicated, and the authors have to conduct very large amount of experiments to verify many components.\n- The proposed task is fine to reject, but the paper addresses an interesting problem and the proposed method is technically correct.\n- The paper is presenting in a way that is not easy to follow.\n- Both the proposed task and method are OK, but the paper is a borderline case.",
    "review_points_list": [
      "The authors propose an interesting and practical task, and the authors present good baseline to address the problem.",
      "The idea of similarity transfer is good and reasonable.",
      "The use of SimNet, and the construction of the relation features is interesting.",
      "Large number of experiments are conducted to verify different factors in the proposed method.",
      "It is a complicated paper. The paper seems revised many times, but the presentation is not very effective in my point of view.",
      "The main goal is to train a novel-category classifier using the regularizations obtained from clean base categories.",
      "The presentation can be improved by first presenting the overall pipeline and then talk about Sec 4.2.",
      "The regularizations terms should be discussed, such as how to obtain the similarity matrix.",
      "The paper is more relevant to web supervision but not zero/few-shot learning.",
      "The term 'weak-shot learning' is somehow confusing.",
      "The proposed idea fundamentally work for general image classification problem but is restricted to fine-grained image classification.",
      "It is suggested to first address a simple, general problem (general image classification), and then extend it to a more complicated task (fine-grained image classification).",
      "The similarity transfer method can be applied to real-world problems, but is there any restriction?",
      "The base and novel sets are disjoint in the experiments, but it implies there are requirements for the base and novel sets.",
      "The base and novel sets must belong to the same meta-category, such as bird.",
      "If we would like to train a novel bird classifier, but only CompCars dataset is available as the clean base set, the transferability may not hold.",
      "The proposed task is too complicated, and the authors have to conduct very large amount of experiments to verify many components.",
      "The proposed task is fine to reject, but the paper addresses an interesting problem and the proposed method is technically correct.",
      "The paper is presenting in a way that is not easy to follow.",
      "Both the proposed task and method are OK, but the paper is a borderline case."
    ]
  },
  {
    "paper_id": "2009.09197v2",
    "submission_id": "wDJUUcCTNI2",
    "submission_title": "Weak-shot Fine-grained Classification via Similarity Transfer",
    "review_id": "-EmSOmKBYwW",
    "input": {
      "title": "Weak-shot Fine-grained Classification via Similarity Transfer",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The idea of using web supervision is interesting and there are large-scale web-based datasets available, these are only a few relevant examples: https://paperswithcode.com/dataset/pinterest, https://arxiv.org/pdf/1611.08321.pdf, https://aclanthology.org/2021.naacl-main.473.pdf.\n- The main motivation of the work seems to be able to learn from web data and transfer the learnings to other datasets.\n- I do not believe the authors have adequately addressed the previous reviews\n- From the architectural standpoint, the novelty is very limited. A major contribution could have been a definition of new transfer task from the web data.\n- However, in my opinion the authors fail to design the experiments to prove the concept of transferrability from the web data.\n- In particular, I do not believe they use a large-scale web-based dataset as a base and then demonstrate successful transfer to another dataset.\n- The paper is not clearly written. The introduction is jumping around zero-/few- shot and web data concepts without ever clearly defining the use case that the authors want to address.\n- I cannot figure out the use case even after reading the entire article, because the authors claim that they can learn and transfer from the web data, but experiments do not consider a real-life web dataset at all.\n- The Problem Definition section provides a really short and abstract definition of the task.\n- In my opinion a detailed description of the real use case transitioning to its mathematical description would have done a much better job here.\n- The Experiments section has way too many subsections and it is very hard to navigate.\n- There is no clear message in the section and none of the sections really addresses the main question (according to my guess) whether web driven learning is viable in the context of the task that the authors consider.\n- The research questions that the authors want to answer in the section are not defined either, so it is really hard to understand the motivation behind ten different subsections of Section 5.\n- I believe the authors themselves do not see the forest behind the trees and it is even worse for the reader.\n- Please define your research questions and the message you would like to send with your research in a clear and concise way.\n- Definitely a reject.",
    "review_points_list": [
      "The idea of using web supervision is interesting and there are large-scale web-based datasets available, these are only a few relevant examples: https://paperswithcode.com/dataset/pinterest, https://arxiv.org/pdf/1611.08321.pdf, https://aclanthology.org/2021.naacl-main.473.pdf.",
      "The main motivation of the work seems to be able to learn from web data and transfer the learnings to other datasets.",
      "I do not believe the authors have adequately addressed the previous reviews",
      "From the architectural standpoint, the novelty is very limited. A major contribution could have been a definition of new transfer task from the web data.",
      "However, in my opinion the authors fail to design the experiments to prove the concept of transferrability from the web data.",
      "In particular, I do not believe they use a large-scale web-based dataset as a base and then demonstrate successful transfer to another dataset.",
      "The paper is not clearly written. The introduction is jumping around zero-/few- shot and web data concepts without ever clearly defining the use case that the authors want to address.",
      "I cannot figure out the use case even after reading the entire article, because the authors claim that they can learn and transfer from the web data, but experiments do not consider a real-life web dataset at all.",
      "The Problem Definition section provides a really short and abstract definition of the task.",
      "In my opinion a detailed description of the real use case transitioning to its mathematical description would have done a much better job here.",
      "The Experiments section has way too many subsections and it is very hard to navigate.",
      "There is no clear message in the section and none of the sections really addresses the main question (according to my guess) whether web driven learning is viable in the context of the task that the authors consider.",
      "The research questions that the authors want to answer in the section are not defined either, so it is really hard to understand the motivation behind ten different subsections of Section 5.",
      "I believe the authors themselves do not see the forest behind the trees and it is even worse for the reader.",
      "Please define your research questions and the message you would like to send with your research in a clear and concise way.",
      "Definitely a reject."
    ]
  },
  {
    "paper_id": "2009.09197v2",
    "submission_id": "vrXuRmaU_jM",
    "submission_title": "Weak-shot Fine-grained Classification via Similarity Transfer",
    "review_id": "M9-oGrK051",
    "input": {
      "title": "Weak-shot Fine-grained Classification via Similarity Transfer",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper demonstrates improved quality of performance on 3 datasets for fine-grained classification.\n- The problem set up is weak-shot where the base classes in the training set have clean samples while the novel classes have noisy samples from web search.\n- ResNet50 trained on ImageNet-1k is used as backbone.\n- There is no overlap between novel class categories and ImageNet-1k.\n- The paper uses a sample weighting scheme which gives low weights for potential outliers as measured by similarity between images by SimNet pre-trained on base training set.\n- The classifier is trained on novel training set using a blend of weighted classification loss and graph regularization loss.\n- The paper contains extensive experiments while the outcomes are obvious.\n- The paper was written with clarity with clear motivations and outcomes.\n- Novelty is low since the main contributions are sample weighting, graph regularization and use of machine learned similarity to improve precision of labels in noisy data.\n- Thanks to authors for their feedback - specifically response to Q2\n- The analysis does not give insights into performance of popular and rare classes.\n- Web search of rare class will give more noisy results than popular classes.\n- I would like to change my final rating from Marginally below the acceptance threshold to Marginally above the acceptance threshold",
    "review_points_list": [
      "The paper demonstrates improved quality of performance on 3 datasets for fine-grained classification.",
      "The problem set up is weak-shot where the base classes in the training set have clean samples while the novel classes have noisy samples from web search.",
      "ResNet50 trained on ImageNet-1k is used as backbone.",
      "There is no overlap between novel class categories and ImageNet-1k.",
      "The paper uses a sample weighting scheme which gives low weights for potential outliers as measured by similarity between images by SimNet pre-trained on base training set.",
      "The classifier is trained on novel training set using a blend of weighted classification loss and graph regularization loss.",
      "The paper contains extensive experiments while the outcomes are obvious.",
      "The paper was written with clarity with clear motivations and outcomes.",
      "Novelty is low since the main contributions are sample weighting, graph regularization and use of machine learned similarity to improve precision of labels in noisy data.",
      "Thanks to authors for their feedback - specifically response to Q2",
      "The analysis does not give insights into performance of popular and rare classes.",
      "Web search of rare class will give more noisy results than popular classes.",
      "I would like to change my final rating from Marginally below the acceptance threshold to Marginally above the acceptance threshold"
    ]
  },
  {
    "paper_id": "2009.09197v2",
    "submission_id": "vrXuRmaU_jM",
    "submission_title": "Weak-shot Fine-grained Classification via Similarity Transfer",
    "review_id": "UzXte_UQ76",
    "input": {
      "title": "Weak-shot Fine-grained Classification via Similarity Transfer",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The writing is good, with smooth logic and clear illustration.\n- The experiments are solid and sufficient to support the claim.\n- My major concern is also the motivation of the proposed setting.\n- If we can obtain the weakly supervised data from the web and the label accuracy is not so bad, then it's easy and cheap to clean the web dataset (For example, utilizing crowdsourcing).\n- Furthermore, for the application scenarios that truly need expert knowledge for human annotation such as intelligent medical, it's hard to collect the labeled data from the web.\n- Another concern is the ImageNet pre-train. It is not a standard practice in zero-shot and few-shot learning.\n- How about the performance without ImageNet pre-train? Is it fair to compare with the baseline methods?\n- Overall, the writing quality of this paper is good, but the proposed setting is not so practical and the methodological novelty is limited, so I vote negative to this paper.\n- There are a lot of experiments that are only shown in the appendix, so I suggest you move sections 5.8 - 5.10 to the appendix.\n- The authors provide a clear and well-written introduction to the topic.\n- The problem description is concise and relevant.\n- The method section could benefit from some more detail on the training process.\n- One major concern I have is the lack of robustness analysis.\n- The authors only report the results on three different datasets and do not consider the variability of the results.\n- This is particularly concerning given the potential real-world applications of the method.\n- Another concern is the choice of evaluation metrics.\n- The authors use a combination of accuracy, precision, and recall, but do not provide any justification for this choice.\n- This lack of transparency makes it difficult to understand the results and evaluate the performance of the method.\n- In addition, the paper would benefit from more visualizations.\n- While the text is clear, the figures and tables could provide a better understanding of the results.\n- Lastly, I would have liked to see more discussion on the limitations of the method and potential future directions.\n- The authors' main contribution is the development of a novel algorithm to solve the problem of clustering large datasets.\n- The algorithm is novel and shows promise, but the paper would benefit from more experimental results and a more detailed description of how the algorithm works.\n- One of the major concerns I have is that the algorithm is very sensitive to the choice of hyperparameters.\n- The authors do not provide any guidance on how to choose these hyperparameters, which could make it difficult for other researchers to reproduce the results.\n- Another major concern is the lack of comparison to other state-of-the-art algorithms for clustering large datasets.\n- The authors should include a comparison to the most relevant algorithms to validate their claim.\n- Furthermore, the evaluation metric used in the paper (Silhouette Coefficient) is not well-suited for this problem.\n- The Silhouette Coefficient is sensitive to the size of the clusters, which could lead to biased results.\n- In addition, the paper would benefit from more discussion on the limitations of the algorithm and potential future directions.\n- The paper presents an interesting solution for addressing the problem of class imbalance.\n- However, the authors could have done more to make the paper more accessible to readers without a background in machine learning.\n- The introduction is clear and concise, and the authors provide a good overview of the problem and existing solutions.\n- The methods section could be expanded to provide more detail on the implementation of the proposed solution.\n- One major concern I have is that the evaluation metric used is not clearly motivated.\n- The authors could have done more to explain why they chose this metric, and how it relates to the problem of class imbalance.\n- Another concern is that the results are not entirely convincing.\n- While the authors report some promising results, the improvements are not substantial enough to convince readers that the proposed solution is effective.\n- Finally, I would have liked to see more discussion on the limitations of the proposed solution and potential future directions.\n- The paper proposes a new approach to image classification, which is innovative and promising.\n- However, the evaluation metric used in the paper is not well-suited for this task.\n- One major concern I have is that the authors do not provide a clear explanation of how the model works.\n- While they provide a good overview of the approach, the details are not well-explained, which makes it difficult to understand the results.\n- Another concern is that the results are not entirely convincing.\n- While the authors report some promising results, the improvements are not substantial enough to convince readers that the proposed solution is effective.\n- Furthermore, I would have liked to see more discussion on the limitations of the proposed solution and potential future directions.",
    "review_points_list": [
      "The writing is good, with smooth logic and clear illustration.",
      "The experiments are solid and sufficient to support the claim.",
      "My major concern is also the motivation of the proposed setting.",
      "If we can obtain the weakly supervised data from the web and the label accuracy is not so bad, then it's easy and cheap to clean the web dataset (For example, utilizing crowdsourcing).",
      "Furthermore, for the application scenarios that truly need expert knowledge for human annotation such as intelligent medical, it's hard to collect the labeled data from the web.",
      "Another concern is the ImageNet pre-train. It is not a standard practice in zero-shot and few-shot learning.",
      "How about the performance without ImageNet pre-train? Is it fair to compare with the baseline methods?",
      "Overall, the writing quality of this paper is good, but the proposed setting is not so practical and the methodological novelty is limited, so I vote negative to this paper.",
      "There are a lot of experiments that are only shown in the appendix, so I suggest you move sections 5.8 - 5.10 to the appendix.",
      "The authors provide a clear and well-written introduction to the topic.",
      "The problem description is concise and relevant.",
      "The method section could benefit from some more detail on the training process.",
      "One major concern I have is the lack of robustness analysis.",
      "The authors only report the results on three different datasets and do not consider the variability of the results.",
      "This is particularly concerning given the potential real-world applications of the method.",
      "Another concern is the choice of evaluation metrics.",
      "The authors use a combination of accuracy, precision, and recall, but do not provide any justification for this choice.",
      "This lack of transparency makes it difficult to understand the results and evaluate the performance of the method.",
      "In addition, the paper would benefit from more visualizations.",
      "While the text is clear, the figures and tables could provide a better understanding of the results.",
      "Lastly, I would have liked to see more discussion on the limitations of the method and potential future directions.",
      "The authors' main contribution is the development of a novel algorithm to solve the problem of clustering large datasets.",
      "The algorithm is novel and shows promise, but the paper would benefit from more experimental results and a more detailed description of how the algorithm works.",
      "One of the major concerns I have is that the algorithm is very sensitive to the choice of hyperparameters.",
      "The authors do not provide any guidance on how to choose these hyperparameters, which could make it difficult for other researchers to reproduce the results.",
      "Another major concern is the lack of comparison to other state-of-the-art algorithms for clustering large datasets.",
      "The authors should include a comparison to the most relevant algorithms to validate their claim.",
      "Furthermore, the evaluation metric used in the paper (Silhouette Coefficient) is not well-suited for this problem.",
      "The Silhouette Coefficient is sensitive to the size of the clusters, which could lead to biased results.",
      "In addition, the paper would benefit from more discussion on the limitations of the algorithm and potential future directions.",
      "The paper presents an interesting solution for addressing the problem of class imbalance.",
      "However, the authors could have done more to make the paper more accessible to readers without a background in machine learning.",
      "The introduction is clear and concise, and the authors provide a good overview of the problem and existing solutions.",
      "The methods section could be expanded to provide more detail on the implementation of the proposed solution.",
      "One major concern I have is that the evaluation metric used is not clearly motivated.",
      "The authors could have done more to explain why they chose this metric, and how it relates to the problem of class imbalance.",
      "Another concern is that the results are not entirely convincing.",
      "While the authors report some promising results, the improvements are not substantial enough to convince readers that the proposed solution is effective.",
      "Finally, I would have liked to see more discussion on the limitations of the proposed solution and potential future directions.",
      "The paper proposes a new approach to image classification, which is innovative and promising.",
      "However, the evaluation metric used in the paper is not well-suited for this task.",
      "One major concern I have is that the authors do not provide a clear explanation of how the model works.",
      "While they provide a good overview of the approach, the details are not well-explained, which makes it difficult to understand the results.",
      "Another concern is that the results are not entirely convincing.",
      "While the authors report some promising results, the improvements are not substantial enough to convince readers that the proposed solution is effective.",
      "Furthermore, I would have liked to see more discussion on the limitations of the proposed solution and potential future directions."
    ]
  },
  {
    "paper_id": "2009.09197v2",
    "submission_id": "vrXuRmaU_jM",
    "submission_title": "Weak-shot Fine-grained Classification via Similarity Transfer",
    "review_id": "87EbQ2ho6er",
    "input": {
      "title": "Weak-shot Fine-grained Classification via Similarity Transfer",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The investigated scenario has not been considered before, which is also of practical significance.\n- This paper is well-motivated, well-organized, clearly written, and easy to follow.\n- The proposed solution is simple yet powerful, which is well-evaluated with extensive experiments.\n- Lack in discussion of pairwise similarity based methods in related work.\n- Are there any methods that also transfer such similarities?\n- What is the difference between them and the proposed one?\n- Considering that the key issue is the label noise of the novel category set, it could be better to model such an issue with mathematical language.\n- While the proposed solution is quite intuitive -- yet with strong performance -- the insights may be limited.\n- That is to say, the readers may obtain limited knowledge that can be 'transferred' to their own areas of interest.\n- Honestly, the authors should always bear in mind this ultimate standard, but I still think this is a good paper.",
    "review_points_list": [
      "The investigated scenario has not been considered before, which is also of practical significance.",
      "This paper is well-motivated, well-organized, clearly written, and easy to follow.",
      "The proposed solution is simple yet powerful, which is well-evaluated with extensive experiments.",
      "Lack in discussion of pairwise similarity based methods in related work.",
      "Are there any methods that also transfer such similarities?",
      "What is the difference between them and the proposed one?",
      "Considering that the key issue is the label noise of the novel category set, it could be better to model such an issue with mathematical language.",
      "While the proposed solution is quite intuitive -- yet with strong performance -- the insights may be limited.",
      "That is to say, the readers may obtain limited knowledge that can be 'transferred' to their own areas of interest.",
      "Honestly, the authors should always bear in mind this ultimate standard, but I still think this is a good paper."
    ]
  },
  {
    "paper_id": "2105.13462v2",
    "submission_id": "yAvCV6NwWQ",
    "submission_title": "On Linear Stability of SGD and Input-Smoothness of Neural Networks",
    "review_id": "pvf7m9rXrN",
    "input": {
      "title": "On Linear Stability of SGD and Input-Smoothness of Neural Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The article is well written, and the proofs are rigorous.\n- I carefully checked the proofs of Theorems 1-3, and they look fine.\n- On the other proofs I went over more generally, and they also seem good.\n- Why should we consider higher moments for linear stability? E.g., why second order is not sufficient to say that a minimum is stable?\n- If a minimum is not stable for some order but is stable in a lower order, what this tells us?\n- Can a minimum be stable for any order?\n- If so, does it have special properties?\n- The bounds proved by the multiplicative property, namely Theorem 4-7, can be loose.\n- For example, consider the simple case of a two-layer univariate network with ReLU activation (i.e. scalar input/output with a wide hidden layer).\n- Since ReLU is positive homogenous we can arbitrarily increase the $ \\ell_p $-norm of the first layer while preserving the function implemented by the network, and thus making the bounds trivial.\n- This is true for any network with ReLU activation (or its variants).\n- It is not true to say that SGD implicitly regulate the Sobolev semi-norm of the function implemented by the network, since there is no (proven) mechanism in SGD that keeps the the norm of the first layer small.\n- The authors claim that Corollary 3 is more accurate than previous known result, which is written in Proposition 1 (see row 235), however I did not see any explanation nor proof for this claim (maybe I have missed it...).\n- Most of the results hold only for the quadratic loss.\n- I think that Lemma 1 is used to prove necessity in the proof of Theorem 1, and not sufficiency.",
    "review_points_list": [
      "The article is well written, and the proofs are rigorous.",
      "I carefully checked the proofs of Theorems 1-3, and they look fine.",
      "On the other proofs I went over more generally, and they also seem good.",
      "Why should we consider higher moments for linear stability? E.g., why second order is not sufficient to say that a minimum is stable?",
      "If a minimum is not stable for some order but is stable in a lower order, what this tells us?",
      "Can a minimum be stable for any order?",
      "If so, does it have special properties?",
      "The bounds proved by the multiplicative property, namely Theorem 4-7, can be loose.",
      "For example, consider the simple case of a two-layer univariate network with ReLU activation (i.e. scalar input/output with a wide hidden layer).",
      "Since ReLU is positive homogenous we can arbitrarily increase the $ \\ell_p $-norm of the first layer while preserving the function implemented by the network, and thus making the bounds trivial.",
      "This is true for any network with ReLU activation (or its variants).",
      "It is not true to say that SGD implicitly regulate the Sobolev semi-norm of the function implemented by the network, since there is no (proven) mechanism in SGD that keeps the the norm of the first layer small.",
      "The authors claim that Corollary 3 is more accurate than previous known result, which is written in Proposition 1 (see row 235), however I did not see any explanation nor proof for this claim (maybe I have missed it...).",
      "Most of the results hold only for the quadratic loss.",
      "I think that Lemma 1 is used to prove necessity in the proof of Theorem 1, and not sufficiency."
    ]
  },
  {
    "paper_id": "2105.13462v2",
    "submission_id": "yAvCV6NwWQ",
    "submission_title": "On Linear Stability of SGD and Input-Smoothness of Neural Networks",
    "review_id": "15J4M1m340H",
    "input": {
      "title": "On Linear Stability of SGD and Input-Smoothness of Neural Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper examines theoretically how does SGD selects the global minima it converges to.\n- Specifically, the authors analyze the implicit regularization effect and generalization performance of the solution found by SGD using a linear stability analysis.\n- The paper main contributions are:\n- - The authors prove upper bounds on the gradients\u2019 moment at the solution found by SGD, assuming this solution is stable.\n- These conditions also include control on the flatness and non-uniformity.\n- This result provides a better characterization of the implicit bias of SGD.\n- The authors provide upper bounds for the Sobolev seminorm of the model function at stable SGD interpolating solutions.\n- This implies that the Sobolev seminorms of the model on the training data are regularized by the linear stability.\n- In addition, under some smoothness assumption, this result is extended to a neighborhood of the training data.\n- These results suggest a possible explanation for the good generalization of flat minima.\n- Under additional assumptions on the data distribution, the authors provide bounds on the generalization error and adversarial robustness.\n- I enjoyed reading the paper.\n- The paper is well written, the assumptions and results are clearly stated, and many explanations were provided throughout the paper.\n- Many of the upper bounds suggested in the paper include the norm of the first layer weights.\n- Can the author extend on the assumption that the input layer weights are not very large?\n- There is a typo in the title (Stocahstic --> Stochastic).\n- I think that adding \u201csharpness\u201d and \u201cnon-uniformity\u201d as formal definitions will make the paper a bit clearer (these terms were explained verbally but it is easy to miss this).\n- Thank you for the detailed rebuttal and for elaborating on the upper limit with experimental results.\n- This helped to elevate my concern.",
    "review_points_list": [
      "This paper examines theoretically how does SGD selects the global minima it converges to.",
      "Specifically, the authors analyze the implicit regularization effect and generalization performance of the solution found by SGD using a linear stability analysis.",
      "The paper main contributions are:",
      "- The authors prove upper bounds on the gradients\u2019 moment at the solution found by SGD, assuming this solution is stable.",
      "These conditions also include control on the flatness and non-uniformity.",
      "This result provides a better characterization of the implicit bias of SGD.",
      "The authors provide upper bounds for the Sobolev seminorm of the model function at stable SGD interpolating solutions.",
      "This implies that the Sobolev seminorms of the model on the training data are regularized by the linear stability.",
      "In addition, under some smoothness assumption, this result is extended to a neighborhood of the training data.",
      "These results suggest a possible explanation for the good generalization of flat minima.",
      "Under additional assumptions on the data distribution, the authors provide bounds on the generalization error and adversarial robustness.",
      "I enjoyed reading the paper.",
      "The paper is well written, the assumptions and results are clearly stated, and many explanations were provided throughout the paper.",
      "Many of the upper bounds suggested in the paper include the norm of the first layer weights.",
      "Can the author extend on the assumption that the input layer weights are not very large?",
      "There is a typo in the title (Stocahstic --> Stochastic).",
      "I think that adding \u201csharpness\u201d and \u201cnon-uniformity\u201d as formal definitions will make the paper a bit clearer (these terms were explained verbally but it is easy to miss this).",
      "Thank you for the detailed rebuttal and for elaborating on the upper limit with experimental results.",
      "This helped to elevate my concern."
    ]
  },
  {
    "paper_id": "2105.13462v2",
    "submission_id": "yAvCV6NwWQ",
    "submission_title": "On Linear Stability of SGD and Input-Smoothness of Neural Networks",
    "review_id": "YkGpNsXOCiR",
    "input": {
      "title": "On Linear Stability of SGD and Input-Smoothness of Neural Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The viewpoint presented in this work is novel and worthy of publication.\n- The key insight is that since the input $x$ and the neural network weights are first multiplied and then entered into the network, so regularity (stability) properties on $W$ can be transferred onto regularity (wideness/small Sobolev norm) properties with respect to $x$ is a very nice one.\n- Definition 5 seems to be incomplete; the relation between $W^*$ and $\tilde{W}^{\times k}_t$ is not completely specified.\n- The relation between $W^*$ and $\tilde{W}^{\times k}_t$ is that [W_t] is close to $W^*$\n- There is recent evidence that a connected set of global minima is a more accurate model.\n- Can the authors comment on how having a connected set of interpolating global minima may or may not affect the analysis?\n- I find the authors' introduction and problem formulation very clear and well motivated.\n- The explanation of the method and the experimental results are also well-written and easy to follow.\n- How do the different settings (batch size, embedding dimension, etc.) affect the performance of the model?\n- Are there any insights into the underlying mechanisms driving the results?\n- The paper would benefit from some visual aids, such as plots or figures, to help illustrate some of the results and concepts.\n- I appreciate the thoroughness and quality of the experimental setup.\n- The results demonstrate convincing evidence of the effectiveness of the proposed method.\n- Are there any tests to evaluate its performance on noisy or corrupted data?\n- The authors propose a novel algorithm, called Cluster-Margin, for active learning.\n- The algorithm has two stages: first, a set of cluster centers are selected, and then, a margin is computed for each data point and updated iteratively until convergence.\n- I find the algorithm and its variants to be innovative and interesting.\n- How do the authors guarantee that the cluster centers are optimal?\n- I would like to see more experimental results, such as the performance of the algorithm on different datasets and with varying parameters.\n- The authors claim that the proposed algorithm outperforms existing methods in various experiments.\n- While the results are impressive, I have some doubts about the robustness of the algorithm.\n- Are there any tests to evaluate its performance on different types of noisy data?\n- I also find that the paper could benefit from more details on the hyperparameter tuning process.\n- I have a few comments regarding the manuscript.\n- The title is a bit unclear; it does not accurately reflect the main contributions of the paper.\n- The abstract also needs to be rewritten to better capture the essence of the work.\n- The main body of the manuscript is well-written, but some of the sentences are a bit long and could be broken up for better readability.",
    "review_points_list": [
      "The viewpoint presented in this work is novel and worthy of publication.",
      "The key insight is that since the input $x$ and the neural network weights are first multiplied and then entered into the network, so regularity (stability) properties on $W$ can be transferred onto regularity (wideness/small Sobolev norm) properties with respect to $x$ is a very nice one.",
      "Definition 5 seems to be incomplete; the relation between $W^*$ and $\tilde{W}^{\times k}_t$ is not completely specified.",
      "The relation between $W^*$ and $\tilde{W}^{\times k}_t$ is that [W_t] is close to $W^*$",
      "There is recent evidence that a connected set of global minima is a more accurate model.",
      "Can the authors comment on how having a connected set of interpolating global minima may or may not affect the analysis?",
      "I find the authors' introduction and problem formulation very clear and well motivated.",
      "The explanation of the method and the experimental results are also well-written and easy to follow.",
      "How do the different settings (batch size, embedding dimension, etc.) affect the performance of the model?",
      "Are there any insights into the underlying mechanisms driving the results?",
      "The paper would benefit from some visual aids, such as plots or figures, to help illustrate some of the results and concepts.",
      "I appreciate the thoroughness and quality of the experimental setup.",
      "The results demonstrate convincing evidence of the effectiveness of the proposed method.",
      "Are there any tests to evaluate its performance on noisy or corrupted data?",
      "The authors propose a novel algorithm, called Cluster-Margin, for active learning.",
      "The algorithm has two stages: first, a set of cluster centers are selected, and then, a margin is computed for each data point and updated iteratively until convergence.",
      "I find the algorithm and its variants to be innovative and interesting.",
      "How do the authors guarantee that the cluster centers are optimal?",
      "I would like to see more experimental results, such as the performance of the algorithm on different datasets and with varying parameters.",
      "The authors claim that the proposed algorithm outperforms existing methods in various experiments.",
      "While the results are impressive, I have some doubts about the robustness of the algorithm.",
      "Are there any tests to evaluate its performance on different types of noisy data?",
      "I also find that the paper could benefit from more details on the hyperparameter tuning process.",
      "I have a few comments regarding the manuscript.",
      "The title is a bit unclear; it does not accurately reflect the main contributions of the paper.",
      "The abstract also needs to be rewritten to better capture the essence of the work.",
      "The main body of the manuscript is well-written, but some of the sentences are a bit long and could be broken up for better readability."
    ]
  },
  {
    "paper_id": "2106.10800v5",
    "submission_id": "wZrOOO9XBn",
    "submission_title": "Lossy Compression for Lossless Prediction",
    "review_id": "PkybgSQOLQl",
    "input": {
      "title": "Lossy Compression for Lossless Prediction",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Given that transfer learning is of great importance in machine learning, the task of compressing data only for certain downstream tasks is definitely worth exploring.\n- However, though the paper made a good effort to formulate this problem, I think the experiments used in the paper might be insufficient to demonstrate the effect of their proposed technique \u2014 performing data augmentation during training leads to better lossy compressors:\n- - The author claimed in the introduction that they aim to \u201censure good performance on any future tasks of interest\u201d. This setup was only tested in the CLIP experiment in Section 5.3, where the authors trained a compressor and validated on 8 datasets unseen during training. However, the good results may simply come from the fact that the latent representations of CLIP (a large pre-trained model analogous to BERT) already have a low bit-rate.\n- That is, training any lossy compressor with the latent representations as input could lead to similar rate gains.\n- To address this concern, I would recommend the authors to at least compare the bit-rate also with other modern lossy compressors trained on latent representations generated by CLIP.\n- It would also be great if the authors to demonstrate the performance gain provided by different data-augmentation techniques.\n- In general, only comparing with JPEG does not provide useful information about how good the proposed model is since the goal of JPEG is to compress images while not changing its visual appearance by too much.\n- - Need to justify the proposed models is not simply compressing the labels\n- For example, in the experiment in Section 5.2, performance drop and compression gain are compared.\n- However, even by simply compressing the labels, one can get zero decreases in test accuracy and achieve a much better compression gain.\n- The proposed models (VIC, BINCE) are of course not doing this explicitly.\n- However, I am a bit concerned that this could be accidentally done implicitly.\n- For example, consider an MLP with hidden layer size 32 - 16 - 8.\n- If the bottleneck is set at the layer with 32 hidden neurons, the bit-rate could be worse than when the bottleneck is set at the last layer (8 hidden neurons).\n- I think the authors should design a better evaluation metric to avoid the above trivial case.\n- - Overall, I like the high-level idea of the paper, but it seems hard for me to separate the cause of the bit-rate gain:\n- is it caused by the good latent representations learned by SSL models, or the proposed invariant compression technique plays a critical role there?\n- For example, if we have a powerful SSL model trained to classify ImageNet samples, then CIFAR10 can be faithfully solved only by looking at the 1000-class imagenet label.\n- I believe this can be a good paper if this concern is addressed, and I would be willing to increase my score if the authors convince me during rebuttal.",
    "review_points_list": [
      "Given that transfer learning is of great importance in machine learning, the task of compressing data only for certain downstream tasks is definitely worth exploring.",
      "However, though the paper made a good effort to formulate this problem, I think the experiments used in the paper might be insufficient to demonstrate the effect of their proposed technique \u2014 performing data augmentation during training leads to better lossy compressors:",
      "- The author claimed in the introduction that they aim to \u201censure good performance on any future tasks of interest\u201d. This setup was only tested in the CLIP experiment in Section 5.3, where the authors trained a compressor and validated on 8 datasets unseen during training. However, the good results may simply come from the fact that the latent representations of CLIP (a large pre-trained model analogous to BERT) already have a low bit-rate.",
      "That is, training any lossy compressor with the latent representations as input could lead to similar rate gains.",
      "To address this concern, I would recommend the authors to at least compare the bit-rate also with other modern lossy compressors trained on latent representations generated by CLIP.",
      "It would also be great if the authors to demonstrate the performance gain provided by different data-augmentation techniques.",
      "In general, only comparing with JPEG does not provide useful information about how good the proposed model is since the goal of JPEG is to compress images while not changing its visual appearance by too much.",
      "- Need to justify the proposed models is not simply compressing the labels",
      "For example, in the experiment in Section 5.2, performance drop and compression gain are compared.",
      "However, even by simply compressing the labels, one can get zero decreases in test accuracy and achieve a much better compression gain.",
      "The proposed models (VIC, BINCE) are of course not doing this explicitly.",
      "However, I am a bit concerned that this could be accidentally done implicitly.",
      "For example, consider an MLP with hidden layer size 32 - 16 - 8.",
      "If the bottleneck is set at the layer with 32 hidden neurons, the bit-rate could be worse than when the bottleneck is set at the last layer (8 hidden neurons).",
      "I think the authors should design a better evaluation metric to avoid the above trivial case.",
      "- Overall, I like the high-level idea of the paper, but it seems hard for me to separate the cause of the bit-rate gain:",
      "is it caused by the good latent representations learned by SSL models, or the proposed invariant compression technique plays a critical role there?",
      "For example, if we have a powerful SSL model trained to classify ImageNet samples, then CIFAR10 can be faithfully solved only by looking at the 1000-class imagenet label.",
      "I believe this can be a good paper if this concern is addressed, and I would be willing to increase my score if the authors convince me during rebuttal."
    ]
  },
  {
    "paper_id": "2106.10800v5",
    "submission_id": "wZrOOO9XBn",
    "submission_title": "Lossy Compression for Lossless Prediction",
    "review_id": "-Pm_oxP0u6",
    "input": {
      "title": "Lossy Compression for Lossless Prediction",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- 1. The idea is interesting and novel. Compared to other compression work that is aimed at reconstruction quality, the author focus on extracting critical (and of course compressible) information from source data; the extracted data can be applied to different downstream tasks without further fine-tuning.\n- 2. The author proposes 2 invariant neural compressors for this compression scheme; both of them show competitive rate-distortion (or rate-accuracy) results on different tasks.\n- 3. Theoretical Justification\n- In table 3. Higher $\beta$ should correspond to lower distortion, but the table shows higher distortion and lower rate?\n- I wonder how the augmentation methods can influence the rate-distortion performance? The tasks seem to be highly correlated to the augmentation methods we use. For image classification, we can easily use different transforms, but for tasks like image captioning, it could be hard to find the right way to augment the data.\n- The pseudocode for Algorithm 1 is not clear for me. line 5- line 7: $\tilde{\textbf x}$ and $\textbf x$ are not the same thing? To make sure if I understand correctly, $A(x)$ and $A(x^-_i)$ use the same augmentation method and a $x^+$ is augmented differently.",
    "review_points_list": [
      "1. The idea is interesting and novel. Compared to other compression work that is aimed at reconstruction quality, the author focus on extracting critical (and of course compressible) information from source data; the extracted data can be applied to different downstream tasks without further fine-tuning.",
      "2. The author proposes 2 invariant neural compressors for this compression scheme; both of them show competitive rate-distortion (or rate-accuracy) results on different tasks.",
      "3. Theoretical Justification",
      "In table 3. Higher $\beta$ should correspond to lower distortion, but the table shows higher distortion and lower rate?",
      "I wonder how the augmentation methods can influence the rate-distortion performance? The tasks seem to be highly correlated to the augmentation methods we use. For image classification, we can easily use different transforms, but for tasks like image captioning, it could be hard to find the right way to augment the data.",
      "The pseudocode for Algorithm 1 is not clear for me. line 5- line 7: $\tilde{\textbf x}$ and $\textbf x$ are not the same thing? To make sure if I understand correctly, $A(x)$ and $A(x^-_i)$ use the same augmentation method and a $x^+$ is augmented differently."
    ]
  },
  {
    "paper_id": "2106.10800v5",
    "submission_id": "wZrOOO9XBn",
    "submission_title": "Lossy Compression for Lossless Prediction",
    "review_id": "zo65jGcs0kU",
    "input": {
      "title": "Lossy Compression for Lossless Prediction",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think it is a novel idea to introduce a self-supervised approach to neural image compression for classification tasks and theoretical background is well described.\n- But I am curious about the following points.\n- - I don't know the unit of 'bit-rate' in table 3 (it does not seem to be bit per pixel, is it bit per image?). Please write a clear definition.\n- - I don't think this paper (the main paper) adequately describes how the quantizer is handled.\n- However, the Appendix describes the quantizer process with a linear transformation using the learnable parameter.\n- Also, you are probably using a uniform noise quantizer [24], but I think these need to be explained in the main paper.",
    "review_points_list": [
      "I think it is a novel idea to introduce a self-supervised approach to neural image compression for classification tasks and theoretical background is well described.",
      "But I am curious about the following points.",
      "- I don't know the unit of 'bit-rate' in table 3 (it does not seem to be bit per pixel, is it bit per image?). Please write a clear definition.",
      "- I don't think this paper (the main paper) adequately describes how the quantizer is handled.",
      "However, the Appendix describes the quantizer process with a linear transformation using the learnable parameter.",
      "Also, you are probably using a uniform noise quantizer [24], but I think these need to be explained in the main paper."
    ]
  },
  {
    "paper_id": "2106.10800v5",
    "submission_id": "wZrOOO9XBn",
    "submission_title": "Lossy Compression for Lossless Prediction",
    "review_id": "LJ7eApXqBh3",
    "input": {
      "title": "Lossy Compression for Lossless Prediction",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Although the paper is most similar in spirit to 'End-to-End Learning of Compressible Features' (Singh et. al., 2020), and in fact Singh et. al.'s method  can be seen as a special case of the proposed VIC method (where there is only one downstream task of interest and thus no data augmentation), the current paper broadens the scope considerably by considering lossy compression for a *collection* of related invariant tasks, and is therefore a novel and original contribution.\n- The paper is clearly written and well-organized.\n- The theoretical results appear to be rigorously derived (in the supplementary material).\n- However, the discussions in the experiments section leave a few things to be desired.\n- In section 5.2, the worse performance of VIC (e.g., its inability to achieve zero distortion) compared to BINCE can benefit from a better explanation;\n- And more generally, a comparison between the two formulations and discussions on their pros and cons would be beneficial.\n- The worse performance of VIC was attributed to the channel averaging operation of the ResNet18 encoder used;\n- However, since BINCE does not perform reconstructions (unlike VIC) and thus does not suffer from the poor encoder, it would make a more fair comparison by evaluating VIC performance using the compressed Z representation (with a separately trained predictor) as done for the evaluation of BINCE.\n- It would be reassuring to see that VIC is able to achieve comparable performance to BINCE, e.g., by increasing the expressivity of the variational family.\n- It's not clear how the performance of zero-shot compressor using a pre-trained SSL model compares to end-to-end training with the proposed method (either VIC or BINCE).\n- The already good zero-shot performance from fitting an entropy model to the latent representations of a pre-trained model (in section 5.2) seems to render end-to-end training with VIC or BINCE unnecessary.\n- It's not clear how the pretraining of CLIP fits into the BINCE framework (e.g., it's not clear what kind of data augmentation transform $A$ is used during training).\n- As far as I'm aware, this paper is the first to consider the problem of learned lossy compression in a multi-task setting, and lays a solid foundation for future work (both in theory and methods), thus represents a significant contribution.",
    "review_points_list": [
      "Although the paper is most similar in spirit to 'End-to-End Learning of Compressible Features' (Singh et. al., 2020), and in fact Singh et. al.'s method  can be seen as a special case of the proposed VIC method (where there is only one downstream task of interest and thus no data augmentation), the current paper broadens the scope considerably by considering lossy compression for a *collection* of related invariant tasks, and is therefore a novel and original contribution.",
      "The paper is clearly written and well-organized.",
      "The theoretical results appear to be rigorously derived (in the supplementary material).",
      "However, the discussions in the experiments section leave a few things to be desired.",
      "In section 5.2, the worse performance of VIC (e.g., its inability to achieve zero distortion) compared to BINCE can benefit from a better explanation;",
      "And more generally, a comparison between the two formulations and discussions on their pros and cons would be beneficial.",
      "The worse performance of VIC was attributed to the channel averaging operation of the ResNet18 encoder used;",
      "However, since BINCE does not perform reconstructions (unlike VIC) and thus does not suffer from the poor encoder, it would make a more fair comparison by evaluating VIC performance using the compressed Z representation (with a separately trained predictor) as done for the evaluation of BINCE.",
      "It would be reassuring to see that VIC is able to achieve comparable performance to BINCE, e.g., by increasing the expressivity of the variational family.",
      "It's not clear how the performance of zero-shot compressor using a pre-trained SSL model compares to end-to-end training with the proposed method (either VIC or BINCE).",
      "The already good zero-shot performance from fitting an entropy model to the latent representations of a pre-trained model (in section 5.2) seems to render end-to-end training with VIC or BINCE unnecessary.",
      "It's not clear how the pretraining of CLIP fits into the BINCE framework (e.g., it's not clear what kind of data augmentation transform $A$ is used during training).",
      "As far as I'm aware, this paper is the first to consider the problem of learned lossy compression in a multi-task setting, and lays a solid foundation for future work (both in theory and methods), thus represents a significant contribution."
    ]
  },
  {
    "paper_id": "1802.01365v1",
    "submission_id": "zMZPDwm3H3",
    "submission_title": "Learning the optimal Tikhonov regularizer for inverse problems",
    "review_id": "SIc8QIgUU_y",
    "input": {
      "title": "Learning the optimal Tikhonov regularizer for inverse problems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper considers solving the inverse problem with a quadratic regularizer (generalized Tikhonov regularization).\n- The problem is formulated rigorously in the context of functionals.\n- There are two parts of theoretical results provided by this paper.\n- Firstly, it shows that the optimal shifting and scaling parameters in the regularizer should be the mean and covariance of the true signal distribution.\n- Secondly, when the distribution is not available, the paper suggests two ways to learn those parameters from data and provides upper bounds for the excess risk.\n- The results are verified through experiments.\n- The paper shows the optimal parameters for the regularizer are the mean and covariance. By plugging them into the objective, it reduces to the objective of MAP, up to a scalar factor.\n- It would be better to discuss this connection in the paper.\n- Theorem 4.1 relies on the assumption (a), which introduces another Hilbert space H and corresponding maps j1 and j2.\n- It seems unnatural and abstract to me to introduce those notations even for the purpose of bounding covering numbers.\n- It would be better to discuss how this assumption fits into the practice.\n- It is interesting that the unsupervised method outperforms the supervised one in terms of both theory and simulation.\n- Considering that the supervised method requires additional data of y and more computation, the value of using the supervised method is further decreased.\n- The information from y or the error seems unnecessary in estimating h and B, while the paper doesn't provide any discussion on this.\n- In the numerical analysis, the paper only considers a simple case where A=I.\n- That seems not enough since A is really an important component of the inverse problem.\n- The experiments with a more general A are necessary and helpful in justifying the theoretical results.",
    "review_points_list": [
      "This paper considers solving the inverse problem with a quadratic regularizer (generalized Tikhonov regularization).",
      "The problem is formulated rigorously in the context of functionals.",
      "There are two parts of theoretical results provided by this paper.",
      "Firstly, it shows that the optimal shifting and scaling parameters in the regularizer should be the mean and covariance of the true signal distribution.",
      "Secondly, when the distribution is not available, the paper suggests two ways to learn those parameters from data and provides upper bounds for the excess risk.",
      "The results are verified through experiments.",
      "The paper shows the optimal parameters for the regularizer are the mean and covariance. By plugging them into the objective, it reduces to the objective of MAP, up to a scalar factor.",
      "It would be better to discuss this connection in the paper.",
      "Theorem 4.1 relies on the assumption (a), which introduces another Hilbert space H and corresponding maps j1 and j2.",
      "It seems unnatural and abstract to me to introduce those notations even for the purpose of bounding covering numbers.",
      "It would be better to discuss how this assumption fits into the practice.",
      "It is interesting that the unsupervised method outperforms the supervised one in terms of both theory and simulation.",
      "Considering that the supervised method requires additional data of y and more computation, the value of using the supervised method is further decreased.",
      "The information from y or the error seems unnecessary in estimating h and B, while the paper doesn't provide any discussion on this.",
      "In the numerical analysis, the paper only considers a simple case where A=I.",
      "That seems not enough since A is really an important component of the inverse problem.",
      "The experiments with a more general A are necessary and helpful in justifying the theoretical results."
    ]
  },
  {
    "paper_id": "1802.01365v1",
    "submission_id": "zMZPDwm3H3",
    "submission_title": "Learning the optimal Tikhonov regularizer for inverse problems",
    "review_id": "qdibMrKDta7",
    "input": {
      "title": "Learning the optimal Tikhonov regularizer for inverse problems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The main results of the paper are a generalization of well known results in finite dimensions to an infinite-dimensional settings.\n- The main ideas which underlies the proofs are also derived from the finite dimensional setting.\n- In order to find the LMMSE, the authors equate the Gateaux derivative to 0, instead of the 'regular' derivative, as is done in the classical proofs.\n- The results are not surprising and perhaps, one could claim, are not very exciting.\n- The move to infinite-dimensions has many technical difficulties and is a highly non-trivial task.\n- Special care must be taken when discussing the type of spaces involved in the problem, the type of linear operator between those spaces and even the form of admissible randomness.\n- The paper is well written, and the authors do a rather good job in motivating the formulation of the problem and the definitions.\n- The math itself is very elegant and it could even prove useful for other, similar, problems.\n- It can fit well with the theme of conference.\n- The style and presentation of the paper could be improved.\n- The analogy to the finite-dimensional case is important and is not highlighted enough in the paper.\n- Some of the results obtained in the paper transform into simple exercises in optimization, when one considers well posed problems in finite dimensions.\n- It would be beneficial to show (or at least state) those proofs in the paper, followed by a discussion of the technical difficulties which arise when one moves to infinite dimensions.\n- Nice math, hence my score.\n- It would be happy for some motivating examples where one would actually want to consider the specific problems introduced in the paper.\n- Can the authors comment on this point?\n- Presumably one also wants for the noise \u03b5 to be independent of x.\n- After reading Examples 2.3 I do not feel like I understand the problem better.\n- I feel that Remark 2.5 is very important and actually fundamental to the paper.\n- I do not understand the comment that K is not identified with K*.\n- Shouldn't it be v in K?\n- <Ax, v> should be <Ax, i(v)>.\n- 'to be at least as smoothing'.\n- I tried to understand why the main result is constrained to a linear map between Hilbert spaces, rather than, say, Banach spaces.\n- Can the authors comment on that?\n- It would be to have all assumptions written together in one place.\n- It's not very common to write 'A = B in some subspace'.\n- The quantity in this line is first defined as \u03c11 but treated as a different letter in the following display.\n- The notation HS(\u00b7, \u00b7) was not properly defined.\n- I am not sure whether I agree with the statement in this line.\n- Perhaps the authors mean to think about s as being largish and then say that for any 'reasonable' m the two bounds are close?\n- I would be happy for a clarification.\n- Again, would be happy for a clarification.\n- On one hand, I am happy that the authors added this appendix.\n- It supplies some intuition, definitions and examples.\n- On the other hand, I'm not sure what purpose it actually serves since all the necessary material was presented in the main paper and this appendix was never referenced in the main text.\n- As far as I can see, these are just the same assumptions, used before.\n- This brings me back to the suggestion of having one place to gather all assumptions.\n- what do you mean by independence of x and \u03bc?\n- 'such functional' -> 'such a functional'",
    "review_points_list": [
      "The main results of the paper are a generalization of well known results in finite dimensions to an infinite-dimensional settings.",
      "The main ideas which underlies the proofs are also derived from the finite dimensional setting.",
      "In order to find the LMMSE, the authors equate the Gateaux derivative to 0, instead of the 'regular' derivative, as is done in the classical proofs.",
      "The results are not surprising and perhaps, one could claim, are not very exciting.",
      "The move to infinite-dimensions has many technical difficulties and is a highly non-trivial task.",
      "Special care must be taken when discussing the type of spaces involved in the problem, the type of linear operator between those spaces and even the form of admissible randomness.",
      "The paper is well written, and the authors do a rather good job in motivating the formulation of the problem and the definitions.",
      "The math itself is very elegant and it could even prove useful for other, similar, problems.",
      "It can fit well with the theme of conference.",
      "The style and presentation of the paper could be improved.",
      "The analogy to the finite-dimensional case is important and is not highlighted enough in the paper.",
      "Some of the results obtained in the paper transform into simple exercises in optimization, when one considers well posed problems in finite dimensions.",
      "It would be beneficial to show (or at least state) those proofs in the paper, followed by a discussion of the technical difficulties which arise when one moves to infinite dimensions.",
      "Nice math, hence my score.",
      "It would be happy for some motivating examples where one would actually want to consider the specific problems introduced in the paper.",
      "Can the authors comment on this point?",
      "Presumably one also wants for the noise \u03b5 to be independent of x.",
      "After reading Examples 2.3 I do not feel like I understand the problem better.",
      "I feel that Remark 2.5 is very important and actually fundamental to the paper.",
      "I do not understand the comment that K is not identified with K*.",
      "Shouldn't it be v in K?",
      "<Ax, v> should be <Ax, i(v)>.",
      "'to be at least as smoothing'.",
      "I tried to understand why the main result is constrained to a linear map between Hilbert spaces, rather than, say, Banach spaces.",
      "Can the authors comment on that?",
      "It would be to have all assumptions written together in one place.",
      "It's not very common to write 'A = B in some subspace'.",
      "The quantity in this line is first defined as \u03c11 but treated as a different letter in the following display.",
      "The notation HS(\u00b7, \u00b7) was not properly defined.",
      "I am not sure whether I agree with the statement in this line.",
      "Perhaps the authors mean to think about s as being largish and then say that for any 'reasonable' m the two bounds are close?",
      "I would be happy for a clarification.",
      "Again, would be happy for a clarification.",
      "On one hand, I am happy that the authors added this appendix.",
      "It supplies some intuition, definitions and examples.",
      "On the other hand, I'm not sure what purpose it actually serves since all the necessary material was presented in the main paper and this appendix was never referenced in the main text.",
      "As far as I can see, these are just the same assumptions, used before.",
      "This brings me back to the suggestion of having one place to gather all assumptions.",
      "what do you mean by independence of x and \u03bc?",
      "'such functional' -> 'such a functional'"
    ]
  },
  {
    "paper_id": "1802.01365v1",
    "submission_id": "zMZPDwm3H3",
    "submission_title": "Learning the optimal Tikhonov regularizer for inverse problems",
    "review_id": "yKdzgo6jMI9",
    "input": {
      "title": "Learning the optimal Tikhonov regularizer for inverse problems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Here are my key reservations about the paper and the scope of its novelty:\n- 1) The main result of the paper is an extension of a known result for finite-dimensional spaces to infinite-dimensional spaces.\n- The authors do not motivate the necessity and relevance of such as extension.\n- The problems they describe in the Introduction are already addressed by the prior art.\n- Moreover, the extension, as far as I can tell, is very technical but straightforward.\n- 2) The title of the paper is misleading.\n- The paper focuses on a very specific type of regularization, namely generalized Tikhonov regularization.\n- Clearly, this type of regularization is not optimal for many structured sources of interest.\n- Constrained to this specific (and non-optimal) regularization, the paper characterizes the optimal parameters of the regularizer.\n- This is far from 'learning the optimal regularizer'.\n- Moreover, for finite-dimensional data, there are known results in the literature (not cited in the paper) on Bayesian high-dimensional linear regression that in fact characterize the optimal regularizer dependent on the source distribution, at least in the cases of noise-free measurements.",
    "review_points_list": [
      "Here are my key reservations about the paper and the scope of its novelty:",
      "1) The main result of the paper is an extension of a known result for finite-dimensional spaces to infinite-dimensional spaces.",
      "The authors do not motivate the necessity and relevance of such as extension.",
      "The problems they describe in the Introduction are already addressed by the prior art.",
      "Moreover, the extension, as far as I can tell, is very technical but straightforward.",
      "2) The title of the paper is misleading.",
      "The paper focuses on a very specific type of regularization, namely generalized Tikhonov regularization.",
      "Clearly, this type of regularization is not optimal for many structured sources of interest.",
      "Constrained to this specific (and non-optimal) regularization, the paper characterizes the optimal parameters of the regularizer.",
      "This is far from 'learning the optimal regularizer'.",
      "Moreover, for finite-dimensional data, there are known results in the literature (not cited in the paper) on Bayesian high-dimensional linear regression that in fact characterize the optimal regularizer dependent on the source distribution, at least in the cases of noise-free measurements."
    ]
  },
  {
    "paper_id": "2107.03358v2",
    "submission_id": "xWq1MVj7YrE",
    "submission_title": "Novel Visual Category Discovery with Dual Ranking Statistics and Mutual Knowledge Distillation",
    "review_id": "3FB3qAUglVr",
    "input": {
      "title": "Novel Visual Category Discovery with Dual Ranking Statistics and Mutual Knowledge Distillation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The approach seems sound.\n- Some components are more novel (ranking statistics for labels, global/local alignment) and others are less novel.\n- The contribution of each part seems properly verified through ablations.\n- Results overall are strong enough, although margins to the baselines are not huge.\n- In particular, both ranking statistics and global/local alignment are shown to have an impact.\n- The particular manner of doing distillation, local-to-global, is also ablated.\n- Multiple evaluation settings are shown, i.e. standard (coarse) classification as well as fine-grained.\n- The s_{ij} notation is a bit strange--usually labels are for one sample?\n- What is z_i^{'u} i.e. what is the ' here? (above Eq. 4)?\n- There shouldn't be a sentence break on L134.",
    "review_points_list": [
      "The approach seems sound.",
      "Some components are more novel (ranking statistics for labels, global/local alignment) and others are less novel.",
      "The contribution of each part seems properly verified through ablations.",
      "Results overall are strong enough, although margins to the baselines are not huge.",
      "In particular, both ranking statistics and global/local alignment are shown to have an impact.",
      "The particular manner of doing distillation, local-to-global, is also ablated.",
      "Multiple evaluation settings are shown, i.e. standard (coarse) classification as well as fine-grained.",
      "The s_{ij} notation is a bit strange--usually labels are for one sample?",
      "What is z_i^{'u} i.e. what is the ' here? (above Eq. 4)?",
      "There shouldn't be a sentence break on L134."
    ]
  },
  {
    "paper_id": "2107.03358v2",
    "submission_id": "xWq1MVj7YrE",
    "submission_title": "Novel Visual Category Discovery with Dual Ranking Statistics and Mutual Knowledge Distillation",
    "review_id": "6KX2Yzfrxed",
    "input": {
      "title": "Novel Visual Category Discovery with Dual Ranking Statistics and Mutual Knowledge Distillation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper is well written and easy to follow.\n- The overall paper is well-organized.\n- Figures and Tables are clear to show the methods and comparisons.\n- This paper considers an interesting problem, i.e., novel class discovery.\n- In addition, a fine-grained setting is introduced in this paper, which is not studied in previous NCD works.\n- For the method, this paper introduces two simple but effective approaches, which explicitly take the advantage of both the global and local factors and obtain consistent improvement.\n- This paper presents extensive experiments to show the effectiveness of the components of the proposed method.\n- The comparisons with other methods are comprehensive and fair.\n- In addition, the authors also provide the experiments on more difficult settings: unknown number of novel classes and open-set unlabeled data.\n- I have some questions about the method and the experiment.\n- Did you use the proposed losses for the labeled data, especially the local loss?\n- If no, how about the results of using them for the labeled data.\n- Will this improve the discrimination of the representation?\n- For the part dictionary memory bank, why not save all the parts of a sample into the memory?\n- Could you provide the difference between using a random part of a sample and using all parts of a sample?\n- Saving random/all part features into the memory is a bit wild?\n- Is it possible to first find high-response regions (for example the activations) and only save them into the memory?\n- The proposed has two branches, which one is used for the testing stage?\n- With JSD loss, I think these two branches may have similar results.\n- However, when removing JSD loss, which one is used?",
    "review_points_list": [
      "This paper is well written and easy to follow.",
      "The overall paper is well-organized.",
      "Figures and Tables are clear to show the methods and comparisons.",
      "This paper considers an interesting problem, i.e., novel class discovery.",
      "In addition, a fine-grained setting is introduced in this paper, which is not studied in previous NCD works.",
      "For the method, this paper introduces two simple but effective approaches, which explicitly take the advantage of both the global and local factors and obtain consistent improvement.",
      "This paper presents extensive experiments to show the effectiveness of the components of the proposed method.",
      "The comparisons with other methods are comprehensive and fair.",
      "In addition, the authors also provide the experiments on more difficult settings: unknown number of novel classes and open-set unlabeled data.",
      "I have some questions about the method and the experiment.",
      "Did you use the proposed losses for the labeled data, especially the local loss?",
      "If no, how about the results of using them for the labeled data.",
      "Will this improve the discrimination of the representation?",
      "For the part dictionary memory bank, why not save all the parts of a sample into the memory?",
      "Could you provide the difference between using a random part of a sample and using all parts of a sample?",
      "Saving random/all part features into the memory is a bit wild?",
      "Is it possible to first find high-response regions (for example the activations) and only save them into the memory?",
      "The proposed has two branches, which one is used for the testing stage?",
      "With JSD loss, I think these two branches may have similar results.",
      "However, when removing JSD loss, which one is used?"
    ]
  },
  {
    "paper_id": "2107.03358v2",
    "submission_id": "xWq1MVj7YrE",
    "submission_title": "Novel Visual Category Discovery with Dual Ranking Statistics and Mutual Knowledge Distillation",
    "review_id": "z36c1SmYQB0",
    "input": {
      "title": "Novel Visual Category Discovery with Dual Ranking Statistics and Mutual Knowledge Distillation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.\n- The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.\n- The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset.\n- The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).\n- Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.\n- The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.\n- The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.\n- This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.\n- The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.\n- log(k) is an upper bound on the improvement of query complexity for any sampler.\n- The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.\n- The paper is very clear and well organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.\n- The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.\n- The paper is overall well-written and well-organized with clear motivation.\n- The setting of the novel class discovery is interesting and should be practically important.\n- The experiments are comprehensive and the results show clear improvement over previous SOTA.",
    "review_points_list": [
      "The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.",
      "The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.",
      "The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset.",
      "The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).",
      "Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.",
      "The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.",
      "The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.",
      "This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.",
      "The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.",
      "log(k) is an upper bound on the improvement of query complexity for any sampler.",
      "The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.",
      "The paper is very clear and well organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.",
      "The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.",
      "The paper is overall well-written and well-organized with clear motivation.",
      "The setting of the novel class discovery is interesting and should be practically important.",
      "The experiments are comprehensive and the results show clear improvement over previous SOTA."
    ]
  },
  {
    "paper_id": "2107.03358v2",
    "submission_id": "xWq1MVj7YrE",
    "submission_title": "Novel Visual Category Discovery with Dual Ranking Statistics and Mutual Knowledge Distillation",
    "review_id": "M2CDkdaxhC",
    "input": {
      "title": "Novel Visual Category Discovery with Dual Ranking Statistics and Mutual Knowledge Distillation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper utilizes dual ranking statistics to transfer knowledge from known classes in the labeled data to the unlabelled data and can generate a more robust pseudo label for learning on the unlabelled data.\n- A mutual knowledge distillation method is proposed to allow information exchange and encourage agreement between the local and global branches.\n- The paper is well organized and easy to follow.\n- The proposed model consists of two branches.\n- Although the usage of the existing binary pseudo label limits the novelty of the model, the dual structure and the distillation to encourage agreement between branches are innovative.\n- The global branch originates from and the local branch includes a FIFO queue as a memory bank to query the ranking statistics as a dynamic object part dictionary.\n- Typo: a redundant close parenthesis in the rear of Eqn.\n- The global branch originates from and the local branch includes a FIFO queue as a memory bank to query the ranking statistics as a dynamic object part dictionary.",
    "review_points_list": [
      "The paper utilizes dual ranking statistics to transfer knowledge from known classes in the labeled data to the unlabelled data and can generate a more robust pseudo label for learning on the unlabelled data.",
      "A mutual knowledge distillation method is proposed to allow information exchange and encourage agreement between the local and global branches.",
      "The paper is well organized and easy to follow.",
      "The proposed model consists of two branches.",
      "Although the usage of the existing binary pseudo label limits the novelty of the model, the dual structure and the distillation to encourage agreement between branches are innovative.",
      "The global branch originates from and the local branch includes a FIFO queue as a memory bank to query the ranking statistics as a dynamic object part dictionary.",
      "Typo: a redundant close parenthesis in the rear of Eqn.",
      "The global branch originates from and the local branch includes a FIFO queue as a memory bank to query the ranking statistics as a dynamic object part dictionary."
    ]
  },
  {
    "paper_id": "2205.08038v3",
    "submission_id": "z4L8_Egn5Ey",
    "submission_title": "Global Convergence  to Local Minmax Equilibrium in Classes of Nonconvex Zero-Sum Games",
    "review_id": "K5giymVGZef",
    "input": {
      "title": "Global Convergence  to Local Minmax Equilibrium in Classes of Nonconvex Zero-Sum Games",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- There are a few assumptions that need clarification\n- Novelty needs further clarification\n- Theorem 1 is established for non-convex P\u0141 games\n- Theorem 1 looks like a corollary of [Theorem 1, 15]\n- Theorem 1 does not give the choice of \u03c4_*\n- The P\u0141 and SC conditions bring the global asymptotic convergence of \u03c4-GDA and \u03c4-PGDA\n- The results of Sec. 5 and 6 are familiar with non-convex optimization researchers\n- The authors should include the results of [15] in Table 1\n- This paper ignores the empirical studies at all\n- The authors claim that fair classification, adversarial training, and distributionally robust optimization belong to the class of games they consider\n- None of these applications are conducted in the paper\n- It intensified the reviewers\u2019 concerns about the above assumptions\n- The code is in the supplementary material\n- Numerical visualization is an indispensable part",
    "review_points_list": [
      "There are a few assumptions that need clarification",
      "Novelty needs further clarification",
      "Theorem 1 is established for non-convex P\u0141 games",
      "Theorem 1 looks like a corollary of [Theorem 1, 15]",
      "Theorem 1 does not give the choice of \u03c4_*",
      "The P\u0141 and SC conditions bring the global asymptotic convergence of \u03c4-GDA and \u03c4-PGDA",
      "The results of Sec. 5 and 6 are familiar with non-convex optimization researchers",
      "The authors should include the results of [15] in Table 1",
      "This paper ignores the empirical studies at all",
      "The authors claim that fair classification, adversarial training, and distributionally robust optimization belong to the class of games they consider",
      "None of these applications are conducted in the paper",
      "It intensified the reviewers\u2019 concerns about the above assumptions",
      "The code is in the supplementary material",
      "Numerical visualization is an indispensable part"
    ]
  },
  {
    "paper_id": "2205.08038v3",
    "submission_id": "z4L8_Egn5Ey",
    "submission_title": "Global Convergence  to Local Minmax Equilibrium in Classes of Nonconvex Zero-Sum Games",
    "review_id": "l1BjRP-HFX",
    "input": {
      "title": "Global Convergence  to Local Minmax Equilibrium in Classes of Nonconvex Zero-Sum Games",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The fact that local minimax points are stable for non-convex strong concave or PL landscapes is not suprising since effectively the hessian with respect to y is negative definite (invertible) and all degenerecies are avoided.\n- we can decide about stability by checking the eigenvalues of the hessian and not cheking third order terms\n- the multiplicative property of the determinant and Schur complement to derive a relation between the eigenvalues of the Hessian, the lower right block matrix of the Hessian and its schur complement\n- all the other critical points are unstable\n- I feel that every critical point that is unstable, it is unstable because of the x variables (for the examined landscapes), is this true?\n- The fact that we have convergence to local minimax is not surprising (similar result appears in https://arxiv.org/abs/1902.08297), I like though that the authors use potential argument to show this fact\n- The result about SGDA follows standard machinery for perturbed GD dynamics (see Jin et al 2017) and the \tilde{O}(1/\\eps^4) was expected\n- Overall, I think the paper is an interesting but not super strong\n- Can also the authors argue about constructing functions (non-convex in x and PL condition in y) with a critical point the corresponding matrix of which has at least one imaginary eigenvalue (for the continuous time dynamics)?\n- Which parts of the proofs carry over for constrained min-max optimization?",
    "review_points_list": [
      "The fact that local minimax points are stable for non-convex strong concave or PL landscapes is not suprising since effectively the hessian with respect to y is negative definite (invertible) and all degenerecies are avoided.",
      "we can decide about stability by checking the eigenvalues of the hessian and not cheking third order terms",
      "the multiplicative property of the determinant and Schur complement to derive a relation between the eigenvalues of the Hessian, the lower right block matrix of the Hessian and its schur complement",
      "all the other critical points are unstable",
      "I feel that every critical point that is unstable, it is unstable because of the x variables (for the examined landscapes), is this true?",
      "The fact that we have convergence to local minimax is not surprising (similar result appears in https://arxiv.org/abs/1902.08297), I like though that the authors use potential argument to show this fact",
      "The result about SGDA follows standard machinery for perturbed GD dynamics (see Jin et al 2017) and the \tilde{O}(1/\\eps^4) was expected",
      "Overall, I think the paper is an interesting but not super strong",
      "Can also the authors argue about constructing functions (non-convex in x and PL condition in y) with a critical point the corresponding matrix of which has at least one imaginary eigenvalue (for the continuous time dynamics)?",
      "Which parts of the proofs carry over for constrained min-max optimization?"
    ]
  },
  {
    "paper_id": "2205.08038v3",
    "submission_id": "z4L8_Egn5Ey",
    "submission_title": "Global Convergence  to Local Minmax Equilibrium in Classes of Nonconvex Zero-Sum Games",
    "review_id": "-Js0BTR_Zph",
    "input": {
      "title": "Global Convergence  to Local Minmax Equilibrium in Classes of Nonconvex Zero-Sum Games",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper studies a significant topic that belongs to a vibrant research field.\n- The paper is easy to follow and clearly written.\n- More specifically, they obtain convergence guarantees in regards to differential Stackelberg equilibria compared to assessing convergence to approximate stationary points in past works.\n- The results presented are not very surprising since Danskin's (or a Danskin's like) theorem holds for these classes of non-convex settings.\n- However, the results are not trivial and cleanly developed.\n- Some practical examples presented in section 1.2 do not apply to the non-convex PL/SC settings.\n- Also in equation (3), should it be f_i?\n- Line 162: I believe the gradient does not always exist.\n- The authors define the constrained min-max problem, but then study the unconstrained problem.\n- Also why f^* is defined in line 379.\n- A major concern is that the paper lacks experimental results.\n- Motivating the class of problem under study with practical examples and illustrating the results through empirical results would help improve the paper.",
    "review_points_list": [
      "The paper studies a significant topic that belongs to a vibrant research field.",
      "The paper is easy to follow and clearly written.",
      "More specifically, they obtain convergence guarantees in regards to differential Stackelberg equilibria compared to assessing convergence to approximate stationary points in past works.",
      "The results presented are not very surprising since Danskin's (or a Danskin's like) theorem holds for these classes of non-convex settings.",
      "However, the results are not trivial and cleanly developed.",
      "Some practical examples presented in section 1.2 do not apply to the non-convex PL/SC settings.",
      "Also in equation (3), should it be f_i?",
      "Line 162: I believe the gradient does not always exist.",
      "The authors define the constrained min-max problem, but then study the unconstrained problem.",
      "Also why f^* is defined in line 379.",
      "A major concern is that the paper lacks experimental results.",
      "Motivating the class of problem under study with practical examples and illustrating the results through empirical results would help improve the paper."
    ]
  },
  {
    "paper_id": "2110.00535v2",
    "submission_id": "weBSeGTv0i",
    "submission_title": "A Cram\u00e9r Distance perspective on Non-crossing Quantile Regression in Distributional Reinforcement Learning",
    "review_id": "gCdXH5-7tSw",
    "input": {
      "title": "A Cram\u00e9r Distance perspective on Non-crossing Quantile Regression in Distributional Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The idea of this paper is novel and not incremental.\n- It proposed a new framework for modeling the distance between distribution in the distributional Bellman operator.\n- Given that most of the recent algorithms for distributional RL are based on QR, this paper is a significant plus to this field.\n- The major issue of this paper is that the author(s) generally can not convince me that the Cram\u00e9r-based models can outperform the QR-based models.\n- The proofs generally guarantee that CR-DQN can learn reasonable distributions of Q values because it resembles QR-DQN, but none of them can help readers understand where is the improvement.\n- The paper lists some benefits like 1) CR enables removing a constraint (line 172-174) and 2) extreme quantiles are hard to estimate in the classic QR-DQN (line 186), but none of them is fully defined or evaluated.\n- The motivation is vague from my point of view.\n- The empirical results do not show a clear win of CNC-CR_QDN and the results are not explained.\n- Line 185 'As shown by the classical theory of extreme values', could you explain more to help readers understand it? since it is a major motivation for your network architecture.\n- By the way, figure 4 in [31](NC-QR_DQN) has claimed NC-QR_DQN converged faster than QR_DQN, which make me believe the reduction of training efficiency (from the 'symmetries' (line 177)) in CR is significant and adding the CNC structure can not resolve this issue.\n- It explains why CR-DQN is generally more sample inefficient than the QR-based methods.\n- Your results in Figure 7 and the appendix generally confirm this problem.\n- The Atari 57 experiment should include both NC-QR-DQN and NC-CR-DQN as baselines since the author(s) proposed replacing the original non-crossing network with the CNC architecture.\n- Comparing both NC-QR-DQN and NC-CR-DQN can provide a form of ablation study that helps readers understand the influence of each component (CR and CNC).",
    "review_points_list": [
      "The idea of this paper is novel and not incremental.",
      "It proposed a new framework for modeling the distance between distribution in the distributional Bellman operator.",
      "Given that most of the recent algorithms for distributional RL are based on QR, this paper is a significant plus to this field.",
      "The major issue of this paper is that the author(s) generally can not convince me that the Cram\u00e9r-based models can outperform the QR-based models.",
      "The proofs generally guarantee that CR-DQN can learn reasonable distributions of Q values because it resembles QR-DQN, but none of them can help readers understand where is the improvement.",
      "The paper lists some benefits like 1) CR enables removing a constraint (line 172-174) and 2) extreme quantiles are hard to estimate in the classic QR-DQN (line 186), but none of them is fully defined or evaluated.",
      "The motivation is vague from my point of view.",
      "The empirical results do not show a clear win of CNC-CR_QDN and the results are not explained.",
      "Line 185 'As shown by the classical theory of extreme values', could you explain more to help readers understand it? since it is a major motivation for your network architecture.",
      "By the way, figure 4 in [31](NC-QR_DQN) has claimed NC-QR_DQN converged faster than QR_DQN, which make me believe the reduction of training efficiency (from the 'symmetries' (line 177)) in CR is significant and adding the CNC structure can not resolve this issue.",
      "It explains why CR-DQN is generally more sample inefficient than the QR-based methods.",
      "Your results in Figure 7 and the appendix generally confirm this problem.",
      "The Atari 57 experiment should include both NC-QR-DQN and NC-CR-DQN as baselines since the author(s) proposed replacing the original non-crossing network with the CNC architecture.",
      "Comparing both NC-QR-DQN and NC-CR-DQN can provide a form of ablation study that helps readers understand the influence of each component (CR and CNC)."
    ]
  },
  {
    "paper_id": "2110.00535v2",
    "submission_id": "weBSeGTv0i",
    "submission_title": "A Cram\u00e9r Distance perspective on Non-crossing Quantile Regression in Distributional Reinforcement Learning",
    "review_id": "XRro221nWUc",
    "input": {
      "title": "A Cram\u00e9r Distance perspective on Non-crossing Quantile Regression in Distributional Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The connection between 1-Wasserstein and Cramer seems novel and interesting in DRL.\n- Quantile regression in QR-DQN imposes order into the learnable particles as each is an estimate of the quantile which implies monotonicity in the particles.\n- Cramer distance on the other hand is equivalent to 1-Wasserstein in terms of projection onto the space of a mixture of Heaviside step functions and in terms of gradients.\n- Cramer distance does not require order among \n- Many parts of the writing are unclear and need more improvement.\n- I think the present paper lacks a discussion and comparison with related work that is directly related to the problem and proposed solution.\n- The motivation and purpose of the experimental section are unclear and there is no conclusion or discussion drawn from the experiment.\n- The experimental result does not show that the proposed algorithm CNC-CR-DQN outperforms QR-DQN with statistical significance in the whole range of Atari games.\n- This raises the question of whether the proposed algorithm is effective and necessary.\n- Theoretical results are quite simple and the connection between Cramer and Wasserstein is already made in.\n- I think a recent work Nguyen-Tang et al AAAI\u201921, \u201cDistributional Reinforcement Learning via Moment Matching\u201d can completely avoid such problems in quantile-regression-based methods using moment matching;\n- What is the difference between your approach and Nguyen-Tang's in addressing the order statistics constraint in QR-based DRL?\n- The paper addresses the crossing quantile problem in DRL but it only briefly touches on crossing quantile in one sentence.\n- I think it is inadequate. More discussion is needed and probably one dedicated paragraph for this is necessary.\n- Line What exactly permutation in the symmetric group of size N? What symmetric group are you referring to?\n- This part needs to be clearer.\n- Eq. What is A typo?\n- The experiment section lacks a clear explanation what is the purpose of the experiment?\n- What conclusions can be drawn from the results?\n- Currently, this section merely just describes the experimental procedure without insights drawn from it.\n- I think putting markers on Fig 6 would make it easier to read. Some colors are very similar.\n- CNC-CR-DQN outperforms QR-DQN in several games but in the entire Atari set, they perform very similarly.\n- How can you conclude that the proposed method that draws on Cramer distance without crossing quantiles works better in a statistical sense?\n- Cramer distance is identical to 1-Wasserstein distance and using 1-Crammer distance also does not require order among as 2-Cramder distance.\n- Why don't just use 1-Cramer distance?\n- What kind of games from the Atari set the proposed algorithm performs better than QR-DQN?",
    "review_points_list": [
      "The connection between 1-Wasserstein and Cramer seems novel and interesting in DRL.",
      "Quantile regression in QR-DQN imposes order into the learnable particles as each is an estimate of the quantile which implies monotonicity in the particles.",
      "Cramer distance on the other hand is equivalent to 1-Wasserstein in terms of projection onto the space of a mixture of Heaviside step functions and in terms of gradients.",
      "Cramer distance does not require order among ",
      "Many parts of the writing are unclear and need more improvement.",
      "I think the present paper lacks a discussion and comparison with related work that is directly related to the problem and proposed solution.",
      "The motivation and purpose of the experimental section are unclear and there is no conclusion or discussion drawn from the experiment.",
      "The experimental result does not show that the proposed algorithm CNC-CR-DQN outperforms QR-DQN with statistical significance in the whole range of Atari games.",
      "This raises the question of whether the proposed algorithm is effective and necessary.",
      "Theoretical results are quite simple and the connection between Cramer and Wasserstein is already made in.",
      "I think a recent work Nguyen-Tang et al AAAI\u201921, \u201cDistributional Reinforcement Learning via Moment Matching\u201d can completely avoid such problems in quantile-regression-based methods using moment matching;",
      "What is the difference between your approach and Nguyen-Tang's in addressing the order statistics constraint in QR-based DRL?",
      "The paper addresses the crossing quantile problem in DRL but it only briefly touches on crossing quantile in one sentence.",
      "I think it is inadequate. More discussion is needed and probably one dedicated paragraph for this is necessary.",
      "Line What exactly permutation in the symmetric group of size N? What symmetric group are you referring to?",
      "This part needs to be clearer.",
      "Eq. What is A typo?",
      "The experiment section lacks a clear explanation what is the purpose of the experiment?",
      "What conclusions can be drawn from the results?",
      "Currently, this section merely just describes the experimental procedure without insights drawn from it.",
      "I think putting markers on Fig 6 would make it easier to read. Some colors are very similar.",
      "CNC-CR-DQN outperforms QR-DQN in several games but in the entire Atari set, they perform very similarly.",
      "How can you conclude that the proposed method that draws on Cramer distance without crossing quantiles works better in a statistical sense?",
      "Cramer distance is identical to 1-Wasserstein distance and using 1-Crammer distance also does not require order among as 2-Cramder distance.",
      "Why don't just use 1-Cramer distance?",
      "What kind of games from the Atari set the proposed algorithm performs better than QR-DQN?"
    ]
  },
  {
    "paper_id": "2110.00535v2",
    "submission_id": "weBSeGTv0i",
    "submission_title": "A Cram\u00e9r Distance perspective on Non-crossing Quantile Regression in Distributional Reinforcement Learning",
    "review_id": "vmqUjG7ntbE",
    "input": {
      "title": "A Cram\u00e9r Distance perspective on Non-crossing Quantile Regression in Distributional Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Originality: Low. Cramer distance in dsitributional RL has been studied in prior works, the authors provide some missing theoretical results. The proposed algorithm is slightly modified from NC-QR-DQN.\n- Quality: Medium. The theories are correct, but the experiment results are insignificant.\n- Clarity: Medium. The paper is easy to read, except for some minor issues. 1. l.154 Formula... 2. In l.92, l_p is the p-Wasserstein distance, but later used as the Cramer distance without clarification. 3. Figure 3. is a little hard to interpret\n- Significance: Low.\n- Major concerns: 1. After reading the paper, I find that while correct, the theoretical results are not likely to be able to improve dsitributional RL algorithms. 2. From my opinion, NC-QR-DQN should be an important baseline of the work. But the authors didn't provide further comparison other than the three cases in Figure.5, therefore it is hard to tell the actual improvements of the proposed neural architecture. 3. Missing score table, incomplete experiments (2 seeds) in Figure 10.\n- Questions & suggestions: 1. If Cramer loss and Quantile Regression loss yields collinear gradients, why not use QR loss to save the trouble of computing Cramer distance? We only need the gradients to update network parameters. 2. According to my understanding of the paper, the proposed neural architecture, CNC, has three major differences compared with NC-QR-DQN: 1). For subnetwork 1, outputs median quantile value instead of minimum quantile value. Then, subtract the cumsum of the first half per-quantile value differences instead of add. 2). Remove the scaling factor, thereby using ReLU instead of Softmax for per-quantile value difference. I would suggest an ablation study on those two modifications to further investigate which one contributes more to the improvements.",
    "review_points_list": [
      "Originality: Low. Cramer distance in dsitributional RL has been studied in prior works, the authors provide some missing theoretical results. The proposed algorithm is slightly modified from NC-QR-DQN.",
      "Quality: Medium. The theories are correct, but the experiment results are insignificant.",
      "Clarity: Medium. The paper is easy to read, except for some minor issues. 1. l.154 Formula... 2. In l.92, l_p is the p-Wasserstein distance, but later used as the Cramer distance without clarification. 3. Figure 3. is a little hard to interpret",
      "Significance: Low.",
      "Major concerns: 1. After reading the paper, I find that while correct, the theoretical results are not likely to be able to improve dsitributional RL algorithms. 2. From my opinion, NC-QR-DQN should be an important baseline of the work. But the authors didn't provide further comparison other than the three cases in Figure.5, therefore it is hard to tell the actual improvements of the proposed neural architecture. 3. Missing score table, incomplete experiments (2 seeds) in Figure 10.",
      "Questions & suggestions: 1. If Cramer loss and Quantile Regression loss yields collinear gradients, why not use QR loss to save the trouble of computing Cramer distance? We only need the gradients to update network parameters. 2. According to my understanding of the paper, the proposed neural architecture, CNC, has three major differences compared with NC-QR-DQN: 1). For subnetwork 1, outputs median quantile value instead of minimum quantile value. Then, subtract the cumsum of the first half per-quantile value differences instead of add. 2). Remove the scaling factor, thereby using ReLU instead of Softmax for per-quantile value difference. I would suggest an ablation study on those two modifications to further investigate which one contributes more to the improvements."
    ]
  },
  {
    "paper_id": "2110.00535v2",
    "submission_id": "weBSeGTv0i",
    "submission_title": "A Cram\u00e9r Distance perspective on Non-crossing Quantile Regression in Distributional Reinforcement Learning",
    "review_id": "XDvZxRuoGat",
    "input": {
      "title": "A Cram\u00e9r Distance perspective on Non-crossing Quantile Regression in Distributional Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well structured.\n- A efficient algorithm is proposed to compute the Cramer distance.\n- I am concerned about the validity of the experiment results, since the performance of QR-DQN in Figure 5 is much worse than the results in their original paper. I am not sure if the authors correctly implement this method and the conclusion seems to be unconvincing.\n- The advantages of Cramer loss over quantile (Huber) loss are not well presented. As mentioned in your paper, both losses achieve unbiased gradient and equivalence to 1-Wasserstein in minimization problem. What are the pros of Cramer loss? Computation efficiency? Or else? Corresponding ablation studies are lacked.\n- There is a nearly same network architecture called NDQFN (Zhou et al., 2021) with proposed centered non-crossing architecture (CNC), except that CNC focus on median while NDQFN aims at \tau = 0. However, NDQFN seems to achieve much better performance than CNC with Cramer loss.\n- The experimental results in the present form is not strong. From the Figure 6 and Figure 10 in Appendix, it seems CNC-CR-DQN perform comparable with QR-DQN, even slightly worse.\n- I vote for rejection for current form.\n- Zhou, F.,Zhu, Z., Kuang, Q., Zhang, L*. Non-decreasing quantile function network withefficient exploration for distributional reinforcementlearning. International Joint Conference onArtificial Intelligence (IJCAI), 2021. In press.",
    "review_points_list": [
      "The paper is well structured.",
      "A efficient algorithm is proposed to compute the Cramer distance.",
      "I am concerned about the validity of the experiment results, since the performance of QR-DQN in Figure 5 is much worse than the results in their original paper. I am not sure if the authors correctly implement this method and the conclusion seems to be unconvincing.",
      "The advantages of Cramer loss over quantile (Huber) loss are not well presented. As mentioned in your paper, both losses achieve unbiased gradient and equivalence to 1-Wasserstein in minimization problem. What are the pros of Cramer loss? Computation efficiency? Or else? Corresponding ablation studies are lacked.",
      "There is a nearly same network architecture called NDQFN (Zhou et al., 2021) with proposed centered non-crossing architecture (CNC), except that CNC focus on median while NDQFN aims at \tau = 0. However, NDQFN seems to achieve much better performance than CNC with Cramer loss.",
      "The experimental results in the present form is not strong. From the Figure 6 and Figure 10 in Appendix, it seems CNC-CR-DQN perform comparable with QR-DQN, even slightly worse.",
      "I vote for rejection for current form.",
      "Zhou, F.,Zhu, Z., Kuang, Q., Zhang, L*. Non-decreasing quantile function network withefficient exploration for distributional reinforcementlearning. International Joint Conference onArtificial Intelligence (IJCAI), 2021. In press."
    ]
  },
  {
    "paper_id": "2111.14338v1",
    "submission_id": "x4zs7eC-BsI",
    "submission_title": "Improving Deep Learning Interpretability by Saliency Guided Training",
    "review_id": "Ema6ht2uogm",
    "input": {
      "title": "Improving Deep Learning Interpretability by Saliency Guided Training",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well motivated -- a number of saliency methods are affected by noisy gradients, often mitigating this effect with solutions that aren't well motivated (e.g., changing backprop rules).\n- This paper is extensive, thoughtful, and thorough in its experimentation and analysis, covering a wide range of ML domains and showing convincingly that their paradigm works across different settings, for instance, by reducing the noise in saliency maps, widening the separation between uninformative and informative input features as highlighted by saliency methods, improving performance of saliency map methods when evaluated on the model accuracy drop benchmark.\n- In particular, its analysis on feature replacement paradigms (section 5.1, under 'model accuracy drop') a useful insight into how to consider methods like ROAR and OOD.\n- Additionally, its experiment showing that its interpretable training paradigm mitigates the vanishing saliency of recurrent neural networks is an exciting result.\n- Both the insights presented in this paper as well as the novel training paradigm introduced can be used and built upon in future works.\n- Could this paradigm be adapted and used as a fine-tuning procedure? Would we see the same benefits (for less training time)?\n- How does this training paradigm impact performance (e.g., accuracy)? Accuracy numbers provided for language but not other domains\n- Figure 2A -- distribution plots are hard to interpret -- use the box plot versions for MNIST (as shown in supp mat)\n- Table 1 -- include additional results when using other saliency methods as well as LSTM Interpretable + other saliency methods\n- Additional related works from weak localization literature that use input-level perturbations during training: Wei et al., CVPR 2017 (Object Region Mining with Adversarial Erasure), Singh & Lee, ICCV 2017 (Hide-and-Seek), DeVries 2017 (Cutout).\n- Line 119: Expand a bit more on what additional computational cost is needed (does it take the same # of epochs to converge; what's the added memory cost?)\n- Explain more clearly why we should expect feature replacement methods to match IID replacement\n- Line 114: Be more explicit that only input features are being masked (e.g., not intermediate features), be more clear in main paper about what masked features are being replaced by (e.g., copy parts from supp mat)\n- Line 132: Spell out which VGG network is used (e.g., VGG-16?)\n- Line 186: Explain what R_i (predicted rationales) are in this context\n- Figure 5 -- in caption, explain what the abbreviations for saliency methods mean (Grad, DL, GS, DLS - last few are a bit unclear)",
    "review_points_list": [
      "The paper is well motivated -- a number of saliency methods are affected by noisy gradients, often mitigating this effect with solutions that aren't well motivated (e.g., changing backprop rules).",
      "This paper is extensive, thoughtful, and thorough in its experimentation and analysis, covering a wide range of ML domains and showing convincingly that their paradigm works across different settings, for instance, by reducing the noise in saliency maps, widening the separation between uninformative and informative input features as highlighted by saliency methods, improving performance of saliency map methods when evaluated on the model accuracy drop benchmark.",
      "In particular, its analysis on feature replacement paradigms (section 5.1, under 'model accuracy drop') a useful insight into how to consider methods like ROAR and OOD.",
      "Additionally, its experiment showing that its interpretable training paradigm mitigates the vanishing saliency of recurrent neural networks is an exciting result.",
      "Both the insights presented in this paper as well as the novel training paradigm introduced can be used and built upon in future works.",
      "Could this paradigm be adapted and used as a fine-tuning procedure? Would we see the same benefits (for less training time)?",
      "How does this training paradigm impact performance (e.g., accuracy)? Accuracy numbers provided for language but not other domains",
      "Figure 2A -- distribution plots are hard to interpret -- use the box plot versions for MNIST (as shown in supp mat)",
      "Table 1 -- include additional results when using other saliency methods as well as LSTM Interpretable + other saliency methods",
      "Additional related works from weak localization literature that use input-level perturbations during training: Wei et al., CVPR 2017 (Object Region Mining with Adversarial Erasure), Singh & Lee, ICCV 2017 (Hide-and-Seek), DeVries 2017 (Cutout).",
      "Line 119: Expand a bit more on what additional computational cost is needed (does it take the same # of epochs to converge; what's the added memory cost?)",
      "Explain more clearly why we should expect feature replacement methods to match IID replacement",
      "Line 114: Be more explicit that only input features are being masked (e.g., not intermediate features), be more clear in main paper about what masked features are being replaced by (e.g., copy parts from supp mat)",
      "Line 132: Spell out which VGG network is used (e.g., VGG-16?)",
      "Line 186: Explain what R_i (predicted rationales) are in this context",
      "Figure 5 -- in caption, explain what the abbreviations for saliency methods mean (Grad, DL, GS, DLS - last few are a bit unclear)"
    ]
  },
  {
    "paper_id": "2111.14338v1",
    "submission_id": "x4zs7eC-BsI",
    "submission_title": "Improving Deep Learning Interpretability by Saliency Guided Training",
    "review_id": "XOueSQJFPa",
    "input": {
      "title": "Improving Deep Learning Interpretability by Saliency Guided Training",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Based on an intuitive idea that if gradient-based explanation methods faithfully interpret the model's predictions, irrelevant features should have gradient values close to zero, the authors provide a method (interpretable training) to improve interpretability.\n- The proposed method combines the masking approach (line 103) and the KL divergence regularization (line 97) to solve the optimization problem in different tasks.\n- The authors formulated this interpretable training with a concise equation of loss function (i.e., the prediction loss and the KL loss, line 107).\n- The algorithm for interpretable training (Algorithm 1) is simple but novel for computing the masked input in each minibatch.\n- Nevertheless, the reviewer thinks it is an effective approach to improve explainability.\n- The authors give extensive empirical analysis, especially for CV tasks (i.e., qualitative analysis in Figures 2A and 2B, quantitative analysis in Figure 2C and Figure 3), to demonstrate the better performance for interpretable training compared with other regular training methods.\n- However, the following substantial issues should be addressed: (1) In Table 1, the performance for interpretable training for NLP tasks does not demonstrate consistent performance; the reason why a lower sufficiency for both FEVER and e-SNLI is not explained.\n- (2) In Table 1, for NLP tasks, only the vanilla gradient-based method is used; how about the more popular ones like DeepLift or IG?\n- (3) In lines 114-116, the authors give how to implement masking functions in image, language, but how about for the time series?\n- Why can't these operations replace the low salient word with the previous high salient word (line 115) guarantee the argument of assigning low gradient values to irrelevant features in model predictions (in line 112), any theoretical explanation?\n- (4) Since the parameter k is very important for masking operation, in lines 116 -117, the authors point out how to select k for images (MNIST dataset); however, the selection of k for language and time series is not clear.\n- (5) Other minor problems, e.g., the sequence number should be added for other formulas other than the KL-divergence (Eq (1)), line number for Algorithm 1.\n- I appreciate the response given by the authors, and most of my concerns have been successfully addressed by the responses.\n- I think this work is  novel compared to other existing works on \"interpretable training\" in that this method can be used in more broad areas, NLP, CV, and time series prediction tasks, which is achieved via masking gradients without using attention maps.\n- As such, I raise my rating to 6 to reflect my new assessment of the updated manuscript.",
    "review_points_list": [
      "Based on an intuitive idea that if gradient-based explanation methods faithfully interpret the model's predictions, irrelevant features should have gradient values close to zero, the authors provide a method (interpretable training) to improve interpretability.",
      "The proposed method combines the masking approach (line 103) and the KL divergence regularization (line 97) to solve the optimization problem in different tasks.",
      "The authors formulated this interpretable training with a concise equation of loss function (i.e., the prediction loss and the KL loss, line 107).",
      "The algorithm for interpretable training (Algorithm 1) is simple but novel for computing the masked input in each minibatch.",
      "Nevertheless, the reviewer thinks it is an effective approach to improve explainability.",
      "The authors give extensive empirical analysis, especially for CV tasks (i.e., qualitative analysis in Figures 2A and 2B, quantitative analysis in Figure 2C and Figure 3), to demonstrate the better performance for interpretable training compared with other regular training methods.",
      "However, the following substantial issues should be addressed: (1) In Table 1, the performance for interpretable training for NLP tasks does not demonstrate consistent performance; the reason why a lower sufficiency for both FEVER and e-SNLI is not explained.",
      "(2) In Table 1, for NLP tasks, only the vanilla gradient-based method is used; how about the more popular ones like DeepLift or IG?",
      "(3) In lines 114-116, the authors give how to implement masking functions in image, language, but how about for the time series?",
      "Why can't these operations replace the low salient word with the previous high salient word (line 115) guarantee the argument of assigning low gradient values to irrelevant features in model predictions (in line 112), any theoretical explanation?",
      "(4) Since the parameter k is very important for masking operation, in lines 116 -117, the authors point out how to select k for images (MNIST dataset); however, the selection of k for language and time series is not clear.",
      "(5) Other minor problems, e.g., the sequence number should be added for other formulas other than the KL-divergence (Eq (1)), line number for Algorithm 1.",
      "I appreciate the response given by the authors, and most of my concerns have been successfully addressed by the responses.",
      "I think this work is  novel compared to other existing works on \"interpretable training\" in that this method can be used in more broad areas, NLP, CV, and time series prediction tasks, which is achieved via masking gradients without using attention maps.",
      "As such, I raise my rating to 6 to reflect my new assessment of the updated manuscript."
    ]
  },
  {
    "paper_id": "2111.14338v1",
    "submission_id": "x4zs7eC-BsI",
    "submission_title": "Improving Deep Learning Interpretability by Saliency Guided Training",
    "review_id": "hsG2oSfBDmA",
    "input": {
      "title": "Improving Deep Learning Interpretability by Saliency Guided Training",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors do not provide another interpretable training baseline.\n- The algorithm seems to be novel and differs from previous comparable approaches.\n- The authors show empirically that their algorithm, Cluster-Margin, is both more efficient and more effective.\n- The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset.\n- Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.\n- The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.\n- The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.\n- This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.\n- The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.\n- log(k) is an upper bound on the improvement of query complexity for any sampler.\n- The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.\n- The paper is very clear and well organized.\n- The authors detail the hyper-parameters and compute details used for the experiments.\n- The Cluster-Margin algorithm is also explained in detail.\n- The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods.\n- The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.\n- There are many prior works in 'interpretable training', and it seems uneasy to name the method after this general field.\n- Some works which incorporate interpretability into the training process in a self-supervised fashion include several authors and papers.\n- Although 'interpretable training' has been around for a while, the authors do not include another interpretable training baseline.\n- I did not understand the ability of the box plots to show interpretability.\n- Why is it true?\n- I am wary of these results, since they seem to go against Goodhart's Law.\n- If a saliency method is used for evaluating the interpretability, it should be a different one than what was used in optimization.\n- There is prior work which shows that input gradients are often not interpretable.\n- It is admirable that the authors evaluate their algorithm on many benchmarks, in a variety of forms of data.\n- They also use a variety of model architectures.\n- The paper contains many grammar errors, although they are generally not a hindrance to understanding.\n- On Line 119: 'Although we use on vanilla gradients during training...',\n- This is not always true (e.g., the background can easily be correlated with the object, and thus feature importance on the background is likely to be non-zero).\n- But, the model focusing on object features rather than background features can instead be stated as a desirable quality to have, rather than the expectation.\n- It is great that the method the authors propose is self-supervised,\n- And does not rely on the need for ground truth saliency maps, which are often not available.\n- The loss function is also nice in its simplicity.\n- However, as stated above, there are many prior works in interpretable training, which this paper has not compared to.",
    "review_points_list": [
      "The authors do not provide another interpretable training baseline.",
      "The algorithm seems to be novel and differs from previous comparable approaches.",
      "The authors show empirically that their algorithm, Cluster-Margin, is both more efficient and more effective.",
      "The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset.",
      "Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.",
      "The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.",
      "The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.",
      "This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.",
      "The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.",
      "log(k) is an upper bound on the improvement of query complexity for any sampler.",
      "The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.",
      "The paper is very clear and well organized.",
      "The authors detail the hyper-parameters and compute details used for the experiments.",
      "The Cluster-Margin algorithm is also explained in detail.",
      "The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods.",
      "The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.",
      "There are many prior works in 'interpretable training', and it seems uneasy to name the method after this general field.",
      "Some works which incorporate interpretability into the training process in a self-supervised fashion include several authors and papers.",
      "Although 'interpretable training' has been around for a while, the authors do not include another interpretable training baseline.",
      "I did not understand the ability of the box plots to show interpretability.",
      "Why is it true?",
      "I am wary of these results, since they seem to go against Goodhart's Law.",
      "If a saliency method is used for evaluating the interpretability, it should be a different one than what was used in optimization.",
      "There is prior work which shows that input gradients are often not interpretable.",
      "It is admirable that the authors evaluate their algorithm on many benchmarks, in a variety of forms of data.",
      "They also use a variety of model architectures.",
      "The paper contains many grammar errors, although they are generally not a hindrance to understanding.",
      "On Line 119: 'Although we use on vanilla gradients during training...',",
      "This is not always true (e.g., the background can easily be correlated with the object, and thus feature importance on the background is likely to be non-zero).",
      "But, the model focusing on object features rather than background features can instead be stated as a desirable quality to have, rather than the expectation.",
      "It is great that the method the authors propose is self-supervised,",
      "And does not rely on the need for ground truth saliency maps, which are often not available.",
      "The loss function is also nice in its simplicity.",
      "However, as stated above, there are many prior works in interpretable training, which this paper has not compared to."
    ]
  },
  {
    "paper_id": "2111.14338v1",
    "submission_id": "x4zs7eC-BsI",
    "submission_title": "Improving Deep Learning Interpretability by Saliency Guided Training",
    "review_id": "Z40kpbGTcXt",
    "input": {
      "title": "Improving Deep Learning Interpretability by Saliency Guided Training",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors can improve the contribution and clarity of the paper by addressing the following questions:\n- I don\u2019t see the connection between the large gap in gradient values (between mean and outliers) and models\u2019 ability to differentiate between informative and non-informative features. Gradient values can be related to the long-term dependency in backpropagation algorithms, however, I am not sure how that can be related to informative and non-informative features; the vanishing gradient problems in neural network (e.g. LSTM) training suggest that the small gradients are related to the longer sequence (long term dependency) due to the repeated application of chain rule in the backpropagation algorithms.\n- It would be beneficial to provide elaborated examples to show how the small gradients and irrelevant features are related.\n- What is the interpretation of the sum of the feature embeddings of each word?\n- Feature embeddings are points in a vector space and summing up the coordinate values in that vector space for a word for sorting might not have any meaning; the phrase \"the maps produced are often noisy.\" in line 25 is unclear.",
    "review_points_list": [
      "The authors can improve the contribution and clarity of the paper by addressing the following questions:",
      "I don\u2019t see the connection between the large gap in gradient values (between mean and outliers) and models\u2019 ability to differentiate between informative and non-informative features. Gradient values can be related to the long-term dependency in backpropagation algorithms, however, I am not sure how that can be related to informative and non-informative features; the vanishing gradient problems in neural network (e.g. LSTM) training suggest that the small gradients are related to the longer sequence (long term dependency) due to the repeated application of chain rule in the backpropagation algorithms.",
      "It would be beneficial to provide elaborated examples to show how the small gradients and irrelevant features are related.",
      "What is the interpretation of the sum of the feature embeddings of each word?",
      "Feature embeddings are points in a vector space and summing up the coordinate values in that vector space for a word for sorting might not have any meaning; the phrase \"the maps produced are often noisy.\" in line 25 is unclear."
    ]
  },
  {
    "paper_id": "2102.08124v2",
    "submission_id": "vRWZsBLKqA",
    "submission_title": "Accelerated Sparse Neural Training: A Provable and Efficient Method to Find N:M Transposable Masks",
    "review_id": "1Uf8-TgXPeB",
    "input": {
      "title": "Accelerated Sparse Neural Training: A Provable and Efficient Method to Find N:M Transposable Masks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper proposes a method to utilize ampere GPUs sufficiently by exploring N:M sparse training.\n- To find the optimal transposable mask, this paper formulates the problem as an integer program solved by an approximated algorithm (2-Approximation algorithm).\n- 1. Direct sparse training using modern hardware is an important direction to train gigantic models [2].\n- 2. The 2-Approximation algorithm is novel and efficient.\n- 3. The performance of ResNets and Bert models is persuasive.\n- 4. The code is available and can reproduce the results.\n- Typo: line 273 'N   :  M '\n- The main flaw of this paper may be the gap between theory and practical.\n- I look forward to authors give more discussion.\n- Overall, this paper goes out an important step about fully sparse training, which should draw more attention in the future.\n- I am inclined to accept this paper.",
    "review_points_list": [
      "This paper proposes a method to utilize ampere GPUs sufficiently by exploring N:M sparse training.",
      "To find the optimal transposable mask, this paper formulates the problem as an integer program solved by an approximated algorithm (2-Approximation algorithm).",
      "1. Direct sparse training using modern hardware is an important direction to train gigantic models [2].",
      "2. The 2-Approximation algorithm is novel and efficient.",
      "3. The performance of ResNets and Bert models is persuasive.",
      "4. The code is available and can reproduce the results.",
      "Typo: line 273 'N   :  M '",
      "The main flaw of this paper may be the gap between theory and practical.",
      "I look forward to authors give more discussion.",
      "Overall, this paper goes out an important step about fully sparse training, which should draw more attention in the future.",
      "I am inclined to accept this paper."
    ]
  },
  {
    "paper_id": "2102.08124v2",
    "submission_id": "vRWZsBLKqA",
    "submission_title": "Accelerated Sparse Neural Training: A Provable and Efficient Method to Find N:M Transposable Masks",
    "review_id": "JN_MNi9eju",
    "input": {
      "title": "Accelerated Sparse Neural Training: A Provable and Efficient Method to Find N:M Transposable Masks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is very well done.\n- Structure causing accuracy degradation in sparsification is not a hypothesis. It's well documented empirically [1, 2].\n- However [unstructured sparsity's] hardware cost makes it infeasible to use on modern architectures.\n- Recent work has shown that unstructured sparsity can be accelerated, although it still requires high sparsity to exceed the performance of dense computation [1, 3].\n- Table 3, claiming a '2x' speedup over ASP is not correct. 2x more of the FLOPs in the model can now be accelerated by sparse tensor cores, which provide up to 2x performance over dense tensor cores.\n- Let's say dense models speed is (fwd + bwd + update) / dense_throughput. For simplicity, we\u2019ll say fwd = bwd = update so baseline takes 3 * fwd / dense_throughput seconds.\n- The ASP model would then take fwd / (2 * dense_throughput + 2 * fwd / dense_throughput = 2.5 * fwd / dense_throughput.\n- Your model would then take 2 * fwd / (2 * dense_throughput) + fwd / dense_throughput = 2 * fwd / dense_throughput.\n- Thus, ASP provides a 3 / 2.5 = 1.2x speedup over the baseline and you would provide a 2.5 / 2 = 1.25x speedup over ASP.\n- In reality your speedup will be lower because not all operations (e.g., batch normalization, activation functions) are accelerated by sparse tensor cores and the sparse tensor core operations will not fully realize the theoretical 2x gain over the dense tensor cores.\n- This should be corrected in the authors\u2019 response.\n- I understand that 4:8 transposable masks have a similar MD to 2:4 masks but comparing 4:8 sparsity to 2:4 sparsity is not apples-to-apples as I expect 4:8 sparsity will make it much easier to maintain model quality.\n- I like the inclusion of 4:8 sparsity results, but I\u2019d also like to see 2:4 transposable results to see what the accuracy loss looks like in comparison to non-transposable masks.\n- In Table 2, what N:M are used? As I understand it, the algorithm complexity depends on these factors.\n- X-axis in Figure 5 (b) should be scaled by 100 to be percent.\n- The hypothesis that MD is correlated with accuracy would be made much stronger with results on other kinds of structured sparsity.\n- For example, block sparsity and channel-sparsity.\n- As someone who works on this topic, I\u2019d be very interested to see these results.\n- In Table 1, it might be nice to include the MD normalized to unstructured as well.\n- This would make it easier to compare across the different structures for the reader.\n- Most sparse training algorithms only perform mask updates periodically to reduce overhead (and also because it usually leads to higher accuracy).\n- The update period is usually ~100 (e.g., with RigL). 40 is a tighter bound, but you could also run 100 (in Table 2) to align with prior work.\n- On page 2, your 3 questions are in a different order than they\u2019re shown in your diagram (Figure 4)\n- Sparse core tensor should be sparse tensor core\n- Nvidia has recently proposed using permutations to reduce accuracy loss (talk, poster from SNN).\n- How do permutations affect your MD metric? Do the results still correlate with accuracy?\n- Do they make finding transposable N:M masks more difficult?\n- These might be interesting questions to discuss in your conclusion.",
    "review_points_list": [
      "The paper is very well done.",
      "Structure causing accuracy degradation in sparsification is not a hypothesis. It's well documented empirically [1, 2].",
      "However [unstructured sparsity's] hardware cost makes it infeasible to use on modern architectures.",
      "Recent work has shown that unstructured sparsity can be accelerated, although it still requires high sparsity to exceed the performance of dense computation [1, 3].",
      "Table 3, claiming a '2x' speedup over ASP is not correct. 2x more of the FLOPs in the model can now be accelerated by sparse tensor cores, which provide up to 2x performance over dense tensor cores.",
      "Let's say dense models speed is (fwd + bwd + update) / dense_throughput. For simplicity, we\u2019ll say fwd = bwd = update so baseline takes 3 * fwd / dense_throughput seconds.",
      "The ASP model would then take fwd / (2 * dense_throughput + 2 * fwd / dense_throughput = 2.5 * fwd / dense_throughput.",
      "Your model would then take 2 * fwd / (2 * dense_throughput) + fwd / dense_throughput = 2 * fwd / dense_throughput.",
      "Thus, ASP provides a 3 / 2.5 = 1.2x speedup over the baseline and you would provide a 2.5 / 2 = 1.25x speedup over ASP.",
      "In reality your speedup will be lower because not all operations (e.g., batch normalization, activation functions) are accelerated by sparse tensor cores and the sparse tensor core operations will not fully realize the theoretical 2x gain over the dense tensor cores.",
      "This should be corrected in the authors\u2019 response.",
      "I understand that 4:8 transposable masks have a similar MD to 2:4 masks but comparing 4:8 sparsity to 2:4 sparsity is not apples-to-apples as I expect 4:8 sparsity will make it much easier to maintain model quality.",
      "I like the inclusion of 4:8 sparsity results, but I\u2019d also like to see 2:4 transposable results to see what the accuracy loss looks like in comparison to non-transposable masks.",
      "In Table 2, what N:M are used? As I understand it, the algorithm complexity depends on these factors.",
      "X-axis in Figure 5 (b) should be scaled by 100 to be percent.",
      "The hypothesis that MD is correlated with accuracy would be made much stronger with results on other kinds of structured sparsity.",
      "For example, block sparsity and channel-sparsity.",
      "As someone who works on this topic, I\u2019d be very interested to see these results.",
      "In Table 1, it might be nice to include the MD normalized to unstructured as well.",
      "This would make it easier to compare across the different structures for the reader.",
      "Most sparse training algorithms only perform mask updates periodically to reduce overhead (and also because it usually leads to higher accuracy).",
      "The update period is usually ~100 (e.g., with RigL). 40 is a tighter bound, but you could also run 100 (in Table 2) to align with prior work.",
      "On page 2, your 3 questions are in a different order than they\u2019re shown in your diagram (Figure 4)",
      "Sparse core tensor should be sparse tensor core",
      "Nvidia has recently proposed using permutations to reduce accuracy loss (talk, poster from SNN).",
      "How do permutations affect your MD metric? Do the results still correlate with accuracy?",
      "Do they make finding transposable N:M masks more difficult?",
      "These might be interesting questions to discuss in your conclusion."
    ]
  },
  {
    "paper_id": "2102.08124v2",
    "submission_id": "vRWZsBLKqA",
    "submission_title": "Accelerated Sparse Neural Training: A Provable and Efficient Method to Find N:M Transposable Masks",
    "review_id": "1JauHbAHJHr",
    "input": {
      "title": "Accelerated Sparse Neural Training: A Provable and Efficient Method to Find N:M Transposable Masks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The transposable mask is an interesting idea to enable the system capability of N:M sparse training.\n- The proposed 2-approximation solution adds a low overhead in finding transposable masks.\n- The proposed transposable N:M masks add strong constraints to weight diversity, which may limit the expressiveness of the model.\n- No real training speedups from the proposed method, because real hardware constraints are not satisfied.\n- Lack of details of implementation and hyperparameter settings.\n- Baseline results are inconsistent.\n- No discussions on how model convergence or training dynamics are affected by N:M sparse training.\n- The transposable N:M sparsity masks seem to add very strong constraints to the weight matrices, which might limit the model's expressiveness in a significant way.\n- After applying transposable N:M sparsity masks, there won't be enough mask diversity for 2:4 sparsity.\n- The proposed method, therefore, cannot speed up training on real hardware either.\n- It is disappointing as the paper motivates itself as a way to accelerate sparse training on real hardware in the introduction and only to find out later that the solution does not really work on real hardware.\n- Some of the results of the evaluations are inconsistent, especially the baseline results.\n- While the baseline results for ResNet18 and ResNet50 are 69.7% and 76.1% in Table 3, they become 70.5% and 77.3% in Table 4.\n- Why are there two results for the same dataset and task?\n- Which baseline should we look at?\n- If we take 77.3% as the baseline result for ResNet50, then the proposed N:M sparse training actually leads to a non-trivial drop (77.3 vs. 76.6) in Table 3, and the 'no accuracy degradation' claim is also not true.\n- Please double-check the results and also provide detailed hyperparameter information.\n- Despite claiming 2x speedup, no real training time is reported for all evaluations.\n- The training cost depends on both the training time per iteration as well as the total number of iterations needed to converge.\n- Although N:M sparse training might reduce the training time per iteration by 2x,  if the N:M sparse training takes more iterations to converge to get the same accuracy or introduces training instability, then N:M sparse training cannot really reduce the training cost and reducing the cost of finding transposable N:M sparsity becomes even less motivated.\n- Furthermore, the 2x speedup claim also seems to be problematic because (1) finding the transposable N:M masks still add non-negligible cost, which would make the speedup to be less than 2X, and (2) even with sparse tensor core, one cannot expect a 2x speedup because a DNN contains more components than just the matrix multiplication, such as non-linear functions or BatchNorm, which cannot be accelerated by sparse tensor core.\n- The paper lacks details for implementation and hyperparameter settings.\n- Can the authors add details for how the model has been trained, such as the number of update steps, the batch size, etc. for both the baseline and the N:M sparse training, as well as parameters for AdaPrune?\n- The current paper doesn't seem like it could be reproduced.\n- The proposed AdaPrune only seems to convert models trained with 8:4 to 4:2 for inference.\n- Can it also be used to accelerate the training speed as well?\n- The writing of Section 5 seems to be not good, with many typos and grammar errors.\n- It seems to be not good, with many typos and grammar errors. Just to give a few examples:",
    "review_points_list": [
      "The transposable mask is an interesting idea to enable the system capability of N:M sparse training.",
      "The proposed 2-approximation solution adds a low overhead in finding transposable masks.",
      "The proposed transposable N:M masks add strong constraints to weight diversity, which may limit the expressiveness of the model.",
      "No real training speedups from the proposed method, because real hardware constraints are not satisfied.",
      "Lack of details of implementation and hyperparameter settings.",
      "Baseline results are inconsistent.",
      "No discussions on how model convergence or training dynamics are affected by N:M sparse training.",
      "The transposable N:M sparsity masks seem to add very strong constraints to the weight matrices, which might limit the model's expressiveness in a significant way.",
      "After applying transposable N:M sparsity masks, there won't be enough mask diversity for 2:4 sparsity.",
      "The proposed method, therefore, cannot speed up training on real hardware either.",
      "It is disappointing as the paper motivates itself as a way to accelerate sparse training on real hardware in the introduction and only to find out later that the solution does not really work on real hardware.",
      "Some of the results of the evaluations are inconsistent, especially the baseline results.",
      "While the baseline results for ResNet18 and ResNet50 are 69.7% and 76.1% in Table 3, they become 70.5% and 77.3% in Table 4.",
      "Why are there two results for the same dataset and task?",
      "Which baseline should we look at?",
      "If we take 77.3% as the baseline result for ResNet50, then the proposed N:M sparse training actually leads to a non-trivial drop (77.3 vs. 76.6) in Table 3, and the 'no accuracy degradation' claim is also not true.",
      "Please double-check the results and also provide detailed hyperparameter information.",
      "Despite claiming 2x speedup, no real training time is reported for all evaluations.",
      "The training cost depends on both the training time per iteration as well as the total number of iterations needed to converge.",
      "Although N:M sparse training might reduce the training time per iteration by 2x,  if the N:M sparse training takes more iterations to converge to get the same accuracy or introduces training instability, then N:M sparse training cannot really reduce the training cost and reducing the cost of finding transposable N:M sparsity becomes even less motivated.",
      "Furthermore, the 2x speedup claim also seems to be problematic because (1) finding the transposable N:M masks still add non-negligible cost, which would make the speedup to be less than 2X, and (2) even with sparse tensor core, one cannot expect a 2x speedup because a DNN contains more components than just the matrix multiplication, such as non-linear functions or BatchNorm, which cannot be accelerated by sparse tensor core.",
      "The paper lacks details for implementation and hyperparameter settings.",
      "Can the authors add details for how the model has been trained, such as the number of update steps, the batch size, etc. for both the baseline and the N:M sparse training, as well as parameters for AdaPrune?",
      "The current paper doesn't seem like it could be reproduced.",
      "The proposed AdaPrune only seems to convert models trained with 8:4 to 4:2 for inference.",
      "Can it also be used to accelerate the training speed as well?",
      "The writing of Section 5 seems to be not good, with many typos and grammar errors.",
      "It seems to be not good, with many typos and grammar errors. Just to give a few examples:"
    ]
  },
  {
    "paper_id": "2112.09055v1",
    "submission_id": "zjJyjQj1W7U",
    "submission_title": "Hierarchical Clustering: $O(1)$-Approximation for Well-Clustered Graphs",
    "review_id": "gn7LbaGxIbx",
    "input": {
      "title": "Hierarchical Clustering: $O(1)$-Approximation for Well-Clustered Graphs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Roughly speaking, the technical part of the paper is structured as follows:\n- - It starts with a discussion on graphs with high conductance.\n- Such a graph can be though of as one single cluster for which there might not be a reasonable cut.\n- With a motivating example (Figure 1), the authors proposed to group vertices of similar degrees first to reduce the hierarchical clustering cost.\n- On such a graph, the authors designs Algorithm 1 which constructs the hierarchical clustering tree based on degrees, and proves it is a constant approximation by moving vertices around in the HC tree and slightly modifying the HC tree step by step.\n- Such movements of vertices are centered around a 'dense branch' which is a path in the HC tree, where the internal nodes represent clusters whose sizes are bigger than their siblings.\n- The paper then considers a well-clustered graph which is composed of a given number of such high-conductance subgraphs (clusters), where the inter-cluster edges are more sparse than intra-cluster edges.\n- The paper contains novel ideas for performing theoretical analysis on HC algorithms and in particular for Dasgupta's objective.\n- Some of the techniques used in the paper, including focusing on the 'dense branch' and reconstructing trees by slightly modifying some of the branches, were also adopted by previous work, but this paper carefully managed to put them to good use, and has found a nice breakthrough for HC-related theory, in my opinion.\n- Analysis for Dasgupta's objective function often comes hand in hand with finding sparsest-cut, and the methods proposed in this paper at least offered a different perspective.\n- The submission seems to be technically sound.\n- The writing quality is good.\n- The underlying algorithms are quite complicated but the authors were able to at least convey the main ideas.\n- In particular, they have motivated the assumptions and the algorithm design very well.\n- The paper's main contributions are theoretical.\n- Assuming it is correct, it adds to the community's understanding of HC objective functions and may contain some new tools that can be used for studying Dasgupta's objective.\n- Emprically, the algorithm is on par with other algorithms developed in previous work.\n- It does not outperform the most widely used HC algorithms yet, but the results may still enlighten us.\n- In Algorithm 1, by definition, for some |V| values r could be very close to |V|?\n- For example if |V| = 2^m + 1, does it mean r = |V| - 1?\n- It seems a bit unusual then, since the algorithm splits off one point.\n- I wasn't able to check the details due to time limits, but maybe the authors can share some intuition about why this is fine?\n- The intuition behind the algorithm is to group vertices of similar degrees first, which is also a bit non-intuitive, as I cannot really tell why it might give good HC trees at the high level.\n- It might work in this context, but I wonder whether it is easily extendable.",
    "review_points_list": [
      "Roughly speaking, the technical part of the paper is structured as follows:",
      "- It starts with a discussion on graphs with high conductance.",
      "Such a graph can be though of as one single cluster for which there might not be a reasonable cut.",
      "With a motivating example (Figure 1), the authors proposed to group vertices of similar degrees first to reduce the hierarchical clustering cost.",
      "On such a graph, the authors designs Algorithm 1 which constructs the hierarchical clustering tree based on degrees, and proves it is a constant approximation by moving vertices around in the HC tree and slightly modifying the HC tree step by step.",
      "Such movements of vertices are centered around a 'dense branch' which is a path in the HC tree, where the internal nodes represent clusters whose sizes are bigger than their siblings.",
      "The paper then considers a well-clustered graph which is composed of a given number of such high-conductance subgraphs (clusters), where the inter-cluster edges are more sparse than intra-cluster edges.",
      "The paper contains novel ideas for performing theoretical analysis on HC algorithms and in particular for Dasgupta's objective.",
      "Some of the techniques used in the paper, including focusing on the 'dense branch' and reconstructing trees by slightly modifying some of the branches, were also adopted by previous work, but this paper carefully managed to put them to good use, and has found a nice breakthrough for HC-related theory, in my opinion.",
      "Analysis for Dasgupta's objective function often comes hand in hand with finding sparsest-cut, and the methods proposed in this paper at least offered a different perspective.",
      "The submission seems to be technically sound.",
      "The writing quality is good.",
      "The underlying algorithms are quite complicated but the authors were able to at least convey the main ideas.",
      "In particular, they have motivated the assumptions and the algorithm design very well.",
      "The paper's main contributions are theoretical.",
      "Assuming it is correct, it adds to the community's understanding of HC objective functions and may contain some new tools that can be used for studying Dasgupta's objective.",
      "Emprically, the algorithm is on par with other algorithms developed in previous work.",
      "It does not outperform the most widely used HC algorithms yet, but the results may still enlighten us.",
      "In Algorithm 1, by definition, for some |V| values r could be very close to |V|?",
      "For example if |V| = 2^m + 1, does it mean r = |V| - 1?",
      "It seems a bit unusual then, since the algorithm splits off one point.",
      "I wasn't able to check the details due to time limits, but maybe the authors can share some intuition about why this is fine?",
      "The intuition behind the algorithm is to group vertices of similar degrees first, which is also a bit non-intuitive, as I cannot really tell why it might give good HC trees at the high level.",
      "It might work in this context, but I wonder whether it is easily extendable."
    ]
  },
  {
    "paper_id": "2112.09055v1",
    "submission_id": "zjJyjQj1W7U",
    "submission_title": "Hierarchical Clustering: $O(1)$-Approximation for Well-Clustered Graphs",
    "review_id": "EEPGAqNaveH",
    "input": {
      "title": "Hierarchical Clustering: $O(1)$-Approximation for Well-Clustered Graphs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Clustering well-clusterable graphs is a top topic, and this work certainly adds to the literature.\n- The algorithms and theoretical bounds are not very practical, though.\n- The gains in practice are small.\n- The paper is easy to read despite the heavy math.",
    "review_points_list": [
      "Clustering well-clusterable graphs is a top topic, and this work certainly adds to the literature.",
      "The algorithms and theoretical bounds are not very practical, though.",
      "The gains in practice are small.",
      "The paper is easy to read despite the heavy math."
    ]
  },
  {
    "paper_id": "2112.09055v1",
    "submission_id": "zjJyjQj1W7U",
    "submission_title": "Hierarchical Clustering: $O(1)$-Approximation for Well-Clustered Graphs",
    "review_id": "vmpqcRRdGXQ",
    "input": {
      "title": "Hierarchical Clustering: $O(1)$-Approximation for Well-Clustered Graphs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors study the important problem of clustering graph in a hierarchical way optimizing an objective function introduced by Dasgupta [13].\n- The authors study the problem under the assumption that the graph is well clusterable, in particular that it has high conductance (O(1)).\n- Under this assumption they show a very fast near linear algorithm constant factor algorithm.\n- Then they generalize this to well clustered graphs going beyond the stochastic block model to arbitrary graphs with this property.\n- Moreover the paper is complemented with an empirical analysis.\n- The first structural observation is that if the graph has constant conductance and constant ratio of min max degree any tree is a constant approx solution.\n- Then they introduce an algorithm which simply sorts nodes by degree and builds a tree balancing the nodes in order.\n- Surprisingly this algorithm is a O(1/poly(conductance)) approximate despite being oblivious to the structure of the graph.\n- This suggests to me that getting a constant approximate hierarchical clustering of such graphs (despite the theoretical interest) is not an practically interesting result and as such the algorithm is not practically useful (expect as a building block).\n- Then they adapt their algorithm to well clustered graphs using results from Trevisan et al. on finding sparse cuts.\n- The algorithm is non-trivial.\n- Then they provide an empirical evaluation of their algorithm against standard heuristic baselines for HC and some algorithms with theoretical guarantees for special cases of the HC problem.\n- First they compare on synthetic SBM data where the performance ties with state of the art.\n- On other synthetic data with multiple densities they improve over some baselines but the performance is tied with average linkage.\n- Finally on real data their performance is better than some state off the art method (for HC in some objective and setting) but worse than the baselines of Average and complete linkage.\n- Minor: very interesting theoretical fact, -> perhaps just interesting.",
    "review_points_list": [
      "The authors study the important problem of clustering graph in a hierarchical way optimizing an objective function introduced by Dasgupta [13].",
      "The authors study the problem under the assumption that the graph is well clusterable, in particular that it has high conductance (O(1)).",
      "Under this assumption they show a very fast near linear algorithm constant factor algorithm.",
      "Then they generalize this to well clustered graphs going beyond the stochastic block model to arbitrary graphs with this property.",
      "Moreover the paper is complemented with an empirical analysis.",
      "The first structural observation is that if the graph has constant conductance and constant ratio of min max degree any tree is a constant approx solution.",
      "Then they introduce an algorithm which simply sorts nodes by degree and builds a tree balancing the nodes in order.",
      "Surprisingly this algorithm is a O(1/poly(conductance)) approximate despite being oblivious to the structure of the graph.",
      "This suggests to me that getting a constant approximate hierarchical clustering of such graphs (despite the theoretical interest) is not an practically interesting result and as such the algorithm is not practically useful (expect as a building block).",
      "Then they adapt their algorithm to well clustered graphs using results from Trevisan et al. on finding sparse cuts.",
      "The algorithm is non-trivial.",
      "Then they provide an empirical evaluation of their algorithm against standard heuristic baselines for HC and some algorithms with theoretical guarantees for special cases of the HC problem.",
      "First they compare on synthetic SBM data where the performance ties with state of the art.",
      "On other synthetic data with multiple densities they improve over some baselines but the performance is tied with average linkage.",
      "Finally on real data their performance is better than some state off the art method (for HC in some objective and setting) but worse than the baselines of Average and complete linkage.",
      "Minor: very interesting theoretical fact, -> perhaps just interesting."
    ]
  },
  {
    "paper_id": "2106.02346v2",
    "submission_id": "yKdYdQbo22W",
    "submission_title": "Provably Strict Generalisation Benefit for Invariance in Kernel Methods",
    "review_id": "6PUACeTl8c6",
    "input": {
      "title": "Provably Strict Generalisation Benefit for Invariance in Kernel Methods",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- My review is based on the supplementary material, because it seemed to me that the submission is simply a condensed version of the supplementary material.\n- My overall impression is overwhelmingly positive.\n- It is written in good English, the structure of the paper is solid and I really appreciated the superb clarity of mathematical exposition, which is oftentimes lacking in machine learning papers.\n- I have tried my best to do it justice with the review, although I must admit I was not familiar with the literature of group invariant models before reading this submission.\n- I thank the authors for their work, and I apologise in advance for any misunderstandings on my part.\n- [8] is important prior work, where Elesedy and Zaidi proved benefit in terms of expected risk of orbit-averaged linear solutions.\n- This work extends their contributions by proving an analogous result for kernel ridge regression, which is a much more flexible regression technique.\n- I tried to read up [8] as much as possible, and even though I am not familiar with the related work that came before [8], I am prepared to believe that no prior work proved the kind of generalisation benefits that [8] and the current submission provide, and if that is the case, I deem the contributions significant.\n- I checked the proofs as much as I can, and although of course there may be things that I have missed, they look correct.\n- Often in learning theory papers for RKHS-based regression, the input space is constrained to be compact, but I appreciated that they relaxed this assumption.\n- I would have liked to give a higher overall rating than a 7, but I can't help thinking that the main original contributions came in [8], and this is rather an extension of that.\n- But I do very much value the extension to kernel ridge regression.\n- I foresee that some reviewers will not like the fact that no experiments have been conducted to validate the results, but I am prepared to argue that the theoretical contributions suffice for acceptance.\n- Some additional points / questions:\n- 1) I'm a bit confused by the paragraph of lines 55-59.\n- It says that Delta(f,f')>0 then f has strictly better test performance at f', but shouldn't it be the other way round, or 'larger test error than'?\n- This would be consistent with the rest of the paragraph, and also with the definition of Delta(f,f') in Section 4.2.\n- 2) Just a matter of exposition - it would be good if the displayed equation after line 105 had a full stop.\n- 3) On line 388, it is currently written iota:L_2(X,mu) -> H, which I imagine is not what the authors intended.\n- In the proof of Lemma C.1, iota:H->L_2(X,mu) is correctly written.\n- 4) Lines 259-260 need to be re-written.\n- 5) In the displayed equations after lines 261 and 262, M needs to be M_k.\n- 6) In the displayed equations after line 290, the first and second lines on the right-hand side seem identical.\n- 7) The term 'effective dimension' was coined in [Optimal Rates for the Regularised Least-Squares Algorithm, Caponnetto and de Vito, 2007]; however, in that paper, it depends on the regulariser lambda (rho, in your notation) of kernel ridge regression, and is defined, if I\u2019m not mistaken, as the trace of (T+lambda)^{-1}T, where T, unlike your T_k, is the operator H -> H.\n- So the order of composing the inclusion of H into L_2 and its adjoint is opposite to yours.\n- I think there is a case to be made for both; on the one hand, any kind of 'dimension' of a space should be an inherent property of itself, and shouldn\u2019t depend on the regulariser used, which is a case for your definition, but then again, if the dimension is to take into account the functions considered for kernel ridge regression, then it does make sense that the amount of regularisation plays a role.\n- I would be extremely grateful if the authors could comment on this difference, and also the fact that you consider the trace of T_k^2, whereas they consider (T+lambda)^{-1}T.\n- I think it might still be worth using a different terminology, or at the very least mention the existing usage and explain how your definition is different.\n- 8) I am more familiar with the kernel literature, and I know that the assumptions that you placed on the kernels are not restrictive.\n- However, I am not familiar with the group invariance literature, and I would be very grateful if you could just mention whether or not the assumptions you placed on G are not restrictive (e.g. that it is compact).\n- Also, the assumption that the measure is supported on the whole of X seems crucial, since it is required for Lemma C.1 and thence the rest of the results, but this loses a little bit of generality.",
    "review_points_list": [
      "My review is based on the supplementary material, because it seemed to me that the submission is simply a condensed version of the supplementary material.",
      "My overall impression is overwhelmingly positive.",
      "It is written in good English, the structure of the paper is solid and I really appreciated the superb clarity of mathematical exposition, which is oftentimes lacking in machine learning papers.",
      "I have tried my best to do it justice with the review, although I must admit I was not familiar with the literature of group invariant models before reading this submission.",
      "I thank the authors for their work, and I apologise in advance for any misunderstandings on my part.",
      "[8] is important prior work, where Elesedy and Zaidi proved benefit in terms of expected risk of orbit-averaged linear solutions.",
      "This work extends their contributions by proving an analogous result for kernel ridge regression, which is a much more flexible regression technique.",
      "I tried to read up [8] as much as possible, and even though I am not familiar with the related work that came before [8], I am prepared to believe that no prior work proved the kind of generalisation benefits that [8] and the current submission provide, and if that is the case, I deem the contributions significant.",
      "I checked the proofs as much as I can, and although of course there may be things that I have missed, they look correct.",
      "Often in learning theory papers for RKHS-based regression, the input space is constrained to be compact, but I appreciated that they relaxed this assumption.",
      "I would have liked to give a higher overall rating than a 7, but I can't help thinking that the main original contributions came in [8], and this is rather an extension of that.",
      "But I do very much value the extension to kernel ridge regression.",
      "I foresee that some reviewers will not like the fact that no experiments have been conducted to validate the results, but I am prepared to argue that the theoretical contributions suffice for acceptance.",
      "Some additional points / questions:",
      "1) I'm a bit confused by the paragraph of lines 55-59.",
      "It says that Delta(f,f')>0 then f has strictly better test performance at f', but shouldn't it be the other way round, or 'larger test error than'?",
      "This would be consistent with the rest of the paragraph, and also with the definition of Delta(f,f') in Section 4.2.",
      "2) Just a matter of exposition - it would be good if the displayed equation after line 105 had a full stop.",
      "3) On line 388, it is currently written iota:L_2(X,mu) -> H, which I imagine is not what the authors intended.",
      "In the proof of Lemma C.1, iota:H->L_2(X,mu) is correctly written.",
      "4) Lines 259-260 need to be re-written.",
      "5) In the displayed equations after lines 261 and 262, M needs to be M_k.",
      "6) In the displayed equations after line 290, the first and second lines on the right-hand side seem identical.",
      "7) The term 'effective dimension' was coined in [Optimal Rates for the Regularised Least-Squares Algorithm, Caponnetto and de Vito, 2007]; however, in that paper, it depends on the regulariser lambda (rho, in your notation) of kernel ridge regression, and is defined, if I\u2019m not mistaken, as the trace of (T+lambda)^{-1}T, where T, unlike your T_k, is the operator H -> H.",
      "So the order of composing the inclusion of H into L_2 and its adjoint is opposite to yours.",
      "I think there is a case to be made for both; on the one hand, any kind of 'dimension' of a space should be an inherent property of itself, and shouldn\u2019t depend on the regulariser used, which is a case for your definition, but then again, if the dimension is to take into account the functions considered for kernel ridge regression, then it does make sense that the amount of regularisation plays a role.",
      "I would be extremely grateful if the authors could comment on this difference, and also the fact that you consider the trace of T_k^2, whereas they consider (T+lambda)^{-1}T.",
      "I think it might still be worth using a different terminology, or at the very least mention the existing usage and explain how your definition is different.",
      "8) I am more familiar with the kernel literature, and I know that the assumptions that you placed on the kernels are not restrictive.",
      "However, I am not familiar with the group invariance literature, and I would be very grateful if you could just mention whether or not the assumptions you placed on G are not restrictive (e.g. that it is compact).",
      "Also, the assumption that the measure is supported on the whole of X seems crucial, since it is required for Lemma C.1 and thence the rest of the results, but this loses a little bit of generality."
    ]
  },
  {
    "paper_id": "2106.02346v2",
    "submission_id": "yKdYdQbo22W",
    "submission_title": "Provably Strict Generalisation Benefit for Invariance in Kernel Methods",
    "review_id": "x5qbPH25vIU",
    "input": {
      "title": "Provably Strict Generalisation Benefit for Invariance in Kernel Methods",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper shows an interesting theoretical effect of incorporating invariances on the reduction of generalization gap.\n- Introducing the notion of effective dimensionality of kernels and its usage in bounding the reduction of generalization gap is a clear contribution of the paper.\n- The presentation of the paper is quite abstract, and it is not clear how the theory can be applied to real applications.\n- Unfortunately, the authors did not show any examples of invariance incorporation or experimental results, and it is hard to have an idea how well-known invariances can be formulated in terms of the equations in this paper.\n- For example, the translation invariance in vision problem is a local property, and it depends on the point of interest.\n- A single invariant transformation g\u2208G (e.g. one tangent vector) does not apply globally to all data (in the data manifold) violating the assumptions in lines 80-81.\n- The condition for the target function f* in line 232 is too strong.\n- In real problems, the invariance is a model that is not necessarily exist in true data-generating function or some invariances can be ignored by the model, so f* can be outside of (though can be close to) the invariant functions.\n- Also, the way to calculate the effective dimensionality in real problems is unclear.\n- Given a kernel with invariance G, can the effective dimensionality be obtained?\n- All these questions arise because the authors did not present a concrete example and an experiment that confirms the theoretical derivation.\n- Though the way to present the theoretical results is nice in this paper, the meaning of equations and its usefulness in real applications are limited.",
    "review_points_list": [
      "The paper shows an interesting theoretical effect of incorporating invariances on the reduction of generalization gap.",
      "Introducing the notion of effective dimensionality of kernels and its usage in bounding the reduction of generalization gap is a clear contribution of the paper.",
      "The presentation of the paper is quite abstract, and it is not clear how the theory can be applied to real applications.",
      "Unfortunately, the authors did not show any examples of invariance incorporation or experimental results, and it is hard to have an idea how well-known invariances can be formulated in terms of the equations in this paper.",
      "For example, the translation invariance in vision problem is a local property, and it depends on the point of interest.",
      "A single invariant transformation g\u2208G (e.g. one tangent vector) does not apply globally to all data (in the data manifold) violating the assumptions in lines 80-81.",
      "The condition for the target function f* in line 232 is too strong.",
      "In real problems, the invariance is a model that is not necessarily exist in true data-generating function or some invariances can be ignored by the model, so f* can be outside of (though can be close to) the invariant functions.",
      "Also, the way to calculate the effective dimensionality in real problems is unclear.",
      "Given a kernel with invariance G, can the effective dimensionality be obtained?",
      "All these questions arise because the authors did not present a concrete example and an experiment that confirms the theoretical derivation.",
      "Though the way to present the theoretical results is nice in this paper, the meaning of equations and its usefulness in real applications are limited."
    ]
  },
  {
    "paper_id": "2106.02346v2",
    "submission_id": "yKdYdQbo22W",
    "submission_title": "Provably Strict Generalisation Benefit for Invariance in Kernel Methods",
    "review_id": "XCMRoepdI8M",
    "input": {
      "title": "Provably Strict Generalisation Benefit for Invariance in Kernel Methods",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This is a novel quantitative result on KRR with invariant features.\n- The authors show a strictly positive generalisation gap (test error difference) between the vanilla KRR estimator and its invariant version (realised by posthoc symmetrisation with respect to the group); it is a finite-sample lower bound expressed with kernel and RKHS quantities.\n- The paper provides rigorous insights into the learning problem, and auxiliary results that contain an interesting interplay between RKHSs and invariance;\n- I am in favour of its acceptance therefore.\n- The use of Fubini's theorem in Theorem 5 (L247) is minor and negative.\n- The integrated is not necessarily non-negative and Eq. (5) does not seem to suffice.\n- We should be able to prove the L_2(\text{X} \times \text{X}, \text{X} \times \text{X})$-convergence of the finite sum kernel to j^{\text{perp}}.\n- Other uses such as the display below L256 can also be replaced with different techniques such as the monotone convergence theorem.\n- If these are fixed, I can confidently support the technical results in the paper and raise my score.\n- Typos: RHKS, Reisz.\n- Reference for Lemma 2. The result in the cited paper concerns equivariant functions. Is this reference okay?\n- L232: Typo, $\text{E}[\text{xi}_i^2]=0$.\n- You might want to replace the symbol for the operator norm in the supplementary, as it can be read as the Frobenius norm.\n- It might be good if some properties of j(x, y) such as the boundedness are mentioned for later results.\n- It would also be great if the authors could provide analysis for the symmetrised KRR when it is approximated by finite samples (from the Haar measure); orbit averaging appears to be intractable in practice.\n- Lemma C.3: The first line in the proof should mention that a and b are defined as Bochner integrals; and therefore they are weakly integrable.",
    "review_points_list": [
      "This is a novel quantitative result on KRR with invariant features.",
      "The authors show a strictly positive generalisation gap (test error difference) between the vanilla KRR estimator and its invariant version (realised by posthoc symmetrisation with respect to the group); it is a finite-sample lower bound expressed with kernel and RKHS quantities.",
      "The paper provides rigorous insights into the learning problem, and auxiliary results that contain an interesting interplay between RKHSs and invariance;",
      "I am in favour of its acceptance therefore.",
      "The use of Fubini's theorem in Theorem 5 (L247) is minor and negative.",
      "The integrated is not necessarily non-negative and Eq. (5) does not seem to suffice.",
      "We should be able to prove the L_2(\text{X} \times \text{X}, \text{X} \times \text{X})$-convergence of the finite sum kernel to j^{\text{perp}}.",
      "Other uses such as the display below L256 can also be replaced with different techniques such as the monotone convergence theorem.",
      "If these are fixed, I can confidently support the technical results in the paper and raise my score.",
      "Typos: RHKS, Reisz.",
      "Reference for Lemma 2. The result in the cited paper concerns equivariant functions. Is this reference okay?",
      "L232: Typo, $\text{E}[\text{xi}_i^2]=0$.",
      "You might want to replace the symbol for the operator norm in the supplementary, as it can be read as the Frobenius norm.",
      "It might be good if some properties of j(x, y) such as the boundedness are mentioned for later results.",
      "It would also be great if the authors could provide analysis for the symmetrised KRR when it is approximated by finite samples (from the Haar measure); orbit averaging appears to be intractable in practice.",
      "Lemma C.3: The first line in the proof should mention that a and b are defined as Bochner integrals; and therefore they are weakly integrable."
    ]
  },
  {
    "paper_id": "2011.10006v3",
    "submission_id": "uJDmJp7kn2F",
    "submission_title": "Improved rates for prediction and identification for partially observed linear dynamical systems",
    "review_id": "E-QCaQ0FtC",
    "input": {
      "title": "Improved rates for prediction and identification for partially observed linear dynamical systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Obtaining finite-time bounds for the estimation of linear dynamical systems\u2014in both the setting where the state is observed and the state is unobserved\u2014has been a well-studied problem in the machine learning community over the last several years, and this works fits in that literature.\n- A primary goal of existing works has been to obtain error bounds which do not scale with the \u201cmemory\u201d of the system, 1/(1-\rho(A)).\n- Several existing works have addressed this\u2014for example, [1] introduces the notion of \"phase rank\" to avoid the memory dependence\u2014but it is not clear that the issue has been completely solved (phase rank could be exponential in the dimension in some cases, which is also highly undesirable).\n- This work claims to remove the memory dependence without incurring poor dependence on other quantities, but is only able to do so in the case with 0 process noise.\n- As noted above, removing the 1/(1-\rho(A)) dependence is an important goal, and as yet has not been completely achieved in the case when the state is unobserved.\n- The authors do solve the problem in the case when the process noise is 0, eliminating the dependence on the memory in this setting.\n- The primary issue with this paper is that the memory dependence can only be removed in the case when there is no process noise, i.e. the results improve on the state of the art only when there is no process noise.\n- This is a very restrictive assumption, is likely unrealistic in practice, and it is not clear how interesting this setting is to the learning theory community (existing works have all assumed non-zero process noise).\n- Even in the noiseless setting, the memory dependence is not removed for the recovery of the system parameters (i.e. A,B,C,D) but only for the recovery of the impulse response.\n- The authors restrict to the case when \\rho(A) < 1 while existing works also encompass the case when \\rho(A) = 1.\n- The algorithm takes as input the memory length of the system, but it is not clear how one should actually set this without knowing the system parameters.\n- More care should be taken in comparing to [1]. [1] introduces the idea of phase rank, and provides bounds that scale with the phase rank instead of 1/(1-\rho(A)) in some cases (even with non-zero process noise).\n- No discussion of this is given\u2014it should be clarified what precisely the bounds in [1] work out to be, and what the actual memory dependence suffered is.\n- At minimum the authors should not claim that no existing works obtain bounds that are memory-independent and should show explicit examples where their results improve over the phase rank dependence in [1].\n- While this work does make a contribution, the restrictive assumptions noted above and the fact that [1] partially solves the problem already are, in my opinion, significant enough that it does not warrant an accept.",
    "review_points_list": [
      "Obtaining finite-time bounds for the estimation of linear dynamical systems\u2014in both the setting where the state is observed and the state is unobserved\u2014has been a well-studied problem in the machine learning community over the last several years, and this works fits in that literature.",
      "A primary goal of existing works has been to obtain error bounds which do not scale with the \u201cmemory\u201d of the system, 1/(1-\rho(A)).",
      "Several existing works have addressed this\u2014for example, [1] introduces the notion of \"phase rank\" to avoid the memory dependence\u2014but it is not clear that the issue has been completely solved (phase rank could be exponential in the dimension in some cases, which is also highly undesirable).",
      "This work claims to remove the memory dependence without incurring poor dependence on other quantities, but is only able to do so in the case with 0 process noise.",
      "As noted above, removing the 1/(1-\rho(A)) dependence is an important goal, and as yet has not been completely achieved in the case when the state is unobserved.",
      "The authors do solve the problem in the case when the process noise is 0, eliminating the dependence on the memory in this setting.",
      "The primary issue with this paper is that the memory dependence can only be removed in the case when there is no process noise, i.e. the results improve on the state of the art only when there is no process noise.",
      "This is a very restrictive assumption, is likely unrealistic in practice, and it is not clear how interesting this setting is to the learning theory community (existing works have all assumed non-zero process noise).",
      "Even in the noiseless setting, the memory dependence is not removed for the recovery of the system parameters (i.e. A,B,C,D) but only for the recovery of the impulse response.",
      "The authors restrict to the case when \\rho(A) < 1 while existing works also encompass the case when \\rho(A) = 1.",
      "The algorithm takes as input the memory length of the system, but it is not clear how one should actually set this without knowing the system parameters.",
      "More care should be taken in comparing to [1]. [1] introduces the idea of phase rank, and provides bounds that scale with the phase rank instead of 1/(1-\rho(A)) in some cases (even with non-zero process noise).",
      "No discussion of this is given\u2014it should be clarified what precisely the bounds in [1] work out to be, and what the actual memory dependence suffered is.",
      "At minimum the authors should not claim that no existing works obtain bounds that are memory-independent and should show explicit examples where their results improve over the phase rank dependence in [1].",
      "While this work does make a contribution, the restrictive assumptions noted above and the fact that [1] partially solves the problem already are, in my opinion, significant enough that it does not warrant an accept."
    ]
  },
  {
    "paper_id": "2011.10006v3",
    "submission_id": "uJDmJp7kn2F",
    "submission_title": "Improved rates for prediction and identification for partially observed linear dynamical systems",
    "review_id": "fYQ4_XDhuwS",
    "input": {
      "title": "Improved rates for prediction and identification for partially observed linear dynamical systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think the algorithm and its analysis is novel on both technical and conceptual level.\n- It solves an important problem with near optimal bounds which does not depend on the memory length by using the elegant idea of SVD to denoise the Hankel matrix estimate obtained through least squares regression.\n- Rest of the algorithm seems to be fairly standard.\n- I think this deserves to be published in NeurIPS 2021.\n- Some comments:\n- 1. The improved rates only hold when there is no additional noise in the hidden dynamics of the system. (This is mentioned in the paper)\n- 2. The parameter recovery in Theorem 2.3 has an additional factor L, which is not clearly explained.\n- 3. It would be great if the magnitude of \u025btrunc is mentioned.\n- 4. It would be useful to mention the computational complexity of the algorithm.",
    "review_points_list": [
      "I think the algorithm and its analysis is novel on both technical and conceptual level.",
      "It solves an important problem with near optimal bounds which does not depend on the memory length by using the elegant idea of SVD to denoise the Hankel matrix estimate obtained through least squares regression.",
      "Rest of the algorithm seems to be fairly standard.",
      "I think this deserves to be published in NeurIPS 2021.",
      "Some comments:",
      "1. The improved rates only hold when there is no additional noise in the hidden dynamics of the system. (This is mentioned in the paper)",
      "2. The parameter recovery in Theorem 2.3 has an additional factor L, which is not clearly explained.",
      "3. It would be great if the magnitude of \u025btrunc is mentioned.",
      "4. It would be useful to mention the computational complexity of the algorithm."
    ]
  },
  {
    "paper_id": "2011.10006v3",
    "submission_id": "uJDmJp7kn2F",
    "submission_title": "Improved rates for prediction and identification for partially observed linear dynamical systems",
    "review_id": "naiUOIW1GDC",
    "input": {
      "title": "Improved rates for prediction and identification for partially observed linear dynamical systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper's overall structure and organization are clear, and it is well-written.\n- The authors have successfully demonstrated the effectiveness of their proposed algorithm, Cluster-Margin.\n- However, I have some concerns.\n- The authors could have done a better job at discussing how their method compares to other active learning algorithms.\n- Additionally, the experimental results seem to be overly focused on the Open Images dataset.\n- The paper's strengths include its clear presentation, the thoroughness of the experiments, and the novel idea of using a cluster-based approach for active learning.\n- Weaknesses include the lack of evaluation on real-world datasets and the need for further analysis on the computational complexity of the algorithm.\n- The authors should also consider exploring the applicability of the method to other domains, such as text or speech processing.\n- I would recommend this paper for publication after the authors address these concerns.",
    "review_points_list": [
      "The paper's overall structure and organization are clear, and it is well-written.",
      "The authors have successfully demonstrated the effectiveness of their proposed algorithm, Cluster-Margin.",
      "However, I have some concerns.",
      "The authors could have done a better job at discussing how their method compares to other active learning algorithms.",
      "Additionally, the experimental results seem to be overly focused on the Open Images dataset.",
      "The paper's strengths include its clear presentation, the thoroughness of the experiments, and the novel idea of using a cluster-based approach for active learning.",
      "Weaknesses include the lack of evaluation on real-world datasets and the need for further analysis on the computational complexity of the algorithm.",
      "The authors should also consider exploring the applicability of the method to other domains, such as text or speech processing.",
      "I would recommend this paper for publication after the authors address these concerns."
    ]
  },
  {
    "paper_id": "2209.09344v1",
    "submission_id": "xj2sE--Q90e",
    "submission_title": "Understanding End-to-End Model-Based Reinforcement Learning Methods as Implicit Parameterization",
    "review_id": "cOEgM43FAu",
    "input": {
      "title": "Understanding End-to-End Model-Based Reinforcement Learning Methods as Implicit Parameterization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- While this analysis is fairly disconnected from existing empirical implicit-model methods, what it suggests has very interesting implications.\n- The disconnect to me is the MDP->MRP simplification, and the control->evaluation->supervised simplification;\n- both are fair simplifications for theoretical analysis, but they still reduce its predictive power.\n- The interesting implications I see is that this intuitively translates very well to gradient dynamics in non-linear (deep) models:\n- if the partial derivatives between the implicit model predictions and the residual are well conditioned, we should expect the same effect regardless of how complicated that implicit model is.\n- I am unfortunately not comfortable enough with the theory here to spot non-obvious mistakes, but I did not spot any superficial mistake.\n- I am also only superficially familiar with the implicit-model literature, but as far as I know analysing particular RL methods as preconditioners has mostly only been done in the options literature;\n- This seems like a new take.\n- The paper was fairly easy to read, and the ideas here are well communicated.\n- The empirical results link the theoretical claims to empirical claims, although very basic.\n- I think that, without starting to solve Atari, more could have been done to illustrate the implications of the theorem.\n- For example, one could repeat these experiments in the control case, or in the temporal difference case;\n- while we shouldn't expect the theory to exactly hold, we may still observe effects which, in the long run, we would like to see in complicated environments.\n- I usually write a long list of comments and nitpicking in my reviews, but this paper was fairly straightforward and I don't have much to add here.\n- Rebuttal update: I've read the other reviews and rebuttals and I'm inclined to keep my current score. I think this is a good contribution.",
    "review_points_list": [
      "While this analysis is fairly disconnected from existing empirical implicit-model methods, what it suggests has very interesting implications.",
      "The disconnect to me is the MDP->MRP simplification, and the control->evaluation->supervised simplification;",
      "both are fair simplifications for theoretical analysis, but they still reduce its predictive power.",
      "The interesting implications I see is that this intuitively translates very well to gradient dynamics in non-linear (deep) models:",
      "if the partial derivatives between the implicit model predictions and the residual are well conditioned, we should expect the same effect regardless of how complicated that implicit model is.",
      "I am unfortunately not comfortable enough with the theory here to spot non-obvious mistakes, but I did not spot any superficial mistake.",
      "I am also only superficially familiar with the implicit-model literature, but as far as I know analysing particular RL methods as preconditioners has mostly only been done in the options literature;",
      "This seems like a new take.",
      "The paper was fairly easy to read, and the ideas here are well communicated.",
      "The empirical results link the theoretical claims to empirical claims, although very basic.",
      "I think that, without starting to solve Atari, more could have been done to illustrate the implications of the theorem.",
      "For example, one could repeat these experiments in the control case, or in the temporal difference case;",
      "while we shouldn't expect the theory to exactly hold, we may still observe effects which, in the long run, we would like to see in complicated environments.",
      "I usually write a long list of comments and nitpicking in my reviews, but this paper was fairly straightforward and I don't have much to add here.",
      "Rebuttal update: I've read the other reviews and rebuttals and I'm inclined to keep my current score. I think this is a good contribution."
    ]
  },
  {
    "paper_id": "2209.09344v1",
    "submission_id": "xj2sE--Q90e",
    "submission_title": "Understanding End-to-End Model-Based Reinforcement Learning Methods as Implicit Parameterization",
    "review_id": "i4MLr2oHAC9",
    "input": {
      "title": "Understanding End-to-End Model-Based Reinforcement Learning Methods as Implicit Parameterization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well written, concepts are carefully and clearly exposed.\n- My main issue is that more theoretical results could be empirically verified such as the superiority of the variance to expectation ratio for updates.\n- Was it tried and not found conclusively?\n- Theorem 1 is a bit unclear.\n- The two updates in (4) that are claimed to hold, among them the first one is by choice as mentioned earlier in line 132 and it is not clear what the optimization procedure involved is for the implicit parameterization.\n- The only knowledge provided is in line 133 \u201cimplicitly parameterized linear weights obtained by optimizing L.\u201d\n- But optimizing using what? SGD? Least squares?\n- Depending on the choice of the optimizer, the evolution may follow different paths.\n- Also, the theorem statement should explicitly contain this information instead of relying on text in the prior paragraph.\n- Line 87: it will be better to replace (w, F) with psi = (w, F).\n- **** post rebuttal ****\n- Thanks for the clarifications.",
    "review_points_list": [
      "The paper is well written, concepts are carefully and clearly exposed.",
      "My main issue is that more theoretical results could be empirically verified such as the superiority of the variance to expectation ratio for updates.",
      "Was it tried and not found conclusively?",
      "Theorem 1 is a bit unclear.",
      "The two updates in (4) that are claimed to hold, among them the first one is by choice as mentioned earlier in line 132 and it is not clear what the optimization procedure involved is for the implicit parameterization.",
      "The only knowledge provided is in line 133 \u201cimplicitly parameterized linear weights obtained by optimizing L.\u201d",
      "But optimizing using what? SGD? Least squares?",
      "Depending on the choice of the optimizer, the evolution may follow different paths.",
      "Also, the theorem statement should explicitly contain this information instead of relying on text in the prior paragraph.",
      "Line 87: it will be better to replace (w, F) with psi = (w, F).",
      "**** post rebuttal ****",
      "Thanks for the clarifications."
    ]
  },
  {
    "paper_id": "2209.09344v1",
    "submission_id": "xj2sE--Q90e",
    "submission_title": "Understanding End-to-End Model-Based Reinforcement Learning Methods as Implicit Parameterization",
    "review_id": "UQ4R4eYnMdt",
    "input": {
      "title": "Understanding End-to-End Model-Based Reinforcement Learning Methods as Implicit Parameterization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- It is difficult to understand the significance and novelty of the theoretical analysis presented in the paper.\n- Some areas of concern are discussed below.\n- The analysis is only presented for the case of an MDP with a singleton action.\n- This means the theoretical analysis is only valid for Markov reward chains, not Markov Decision Processes.\n- It is stated in the Conclusion that the results might generalize to full MDPs, but there does not seem to be any evidence for this assertion.\n- In the absence of this generalization, it is confusing to frame the analysis in terms of understanding RL methods.\n- Being restricted to a singleton action is far too stringent an assumption for the study of RL methods.\n- The authors should clarify how the assumption of working in the supervised learning setting impacts the theoretical analysis, and what results one might expect in the full reinforcement learning case.\n- In particular, it seems that convergence to the global optimum would not hold in the absence of a fixed set of datapoints (since convergence on each set individually is not sufficient for convergence globally).\n- The analysis is presented in a formulation that closely resembles that of value iteration networks (VIN) (Line 88).\n- However, as the VIN paper points out '[This] approach is different from model-based RL, which requires system identification to map the observations to a dynamics model, which is then solved for a policy.'\n- Considering this difference, it would be helpful if the authors would clearly comment on how this formulation is related and differentiated from typical model-based RL.\n- Presenting the analysis for end-to-end model based RL, while only considering the VIN formulation is likely to create confusion.\n- It would help if the authors would clearly delineate the novel technical innovations in the theoretical analysis.\n- The authors seem to state that results for the explicit parametrization case are not novel (Line 189).\n- Is this the case for all the results regarding explicit parametrization?\n- It would also be helpful to highlight the key steps and theorems that do not simply follow from standard results.",
    "review_points_list": [
      "It is difficult to understand the significance and novelty of the theoretical analysis presented in the paper.",
      "Some areas of concern are discussed below.",
      "The analysis is only presented for the case of an MDP with a singleton action.",
      "This means the theoretical analysis is only valid for Markov reward chains, not Markov Decision Processes.",
      "It is stated in the Conclusion that the results might generalize to full MDPs, but there does not seem to be any evidence for this assertion.",
      "In the absence of this generalization, it is confusing to frame the analysis in terms of understanding RL methods.",
      "Being restricted to a singleton action is far too stringent an assumption for the study of RL methods.",
      "The authors should clarify how the assumption of working in the supervised learning setting impacts the theoretical analysis, and what results one might expect in the full reinforcement learning case.",
      "In particular, it seems that convergence to the global optimum would not hold in the absence of a fixed set of datapoints (since convergence on each set individually is not sufficient for convergence globally).",
      "The analysis is presented in a formulation that closely resembles that of value iteration networks (VIN) (Line 88).",
      "However, as the VIN paper points out '[This] approach is different from model-based RL, which requires system identification to map the observations to a dynamics model, which is then solved for a policy.'",
      "Considering this difference, it would be helpful if the authors would clearly comment on how this formulation is related and differentiated from typical model-based RL.",
      "Presenting the analysis for end-to-end model based RL, while only considering the VIN formulation is likely to create confusion.",
      "It would help if the authors would clearly delineate the novel technical innovations in the theoretical analysis.",
      "The authors seem to state that results for the explicit parametrization case are not novel (Line 189).",
      "Is this the case for all the results regarding explicit parametrization?",
      "It would also be helpful to highlight the key steps and theorems that do not simply follow from standard results."
    ]
  },
  {
    "paper_id": "2209.09344v1",
    "submission_id": "xj2sE--Q90e",
    "submission_title": "Understanding End-to-End Model-Based Reinforcement Learning Methods as Implicit Parameterization",
    "review_id": "U-cWEJCXA8k",
    "input": {
      "title": "Understanding End-to-End Model-Based Reinforcement Learning Methods as Implicit Parameterization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Most of the theoretical results are novel to my knowledge (some were already known but are included for comparison), and I am glad to see some progress being made on the theoretical analysis of end-to-end methods, which has so far been limited to empirical study.\n- The results in this paper provide some insight as to why one parameterization may be easier to optimize than the other, which is useful to practitioners.\n- A limitation of the results proved in the paper is that the questions it answers are all concerned with the optimization of the ERM loss, so it tells us essentially nothing about the generalization properties of the solutions found by the two parameterizations, even though the generalization abilities of end-to-end methods are the stated motivation for studying them.\n- If my understanding is correct, the paper\u2019s result about (S)GD finding global optima tells us that the asymptotic solutions of the two parameterizations should be exactly the same if the global minimum of $L(\theta)$ is unique (which it will if the feature matrix $X$ has full rank).\n- The corresponding $(w, F)$ may not be unique, but any optimal solution would still have to induce the same $\theta$.\n- That said, some of the analysis performed in this paper (e.g., Theorem 1) may be useful for analyzing the generalization as well, even though this paper does not itself present results regarding generalization.\n- In experiments, it is interesting that the optimal $\text{eta}$ can be different from the true $\text{gamma}$ that generates the labels. However, no insight regarding how to set $\text{eta}$ is provided.\n- The writing of the paper is clear.\n- I have a few miscellaneous comments/questions:\n- In the experiments, do you stop running SGD before convergence? As mentioned above, my understanding is that the two parameterizations should converge to the same value, even if one converges more quickly than the other. However in the results there is a clear difference between the two.\n- In (48) and (49), what is $U$? It seems that it should be $A$?\n- In places you write \u2018If $\text{O}(\text{alpha}_{(t)}^2) \text{leq} \text{alpha}_{(t)}^2 C$\u2019 for some $C \text{ge} 0$. Is this not always true by the definition of the $\text{O}(\text{cdot})$ notation? (Perhaps for clarify you can write exactly what is meant by $\text{O}(\text{cdot})$.)\n- The statement of Corollary 1 says that the learning rates $\text{alpha}_{(t)}$ are given, but to go from (7) to (8) you specify a value for $\text{alpha}_{(t)}$. Please justify.\n- Equation (87) seems to have a typo (extra $\text{phi}$)\n- In (106), the index $i$ is reused.\n- In the second-to-last step in the proof of Corollary 4, $r_{max}$ should be squared since it is bounding $r_i^2$. (This seems to be just a typo, as the final result has $r_{max}^2$.)",
    "review_points_list": [
      "Most of the theoretical results are novel to my knowledge (some were already known but are included for comparison), and I am glad to see some progress being made on the theoretical analysis of end-to-end methods, which has so far been limited to empirical study.",
      "The results in this paper provide some insight as to why one parameterization may be easier to optimize than the other, which is useful to practitioners.",
      "A limitation of the results proved in the paper is that the questions it answers are all concerned with the optimization of the ERM loss, so it tells us essentially nothing about the generalization properties of the solutions found by the two parameterizations, even though the generalization abilities of end-to-end methods are the stated motivation for studying them.",
      "If my understanding is correct, the paper\u2019s result about (S)GD finding global optima tells us that the asymptotic solutions of the two parameterizations should be exactly the same if the global minimum of $L(\theta)$ is unique (which it will if the feature matrix $X$ has full rank).",
      "The corresponding $(w, F)$ may not be unique, but any optimal solution would still have to induce the same $\theta$.",
      "That said, some of the analysis performed in this paper (e.g., Theorem 1) may be useful for analyzing the generalization as well, even though this paper does not itself present results regarding generalization.",
      "In experiments, it is interesting that the optimal $\text{eta}$ can be different from the true $\text{gamma}$ that generates the labels. However, no insight regarding how to set $\text{eta}$ is provided.",
      "The writing of the paper is clear.",
      "I have a few miscellaneous comments/questions:",
      "In the experiments, do you stop running SGD before convergence? As mentioned above, my understanding is that the two parameterizations should converge to the same value, even if one converges more quickly than the other. However in the results there is a clear difference between the two.",
      "In (48) and (49), what is $U$? It seems that it should be $A$?",
      "In places you write \u2018If $\text{O}(\text{alpha}_{(t)}^2) \text{leq} \text{alpha}_{(t)}^2 C$\u2019 for some $C \text{ge} 0$. Is this not always true by the definition of the $\text{O}(\text{cdot})$ notation? (Perhaps for clarify you can write exactly what is meant by $\text{O}(\text{cdot})$.)",
      "The statement of Corollary 1 says that the learning rates $\text{alpha}_{(t)}$ are given, but to go from (7) to (8) you specify a value for $\text{alpha}_{(t)}$. Please justify.",
      "Equation (87) seems to have a typo (extra $\text{phi}$)",
      "In (106), the index $i$ is reused.",
      "In the second-to-last step in the proof of Corollary 4, $r_{max}$ should be squared since it is bounding $r_i^2$. (This seems to be just a typo, as the final result has $r_{max}^2$.)"
    ]
  },
  {
    "paper_id": "2011.13034v3",
    "submission_id": "xdk17QJpf5q",
    "submission_title": "Accommodating Picky Customers: Regret Bound and Exploration Complexity for Multi-Objective Reinforcement Learning",
    "review_id": "PUUGzjlX4I",
    "input": {
      "title": "Accommodating Picky Customers: Regret Bound and Exploration Complexity for Multi-Objective Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper addresses an important problem: accommodating users with varying goals and preferences, which could be relevant for many domains.\n- Authors give the example of autonomous driving, which also explains how exactly the two settings considered in the paper might arise in a practical application.\n- Maybe one or two additional examples from other domains could make the motivation even stronger.\n- Demonstrating how existing solutions for the single-objective case cannot be used in the multi-objective case when the preferences are designed adversarially is important in motivating the need for a new algorithm like MO-UCBVI.\n- The demonstration is deferred to Appendix A, which does not have enough details to make a convincing argument.\n- In particular, what 'the best-in-hindsight policy' formally means and how preferences are 'designed adversarially' in the experiment presented in Figure 1 needs to be explained.\n- Considering the importance of this argument, authors might consider moving some of the discussion in Appendix A to the main paper.\n- While I believe an empirical demonstration is sufficient for this paper, a future question might be to formally prove that single-objective solutions would indeed incur O(K) regret.\n- Remark 2 mentions that Theorem 1 can be extended to more general cases.\n- Does this mean that any arbitrary deterministic function f such that r=f(\\mathbf{r};w) can be accommodated?\n- If not, the necessary conditions should be given formally.\n- Theorem 3 confirming the conjecture of Jin et al. (2020) is a nice result that makes the contributions of the paper stronger.\n- Corollary 5 gives a regret bound for the case when the MDP is non-stationary.\n- Is this true for any arbitrary forms of non-stationarity?\n- If so, how is PF-UCB able to achieve this in the setting of reward-free exploration?\n- Why does Theorem 3 not give a similar bound for non-stationary MDPs as well (i.e. why is PF-UCB *not* able to achieve the same thing in the setting of preference-free exploration?)\n- I understand the duality between preference-free and reward-free exploration quite easily, but how preference-free exploration can be applied to the setting of task-agnostic exploration is not immediately clear to me (especially, why the regret bound would change from \\min\\{d,S\\} to \\log N).\n- Both the explanation in line 302 should be improved and a formal proof of the regret bound \\tilde{O}(\\log N \\cdot H^4S A/\\epsilon^2) should be given (or an explanation of how the proof of Theorem 3 can be adapted to the setting of task-agnostic exploration).",
    "review_points_list": [
      "The paper addresses an important problem: accommodating users with varying goals and preferences, which could be relevant for many domains.",
      "Authors give the example of autonomous driving, which also explains how exactly the two settings considered in the paper might arise in a practical application.",
      "Maybe one or two additional examples from other domains could make the motivation even stronger.",
      "Demonstrating how existing solutions for the single-objective case cannot be used in the multi-objective case when the preferences are designed adversarially is important in motivating the need for a new algorithm like MO-UCBVI.",
      "The demonstration is deferred to Appendix A, which does not have enough details to make a convincing argument.",
      "In particular, what 'the best-in-hindsight policy' formally means and how preferences are 'designed adversarially' in the experiment presented in Figure 1 needs to be explained.",
      "Considering the importance of this argument, authors might consider moving some of the discussion in Appendix A to the main paper.",
      "While I believe an empirical demonstration is sufficient for this paper, a future question might be to formally prove that single-objective solutions would indeed incur O(K) regret.",
      "Remark 2 mentions that Theorem 1 can be extended to more general cases.",
      "Does this mean that any arbitrary deterministic function f such that r=f(\\mathbf{r};w) can be accommodated?",
      "If not, the necessary conditions should be given formally.",
      "Theorem 3 confirming the conjecture of Jin et al. (2020) is a nice result that makes the contributions of the paper stronger.",
      "Corollary 5 gives a regret bound for the case when the MDP is non-stationary.",
      "Is this true for any arbitrary forms of non-stationarity?",
      "If so, how is PF-UCB able to achieve this in the setting of reward-free exploration?",
      "Why does Theorem 3 not give a similar bound for non-stationary MDPs as well (i.e. why is PF-UCB *not* able to achieve the same thing in the setting of preference-free exploration?)",
      "I understand the duality between preference-free and reward-free exploration quite easily, but how preference-free exploration can be applied to the setting of task-agnostic exploration is not immediately clear to me (especially, why the regret bound would change from \\min\\{d,S\\} to \\log N).",
      "Both the explanation in line 302 should be improved and a formal proof of the regret bound \\tilde{O}(\\log N \\cdot H^4S A/\\epsilon^2) should be given (or an explanation of how the proof of Theorem 3 can be adapted to the setting of task-agnostic exploration)."
    ]
  },
  {
    "paper_id": "2011.13034v3",
    "submission_id": "xdk17QJpf5q",
    "submission_title": "Accommodating Picky Customers: Regret Bound and Exploration Complexity for Multi-Objective Reinforcement Learning",
    "review_id": "QE8AcbfxVv5",
    "input": {
      "title": "Accommodating Picky Customers: Regret Bound and Exploration Complexity for Multi-Objective Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors design an algorithm based on UCBVI (Azar et al., 2017) and Bernstein-style confidence intervals, which achieves sqrt(min(d,S) H^2SAK) regret.\n- This regret guarantee is not comparable with the existing results for adversarial or stochastic episodic MDPs as the preference is known at the beginning of episode.\n- First, the MORL provides the preference at the beginning of each episode. Second, the regret of MORL compares with a sequence of optimal policies with respect to the given preference, instead of a fixed stationary policy.\n- This setting can be regarded as an extension of the tabular episodic stochastic MDP setting of Azar et al. (2017).\n- Some parts of the proof is standard and similar to the previous works such as Zanette and Brunskill (2019) and Azar et al. (2017).\n- The usage of a specific covering argument and union bound in Lemma 1 is novel and interesting, which leads to a tighter regret bound with min(d,S).\n- Then, the authors show a lower bound for PFE based on J-L Lemma (Lemma 13) and the existing hard instance of Jin et al. (2020).\n- This lower bound is meaningful and inspiring.\n- The contributions are purely theoretical, as the algorithm may be difficult to implement.\n- Most parts of the proof are quite standard and expected.\n- line 305, 'Due' -> 'Due to'\n- line 409\uff0c 'Adish Singla, et al.' seems wrong\n- line 471, 'an covering' -> 'a covering' (also 473, 819)",
    "review_points_list": [
      "The authors design an algorithm based on UCBVI (Azar et al., 2017) and Bernstein-style confidence intervals, which achieves sqrt(min(d,S) H^2SAK) regret.",
      "This regret guarantee is not comparable with the existing results for adversarial or stochastic episodic MDPs as the preference is known at the beginning of episode.",
      "First, the MORL provides the preference at the beginning of each episode. Second, the regret of MORL compares with a sequence of optimal policies with respect to the given preference, instead of a fixed stationary policy.",
      "This setting can be regarded as an extension of the tabular episodic stochastic MDP setting of Azar et al. (2017).",
      "Some parts of the proof is standard and similar to the previous works such as Zanette and Brunskill (2019) and Azar et al. (2017).",
      "The usage of a specific covering argument and union bound in Lemma 1 is novel and interesting, which leads to a tighter regret bound with min(d,S).",
      "Then, the authors show a lower bound for PFE based on J-L Lemma (Lemma 13) and the existing hard instance of Jin et al. (2020).",
      "This lower bound is meaningful and inspiring.",
      "The contributions are purely theoretical, as the algorithm may be difficult to implement.",
      "Most parts of the proof are quite standard and expected.",
      "line 305, 'Due' -> 'Due to'",
      "line 409\uff0c 'Adish Singla, et al.' seems wrong",
      "line 471, 'an covering' -> 'a covering' (also 473, 819)"
    ]
  },
  {
    "paper_id": "2011.13034v3",
    "submission_id": "xdk17QJpf5q",
    "submission_title": "Accommodating Picky Customers: Regret Bound and Exploration Complexity for Multi-Objective Reinforcement Learning",
    "review_id": "ZcR6FYxIG72",
    "input": {
      "title": "Accommodating Picky Customers: Regret Bound and Exploration Complexity for Multi-Objective Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Strengths\n- The paper is well written and organized. The insights behind the main results are well presented.\n- This paper extends the reward-free approach recently introduced in [1] to multi-objective reinforcement learning MDPs.\n- Weaknesses\n- The baseline in the numerical simulations is the single-objective RL, which seems unfair because the objective functions are different.\n- How about comparing MO-UCBVI with a more related task-agnostic algorithm [2]?\n- Most of the theoretical analysis follows from the previous work.\n- The authors state that there is a connection between MORL and soft constrained MDPs by setting the weights to be negative.\n- I do not quite agree.\n- The results are derived based on the assumption that all the preference weights are bounded between [0,1]. It is not clear whether the results hold when the weights are negative.",
    "review_points_list": [
      "Strengths",
      "The paper is well written and organized. The insights behind the main results are well presented.",
      "This paper extends the reward-free approach recently introduced in [1] to multi-objective reinforcement learning MDPs.",
      "Weaknesses",
      "The baseline in the numerical simulations is the single-objective RL, which seems unfair because the objective functions are different.",
      "How about comparing MO-UCBVI with a more related task-agnostic algorithm [2]?",
      "Most of the theoretical analysis follows from the previous work.",
      "The authors state that there is a connection between MORL and soft constrained MDPs by setting the weights to be negative.",
      "I do not quite agree.",
      "The results are derived based on the assumption that all the preference weights are bounded between [0,1]. It is not clear whether the results hold when the weights are negative."
    ]
  },
  {
    "paper_id": "2011.13034v3",
    "submission_id": "xdk17QJpf5q",
    "submission_title": "Accommodating Picky Customers: Regret Bound and Exploration Complexity for Multi-Objective Reinforcement Learning",
    "review_id": "BihGRSmy_bt",
    "input": {
      "title": "Accommodating Picky Customers: Regret Bound and Exploration Complexity for Multi-Objective Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- While the paper uses technical tools from UCBVI, they involve a different definition of confident radius, by incorporating the factor $\text{min}\text{S, d}$.\n- The technical contributions to the regret upper and lower bounds in the two problem settings are quite concrete, and provide strict improvement over existing results.\n- For MORL, when we specialize the multi-obj setting to the single objective setting, do we still recover the state of the art?\n- My understanding is that it is not, since there seem to be an extra $\text{sqrtS}$, and the authors should check on that.\n- While I do not think it is a major shortcoming to the paper even in the case when the best possible regret bound is not recovered, it is still informative for the authors to know how it is positioned.\n- The inclusion of numerical experiments would be informative, in particular it will shine light (empirically) on how the hardness of the problem depends on d.\n- The authors should also cite the following recent work, which involves a general concave reward function for the episodic RL (NeurIPS 2020): https://arxiv.org/pdf/2006.05051.pdf.\n- In addition, the long version of (Cheung 2019) shows how concave reward function can model multi-objective optimization (in a different manner from the submission) https://arxiv.org/pdf/1905.06466.pdf\n- Overall, I am happy with the paper's contributions.",
    "review_points_list": [
      "While the paper uses technical tools from UCBVI, they involve a different definition of confident radius, by incorporating the factor $\text{min}\text{S, d}$.",
      "The technical contributions to the regret upper and lower bounds in the two problem settings are quite concrete, and provide strict improvement over existing results.",
      "For MORL, when we specialize the multi-obj setting to the single objective setting, do we still recover the state of the art?",
      "My understanding is that it is not, since there seem to be an extra $\text{sqrtS}$, and the authors should check on that.",
      "While I do not think it is a major shortcoming to the paper even in the case when the best possible regret bound is not recovered, it is still informative for the authors to know how it is positioned.",
      "The inclusion of numerical experiments would be informative, in particular it will shine light (empirically) on how the hardness of the problem depends on d.",
      "The authors should also cite the following recent work, which involves a general concave reward function for the episodic RL (NeurIPS 2020): https://arxiv.org/pdf/2006.05051.pdf.",
      "In addition, the long version of (Cheung 2019) shows how concave reward function can model multi-objective optimization (in a different manner from the submission) https://arxiv.org/pdf/1905.06466.pdf",
      "Overall, I am happy with the paper's contributions."
    ]
  },
  {
    "paper_id": "2106.00445v1",
    "submission_id": "zGsRcuoR5-0",
    "submission_title": "Sample Selection with Uncertainty of Losses for Learning with Noisy Labels",
    "review_id": "B1upq4Gs1vV",
    "input": {
      "title": "Sample Selection with Uncertainty of Losses for Learning with Noisy Labels",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- In learning with noisy labels, the sample selection based on small-loss criteria is the most common method.\n- This paper reveals the limitation of small-loss criteria and proposes a new selection criterion based on uncertainty to give large-loss data a try.\n- The theoretical analyses are detailed and the claims are well supported by experimental results.\n- This paper adopts interval estimation instead of point estimation, where the lower bounds are used for sample selection.\n- The writer focuses on promoting the prior sample selection.\n- However, this paper is not well organized and there is quite a bit of room for improvement in the representation.\n- The overall writing is not fluent and the theorems are lack of interpretation.\n- Besides, the penultimate paragraph in the introduction is a little bit confusing\n- Figure 2 is worthy of improvement",
    "review_points_list": [
      "In learning with noisy labels, the sample selection based on small-loss criteria is the most common method.",
      "This paper reveals the limitation of small-loss criteria and proposes a new selection criterion based on uncertainty to give large-loss data a try.",
      "The theoretical analyses are detailed and the claims are well supported by experimental results.",
      "This paper adopts interval estimation instead of point estimation, where the lower bounds are used for sample selection.",
      "The writer focuses on promoting the prior sample selection.",
      "However, this paper is not well organized and there is quite a bit of room for improvement in the representation.",
      "The overall writing is not fluent and the theorems are lack of interpretation.",
      "Besides, the penultimate paragraph in the introduction is a little bit confusing",
      "Figure 2 is worthy of improvement"
    ]
  },
  {
    "paper_id": "2106.00445v1",
    "submission_id": "zGsRcuoR5-0",
    "submission_title": "Sample Selection with Uncertainty of Losses for Learning with Noisy Labels",
    "review_id": "8L5prE0fQBG",
    "input": {
      "title": "Sample Selection with Uncertainty of Losses for Learning with Noisy Labels",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The sample selection approach is popular and useful in learning with noisy labels.\n- Motivated by the fact that deep networks first memorize the training data with clean labels, the training data with small losses can be seen as clean data and used for optimization.\n- This paper considers the uncertainty of losses in the sample selection procedure, which consists of two aspects: the uncertainty of small-loss data and the uncertainty of large-loss data.\n- The authors use the concentration inequalities and confidence bounds to study these uncertainties at the same time.\n- The experiments in this paper are comprehensive.\n- The results are also promising, especially when the training data are noisy and imbalanced.\n- Strong motivation. This paper is motivated by experimental results, which show that sometimes the loss values cannot fully reflect the purity of an example.\n- When the data are noisy and imbalanced, the losses of mislabeled data and clean imbalanced data are almost equal and hence cannot be used directly for sample selection.\n- Besides, the loss achieved at a certain epoch may not be trusted.\n- The results are clear and well motivate this paper.\n- Great writing. The logic of this paper is smooth.\n- The authors first reveal the issues of prior effects and then present the proposed method step by step.\n- Most of the technical details are described clearly.\n- Theory. This paper provides theoretical analyses for two robust mean estimators, which could guide the process of sample selection during training.\n- Experiments. The experiments of this paper are comprehensive.\n- The authors consider five types of synthetic label noise and real-world label noise, following good experimental results.\n- Detailed experimental analyses and ablation study are also provided.\n- Learning with noisy imbalanced data is challenging.\n- Expect for the results (Figure 1 Right) on the MNIST dataset, would the results on the other datasets be similar to the case on MNIST?\n- The methods CNLCU-S (H) are built on Co-teaching.\n- It seems that the proposed methods can also build on other sample selection methods.\n- Could the authors further add such discussions and results?\n- The proposed method relies on a noisy validation set to find suitable hyperparameters, i.e., $\text{\u03c3}$ and $\text{\u03c4}$, which makes the methods more complex.\n- The authors use ResNet-18 for the experiments on Clothing1M.\n- I agree with the claims of the authors. The proposed method cannot be competitive with DivideMix.\n- However, most of the existing methods use a ResNet-50 network.\n- It would be better if the results with ResNet-50 can be provided.\n- The paper discusses the weaknesses of existing methods on sample selection at a high level (Section 1).\n- Could the authors provide a more detailed algorithm flow like Algorithm 1 to explain this more clearly?\n- It is expected that the above issues/concerns could be addressed.",
    "review_points_list": [
      "The sample selection approach is popular and useful in learning with noisy labels.",
      "Motivated by the fact that deep networks first memorize the training data with clean labels, the training data with small losses can be seen as clean data and used for optimization.",
      "This paper considers the uncertainty of losses in the sample selection procedure, which consists of two aspects: the uncertainty of small-loss data and the uncertainty of large-loss data.",
      "The authors use the concentration inequalities and confidence bounds to study these uncertainties at the same time.",
      "The experiments in this paper are comprehensive.",
      "The results are also promising, especially when the training data are noisy and imbalanced.",
      "Strong motivation. This paper is motivated by experimental results, which show that sometimes the loss values cannot fully reflect the purity of an example.",
      "When the data are noisy and imbalanced, the losses of mislabeled data and clean imbalanced data are almost equal and hence cannot be used directly for sample selection.",
      "Besides, the loss achieved at a certain epoch may not be trusted.",
      "The results are clear and well motivate this paper.",
      "Great writing. The logic of this paper is smooth.",
      "The authors first reveal the issues of prior effects and then present the proposed method step by step.",
      "Most of the technical details are described clearly.",
      "Theory. This paper provides theoretical analyses for two robust mean estimators, which could guide the process of sample selection during training.",
      "Experiments. The experiments of this paper are comprehensive.",
      "The authors consider five types of synthetic label noise and real-world label noise, following good experimental results.",
      "Detailed experimental analyses and ablation study are also provided.",
      "Learning with noisy imbalanced data is challenging.",
      "Expect for the results (Figure 1 Right) on the MNIST dataset, would the results on the other datasets be similar to the case on MNIST?",
      "The methods CNLCU-S (H) are built on Co-teaching.",
      "It seems that the proposed methods can also build on other sample selection methods.",
      "Could the authors further add such discussions and results?",
      "The proposed method relies on a noisy validation set to find suitable hyperparameters, i.e., $\text{\u03c3}$ and $\text{\u03c4}$, which makes the methods more complex.",
      "The authors use ResNet-18 for the experiments on Clothing1M.",
      "I agree with the claims of the authors. The proposed method cannot be competitive with DivideMix.",
      "However, most of the existing methods use a ResNet-50 network.",
      "It would be better if the results with ResNet-50 can be provided.",
      "The paper discusses the weaknesses of existing methods on sample selection at a high level (Section 1).",
      "Could the authors provide a more detailed algorithm flow like Algorithm 1 to explain this more clearly?",
      "It is expected that the above issues/concerns could be addressed."
    ]
  },
  {
    "paper_id": "2106.00445v1",
    "submission_id": "zGsRcuoR5-0",
    "submission_title": "Sample Selection with Uncertainty of Losses for Learning with Noisy Labels",
    "review_id": "PNpntsRlKhQ",
    "input": {
      "title": "Sample Selection with Uncertainty of Losses for Learning with Noisy Labels",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Distinguishing between mislabeled examples and hard examples is a fundamentally difficult problem and worthwhile to investigate.\n- The key idea is to incorporate the uncertainty of losses by adopting interval estimation instead of point estimation of losses.\n- This idea is definitely reasonable, but is not totally new.\n- Although the details are different, batch selection based on uncertainty has been actively discussed in this field.\n- For example, refer to ActiveBias (NeurIPS 2017).\n- The assumption that the loss conforms to a Markov process is not reasonable.\n- Thus, Theorem 2 based on this assumption may not work well with a real loss function.\n- My main concern is on the experiments.\n- The authors argue that they did not compare the proposed algorithms with the state-of-the-art algorithms (e.g., SELF and DivideMix), because they focus on sample selection mechanisms.\n- I understand the authors' intention.\n- However, I believe that this is not acceptable for this top-tier conference, because the proposed algorithms should be proven to improve the cutting edge performance.\n- Sample selection alone may not be very convincing, because combining various techniques is a clear trend these days.\n- According to a nice survey, https:\\/\\/arxiv.org\\/abs\\/2007.08199, there are recent sample selection methods, which are not covered in this paper.\n- Please see Section III.E.\n- Even though the authors want to focus on sample selection, it would be necessary to cover recent advances more comprehensively.\n- Also, it is common to include at least two real-world noisy datasets, e.g., WebVision, Clothing1M.\n- Typo: Line 217, selectionin\n- After the author feedback: the authors have successfully addressed my concern on the experiments (lack of the comparison with the state-of-the-art algorithms).\n- Thus, I am willing to raise my rating to 6.",
    "review_points_list": [
      "Distinguishing between mislabeled examples and hard examples is a fundamentally difficult problem and worthwhile to investigate.",
      "The key idea is to incorporate the uncertainty of losses by adopting interval estimation instead of point estimation of losses.",
      "This idea is definitely reasonable, but is not totally new.",
      "Although the details are different, batch selection based on uncertainty has been actively discussed in this field.",
      "For example, refer to ActiveBias (NeurIPS 2017).",
      "The assumption that the loss conforms to a Markov process is not reasonable.",
      "Thus, Theorem 2 based on this assumption may not work well with a real loss function.",
      "My main concern is on the experiments.",
      "The authors argue that they did not compare the proposed algorithms with the state-of-the-art algorithms (e.g., SELF and DivideMix), because they focus on sample selection mechanisms.",
      "I understand the authors' intention.",
      "However, I believe that this is not acceptable for this top-tier conference, because the proposed algorithms should be proven to improve the cutting edge performance.",
      "Sample selection alone may not be very convincing, because combining various techniques is a clear trend these days.",
      "According to a nice survey, https:\\/\\/arxiv.org\\/abs\\/2007.08199, there are recent sample selection methods, which are not covered in this paper.",
      "Please see Section III.E.",
      "Even though the authors want to focus on sample selection, it would be necessary to cover recent advances more comprehensively.",
      "Also, it is common to include at least two real-world noisy datasets, e.g., WebVision, Clothing1M.",
      "Typo: Line 217, selectionin",
      "After the author feedback: the authors have successfully addressed my concern on the experiments (lack of the comparison with the state-of-the-art algorithms).",
      "Thus, I am willing to raise my rating to 6."
    ]
  },
  {
    "paper_id": "2110.14221v1",
    "submission_id": "xVs5d5ZSWaa",
    "submission_title": "Learning Diverse Policies in MOBA Games via Macro-Goals",
    "review_id": "fbu_qADg5Y7",
    "input": {
      "title": "Learning Diverse Policies in MOBA Games via Macro-Goals",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper has several strengths:\n- Strong empirical results.\n- Variety of experimental comparisons. The experiments test a variety of features of the approach in terms of diversity of strategies, adaptability to new lineups, and overall competitive performance.\n- The paper's primary limitations:\n- Limited novelty: Using imitation learning to bootstrap long horizon decisions from human data is not novel per se. The novelty lies in the combination of elements.\n- Lacking discussion of limitations and remaining open problems. As detailed below there are some areas where there is a gap between the performance of the method and the ideal that should be discussed.\n- Comments specific to the review criteria prompts.\n- # Originality\n- Using imitation learning to bootstrap long horizon decisions from human data is not novel, nor is goal-conditioned learning. The primary technical novelties here lie in the specific modeling choices and their integration.\n- I believe this integration is novel and valuable given the complexity of the domain and problem. It is clear this builds on prior efforts while enabling diversification of policies in a different way.\n- I am not sure if the attention mechanism employed for learning goals to predict is specifically new, but it seems to be.\n- Related work is adequately cited for the relevant techniques to compare.\n- # Quality\n- The results partially support the claims. Some specific points:\n- 1. The new method does not seem to improve over the baseline agent against humans: Figure 6b shows a ~0.04% difference in (cumulative) win rate.\n- 2. MGG does cover more of behavior space compared to the RL-baseline or players (Figure 7). But MGG also more parts of the space that players do not occupy.\n- It is not clear whether this is a good thing or a problem.\n- 3. There is no comparison of computational costs of the techniques.\n- While greater efficiency is not claimed per se, this would help complete the picture.\n- 4. Figure 8 results show a substantial gap remaining between the MGG method and player behavior.\n- The methods employed are appropriate for training RL agents in team games, and incorporating goal prediction into the policy training is clear incremental improvement over prior work.\n- The paper is not careful to address weaknesses or remaining gaps.\n- Points (1), (2), and (4) above were not addressed. Generally limitations are not discussed.\n- The checklist indicates assumptions were addressed in section 3, but there is no explicit text to this point.\n- # Clarity\n- The text can be difficult to read at points, but is generally understandable.\n- The organization is adequate and the reader is informed of relevant methods and prior work related to the techniques (like double clipping).\n- Some clarifications and additions that would improve the text:\n- What were the instructions given to participants?\n- What is the value of the in-game rewards given to participants?\n- How was consent obtained from participants?\n- (describing supervised learning) 'Finally, the macro-goal is predicted via a convergence model of 1 million steps.' Not sure what this means.\n- Does this indicate the model trained for 1 million steps and obtained convergence at that point?\n- Table 3: How were the human values for different goals determined?\n- For the RL agent we know the conditioned goal but it was not clear how the human goal was decided.\n- Consider briefly explaining the Davies-Bouldin index for readers unfamiliar with clustering.\n- # Significance\n- The results are modestly important.\n- Researchers looking to condition agent behavior on human examples of strategic choices could adapt the work to other domains.\n- This will be valuable to those training RL agents starting from imitation learning in domains where strategic or other long-term choices are relevant.\n- The paper advances the state of the art in getting diversity (without compromising quality) for MOBA games in specific and likely for RL game AI agents in general.\n- The comparison to GAIL shows this is superior to at least some alternatives for the same problem.",
    "review_points_list": [
      "The paper has several strengths:",
      "Strong empirical results.",
      "Variety of experimental comparisons. The experiments test a variety of features of the approach in terms of diversity of strategies, adaptability to new lineups, and overall competitive performance.",
      "The paper's primary limitations:",
      "Limited novelty: Using imitation learning to bootstrap long horizon decisions from human data is not novel per se. The novelty lies in the combination of elements.",
      "Lacking discussion of limitations and remaining open problems. As detailed below there are some areas where there is a gap between the performance of the method and the ideal that should be discussed.",
      "Comments specific to the review criteria prompts.",
      "# Originality",
      "Using imitation learning to bootstrap long horizon decisions from human data is not novel, nor is goal-conditioned learning. The primary technical novelties here lie in the specific modeling choices and their integration.",
      "I believe this integration is novel and valuable given the complexity of the domain and problem. It is clear this builds on prior efforts while enabling diversification of policies in a different way.",
      "I am not sure if the attention mechanism employed for learning goals to predict is specifically new, but it seems to be.",
      "Related work is adequately cited for the relevant techniques to compare.",
      "# Quality",
      "The results partially support the claims. Some specific points:",
      "1. The new method does not seem to improve over the baseline agent against humans: Figure 6b shows a ~0.04% difference in (cumulative) win rate.",
      "2. MGG does cover more of behavior space compared to the RL-baseline or players (Figure 7). But MGG also more parts of the space that players do not occupy.",
      "It is not clear whether this is a good thing or a problem.",
      "3. There is no comparison of computational costs of the techniques.",
      "While greater efficiency is not claimed per se, this would help complete the picture.",
      "4. Figure 8 results show a substantial gap remaining between the MGG method and player behavior.",
      "The methods employed are appropriate for training RL agents in team games, and incorporating goal prediction into the policy training is clear incremental improvement over prior work.",
      "The paper is not careful to address weaknesses or remaining gaps.",
      "Points (1), (2), and (4) above were not addressed. Generally limitations are not discussed.",
      "The checklist indicates assumptions were addressed in section 3, but there is no explicit text to this point.",
      "# Clarity",
      "The text can be difficult to read at points, but is generally understandable.",
      "The organization is adequate and the reader is informed of relevant methods and prior work related to the techniques (like double clipping).",
      "Some clarifications and additions that would improve the text:",
      "What were the instructions given to participants?",
      "What is the value of the in-game rewards given to participants?",
      "How was consent obtained from participants?",
      "(describing supervised learning) 'Finally, the macro-goal is predicted via a convergence model of 1 million steps.' Not sure what this means.",
      "Does this indicate the model trained for 1 million steps and obtained convergence at that point?",
      "Table 3: How were the human values for different goals determined?",
      "For the RL agent we know the conditioned goal but it was not clear how the human goal was decided.",
      "Consider briefly explaining the Davies-Bouldin index for readers unfamiliar with clustering.",
      "# Significance",
      "The results are modestly important.",
      "Researchers looking to condition agent behavior on human examples of strategic choices could adapt the work to other domains.",
      "This will be valuable to those training RL agents starting from imitation learning in domains where strategic or other long-term choices are relevant.",
      "The paper advances the state of the art in getting diversity (without compromising quality) for MOBA games in specific and likely for RL game AI agents in general.",
      "The comparison to GAIL shows this is superior to at least some alternatives for the same problem."
    ]
  },
  {
    "paper_id": "2110.14221v1",
    "submission_id": "xVs5d5ZSWaa",
    "submission_title": "Learning Diverse Policies in MOBA Games via Macro-Goals",
    "review_id": "A06GTSET5Kh",
    "input": {
      "title": "Learning Diverse Policies in MOBA Games via Macro-Goals",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Learning Diverse Policies in MOBA Games via Macro-Goals presents a compelling direction for combining offline human feedback with a reinforcement learning policy, and the evaluation criteria investigating exploitability is novel and supports the paper's stated goals.\n- Certain areas of the paper require work to help the reader reproduce the results or understand the significance of the outcomes.\n- The paper's combination of human data using imitation learning and reinforcement learning has been previously explored in the context of 'human preferences' and summarization work.\n- The approach is novel in the context of MOBA games and demonstrates that in long-action sequences this form of supervision is applicable and can lead to demonstrably more diverse policies.\n- The choice of neural network, features, domain, and other aspects are not the focus of the paper, and are also not novel.\n- The paper measures the exploitability of the agents using human evaluations (Figure 6) and this evaluation format has not been used previously in the context of learning game AI policies.\n- This test, while difficult to reproduce, serves as an invaluable showcase for the method's impact on realistic play.\n- The paper's stated goals and application domain is clearly stated.\n- The purpose of the experiments is explained and motivated.\n- 4.4.3 discusses capability analysis while using ELO scores.\n- The compared approaches are stated to be 'converged', however this term is loaded and hard to transfer across architectures and setups.\n- Similarly the results in Figure 6 and 9 do not provide statistical significance of the results, or potentially a comparison across different points during training (as a way of further confirming that the systems have indeed converged).\n- As such, the conclusions from many of these experiments are hard to measure.\n- A key question that should be answered is: 'does using human games and an additional goal reward in this way provide better results provided with the same resources/time/energy as our reinforcement learning baseline?'\n- Ideally a good control would allow the reinforcement learning policy to train supervised from human trajectories and then train with self-play, and account for the additional parameters and training time required by the imitation training.\n- Section 4.4.1 Why is achieving 'resource intent strategies' important? Does the trained policy need to be good at this to improve at the game, or is the purpose to be as similar to human play?\n- Section 4.4.2 discusses human performance for monster resources: what is this human evaluation? how are they chosen? How many attempts are done by humans? Are these humans professional or amateur players?\n- The proposed approach is tested on a challenging benchmark and uses significant resources to train the agents and evaluate them.\n- The significance of this work is limited by two key factors: 1) research in this area is important, but the proposed technique is hard to reproduce owing to the high computational cost, lack of a public interface or system to test and train Honor of Kings agents.\n- 2) the results are provided without statistical significance numbers or selection criteria for human players.\n- The ELO numbers and reward scores should ideally be amended in the final version of the paper with some measure to understand the size of the gains over GAIL or RL-Baseline.\n- The human player performance is hard to asses, and perhaps an ELO score for human players, or a description of the selection process would help.\n- The exploitability plot in Figure 6 strongly depends on the kind of players that tested either agent, and whether they were allowed to play against either system, or only one kind repeatedly, etc.\n- Statistical significance: Figure 6 and Figure 9 provide the most impressive results of the paper, but lack any statistical significance metrics which would help understand the gains between RL-baseline, GAIL, and MGG.\n- Wording: L249 'this test effectively proves' I would reword this as 'this test suggests' or 'provides evidence for' as conclusive demonstrations with human testing and a limited number of samples are unlikely, but do provide a great benchmark.\n- L259, L265 'marco states' -> 'macro states'\n- Citation style: OpenAI Five citation should preferably use https://openai.com/bibtex/openai2019dota.bib (e.g. OpenAI et al.)\n- Related Work: L78 'All the mentioned works except the SL model adopt a single strategy regardless of the 79 heroes and lineups, which cannot take full advantage of heroes and lineups\u2019 characteristics' -> Slight correction: OpenAI Five has a latent vector encoding lane preferences + a representation of the heroes that affect the employed strategy, so in practice the strategy will change dramatically between games when those aspects are randomized.",
    "review_points_list": [
      "Learning Diverse Policies in MOBA Games via Macro-Goals presents a compelling direction for combining offline human feedback with a reinforcement learning policy, and the evaluation criteria investigating exploitability is novel and supports the paper's stated goals.",
      "Certain areas of the paper require work to help the reader reproduce the results or understand the significance of the outcomes.",
      "The paper's combination of human data using imitation learning and reinforcement learning has been previously explored in the context of 'human preferences' and summarization work.",
      "The approach is novel in the context of MOBA games and demonstrates that in long-action sequences this form of supervision is applicable and can lead to demonstrably more diverse policies.",
      "The choice of neural network, features, domain, and other aspects are not the focus of the paper, and are also not novel.",
      "The paper measures the exploitability of the agents using human evaluations (Figure 6) and this evaluation format has not been used previously in the context of learning game AI policies.",
      "This test, while difficult to reproduce, serves as an invaluable showcase for the method's impact on realistic play.",
      "The paper's stated goals and application domain is clearly stated.",
      "The purpose of the experiments is explained and motivated.",
      "4.4.3 discusses capability analysis while using ELO scores.",
      "The compared approaches are stated to be 'converged', however this term is loaded and hard to transfer across architectures and setups.",
      "Similarly the results in Figure 6 and 9 do not provide statistical significance of the results, or potentially a comparison across different points during training (as a way of further confirming that the systems have indeed converged).",
      "As such, the conclusions from many of these experiments are hard to measure.",
      "A key question that should be answered is: 'does using human games and an additional goal reward in this way provide better results provided with the same resources/time/energy as our reinforcement learning baseline?'",
      "Ideally a good control would allow the reinforcement learning policy to train supervised from human trajectories and then train with self-play, and account for the additional parameters and training time required by the imitation training.",
      "Section 4.4.1 Why is achieving 'resource intent strategies' important? Does the trained policy need to be good at this to improve at the game, or is the purpose to be as similar to human play?",
      "Section 4.4.2 discusses human performance for monster resources: what is this human evaluation? how are they chosen? How many attempts are done by humans? Are these humans professional or amateur players?",
      "The proposed approach is tested on a challenging benchmark and uses significant resources to train the agents and evaluate them.",
      "The significance of this work is limited by two key factors: 1) research in this area is important, but the proposed technique is hard to reproduce owing to the high computational cost, lack of a public interface or system to test and train Honor of Kings agents.",
      "2) the results are provided without statistical significance numbers or selection criteria for human players.",
      "The ELO numbers and reward scores should ideally be amended in the final version of the paper with some measure to understand the size of the gains over GAIL or RL-Baseline.",
      "The human player performance is hard to asses, and perhaps an ELO score for human players, or a description of the selection process would help.",
      "The exploitability plot in Figure 6 strongly depends on the kind of players that tested either agent, and whether they were allowed to play against either system, or only one kind repeatedly, etc.",
      "Statistical significance: Figure 6 and Figure 9 provide the most impressive results of the paper, but lack any statistical significance metrics which would help understand the gains between RL-baseline, GAIL, and MGG.",
      "Wording: L249 'this test effectively proves' I would reword this as 'this test suggests' or 'provides evidence for' as conclusive demonstrations with human testing and a limited number of samples are unlikely, but do provide a great benchmark.",
      "L259, L265 'marco states' -> 'macro states'",
      "Citation style: OpenAI Five citation should preferably use https://openai.com/bibtex/openai2019dota.bib (e.g. OpenAI et al.)",
      "Related Work: L78 'All the mentioned works except the SL model adopt a single strategy regardless of the 79 heroes and lineups, which cannot take full advantage of heroes and lineups\u2019 characteristics' -> Slight correction: OpenAI Five has a latent vector encoding lane preferences + a representation of the heroes that affect the employed strategy, so in practice the strategy will change dramatically between games when those aspects are randomized."
    ]
  },
  {
    "paper_id": "2110.14221v1",
    "submission_id": "xVs5d5ZSWaa",
    "submission_title": "Learning Diverse Policies in MOBA Games via Macro-Goals",
    "review_id": "0pxKt-DPQIG",
    "input": {
      "title": "Learning Diverse Policies in MOBA Games via Macro-Goals",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper presents a novel method for pushing the state of the art of AI performance in MOBA games.\n- The large-scale human study to evaluate performance against baselines and the performance exceeding the state-of-the-art baselines clearly demonstrate the effectiveness of the proposed MGG method.\n- Specific analyses also support the diversity claims made about the learned strategies.\n- However, the paper in its current state leaves a lot to be desired in terms of clarity, broader motivation and accessibility.\n- Despite the thorough empirical analysis made in this paper, it remains inaccessible to the reader due to these writing issues.\n- The presented MGG method's main selling point is the diversity in strategies that are aimed to improve performance against human matchups, since humans are capable of overcoming unimodal/repetitive strategies by AI agents given enough time and practice.\n- The claim for diversity in the proposed method is supported by a quantitative analysis with measurements of goal-entropy and Davies-Bouldin Index of the goal embeddings, and a qualitative analysis of specific cases of non-conventional strategies in the chosen game (Honor of Kings) which typically do not align with the default reward models proposed for this game.\n- The large scale human-study with human vs AI matches clearly demonstrates that the proposed method retains performance (w.r.t the baseline) with increasing human test time, which is in line with the hypothesis that diverse strategies are better than unimodal strategies against human matchups.\n- The choice of using expert demonstrations for learning only the high-level macro-goal prediction network is intuitively appealing -- it aims to mimic broader human intentions without worrying about matching the exact execution of each intention.\n- For readers that are familiar with MOBA games, the two case studies in Sections 4.4.1 and 4.4.2 (and the videos linked in the paper) are impressive demonstrations of what the proposed method is capable of in practice. Such strategies seem to be very difficult to learn for AI agents but are easy or obvious for human players.\n- The second paragraph in Section 3 is confusing due to lack of proper explanation and use of arbitrary new notation.\n- The difference between macro states and macro goals is not clear.\n- The role of fi.e. the macro state extraction function is not made clear until much later in the paper.\n- The general reward function is never explained -- what does this mean and what does it consist of?\n- What does the common strategy mean?\n- Why is notation introduced for human macro states when this notation is never used again in the entire paper (i.e. served no purpose later on)?\n- It could have been explained without any notation.\n- The goal space should be completely defined at this stage of the paper, along with the choice of goal dimension and a description of what the dimensions of the goal specify.\n- Also, notation for intrinsic reward R(f(S), G, A) is introduced without being accompanied by a definition (the definition is much later in the paper).\n- Auxiliary tasks are first mentioned in L135 but what auxiliary tasks are used is not mentioned until L173.\n- Since only a single auxiliary task of auto-encoding is used, this explanation does not deserve to be pushed to such a later stage from its first mention.\n- L161 states that C is the number of frames between state and its goal, but it is not made clear how C is specified.\n- Later in the paper, C is then stated to be a hyperparameter which has a fixed value.\n- This description about C being a hyperparam of choice and its value should all be in the same first mention of C in the paper.\n- Equation 2 (and L192 below it) assume that the goal space admits a metric in the form of an L1 norm, but the goal space is not defined at this point in the paper.\n- There is an implicit assumption that the goal space is a multi-dimensional euclidean space (R^d).\n- The paper does not introduce key MOBA-specific terminology before using it at several points in the paper.\n- A basic explanation of the mechanics, heroes and progression milestones of the game should be explained before terms like 'destroying the crystal', 'over 102 heroes...' or 'ban/pick capabilities' are used.\n- However, given that this paper specifically focuses solely on MOBA games, this is a minor issue.\n- The \u2018general reward function\u2019 is mentioned several times in the paper but only introduced on L274 after citing Ye et al. [2020a] without any description.\n- This seems to be an important fact to include in the paper well in advance.\n- The fact that the proposed method is an instance of an imitation learning method where expert data is used is not made clear during comparisons with baselines.\n- It is not mentioned that the 'RL-baseline' method does not use any human supervision, which is an important point to note in the comparison.\n- For the main result of AI vs human win rate obtained from the large scale human study, the Y-axis range in Figure 6 (b) seems to be extremely narrow (98.72% - 98.86%).\n- Due to the absence of error bars, it is very difficult to judge the statistical significance of the presented results.\n- It is also very surprising that the RL-baseline, despite lacking diversity, is able to retain such a high win rate after 26 hours of accumulated human test time.\n- This seems to strongly oppose the premise of the paper that humans can easily overcome AI strategies if they lack diversity.\n- L259 -- A brief explanation of the Davies-Bouldin Index and its relevance should be presented instead of just citing the original paper.\n- Last line of Conclusions seems very vague, what does 'non-transitivity in strategies' mean?\n- The directions for future work can be made more clear.\n- Table 2 and Section 4.3.2 mention measuring 'state entropy'.\n- Shouldn't this be called 'macro state entropy' instead?",
    "review_points_list": [
      "The paper presents a novel method for pushing the state of the art of AI performance in MOBA games.",
      "The large-scale human study to evaluate performance against baselines and the performance exceeding the state-of-the-art baselines clearly demonstrate the effectiveness of the proposed MGG method.",
      "Specific analyses also support the diversity claims made about the learned strategies.",
      "However, the paper in its current state leaves a lot to be desired in terms of clarity, broader motivation and accessibility.",
      "Despite the thorough empirical analysis made in this paper, it remains inaccessible to the reader due to these writing issues.",
      "The presented MGG method's main selling point is the diversity in strategies that are aimed to improve performance against human matchups, since humans are capable of overcoming unimodal/repetitive strategies by AI agents given enough time and practice.",
      "The claim for diversity in the proposed method is supported by a quantitative analysis with measurements of goal-entropy and Davies-Bouldin Index of the goal embeddings, and a qualitative analysis of specific cases of non-conventional strategies in the chosen game (Honor of Kings) which typically do not align with the default reward models proposed for this game.",
      "The large scale human-study with human vs AI matches clearly demonstrates that the proposed method retains performance (w.r.t the baseline) with increasing human test time, which is in line with the hypothesis that diverse strategies are better than unimodal strategies against human matchups.",
      "The choice of using expert demonstrations for learning only the high-level macro-goal prediction network is intuitively appealing -- it aims to mimic broader human intentions without worrying about matching the exact execution of each intention.",
      "For readers that are familiar with MOBA games, the two case studies in Sections 4.4.1 and 4.4.2 (and the videos linked in the paper) are impressive demonstrations of what the proposed method is capable of in practice. Such strategies seem to be very difficult to learn for AI agents but are easy or obvious for human players.",
      "The second paragraph in Section 3 is confusing due to lack of proper explanation and use of arbitrary new notation.",
      "The difference between macro states and macro goals is not clear.",
      "The role of fi.e. the macro state extraction function is not made clear until much later in the paper.",
      "The general reward function is never explained -- what does this mean and what does it consist of?",
      "What does the common strategy mean?",
      "Why is notation introduced for human macro states when this notation is never used again in the entire paper (i.e. served no purpose later on)?",
      "It could have been explained without any notation.",
      "The goal space should be completely defined at this stage of the paper, along with the choice of goal dimension and a description of what the dimensions of the goal specify.",
      "Also, notation for intrinsic reward R(f(S), G, A) is introduced without being accompanied by a definition (the definition is much later in the paper).",
      "Auxiliary tasks are first mentioned in L135 but what auxiliary tasks are used is not mentioned until L173.",
      "Since only a single auxiliary task of auto-encoding is used, this explanation does not deserve to be pushed to such a later stage from its first mention.",
      "L161 states that C is the number of frames between state and its goal, but it is not made clear how C is specified.",
      "Later in the paper, C is then stated to be a hyperparameter which has a fixed value.",
      "This description about C being a hyperparam of choice and its value should all be in the same first mention of C in the paper.",
      "Equation 2 (and L192 below it) assume that the goal space admits a metric in the form of an L1 norm, but the goal space is not defined at this point in the paper.",
      "There is an implicit assumption that the goal space is a multi-dimensional euclidean space (R^d).",
      "The paper does not introduce key MOBA-specific terminology before using it at several points in the paper.",
      "A basic explanation of the mechanics, heroes and progression milestones of the game should be explained before terms like 'destroying the crystal', 'over 102 heroes...' or 'ban/pick capabilities' are used.",
      "However, given that this paper specifically focuses solely on MOBA games, this is a minor issue.",
      "The \u2018general reward function\u2019 is mentioned several times in the paper but only introduced on L274 after citing Ye et al. [2020a] without any description.",
      "This seems to be an important fact to include in the paper well in advance.",
      "The fact that the proposed method is an instance of an imitation learning method where expert data is used is not made clear during comparisons with baselines.",
      "It is not mentioned that the 'RL-baseline' method does not use any human supervision, which is an important point to note in the comparison.",
      "For the main result of AI vs human win rate obtained from the large scale human study, the Y-axis range in Figure 6 (b) seems to be extremely narrow (98.72% - 98.86%).",
      "Due to the absence of error bars, it is very difficult to judge the statistical significance of the presented results.",
      "It is also very surprising that the RL-baseline, despite lacking diversity, is able to retain such a high win rate after 26 hours of accumulated human test time.",
      "This seems to strongly oppose the premise of the paper that humans can easily overcome AI strategies if they lack diversity.",
      "L259 -- A brief explanation of the Davies-Bouldin Index and its relevance should be presented instead of just citing the original paper.",
      "Last line of Conclusions seems very vague, what does 'non-transitivity in strategies' mean?",
      "The directions for future work can be made more clear.",
      "Table 2 and Section 4.3.2 mention measuring 'state entropy'.",
      "Shouldn't this be called 'macro state entropy' instead?"
    ]
  },
  {
    "paper_id": "2110.14221v1",
    "submission_id": "xVs5d5ZSWaa",
    "submission_title": "Learning Diverse Policies in MOBA Games via Macro-Goals",
    "review_id": "0CBB19n9tkM",
    "input": {
      "title": "Learning Diverse Policies in MOBA Games via Macro-Goals",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The originality of the method is limited - hierarchical control systems are well established and games of similar complexity and with similar mechanics have been learnt previously - but it remains interesting to the sub-community focused on these types of applications as additional evidence of approaches that can be successful utilized in modern games.\n- I have some concerns about the correctness of statements in the paper that could significantly improve my rating of this paper if adequately addressed in the author's reply:\n- Figure 6b shows win rate against human without variance. Given the very small differences in percentages on the y-axis, there may not be any significant improvement over the previous RL baseline. Can you provide stronger evidence that the proposed method significantly improves performance in comparison to the chosen baseline?\n- (2) The contributions on page 2 state the proposed method uses the same computational resources as the baseline, but the proposed method introduces an additional pre-training stage for the macro classifier and augments the policy state space. Both of these modifications will require additional compute - the macro classifier in its own training and the augmented policy space I assume will increase training time for the RL agent. Should this statement instead be that once the agent is trained they use the same resources at the evaluation stage?\n- (3) On line 40 it is claimed that 'the agent should exploit [the opponent] instead of playing with a single policy' but these two statements are not mutually exclusive. A single policy can learn to exploit any opponent, either by playing a Nash equilibrium strategy or using opponent modelling to recognize online the type of opponent it is playing and condition its policy on this additional observation.\n- (4) Line 85 claims 'there is no obvious signal ... to represent macro strategies in MOBA games' as a way to differentiate from prior work but the proposed method defines macro goals (section 3.1.1), uses them throughout training and claims they are applicable to other MOBA games (line 143). I think there are other ways to differentiate the proposed method from the past work cited, but this current statement is contradicted by the work done and so currently weakens the evidence of originality presented in the paper.\n- (5) Line 232-233 gives statistics about the agents response time, but provides no grounding for how this compares to human players.\n- (6) In Figure 9 do the built-in bots have an ELO rating of 0? Or is this the no-op agent as in Figure 6?\n- Minor comments that could be easily addressed if accepted (no need to respond):\n- Due to the complexity of the approach and scale of the study, some details are missing that would be interesting insights to the overall system. Most notably, no results are provided for the meta-controller pre-training and the focal loss is not defined (presumably because it is defined in Lin et al. 2017) - adding these to the appendix would make this a more self-contained reference.\n- Line 190: 'even the lineups' -> 'even WHEN the lineups'\n- Line 263: 'the marco state' -> 'macro'",
    "review_points_list": [
      "The originality of the method is limited - hierarchical control systems are well established and games of similar complexity and with similar mechanics have been learnt previously - but it remains interesting to the sub-community focused on these types of applications as additional evidence of approaches that can be successful utilized in modern games.",
      "I have some concerns about the correctness of statements in the paper that could significantly improve my rating of this paper if adequately addressed in the author's reply:",
      "Figure 6b shows win rate against human without variance. Given the very small differences in percentages on the y-axis, there may not be any significant improvement over the previous RL baseline. Can you provide stronger evidence that the proposed method significantly improves performance in comparison to the chosen baseline?",
      "(2) The contributions on page 2 state the proposed method uses the same computational resources as the baseline, but the proposed method introduces an additional pre-training stage for the macro classifier and augments the policy state space. Both of these modifications will require additional compute - the macro classifier in its own training and the augmented policy space I assume will increase training time for the RL agent. Should this statement instead be that once the agent is trained they use the same resources at the evaluation stage?",
      "(3) On line 40 it is claimed that 'the agent should exploit [the opponent] instead of playing with a single policy' but these two statements are not mutually exclusive. A single policy can learn to exploit any opponent, either by playing a Nash equilibrium strategy or using opponent modelling to recognize online the type of opponent it is playing and condition its policy on this additional observation.",
      "(4) Line 85 claims 'there is no obvious signal ... to represent macro strategies in MOBA games' as a way to differentiate from prior work but the proposed method defines macro goals (section 3.1.1), uses them throughout training and claims they are applicable to other MOBA games (line 143). I think there are other ways to differentiate the proposed method from the past work cited, but this current statement is contradicted by the work done and so currently weakens the evidence of originality presented in the paper.",
      "(5) Line 232-233 gives statistics about the agents response time, but provides no grounding for how this compares to human players.",
      "(6) In Figure 9 do the built-in bots have an ELO rating of 0? Or is this the no-op agent as in Figure 6?",
      "Minor comments that could be easily addressed if accepted (no need to respond):",
      "Due to the complexity of the approach and scale of the study, some details are missing that would be interesting insights to the overall system. Most notably, no results are provided for the meta-controller pre-training and the focal loss is not defined (presumably because it is defined in Lin et al. 2017) - adding these to the appendix would make this a more self-contained reference.",
      "Line 190: 'even the lineups' -> 'even WHEN the lineups'",
      "Line 263: 'the marco state' -> 'macro'"
    ]
  },
  {
    "paper_id": "2312.07025v2",
    "submission_id": "u7oKU1iXTa9",
    "submission_title": "Distributional Reinforcement Learning for Multi-Dimensional Reward Functions",
    "review_id": "8CxWhz0jsQv",
    "input": {
      "title": "Distributional Reinforcement Learning for Multi-Dimensional Reward Functions",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The methods used, HRA and distributional RL are not novel, but this is the first work that combines these two and in a well justified manner.\n- Especially given that HRA uses independent losses, it is sensible to consider the modeling approach of learning a joint distribution of the different reward sources.\n- While the extension of the MMD loss to the multivariate case is not a technically novel, but there doesn't necessarily need to be one if it works as is.\n- The submission is technically sound in its theoretical contributions (convergence proof).\n- On the experimental side, capturing the correlation between the random reward sources in the joint distribution is nicely illustrated.\n- It is clear this would not happen when learning separate value functions in HRA.\n- I am less convinced by the 4 Atari experiments as the correlation between the reward signals are either positively correlated or independent as stated in the appendix.\n- Since the actions taken do not need to consider reward tradeoffs (as might happen when rewards are negatively correlated), I would suspect the results seen can be obtained by using separate distributional value networks for each of the reward signals, i.e. IQN or C51 and then combining them in the same way as RD^2 or other HRA architectures.\n- That is to say, the performance gains seen are more attributable to modeling the randomness of each independent reward vs modeling the joint distribution.\n- The clarity around the claim about not having to use the same metric to prove convergence and to train is somewhat confusing.\n- I interpret line 58-61 to mean that the practical loss function used, i.e. sample based MMD is an unbiased estimator and therefore it is still a metric, which allows it to be used as the practical loss for this task.\n- However, MMD is still different that the Wasserstein metric.\n- Is it the case that if convergence is proven with one metric, that is sufficient to show that the operator converges for any metric?\n- If so, this should simply be stated directly.\n- In my opinion, the writing obfuscates this a little.\n- Lines 109-114 and the paragraph starting on line 160 reads as if there will be results and/or a proof to demonstrate *why* the metrics used can be different, and that 'correcting this misunderstanding' seems to be a contribution of the paper.\n- Finally, the exposition on line 160 is still a bit confusing even under the above assumption, because the KL-divergence is not a metric.\n- I think this is a strong contribution if the authors could show that the joint distribution learned which captures the correlation between rewards could be useful in a more complex task/setting.\n- Instead of the Atari experiments, maybe some experiments demonstrating the applications of the joint return learning as outlined in lines 237-245 could be useful.\n- I see one current limitation as not empirically demonstrating a situation where modeling the joint distribution is particularly needed.\n- I am curious if there is any intuition for selecting the kernel bandwiths?",
    "review_points_list": [
      "The methods used, HRA and distributional RL are not novel, but this is the first work that combines these two and in a well justified manner.",
      "Especially given that HRA uses independent losses, it is sensible to consider the modeling approach of learning a joint distribution of the different reward sources.",
      "While the extension of the MMD loss to the multivariate case is not a technically novel, but there doesn't necessarily need to be one if it works as is.",
      "The submission is technically sound in its theoretical contributions (convergence proof).",
      "On the experimental side, capturing the correlation between the random reward sources in the joint distribution is nicely illustrated.",
      "It is clear this would not happen when learning separate value functions in HRA.",
      "I am less convinced by the 4 Atari experiments as the correlation between the reward signals are either positively correlated or independent as stated in the appendix.",
      "Since the actions taken do not need to consider reward tradeoffs (as might happen when rewards are negatively correlated), I would suspect the results seen can be obtained by using separate distributional value networks for each of the reward signals, i.e. IQN or C51 and then combining them in the same way as RD^2 or other HRA architectures.",
      "That is to say, the performance gains seen are more attributable to modeling the randomness of each independent reward vs modeling the joint distribution.",
      "The clarity around the claim about not having to use the same metric to prove convergence and to train is somewhat confusing.",
      "I interpret line 58-61 to mean that the practical loss function used, i.e. sample based MMD is an unbiased estimator and therefore it is still a metric, which allows it to be used as the practical loss for this task.",
      "However, MMD is still different that the Wasserstein metric.",
      "Is it the case that if convergence is proven with one metric, that is sufficient to show that the operator converges for any metric?",
      "If so, this should simply be stated directly.",
      "In my opinion, the writing obfuscates this a little.",
      "Lines 109-114 and the paragraph starting on line 160 reads as if there will be results and/or a proof to demonstrate *why* the metrics used can be different, and that 'correcting this misunderstanding' seems to be a contribution of the paper.",
      "Finally, the exposition on line 160 is still a bit confusing even under the above assumption, because the KL-divergence is not a metric.",
      "I think this is a strong contribution if the authors could show that the joint distribution learned which captures the correlation between rewards could be useful in a more complex task/setting.",
      "Instead of the Atari experiments, maybe some experiments demonstrating the applications of the joint return learning as outlined in lines 237-245 could be useful.",
      "I see one current limitation as not empirically demonstrating a situation where modeling the joint distribution is particularly needed.",
      "I am curious if there is any intuition for selecting the kernel bandwiths?"
    ]
  },
  {
    "paper_id": "2312.07025v2",
    "submission_id": "u7oKU1iXTa9",
    "submission_title": "Distributional Reinforcement Learning for Multi-Dimensional Reward Functions",
    "review_id": "pClkiXhhoP",
    "input": {
      "title": "Distributional Reinforcement Learning for Multi-Dimensional Reward Functions",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The main novelty of the work is the theoretical analysis of convergence of the joint distributional Bellman operators by generalizing contraction mappings to the n-dimensional setting.\n- Upon reading the related work (Nguyen et al., 2020), the algorithmic design and choice of optimization criterion seems to be rather trivial modifications of existing work to higher-dimensional distributions.\n- The work is technically sound. I have not checked all proof details, but they appear to be sound.\n- The claimed results are quite intuitive and expected.\n- The theoretical framework is easy to understand and main results are summarized well, along with their importance.\n- The choice of MMD is also well-motivated as providing unbiased estimates for samples.\n- However, some wording and notation can be significantly improved.\n- In particular: 1. why is r_t bold in equations (1) and line 89?\n- 2. the details regarding how the joint distribution is represented architecturally is not well discussed. in particular, the authors mention that they replace the last layer of DQN with the samples from the joint distribution for each action.\n- 3. Looking at the code briefly, and connecting the work to (Nguyen 2020), I am led to belief that you use something like IQN, where the samples from a base distribution are also provided to the network in addition to (s, a).\n- This way, the joint distribution is implicitly modeled rather than facing the curse of dimensionality with C51 or QR-DQN where it is modeled directly.\n- This then leaves the choice of how to model mu(s, a) architecturally to only IQR, correct?\n- If so, then it would be better to discuss this in the main paper around the algorithm, as the current writeup may be confusing to readers.\n- Cram(e) loss -> Cramer loss in line 169.\n- The work addresses an important problem in distributional RL that has not been studied despite much attention on the subject; how to learn joint distributions.\n- I can envision this work being useful in many applications where Distributional RL has strong potential, and one particular use case is to learn distributions over successor features.\n- However, the authors provide several other examples which could be interesting future work building on this paper.\n- I therefore expect this paper to have significant impact in the RL community in the future.",
    "review_points_list": [
      "The main novelty of the work is the theoretical analysis of convergence of the joint distributional Bellman operators by generalizing contraction mappings to the n-dimensional setting.",
      "Upon reading the related work (Nguyen et al., 2020), the algorithmic design and choice of optimization criterion seems to be rather trivial modifications of existing work to higher-dimensional distributions.",
      "The work is technically sound. I have not checked all proof details, but they appear to be sound.",
      "The claimed results are quite intuitive and expected.",
      "The theoretical framework is easy to understand and main results are summarized well, along with their importance.",
      "The choice of MMD is also well-motivated as providing unbiased estimates for samples.",
      "However, some wording and notation can be significantly improved.",
      "In particular: 1. why is r_t bold in equations (1) and line 89?",
      "2. the details regarding how the joint distribution is represented architecturally is not well discussed. in particular, the authors mention that they replace the last layer of DQN with the samples from the joint distribution for each action.",
      "3. Looking at the code briefly, and connecting the work to (Nguyen 2020), I am led to belief that you use something like IQN, where the samples from a base distribution are also provided to the network in addition to (s, a).",
      "This way, the joint distribution is implicitly modeled rather than facing the curse of dimensionality with C51 or QR-DQN where it is modeled directly.",
      "This then leaves the choice of how to model mu(s, a) architecturally to only IQR, correct?",
      "If so, then it would be better to discuss this in the main paper around the algorithm, as the current writeup may be confusing to readers.",
      "Cram(e) loss -> Cramer loss in line 169.",
      "The work addresses an important problem in distributional RL that has not been studied despite much attention on the subject; how to learn joint distributions.",
      "I can envision this work being useful in many applications where Distributional RL has strong potential, and one particular use case is to learn distributions over successor features.",
      "However, the authors provide several other examples which could be interesting future work building on this paper.",
      "I therefore expect this paper to have significant impact in the RL community in the future."
    ]
  },
  {
    "paper_id": "2312.07025v2",
    "submission_id": "u7oKU1iXTa9",
    "submission_title": "Distributional Reinforcement Learning for Multi-Dimensional Reward Functions",
    "review_id": "vmkk5SJvGf-",
    "input": {
      "title": "Distributional Reinforcement Learning for Multi-Dimensional Reward Functions",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well-written and easy to follow. The authors moved almost all proof to the appendix and made the paper accessible.\n- The motivation of the paper is well-stated, and MD3QN can capture the correlations between the dimensions across the reward function based on the toy demonstration.\n- The experiment part is not strong enough:\n- - The number of experiments is limited, and it's not clear if there are multiple runs or only one run for each task.\n- - I checked the experiment results from MMDQN(Nguyen et al., 2020) Fig 8 in Appendix, and MD3QN seems not outperform MMDQN on Gopher, MsPacman and Pong.\n- - It will be more appropriate to run on the tasks that can truly reflect the value of HSA.\n- Algorithm1, the action is the argmax across all reward dimensions, which is more similar to RD2 (eq7-eq8) than HRA (eq5-eq6). In this case, it's more fair to compare MD3QN with RD2.\n- In eq(2), should it be $\\theta_{i-1}$ or $\\theta_i$?\n- is $\\mu^{\\pi}$ a joint distribution or marginal distribution? From its dimension, $\\mu$ looks like a marginal distribution, however in l.126 it represents a joint distribution.\n- an $\\infty$ sign is missing in eq(17).\n- l.160-l.169, it is better to elaborate more about this part. It is still unclear why it's rigorous to use different metrics for proof and training aside from the fact that they lead to similar empirical performances.",
    "review_points_list": [
      "The paper is well-written and easy to follow. The authors moved almost all proof to the appendix and made the paper accessible.",
      "The motivation of the paper is well-stated, and MD3QN can capture the correlations between the dimensions across the reward function based on the toy demonstration.",
      "The experiment part is not strong enough:",
      "- The number of experiments is limited, and it's not clear if there are multiple runs or only one run for each task.",
      "- I checked the experiment results from MMDQN(Nguyen et al., 2020) Fig 8 in Appendix, and MD3QN seems not outperform MMDQN on Gopher, MsPacman and Pong.",
      "- It will be more appropriate to run on the tasks that can truly reflect the value of HSA.",
      "Algorithm1, the action is the argmax across all reward dimensions, which is more similar to RD2 (eq7-eq8) than HRA (eq5-eq6). In this case, it's more fair to compare MD3QN with RD2.",
      "In eq(2), should it be $\\theta_{i-1}$ or $\\theta_i$?",
      "is $\\mu^{\\pi}$ a joint distribution or marginal distribution? From its dimension, $\\mu$ looks like a marginal distribution, however in l.126 it represents a joint distribution.",
      "an $\\infty$ sign is missing in eq(17).",
      "l.160-l.169, it is better to elaborate more about this part. It is still unclear why it's rigorous to use different metrics for proof and training aside from the fact that they lead to similar empirical performances."
    ]
  },
  {
    "paper_id": "2312.07025v2",
    "submission_id": "u7oKU1iXTa9",
    "submission_title": "Distributional Reinforcement Learning for Multi-Dimensional Reward Functions",
    "review_id": "iGUacEYNUPS",
    "input": {
      "title": "Distributional Reinforcement Learning for Multi-Dimensional Reward Functions",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The definition of distributional RL is more complex than necessary.\n- In eq 4, the a\u2019 notation is overloaded.\n- The bold fonts are not kept consistent in 6) and 8).\n- The reward notation in 8) is better consistent too.\n- 140: the function f has been defined.\n- Theorem 1 and Prop. 1 are for policy evaluation.\n- Theorem 2\u2019s presentation is different from Th. 1, in that the metric is changed.\n- The Wasserstein distance was used in the proofs.\n- The training loss used the metric of ? This wasn\u2019t discussed but perhaps later in the paper.\n- It would be good to add here the discussion as it reads like incomplete.\n- Can the authors explain the technical changes in the proofs because of the extension to hybrid reward setting?\n- Using MMD for training distRL is straightforward and not new.\n- Four Atari games were selected (and unexplained). I\u2019m not sure the experiments carries importance and whether they can support the claim.\n- It is just too few and hard to interpret.",
    "review_points_list": [
      "The definition of distributional RL is more complex than necessary.",
      "In eq 4, the a\u2019 notation is overloaded.",
      "The bold fonts are not kept consistent in 6) and 8).",
      "The reward notation in 8) is better consistent too.",
      "140: the function f has been defined.",
      "Theorem 1 and Prop. 1 are for policy evaluation.",
      "Theorem 2\u2019s presentation is different from Th. 1, in that the metric is changed.",
      "The Wasserstein distance was used in the proofs.",
      "The training loss used the metric of ? This wasn\u2019t discussed but perhaps later in the paper.",
      "It would be good to add here the discussion as it reads like incomplete.",
      "Can the authors explain the technical changes in the proofs because of the extension to hybrid reward setting?",
      "Using MMD for training distRL is straightforward and not new.",
      "Four Atari games were selected (and unexplained). I\u2019m not sure the experiments carries importance and whether they can support the claim.",
      "It is just too few and hard to interpret."
    ]
  },
  {
    "paper_id": "2103.02695v3",
    "submission_id": "tqi_45ApQzF",
    "submission_title": "Shift Invariance Can Reduce Adversarial Robustness",
    "review_id": "OwaRMvkZZJV",
    "input": {
      "title": "Shift Invariance Can Reduce Adversarial Robustness",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is very well-motivated and addresses an important problem in adversarial machine learning, i.e., a better understanding of adversarial attacks.\n- The work provides a better understanding of the relationship between adversarial robustness, shift-invariance, dimensionality, and the linear margin of the data in neural networks.\n- The hypothesis for shift-invariance is empirically tested on large datasets and diverse neural network architectures such as FC, CNNs, and transformers.\n- It would be helpful if the authors can comment on why for easier datasets like Cifar-10, we observe that AlexNet is an outlier both in terms of shift-invariance and robustness, but for harder datasets like ImageNet, the gap reduces significantly (Fig. 4).\n- The connection between shift-invariance and robustness is interesting but unclear. The experimental results show some correlation between the two, but the hypothesis that shift invariance reduces robustness by increasing the implicit dimension of the data is not well explained.\n- From Fig. 2, the authors conclude that 'fully-connected networks (FCNs) are more robust than Shift Invariant CNNs'. It would be beneficial if the authors can provide the shift-invariance score of the respective networks to support their conclusion.\n- In addition, unlike FCNs, convolutional neural networks (CNNs) have a spatial bias -- a type of inductive bias that assumes a certain spatial structure present in the input data. Can this contribute to their poor adversarial robustness performance?\n- In Fig. 1, we observe that the margin of a linear, shift-invariant classifier will shrink in proportion to the inverse of the total number of image pixels. It is interesting because most pixels in the images from Fig. 1 belong to the same color (gray). It would be great if the authors can comment on this answer.",
    "review_points_list": [
      "The paper is very well-motivated and addresses an important problem in adversarial machine learning, i.e., a better understanding of adversarial attacks.",
      "The work provides a better understanding of the relationship between adversarial robustness, shift-invariance, dimensionality, and the linear margin of the data in neural networks.",
      "The hypothesis for shift-invariance is empirically tested on large datasets and diverse neural network architectures such as FC, CNNs, and transformers.",
      "It would be helpful if the authors can comment on why for easier datasets like Cifar-10, we observe that AlexNet is an outlier both in terms of shift-invariance and robustness, but for harder datasets like ImageNet, the gap reduces significantly (Fig. 4).",
      "The connection between shift-invariance and robustness is interesting but unclear. The experimental results show some correlation between the two, but the hypothesis that shift invariance reduces robustness by increasing the implicit dimension of the data is not well explained.",
      "From Fig. 2, the authors conclude that 'fully-connected networks (FCNs) are more robust than Shift Invariant CNNs'. It would be beneficial if the authors can provide the shift-invariance score of the respective networks to support their conclusion.",
      "In addition, unlike FCNs, convolutional neural networks (CNNs) have a spatial bias -- a type of inductive bias that assumes a certain spatial structure present in the input data. Can this contribute to their poor adversarial robustness performance?",
      "In Fig. 1, we observe that the margin of a linear, shift-invariant classifier will shrink in proportion to the inverse of the total number of image pixels. It is interesting because most pixels in the images from Fig. 1 belong to the same color (gray). It would be great if the authors can comment on this answer."
    ]
  },
  {
    "paper_id": "2103.02695v3",
    "submission_id": "tqi_45ApQzF",
    "submission_title": "Shift Invariance Can Reduce Adversarial Robustness",
    "review_id": "AUmhRxOaSu4",
    "input": {
      "title": "Shift Invariance Can Reduce Adversarial Robustness",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- There is originality in this work;\n- however, there are a number of works that address the relationship between invariance and robustness in the past.\n- Related works also seem to be adequately cited.\n- The submission is also well-organized, with good teaser figures and example in the front, followed by a number of theorems and experiments to justify the claims made.\n- There are a wide-range of experiments, testing different architectures and datasets.\n- This shows that authors are willing to testify their claims through their experiments carefully.\n- Having theorems to justify those claims is also a plus usually.",
    "review_points_list": [
      "There is originality in this work;",
      "however, there are a number of works that address the relationship between invariance and robustness in the past.",
      "Related works also seem to be adequately cited.",
      "The submission is also well-organized, with good teaser figures and example in the front, followed by a number of theorems and experiments to justify the claims made.",
      "There are a wide-range of experiments, testing different architectures and datasets.",
      "This shows that authors are willing to testify their claims through their experiments carefully.",
      "Having theorems to justify those claims is also a plus usually."
    ]
  },
  {
    "paper_id": "2103.02695v3",
    "submission_id": "tqi_45ApQzF",
    "submission_title": "Shift Invariance Can Reduce Adversarial Robustness",
    "review_id": "XUbETZdQXvP",
    "input": {
      "title": "Shift Invariance Can Reduce Adversarial Robustness",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Strengths: Their hypothesis about shift invariance is first verified in a simple setting.\n- Their hypothesis about shift invariance is first verified in a simple setting.\n- They also provide theoretical justification\n- and further demonstrate the evidence in real-world architectures and datasets.\n- I found this is a nice paper.\n- I don't particularly see weaknesses.\n- L292: Visual Transformer -> Vision Transformer.\n- It would be interesting to consider more common image corruptions like gaussian noise, blur, etc.",
    "review_points_list": [
      "Strengths: Their hypothesis about shift invariance is first verified in a simple setting.",
      "Their hypothesis about shift invariance is first verified in a simple setting.",
      "They also provide theoretical justification",
      "and further demonstrate the evidence in real-world architectures and datasets.",
      "I found this is a nice paper.",
      "I don't particularly see weaknesses.",
      "L292: Visual Transformer -> Vision Transformer.",
      "It would be interesting to consider more common image corruptions like gaussian noise, blur, etc."
    ]
  },
  {
    "paper_id": "1801.02610v5",
    "submission_id": "xlNpxfGMTTu",
    "submission_title": "Adversarial Attack Generation Empowered by Min-Max Optimization",
    "review_id": "pStzwC3P7tL",
    "input": {
      "title": "Adversarial Attack Generation Empowered by Min-Max Optimization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- It doesn't differ much from previous work (Universal Adversarial Training, Shafahi et al., 2018).\n- It is clear how this work differs from previous contributions.\n- Is the submission technically sound?\n- Claims are mainly supported by experiments.\n- Is this a complete piece of work or work in progress?\n- The authors are careful and honest about evaluating both the strengths and weaknesses of their work.\n- The submission is mostly clear.\n- It does not adequately inform the reader.\n- The results are important?\n- Others are likely to use the ideas or build on them?\n- Does the submission address a difficult task in a better way than previous work?\n- It does not advance the state of the art in a demonstrable way.",
    "review_points_list": [
      "It doesn't differ much from previous work (Universal Adversarial Training, Shafahi et al., 2018).",
      "It is clear how this work differs from previous contributions.",
      "Is the submission technically sound?",
      "Claims are mainly supported by experiments.",
      "Is this a complete piece of work or work in progress?",
      "The authors are careful and honest about evaluating both the strengths and weaknesses of their work.",
      "The submission is mostly clear.",
      "It does not adequately inform the reader.",
      "The results are important?",
      "Others are likely to use the ideas or build on them?",
      "Does the submission address a difficult task in a better way than previous work?",
      "It does not advance the state of the art in a demonstrable way."
    ]
  },
  {
    "paper_id": "1801.02610v5",
    "submission_id": "xlNpxfGMTTu",
    "submission_title": "Adversarial Attack Generation Empowered by Min-Max Optimization",
    "review_id": "gbCq0Oo_K6D",
    "input": {
      "title": "Adversarial Attack Generation Empowered by Min-Max Optimization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper adapts and existing min-max problem that was proposed for multi-domain robust optimization [45] to the problem of generating adversarial attacks.\n- This work clearly explains its contributions and put them into context of existing work.\n- However, the author mention that some paper have explored min-max formulation in the context of adversarial attacks but don't cite them, for example one work related to problem eq. 5 that also uses a min-max formulation is (Bose et al. 2020).\n- The claims of the paper are overall well supported.\n- It would be nice to have confidence intervals for the experimental results.\n- I really enjoyed the experimental section, I found Table 2 and Figure 1 quite interesting, showing the importance of having adaptive weights and how the weights acts like an attention mechanism to focus more on the hardest task.\n- Table 4 is also quite informative.\n- The author address the time complexity and additional parameters in section 5.3.\n- The paper is well written and very clear.\n- The idea of training against the worst-case scenario is very interesting, this could lead to much more universal attacker.\n- Typo L298: $\text{gamma}=\text{infinity}$ for averaging case\n- Bose et al. 'Adversarial Example Games.' (NeurIPS 2020)",
    "review_points_list": [
      "This paper adapts and existing min-max problem that was proposed for multi-domain robust optimization [45] to the problem of generating adversarial attacks.",
      "This work clearly explains its contributions and put them into context of existing work.",
      "However, the author mention that some paper have explored min-max formulation in the context of adversarial attacks but don't cite them, for example one work related to problem eq. 5 that also uses a min-max formulation is (Bose et al. 2020).",
      "The claims of the paper are overall well supported.",
      "It would be nice to have confidence intervals for the experimental results.",
      "I really enjoyed the experimental section, I found Table 2 and Figure 1 quite interesting, showing the importance of having adaptive weights and how the weights acts like an attention mechanism to focus more on the hardest task.",
      "Table 4 is also quite informative.",
      "The author address the time complexity and additional parameters in section 5.3.",
      "The paper is well written and very clear.",
      "The idea of training against the worst-case scenario is very interesting, this could lead to much more universal attacker.",
      "Typo L298: $\text{gamma}=\text{infinity}$ for averaging case",
      "Bose et al. 'Adversarial Example Games.' (NeurIPS 2020)"
    ]
  },
  {
    "paper_id": "1801.02610v5",
    "submission_id": "xlNpxfGMTTu",
    "submission_title": "Adversarial Attack Generation Empowered by Min-Max Optimization",
    "review_id": "lLZrtV5CRsa",
    "input": {
      "title": "Adversarial Attack Generation Empowered by Min-Max Optimization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed method is general in generating attacks when multiple domain losses are needed to be optimized together.\n- The insights behind the method in smoothifying and balancing weights are very interesting for the adversarial attack with multiple domains.\n- The paper is well written and easy to follow.\n- Comprehensive experiments illustrate the strength of the proposed methods over general attack methods.\n- The ablation study and the following analysis are insightful in improving the studied three tasks.\n- The method is not that novel as it simply applies non-convex min-max optimization for adversarial attacks.\n- The proposed min-max optimization and concave regularizer are mostly proposed in existing works like [45].\n- More importantly, a very similar idea for ensemble attack via universal perturbation is explored in [G] (e.g., equation 13 in [G]) even though it is more for black-box attack setting.\n- Comparisons for ensemble model evasions and universal perturbations settings against [G] are very important and discussions about the differences in related work are at least needed.\n- The proposed methods are not well compared with state-of-the-art attacks for the universal adversarial attacks.\n- Generating universal adversarial perturbations (UAPs) has been extensively studied in both targeted [A,B,C] and non-targeted scenarios [D, E, F].\n- The authors should at least compare against one or two recent methods to demonstrate the effectiveness of the proposed methods.",
    "review_points_list": [
      "The proposed method is general in generating attacks when multiple domain losses are needed to be optimized together.",
      "The insights behind the method in smoothifying and balancing weights are very interesting for the adversarial attack with multiple domains.",
      "The paper is well written and easy to follow.",
      "Comprehensive experiments illustrate the strength of the proposed methods over general attack methods.",
      "The ablation study and the following analysis are insightful in improving the studied three tasks.",
      "The method is not that novel as it simply applies non-convex min-max optimization for adversarial attacks.",
      "The proposed min-max optimization and concave regularizer are mostly proposed in existing works like [45].",
      "More importantly, a very similar idea for ensemble attack via universal perturbation is explored in [G] (e.g., equation 13 in [G]) even though it is more for black-box attack setting.",
      "Comparisons for ensemble model evasions and universal perturbations settings against [G] are very important and discussions about the differences in related work are at least needed.",
      "The proposed methods are not well compared with state-of-the-art attacks for the universal adversarial attacks.",
      "Generating universal adversarial perturbations (UAPs) has been extensively studied in both targeted [A,B,C] and non-targeted scenarios [D, E, F].",
      "The authors should at least compare against one or two recent methods to demonstrate the effectiveness of the proposed methods."
    ]
  },
  {
    "paper_id": "1801.02610v5",
    "submission_id": "xlNpxfGMTTu",
    "submission_title": "Adversarial Attack Generation Empowered by Min-Max Optimization",
    "review_id": "XEP-A3nUWI3",
    "input": {
      "title": "Adversarial Attack Generation Empowered by Min-Max Optimization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.\n- The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.\n- The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset. The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).\n- Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.\n- The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.\n- The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.\n- This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.\n- The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.\n- log(k) is an upper bound on the improvement of query complexity for any sampler.\n- The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.\n- The paper is very clear and well organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.\n- The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.",
    "review_points_list": [
      "The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.",
      "The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.",
      "The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset. The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).",
      "Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.",
      "The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.",
      "The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.",
      "This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.",
      "The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.",
      "log(k) is an upper bound on the improvement of query complexity for any sampler.",
      "The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.",
      "The paper is very clear and well organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.",
      "The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm."
    ]
  },
  {
    "paper_id": "1801.02610v5",
    "submission_id": "xlNpxfGMTTu",
    "submission_title": "Adversarial Attack Generation Empowered by Min-Max Optimization",
    "review_id": "xsKu-yiV5tv",
    "input": {
      "title": "Adversarial Attack Generation Empowered by Min-Max Optimization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed regularized formulation of adversarial attack appears to improve the attack performance in all three settings.\n- Empirically, the paper seems sufficient.\n- However, the paper suffers greatly with issues in clarity.\n- The paper introduces their formulation as a problem of robust learning.\n- This is somewhat misleading, as the 'robust learning' in this paper is referring to a robust formulation of the adversarial attack, and not for updating the model parameters (i.e. 'learning').\n- The latter is what I see most commonly in the literature for robust learning, and it is not clear to me that this is a formulation for adversarial attacks until Section 3.\n- The results are not clear and require a lot of parsing.\n- For example, the text refers to ensemble baselines, but it is unclear what in the table this refers to (I assumed it was the ones with 'avg' under 'opt', since the table captions refer to both attacks as ensemble attacks).\n- There is a column in the table that is labeled 'Lift' which seems to suggest an amount of improvement, however it is not clear to me what number or metric this is supposed to be improving and I could not find any explanatory text in either the caption or the text.\n- Overall, the proposed formulation and the corresponding results seem alright.\n- I do like how the authors studied a simple, generalized regularized formulation and evaluated it in multiple attack settings.\n- However this was only after struggling to parse and understand the paper, the presentation of which was not very clear to me.\n- Other minor questions/comments:\n- The convergence analysis (Theorem 1) appears to make very strong assumptions on the problem.\n- Specifically, it is assumed that the problem has L-Lipschitz continuous gradients.\n- Is this really a reasonable assumption for the setting considered in this paper (i.e. classification in deep networks)?\n- There are some recent works that improved upon the multi-perturbation robustness setting (over MSD) that would be nice to compare to.\n- i.e. 'Learning to generate noise for multi-attack robustness' (this is recent work, and so I did not hold this against the authors, but it would be nice to include in the final version).",
    "review_points_list": [
      "The proposed regularized formulation of adversarial attack appears to improve the attack performance in all three settings.",
      "Empirically, the paper seems sufficient.",
      "However, the paper suffers greatly with issues in clarity.",
      "The paper introduces their formulation as a problem of robust learning.",
      "This is somewhat misleading, as the 'robust learning' in this paper is referring to a robust formulation of the adversarial attack, and not for updating the model parameters (i.e. 'learning').",
      "The latter is what I see most commonly in the literature for robust learning, and it is not clear to me that this is a formulation for adversarial attacks until Section 3.",
      "The results are not clear and require a lot of parsing.",
      "For example, the text refers to ensemble baselines, but it is unclear what in the table this refers to (I assumed it was the ones with 'avg' under 'opt', since the table captions refer to both attacks as ensemble attacks).",
      "There is a column in the table that is labeled 'Lift' which seems to suggest an amount of improvement, however it is not clear to me what number or metric this is supposed to be improving and I could not find any explanatory text in either the caption or the text.",
      "Overall, the proposed formulation and the corresponding results seem alright.",
      "I do like how the authors studied a simple, generalized regularized formulation and evaluated it in multiple attack settings.",
      "However this was only after struggling to parse and understand the paper, the presentation of which was not very clear to me.",
      "Other minor questions/comments:",
      "The convergence analysis (Theorem 1) appears to make very strong assumptions on the problem.",
      "Specifically, it is assumed that the problem has L-Lipschitz continuous gradients.",
      "Is this really a reasonable assumption for the setting considered in this paper (i.e. classification in deep networks)?",
      "There are some recent works that improved upon the multi-perturbation robustness setting (over MSD) that would be nice to compare to.",
      "i.e. 'Learning to generate noise for multi-attack robustness' (this is recent work, and so I did not hold this against the authors, but it would be nice to include in the final version)."
    ]
  },
  {
    "paper_id": "1801.02610v5",
    "submission_id": "xlNpxfGMTTu",
    "submission_title": "Adversarial Attack Generation Empowered by Min-Max Optimization",
    "review_id": "-HeNopxss5U",
    "input": {
      "title": "Adversarial Attack Generation Empowered by Min-Max Optimization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- According to Table 1, it is clear that the proposed APGDA outperforms the compared methods in ASR_all metric (for ensemble attack task).\n- However, I found that in the ACC_B metric, the proposed method performs worse than the comparisons under each setting, indicating the possibility of error due to the model selection and causing my great concern.\n- The same problem appears in Table A3 and Table A4.\n- In addition, I think the experiments are not conducted fully.\n- For example, the author conducted experiments (ensemble attacks) on MNIST with model ABCD but forgot to test EFH as tested on CIFAR-10.\n- In Table A4's caption, all of the learning rate and regularization factors are the same as those in Table A3, but why did you change the parameter epsilon (0.05, 0.03 in l_inf, and 2.0, 1.5 in l_2)?\n- The proof of Theorem 1 seems not finished?\n- When it comes to universal attack, I am confused that the PGD attack is not designed for 'universal attack'.\n- Thus, comparing with PGD cannot demonstrate the performance of the proposed APGDA.\n- I am scared that the same concern as I mentioned in issue(1) occurs again according to Table 5.\n- The noise size of the attacking methods has not been fully considered.\n- I think the corresponding results will make this work more solid.",
    "review_points_list": [
      "According to Table 1, it is clear that the proposed APGDA outperforms the compared methods in ASR_all metric (for ensemble attack task).",
      "However, I found that in the ACC_B metric, the proposed method performs worse than the comparisons under each setting, indicating the possibility of error due to the model selection and causing my great concern.",
      "The same problem appears in Table A3 and Table A4.",
      "In addition, I think the experiments are not conducted fully.",
      "For example, the author conducted experiments (ensemble attacks) on MNIST with model ABCD but forgot to test EFH as tested on CIFAR-10.",
      "In Table A4's caption, all of the learning rate and regularization factors are the same as those in Table A3, but why did you change the parameter epsilon (0.05, 0.03 in l_inf, and 2.0, 1.5 in l_2)?",
      "The proof of Theorem 1 seems not finished?",
      "When it comes to universal attack, I am confused that the PGD attack is not designed for 'universal attack'.",
      "Thus, comparing with PGD cannot demonstrate the performance of the proposed APGDA.",
      "I am scared that the same concern as I mentioned in issue(1) occurs again according to Table 5.",
      "The noise size of the attacking methods has not been fully considered.",
      "I think the corresponding results will make this work more solid."
    ]
  },
  {
    "paper_id": "2202.07789v1",
    "submission_id": "vIDBSGl3vzl",
    "submission_title": "Safe Reinforcement Learning by Imagining the Near Future",
    "review_id": "Bv20fBjSqMp",
    "input": {
      "title": "Safe Reinforcement Learning by Imagining the Near Future",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The topic is relevant.\n- The paper does not make exaggerated claims.\n- Terms such as safe state and irrecoverable state are introduced, which were introduced very similarly already in [1], without mentioning that and citing [1].\n- The experiments are based on only three replicates (3 random seeds).\n- The expression 'for any irrecoverable state s, any sequence of actions [...] will lead to an unsafe state' seems to assume deterministic MDPs.\n- It should then rather be a) 'will lead to an unsafe state with a probability greater than 0' or b) 'will lead to an unsafe state with probability 1'.\n- Where a) is more in line with the concept of super-critical or irrecoverable states.\n- $\neu$ is used without having been introduced.\n- There is a missing reference on page 9, line 243.\n- 'Startin' -> 'Starting'\n- 'the min' -> 'the minimum'\n- 'leaerning' -> 'learning'\n- The authors addressed my concerns to my full satisfaction and I agree with the authors that in continuous state spaces even with a restriction to deterministic environments the topic is not trivial.\n- Therefore, I think the paper is a valuable contribution and I increased the score to 6.",
    "review_points_list": [
      "The topic is relevant.",
      "The paper does not make exaggerated claims.",
      "Terms such as safe state and irrecoverable state are introduced, which were introduced very similarly already in [1], without mentioning that and citing [1].",
      "The experiments are based on only three replicates (3 random seeds).",
      "The expression 'for any irrecoverable state s, any sequence of actions [...] will lead to an unsafe state' seems to assume deterministic MDPs.",
      "It should then rather be a) 'will lead to an unsafe state with a probability greater than 0' or b) 'will lead to an unsafe state with probability 1'.",
      "Where a) is more in line with the concept of super-critical or irrecoverable states.",
      "$\neu$ is used without having been introduced.",
      "There is a missing reference on page 9, line 243.",
      "'Startin' -> 'Starting'",
      "'the min' -> 'the minimum'",
      "'leaerning' -> 'learning'",
      "The authors addressed my concerns to my full satisfaction and I agree with the authors that in continuous state spaces even with a restriction to deterministic environments the topic is not trivial.",
      "Therefore, I think the paper is a valuable contribution and I increased the score to 6."
    ]
  },
  {
    "paper_id": "2202.07789v1",
    "submission_id": "vIDBSGl3vzl",
    "submission_title": "Safe Reinforcement Learning by Imagining the Near Future",
    "review_id": "0eNaPcOl3Yl",
    "input": {
      "title": "Safe Reinforcement Learning by Imagining the Near Future",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The motivation is clearly articulated and easy to sympathize with: In order for RL agents to avoid safety violations while learning, it is sensible for agents to acquire a forward predictive model that can steer agent's behavior away from unsafe future states. This backdrop ideology frames much of the paper, which makes the definitions, method, and results fit very neatly with each other.\n- I was surprised to see that the introduced definition of an MDP only allows for deterministic transition functions. This seems like a dramatic simplification, particularly in the case of safe RL.\n- If an agent only ever needs to experience a transition once to learn it, why should we worry about the compounding error phenomenon?\n- Moreover, we need not worry about adding extra pseudo-rewards to prevent agents from landing in irrecoverable states, as in order to experience the pseudo-reward the agent will need to take the action that moves it to the irrecoverable state already.\n- The setup of the analysis quite puzzling.\n- there is no notion of risk.\n- Perhaps this is okay, as the work might build toward the general stochastic case, but I did not see any mention of the choice to stick with deterministic dynamics, nor suggestions for how to relax at to stochastic dynamics in the analysis.\n- The environments used in Section 4. (Experiments) are not themselves deterministic, so I found quite a start contrast between the framing from the previous sections and the experimental section.\n- spiking. Yet\n- for all $t \\in \\mathbb{N}$ satisfies $Unsafe(s_t)$ for some $t \\in \\mathbb{N}$\n- I found the definition of 'irrecoverable' to be slightly confusing in the way that it is worded.\n- slightly confusing in the way that it is worded\n- if $a$ is a safe action (i.e. $T(s,a)$ is a safe state)\n- but as I read it $T(s,a)$ should be a distribution over next states.\n- the agent only needs to see a single transition per $(s,a)$ pair to learn the model.\n- The compounding error problem cited at the beginning should not really be an issue for deterministic transitions, as the agent only needs to see a single transition per $(s,a)$ pair to learn the model.\n- this is likely worth calling attention to the fact that C is less than $r_{\\min}$\n- Why consider model-based algorithms that output a set of states?\n- Are you aware of any algorithms that actually do this, and are themselves designed for deterministic environments?\n- Why would this be a valid way to represent uncertainty in a deterministic environment, since a single experience of a transition will fully resolve any uncertainty?\n- Some of the references are off.\n- Definition 2 is labeled as such, but is referred to as Definition 3.2\n- I believe the paper will be much improved if it takes time to highlight the nature of the setting, motivating why deterministic-but-continuous environments are an interesting case for safety (and bringing closer attention to the choice of deterministic continuous MDPs).\n- The focus on deterministic-but-continuous environments is indeed suitably interesting.\n- I believe more work is needed to adequately expose and handle risk, exploration, and other considerations.\n- The paper will be much improved if it takes time to highlight the nature of the setting, motivating why deterministic-but-continuous environments are an interesting case for safety.\n- I am raising my score from 4 to 6.\n- the author's rebuttal\n- I believe the link provided in the rebuttal is quite helpful in providing a partial path toward the stochastic setting\n- I believe the paper will be much improved if it takes time to highlight the nature of the setting, motivating why deterministic-but-continuous environments are an interesting case for safety (and bringing closer attention to the choice of deterministic continuous MDPs)\n- I am raising my score from 4 to 6.",
    "review_points_list": [
      "The motivation is clearly articulated and easy to sympathize with: In order for RL agents to avoid safety violations while learning, it is sensible for agents to acquire a forward predictive model that can steer agent's behavior away from unsafe future states. This backdrop ideology frames much of the paper, which makes the definitions, method, and results fit very neatly with each other.",
      "I was surprised to see that the introduced definition of an MDP only allows for deterministic transition functions. This seems like a dramatic simplification, particularly in the case of safe RL.",
      "If an agent only ever needs to experience a transition once to learn it, why should we worry about the compounding error phenomenon?",
      "Moreover, we need not worry about adding extra pseudo-rewards to prevent agents from landing in irrecoverable states, as in order to experience the pseudo-reward the agent will need to take the action that moves it to the irrecoverable state already.",
      "The setup of the analysis quite puzzling.",
      "there is no notion of risk.",
      "Perhaps this is okay, as the work might build toward the general stochastic case, but I did not see any mention of the choice to stick with deterministic dynamics, nor suggestions for how to relax at to stochastic dynamics in the analysis.",
      "The environments used in Section 4. (Experiments) are not themselves deterministic, so I found quite a start contrast between the framing from the previous sections and the experimental section.",
      "spiking. Yet",
      "for all $t \\in \\mathbb{N}$ satisfies $Unsafe(s_t)$ for some $t \\in \\mathbb{N}$",
      "I found the definition of 'irrecoverable' to be slightly confusing in the way that it is worded.",
      "slightly confusing in the way that it is worded",
      "if $a$ is a safe action (i.e. $T(s,a)$ is a safe state)",
      "but as I read it $T(s,a)$ should be a distribution over next states.",
      "the agent only needs to see a single transition per $(s,a)$ pair to learn the model.",
      "The compounding error problem cited at the beginning should not really be an issue for deterministic transitions, as the agent only needs to see a single transition per $(s,a)$ pair to learn the model.",
      "this is likely worth calling attention to the fact that C is less than $r_{\\min}$",
      "Why consider model-based algorithms that output a set of states?",
      "Are you aware of any algorithms that actually do this, and are themselves designed for deterministic environments?",
      "Why would this be a valid way to represent uncertainty in a deterministic environment, since a single experience of a transition will fully resolve any uncertainty?",
      "Some of the references are off.",
      "Definition 2 is labeled as such, but is referred to as Definition 3.2",
      "I believe the paper will be much improved if it takes time to highlight the nature of the setting, motivating why deterministic-but-continuous environments are an interesting case for safety (and bringing closer attention to the choice of deterministic continuous MDPs).",
      "The focus on deterministic-but-continuous environments is indeed suitably interesting.",
      "I believe more work is needed to adequately expose and handle risk, exploration, and other considerations.",
      "The paper will be much improved if it takes time to highlight the nature of the setting, motivating why deterministic-but-continuous environments are an interesting case for safety.",
      "I am raising my score from 4 to 6.",
      "the author's rebuttal",
      "I believe the link provided in the rebuttal is quite helpful in providing a partial path toward the stochastic setting",
      "I believe the paper will be much improved if it takes time to highlight the nature of the setting, motivating why deterministic-but-continuous environments are an interesting case for safety (and bringing closer attention to the choice of deterministic continuous MDPs)",
      "I am raising my score from 4 to 6."
    ]
  },
  {
    "paper_id": "2110.14296v2",
    "submission_id": "u8HmtBBSVJS",
    "submission_title": "Learning Stable Deep Dynamics Models for Partially Observed or Delayed Dynamical Systems",
    "review_id": "4iDWxUzc-A5",
    "input": {
      "title": "Learning Stable Deep Dynamics Models for Partially Observed or Delayed Dynamical Systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper targets an important research question of learning stable deep dynamics models for partially observable scenarios.\n- This paper is on the line of adding structures to the learning procedure based on our understanding of the dynamical systems.\n- The authors take a step forward by extending to partially observed or delayed systems, which I believe has the potential to apply to safety-critical systems where it is crucial to have guarantees on convergence.\n- The authors provide theoretical analysis and convergence guarantees on the proposed method.\n- My primary concern of this paper is its novelty.\n- This work builds on top of Neural Delay Differential Equations (NDDE) [1] by jointly learning a neural network Lyapunov-Razumikhin function. However, similar techniques for stabilizing dynamical systems with neural Lyapunov functions have already been investigated in [2, 3] and many others.\n- Therefore, to me, the proposed method seems to be a direct combination of existing methods, making this paper a bit insufficient in technical novelty.\n- My second concern is the lack of evaluation tasks.\n- For evaluation, the authors only consider a simple hand-designed system, a partially observed damped double pendulum, and a friction-less inverted pendulum.\n- However, for papers that line the similar direction like [3], they considered much more challenging cases, including wheeled vehicles and humanoid balancing. In [4], they investigated the n-link pendulum and high-dimensional systems like video texture generation.\n- The current set of evaluating environments may be a bit too simple, limiting the significance and potential impact of this paper.\n- I have read the reviews from other reviewers and the rebuttal from the authors.\n- I appreciate the authors' efforts in providing additional experimental results and detailed discussions about the novelty of the proposed method and the comparison with previous methods.\n- I encourage the authors to include them in the revised version of the paper.\n- The rebuttal has sufficiently addressed my concerns, and I raised my score from 5 (Marginally below the acceptance threshold) to 6 (Marginally above the acceptance threshold).",
    "review_points_list": [
      "The paper targets an important research question of learning stable deep dynamics models for partially observable scenarios.",
      "This paper is on the line of adding structures to the learning procedure based on our understanding of the dynamical systems.",
      "The authors take a step forward by extending to partially observed or delayed systems, which I believe has the potential to apply to safety-critical systems where it is crucial to have guarantees on convergence.",
      "The authors provide theoretical analysis and convergence guarantees on the proposed method.",
      "My primary concern of this paper is its novelty.",
      "This work builds on top of Neural Delay Differential Equations (NDDE) [1] by jointly learning a neural network Lyapunov-Razumikhin function. However, similar techniques for stabilizing dynamical systems with neural Lyapunov functions have already been investigated in [2, 3] and many others.",
      "Therefore, to me, the proposed method seems to be a direct combination of existing methods, making this paper a bit insufficient in technical novelty.",
      "My second concern is the lack of evaluation tasks.",
      "For evaluation, the authors only consider a simple hand-designed system, a partially observed damped double pendulum, and a friction-less inverted pendulum.",
      "However, for papers that line the similar direction like [3], they considered much more challenging cases, including wheeled vehicles and humanoid balancing. In [4], they investigated the n-link pendulum and high-dimensional systems like video texture generation.",
      "The current set of evaluating environments may be a bit too simple, limiting the significance and potential impact of this paper.",
      "I have read the reviews from other reviewers and the rebuttal from the authors.",
      "I appreciate the authors' efforts in providing additional experimental results and detailed discussions about the novelty of the proposed method and the comparison with previous methods.",
      "I encourage the authors to include them in the revised version of the paper.",
      "The rebuttal has sufficiently addressed my concerns, and I raised my score from 5 (Marginally below the acceptance threshold) to 6 (Marginally above the acceptance threshold)."
    ]
  },
  {
    "paper_id": "2110.14296v2",
    "submission_id": "u8HmtBBSVJS",
    "submission_title": "Learning Stable Deep Dynamics Models for Partially Observed or Delayed Dynamical Systems",
    "review_id": "WIlirpMwI3n",
    "input": {
      "title": "Learning Stable Deep Dynamics Models for Partially Observed or Delayed Dynamical Systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper has the following strength.\n- - The paper studies the modeling of the interesting type of time-delayed system and extends to partially observed stable systems.\n- - The proposed method is learning stable dynamics based on sampled trajectories in a data driven way.\n- - The method can be combined with policy learning to jointly learn a stabilizing policy and the dynamics of the closed loop system.\n- However, It has the following weakness about the paper which has stopped me from recommending the paper for publication in NeurIPS.\n- - The paper discusses little and conducts no comparison against the line of work from recurrent neural networks (RNNs) based effort on modeling system dynamics.\n- - The model introduces a few parameters to tune: K, samples of historical observations, r, the length of history to consider, and alpha, q for the exponential stability of the learned system.\n- - The parameters are highly tailored with the system dynamics to learn.\n- - You would not be able to learn a good model for a (internally) higher dimensional partially observed systems with a small K (this is mentioned by authors as there would not be a one-to-one mapping from internal states to the coordinates).\n- - I am expecting a discussion on choosing the parameters and a demonstration/analysis of performance of the method against these parameters.\n- - The method bases on optimizing a loss function where a loss term is introduced to encourage stability.\n- - This only indirectly ensures stability.\n- - I am concerned that unseen observations could lead to non-stabilizing trajectories.\n- - If any theoretical guarantee could be established on this, it would increase the theoretical contribution of the work.\n- - The experiments has only compared the method against ANODE where ANODE's failure is shown through non-matching phase plots, but the success of the proposed method is only shown through lower loss.\n- - This alone is insufficient in showing a better performance of the proposed method as the worse performing ANODE with learned IC achieves lower loss than ANODE with true IC.\n- - More experiments could help make the point clearer.\n- - The method ports the established method of Neural Delay Differential Equations to the dynamics learning problem.\n- - The theoretical analysis of the method bases on established results clearly given in other papers -- The only theorem in this paper is given by (Efimov and Aleksandrov, 2020).\n- - The experiments have not shown any special benefits of the method against existing methods.\n- - Therefore, I am concerned that the novelty of the work is not up to the standard of NeurIPS.\n- I have read the responses from the authors and appreciate the author's responses to my questions.\n- However, I would like to stick with my original reviews and scoring.",
    "review_points_list": [
      "The paper has the following strength.",
      "- The paper studies the modeling of the interesting type of time-delayed system and extends to partially observed stable systems.",
      "- The proposed method is learning stable dynamics based on sampled trajectories in a data driven way.",
      "- The method can be combined with policy learning to jointly learn a stabilizing policy and the dynamics of the closed loop system.",
      "However, It has the following weakness about the paper which has stopped me from recommending the paper for publication in NeurIPS.",
      "- The paper discusses little and conducts no comparison against the line of work from recurrent neural networks (RNNs) based effort on modeling system dynamics.",
      "- The model introduces a few parameters to tune: K, samples of historical observations, r, the length of history to consider, and alpha, q for the exponential stability of the learned system.",
      "- The parameters are highly tailored with the system dynamics to learn.",
      "- You would not be able to learn a good model for a (internally) higher dimensional partially observed systems with a small K (this is mentioned by authors as there would not be a one-to-one mapping from internal states to the coordinates).",
      "- I am expecting a discussion on choosing the parameters and a demonstration/analysis of performance of the method against these parameters.",
      "- The method bases on optimizing a loss function where a loss term is introduced to encourage stability.",
      "- This only indirectly ensures stability.",
      "- I am concerned that unseen observations could lead to non-stabilizing trajectories.",
      "- If any theoretical guarantee could be established on this, it would increase the theoretical contribution of the work.",
      "- The experiments has only compared the method against ANODE where ANODE's failure is shown through non-matching phase plots, but the success of the proposed method is only shown through lower loss.",
      "- This alone is insufficient in showing a better performance of the proposed method as the worse performing ANODE with learned IC achieves lower loss than ANODE with true IC.",
      "- More experiments could help make the point clearer.",
      "- The method ports the established method of Neural Delay Differential Equations to the dynamics learning problem.",
      "- The theoretical analysis of the method bases on established results clearly given in other papers -- The only theorem in this paper is given by (Efimov and Aleksandrov, 2020).",
      "- The experiments have not shown any special benefits of the method against existing methods.",
      "- Therefore, I am concerned that the novelty of the work is not up to the standard of NeurIPS.",
      "I have read the responses from the authors and appreciate the author's responses to my questions.",
      "However, I would like to stick with my original reviews and scoring."
    ]
  },
  {
    "paper_id": "2403.04400v2",
    "submission_id": "yuCiAWddUFq",
    "submission_title": "Distribution-free inference for regression: discrete, continuous, and in between",
    "review_id": "GgQR_3SRvh",
    "input": {
      "title": "Distribution-free inference for regression: discrete, continuous, and in between",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- It is interesting that the size of the confidence interval can be characterized with the *effective support size*, which can be infinite for continuous distributions.\n- Even if it is infinite, the lower bound of the size of the confidence interval is finite (but not zero).\n- The algorithm of Section 3 estimates a finite effective support size $\\hat{M_\\gamma}$ (since it uses only a hypothesized support set) and therefore can derive a finite-size confidence interval.\n- The reviewer felt the paper being insufficient since, although the theory is interesting, it is difficult to imagine how good the method works for real datasets.\n- For example of Section 2.1, if it specifies not only the distribution $P_X$ but also $\\sigma^2_{P,\\beta}$, then it becomes easier to imagine how the proposed method works.\n- In addition, it is desirable to have experiments for some datasets.\n- In the algorithm of Section 3, it seems not so obvious that we always estimate a finite effective support size $\\hat{M_\\gamma}$ in the algorithm even if the true distribution has an infinite effective support size $M_\\gamma = \\infty$.\n- So, it seems better to show how $\\hat{M_\\gamma}$ behaves if $M_\\gamma = \\infty$ in reality.\n- For example, it would be better to provide how the proposed confidence interval is good (narrow) depending on $M_\\gamma$ (distribution = discrete, continuously uniform, gaussian, etc.).\n- In (2), what if $P_X$ is a continuous distribution and therefore $M_\\gamma(P_X)$ is infinite?\n- Or, should not we interpret that $P_X$ is the true distribution?",
    "review_points_list": [
      "It is interesting that the size of the confidence interval can be characterized with the *effective support size*, which can be infinite for continuous distributions.",
      "Even if it is infinite, the lower bound of the size of the confidence interval is finite (but not zero).",
      "The algorithm of Section 3 estimates a finite effective support size $\\hat{M_\\gamma}$ (since it uses only a hypothesized support set) and therefore can derive a finite-size confidence interval.",
      "The reviewer felt the paper being insufficient since, although the theory is interesting, it is difficult to imagine how good the method works for real datasets.",
      "For example of Section 2.1, if it specifies not only the distribution $P_X$ but also $\\sigma^2_{P,\\beta}$, then it becomes easier to imagine how the proposed method works.",
      "In addition, it is desirable to have experiments for some datasets.",
      "In the algorithm of Section 3, it seems not so obvious that we always estimate a finite effective support size $\\hat{M_\\gamma}$ in the algorithm even if the true distribution has an infinite effective support size $M_\\gamma = \\infty$.",
      "So, it seems better to show how $\\hat{M_\\gamma}$ behaves if $M_\\gamma = \\infty$ in reality.",
      "For example, it would be better to provide how the proposed confidence interval is good (narrow) depending on $M_\\gamma$ (distribution = discrete, continuously uniform, gaussian, etc.).",
      "In (2), what if $P_X$ is a continuous distribution and therefore $M_\\gamma(P_X)$ is infinite?",
      "Or, should not we interpret that $P_X$ is the true distribution?"
    ]
  },
  {
    "paper_id": "2403.04400v2",
    "submission_id": "yuCiAWddUFq",
    "submission_title": "Distribution-free inference for regression: discrete, continuous, and in between",
    "review_id": "9h2rv4BmdX4",
    "input": {
      "title": "Distribution-free inference for regression: discrete, continuous, and in between",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This is an important step forward in terms of theoretical understanding of the problem of honest adaptive inference for regression functions.\n- As far as I know, previous works have not considered the 'effective support size' as a parameter for the sample complexity of adaptive inference of functions.\n- In one extreme, when the effective support size is $O (1)$, then estimating $\bb{E}[Y | X = x]$ is essentially estimating the mean of $Y$ which gives us the usual parametric root-n rate.\n- But in the other extreme, when the effective support size is $o (n^2)$, the confidence interval for each $x$ is still shrinking to 0...\n- But regarding the second extreme case, I would like to see if the authors could provide a more intuitive explanation to convince me (please see comments (2)-(4) below), which I believe would help improve the reach of this paper in the general audience.\n- (1) I believe nonatomic or atomic distribution should be defined at the beginning of this paper, rather than delayed to page 4.\n- (2) Can the authors provide a more intuitive explanation on the counterintuitive phenomenon that even when the support size is larger than the sample size, one can still make the confidence interval length shrink to zero?\n- (3) Related to (2), it would be useful if the authors could provide more comments whether or not their results implicitly depend on the dimension $d$.\n- (4) Also related to (2), is it possible to get any meaningful bound on the variance of Lebesgue measure of the confidence sets?\n- (5) A related practical question is the following: as I mentioned, even if the feature $X$ is continuous, one may argue that in the computer at best one can only represent these numbers at a certain decimal accuracy, so essentially every data science question is about discrete or atomic distributions.\n- Based on the result of this paper and other related papers that the authors cited, is it reasonable to simply discretize the distribution (assuming one-dimensional feature $X$) into bins and then make inference on the $\bb{E}[Y | X \text{some bin}]$?\n- If so, is there any reasonable strategy on how to perform such discretization?",
    "review_points_list": [
      "This is an important step forward in terms of theoretical understanding of the problem of honest adaptive inference for regression functions.",
      "As far as I know, previous works have not considered the 'effective support size' as a parameter for the sample complexity of adaptive inference of functions.",
      "In one extreme, when the effective support size is $O (1)$, then estimating $\bb{E}[Y | X = x]$ is essentially estimating the mean of $Y$ which gives us the usual parametric root-n rate.",
      "But in the other extreme, when the effective support size is $o (n^2)$, the confidence interval for each $x$ is still shrinking to 0...",
      "But regarding the second extreme case, I would like to see if the authors could provide a more intuitive explanation to convince me (please see comments (2)-(4) below), which I believe would help improve the reach of this paper in the general audience.",
      "(1) I believe nonatomic or atomic distribution should be defined at the beginning of this paper, rather than delayed to page 4.",
      "(2) Can the authors provide a more intuitive explanation on the counterintuitive phenomenon that even when the support size is larger than the sample size, one can still make the confidence interval length shrink to zero?",
      "(3) Related to (2), it would be useful if the authors could provide more comments whether or not their results implicitly depend on the dimension $d$.",
      "(4) Also related to (2), is it possible to get any meaningful bound on the variance of Lebesgue measure of the confidence sets?",
      "(5) A related practical question is the following: as I mentioned, even if the feature $X$ is continuous, one may argue that in the computer at best one can only represent these numbers at a certain decimal accuracy, so essentially every data science question is about discrete or atomic distributions.",
      "Based on the result of this paper and other related papers that the authors cited, is it reasonable to simply discretize the distribution (assuming one-dimensional feature $X$) into bins and then make inference on the $\bb{E}[Y | X \text{some bin}]$?",
      "If so, is there any reasonable strategy on how to perform such discretization?"
    ]
  },
  {
    "paper_id": "2403.04400v2",
    "submission_id": "yuCiAWddUFq",
    "submission_title": "Distribution-free inference for regression: discrete, continuous, and in between",
    "review_id": "hHLwvdTdKIx",
    "input": {
      "title": "Distribution-free inference for regression: discrete, continuous, and in between",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think that the theory developed by this work so far is elegant.\n- I found the paper easy to follow.\n- The question that they consider I believe is significant, and the proposed solutions make sense.\n- I read the proofs that are contained in the main paper (for the lower bound result), and they use some nontrivial techniques.\n- However, I strongly believe that the work is incomplete on many fronts.\n- While I have no doubt the authors will complete it adequately at some point, the paper is not currently in good shape to be accepted to Neurips.\n- I have summarized some unanswered questions which I had, which indicate why (in my opinion) the paper is incomplete.\n- I hope these questions provide the authors with meaningful feedback.\n- Given the close connections between Theorem 1 and Barber [2020, Theorem 2], it is unsatisfying that \\\n\tsigma_{P,\beta} is not related to L_\\\n\talpha(\\\n\t\tPi_P) from Barber\u2019s work.\n- Can the former be seen as an approximate to the latter? Is one of them always worse than the other?\n- I request the authors to address these and related questions.\n- While the lower bound and the algorithm proposed is quite general and in a novel setting, the main upper bound analysis (Theorem 3) is in a highly restricted setting where previous results also apply;\n- more details are in the next point.\n- Could the authors provide an end-to-end upper bound analysis (including the guessing part) in a setting where previous results do not apply or are weak?\n- Some open questions which the authors do not address (I believe) are summarized below:\n- What is the relationship between Theorem 3 and Barber [2020, Corollary 1]?\n- What is the relationship to Gupta et al. [2020, Theorem 4] (this latter result is a direct comparison since it essentially induces a finite and known support onto P_X, which is exactly the setup of Thm 3)?\n- In particular, suppose instead of starting with a proposed mean function, I constructed a CI around the sample mean (as against around the mean estimate \\\n\tmu).\n- From what I can understand it should be possible to show a DF CI guarantee for such a CI;\n- is that true?\n- How would the length such a CI compare to the CI defined in (5)?\n- The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.\n- Step 1: A natural algorithm is to suggest a stream is to look at the histogram of the first split of the data.\n- What is the 'generalization' behavior of this stream in terms of estimating M_\\\ngamma well?\n- Basically, what about an eq. (2) style result but for the other direction; that is, the estimate \\\n\thaf{M_\\\ngamma} is not too larger than M_\\\ngamma.\n- How does Theorem 3 change if the support is not finite/known?\n- For instance, if less than \\\n\tgamma fraction of the support is nonatomic?\n- Also related to next question.\n- Step 2 of algorithm and err_\\\n\tmu assumption of Thm 3: Is there some prior literature (in non distribution-free setting), where err_\\\n\tmu can be bounded?\n- Without knowing this, it appears that (*** can circumvent this altogether and we can directly construct a CI around the empirical mean which should work?\n- Since Thm 3 is for fixed support, I am not sure if step 2 is perhaps helpful in the distribution-free setting when the support is not actually fixed or known.\n- Line 99 and Thm 1: If the authors wish to allow M_\\\ngamma to take the value \\\n\tinfty, then I believe that the proof of Theorem 1 needs to be made formally valid for this case.\n- Else, Thm 1 should have as an 'assumption' that M_\\\ngamma is not \\\n\tinfty.\n- Specifically, lines 268-273 in the proof do not parse if M_\\\ngamma is \\\n\tinfty (to the best of my mathematical knowledge, these statements are not formal, although I agree with the conclusions).\n- Lines 199-201: In my opinion, these lines should not be a brief remark in parentheses.\n- At the least, they should be in their own paragraph, and preferably, it would be helpful if the authors could elaborate further.\n- My understanding is that for the theory, sample splitting is required, while in practice it may not be required.\n- If the authors could expand on this, that would be useful.\n- Line 23: the min() goes into the next line\n- Steps 1 \u2013\u2013 3: I noticed that step 1 only cares about the n_b values, and the remaining analysis is conditional on n_b.\n- Due to this, I believe if step 1 fails w.p. p, and step 3 fails w.p. q, then the overall failure probability I think is at most p + (1-p)q < p + q.\n- Just an observation; not sure if it is useful or worth exploring.\n- Line 190: \u201ctesting discrete distributions\u201d should be \u201ctesting properties of discrete distributions\u201d?\n- It eventually became clear to me that \\\n\tmu(x) is to be thought of as the null hypothesis for the mean and we are \u2018testing\u2019 if \\\n\tmu_P(x) = \\\n\tmu(x).\n- If you add 1-2 lines to this end, that could improve readability.\n- Line 212: The parameter \\\n\teta sort of comes out of nowhere and is a bit surprising while reading.\n- Line 240: \u201cmay enables us\u201d -> \u201cmay enable us\u201d\n- Line 246: \u201cThe proof is simple, and follows a standard argument\u201d: In my opinion, simplicity is subjective in this context, and the argument is not standard.\n- Thus, I suggest that this qualification be removed.\n- Line 267: The start of the proof of Theorem 1 is difficult to find without appropriate markers\n- Lines 287-288: \u201cimpossible to distinguish\u201d: Are P^n and P_mix \u201cimpossible\u201d to distinguish from each other (a test to distinguish them will have trivial power), or do you mean that a test to distinguish them will have low (but non-trivial power)?\n- If the latter, then I think \u2018impossible\u2019 is not the right characterization.\n- Line 301: The TV bound that that you use, sup_E |P(E) - Q(E)| \\\n\tleq TV(P, Q), should be stated explicitly since it may not be obvious to some readers.\n- Line 303: I stumbled for some time on the first inequality; it may be useful to other readers to add one step\n- References: Arxiv versions have been cited for some published papers",
    "review_points_list": [
      "I think that the theory developed by this work so far is elegant.",
      "I found the paper easy to follow.",
      "The question that they consider I believe is significant, and the proposed solutions make sense.",
      "I read the proofs that are contained in the main paper (for the lower bound result), and they use some nontrivial techniques.",
      "However, I strongly believe that the work is incomplete on many fronts.",
      "While I have no doubt the authors will complete it adequately at some point, the paper is not currently in good shape to be accepted to Neurips.",
      "I have summarized some unanswered questions which I had, which indicate why (in my opinion) the paper is incomplete.",
      "I hope these questions provide the authors with meaningful feedback.",
      "Given the close connections between Theorem 1 and Barber [2020, Theorem 2], it is unsatisfying that \\\n\tsigma_{P,\beta} is not related to L_\\\n\talpha(\\\n\t\tPi_P) from Barber\u2019s work.",
      "Can the former be seen as an approximate to the latter? Is one of them always worse than the other?",
      "I request the authors to address these and related questions.",
      "While the lower bound and the algorithm proposed is quite general and in a novel setting, the main upper bound analysis (Theorem 3) is in a highly restricted setting where previous results also apply;",
      "more details are in the next point.",
      "Could the authors provide an end-to-end upper bound analysis (including the guessing part) in a setting where previous results do not apply or are weak?",
      "Some open questions which the authors do not address (I believe) are summarized below:",
      "What is the relationship between Theorem 3 and Barber [2020, Corollary 1]?",
      "What is the relationship to Gupta et al. [2020, Theorem 4] (this latter result is a direct comparison since it essentially induces a finite and known support onto P_X, which is exactly the setup of Thm 3)?",
      "In particular, suppose instead of starting with a proposed mean function, I constructed a CI around the sample mean (as against around the mean estimate \\\n\tmu).",
      "From what I can understand it should be possible to show a DF CI guarantee for such a CI;",
      "is that true?",
      "How would the length such a CI compare to the CI defined in (5)?",
      "The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.",
      "Step 1: A natural algorithm is to suggest a stream is to look at the histogram of the first split of the data.",
      "What is the 'generalization' behavior of this stream in terms of estimating M_\\\ngamma well?",
      "Basically, what about an eq. (2) style result but for the other direction; that is, the estimate \\\n\thaf{M_\\\ngamma} is not too larger than M_\\\ngamma.",
      "How does Theorem 3 change if the support is not finite/known?",
      "For instance, if less than \\\n\tgamma fraction of the support is nonatomic?",
      "Also related to next question.",
      "Step 2 of algorithm and err_\\\n\tmu assumption of Thm 3: Is there some prior literature (in non distribution-free setting), where err_\\\n\tmu can be bounded?",
      "Without knowing this, it appears that (*** can circumvent this altogether and we can directly construct a CI around the empirical mean which should work?",
      "Since Thm 3 is for fixed support, I am not sure if step 2 is perhaps helpful in the distribution-free setting when the support is not actually fixed or known.",
      "Line 99 and Thm 1: If the authors wish to allow M_\\\ngamma to take the value \\\n\tinfty, then I believe that the proof of Theorem 1 needs to be made formally valid for this case.",
      "Else, Thm 1 should have as an 'assumption' that M_\\\ngamma is not \\\n\tinfty.",
      "Specifically, lines 268-273 in the proof do not parse if M_\\\ngamma is \\\n\tinfty (to the best of my mathematical knowledge, these statements are not formal, although I agree with the conclusions).",
      "Lines 199-201: In my opinion, these lines should not be a brief remark in parentheses.",
      "At the least, they should be in their own paragraph, and preferably, it would be helpful if the authors could elaborate further.",
      "My understanding is that for the theory, sample splitting is required, while in practice it may not be required.",
      "If the authors could expand on this, that would be useful.",
      "Line 23: the min() goes into the next line",
      "Steps 1 \u2013\u2013 3: I noticed that step 1 only cares about the n_b values, and the remaining analysis is conditional on n_b.",
      "Due to this, I believe if step 1 fails w.p. p, and step 3 fails w.p. q, then the overall failure probability I think is at most p + (1-p)q < p + q.",
      "Just an observation; not sure if it is useful or worth exploring.",
      "Line 190: \u201ctesting discrete distributions\u201d should be \u201ctesting properties of discrete distributions\u201d?",
      "It eventually became clear to me that \\\n\tmu(x) is to be thought of as the null hypothesis for the mean and we are \u2018testing\u2019 if \\\n\tmu_P(x) = \\\n\tmu(x).",
      "If you add 1-2 lines to this end, that could improve readability.",
      "Line 212: The parameter \\\n\teta sort of comes out of nowhere and is a bit surprising while reading.",
      "Line 240: \u201cmay enables us\u201d -> \u201cmay enable us\u201d",
      "Line 246: \u201cThe proof is simple, and follows a standard argument\u201d: In my opinion, simplicity is subjective in this context, and the argument is not standard.",
      "Thus, I suggest that this qualification be removed.",
      "Line 267: The start of the proof of Theorem 1 is difficult to find without appropriate markers",
      "Lines 287-288: \u201cimpossible to distinguish\u201d: Are P^n and P_mix \u201cimpossible\u201d to distinguish from each other (a test to distinguish them will have trivial power), or do you mean that a test to distinguish them will have low (but non-trivial power)?",
      "If the latter, then I think \u2018impossible\u2019 is not the right characterization.",
      "Line 301: The TV bound that that you use, sup_E |P(E) - Q(E)| \\\n\tleq TV(P, Q), should be stated explicitly since it may not be obvious to some readers.",
      "Line 303: I stumbled for some time on the first inequality; it may be useful to other readers to add one step",
      "References: Arxiv versions have been cited for some published papers"
    ]
  },
  {
    "paper_id": "2403.04400v2",
    "submission_id": "yuCiAWddUFq",
    "submission_title": "Distribution-free inference for regression: discrete, continuous, and in between",
    "review_id": "1gyXcybLUX_",
    "input": {
      "title": "Distribution-free inference for regression: discrete, continuous, and in between",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper looks at distribution-free inference for the conditional mean, which is much less studied (in the distribution-free setting, anyways) than predictive inference.\n- So, that is new.\n- The proofs seem to combine techniques that can be found in Barber (2020) and Barber et al. (2019), plus a little bit of innovation, but that's all completely fine.\n- Why are you going from a '$\\notin$' symbol to a '$\\in$' one on line 298?\n- Why did you pick the measure of 'concentration' ($M_\\gamma(P_X)$) that you did?\n- What kind of conditions on the conditional law of $Y \\mid X$ might be sensible to make here, to circumvent Theorem 1?\n- So, what would happen if I just agree to give up on coverage in certain parts of the input space?\n- I assume the restriction of $Y \\in [0,1]$ can be weakened to something like $Y \\in [0,C]$ for some (finite) constant $C > 0$ ...\n- How important is the i.i.d. assumption (vs. just exchangeability)?\n- What if $\\hat C_n$ is random?\n- I might suggest running a few simulations as a check on the construction in Section 3, but I guess that's not really the point of the paper.\n- The paper was a pleasure to read.\n- I might change from using the capital '$A$'s around line 285 to (something like) lower case '$a$'s, to be consistent with the notation introduced earlier.\n- I might put the intuition behind the proof conveyed in lines 292-295 into the main body of the paper somewhere.\n- The paper gives a (tight) impossibility result for distribution-free inference about the conditional mean, suggesting for the field that new assumptions may need to be made, and/or new inferential targets may need to be sought.",
    "review_points_list": [
      "The paper looks at distribution-free inference for the conditional mean, which is much less studied (in the distribution-free setting, anyways) than predictive inference.",
      "So, that is new.",
      "The proofs seem to combine techniques that can be found in Barber (2020) and Barber et al. (2019), plus a little bit of innovation, but that's all completely fine.",
      "Why are you going from a '$\\notin$' symbol to a '$\\in$' one on line 298?",
      "Why did you pick the measure of 'concentration' ($M_\\gamma(P_X)$) that you did?",
      "What kind of conditions on the conditional law of $Y \\mid X$ might be sensible to make here, to circumvent Theorem 1?",
      "So, what would happen if I just agree to give up on coverage in certain parts of the input space?",
      "I assume the restriction of $Y \\in [0,1]$ can be weakened to something like $Y \\in [0,C]$ for some (finite) constant $C > 0$ ...",
      "How important is the i.i.d. assumption (vs. just exchangeability)?",
      "What if $\\hat C_n$ is random?",
      "I might suggest running a few simulations as a check on the construction in Section 3, but I guess that's not really the point of the paper.",
      "The paper was a pleasure to read.",
      "I might change from using the capital '$A$'s around line 285 to (something like) lower case '$a$'s, to be consistent with the notation introduced earlier.",
      "I might put the intuition behind the proof conveyed in lines 292-295 into the main body of the paper somewhere.",
      "The paper gives a (tight) impossibility result for distribution-free inference about the conditional mean, suggesting for the field that new assumptions may need to be made, and/or new inferential targets may need to be sought."
    ]
  },
  {
    "paper_id": "2106.11230v3",
    "submission_id": "ud-WYSo9JSL",
    "submission_title": "Can contrastive learning avoid shortcut solutions?",
    "review_id": "N-CcpJl78h",
    "input": {
      "title": "Can contrastive learning avoid shortcut solutions?",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Interesting theoretical analysis to explain the feature suppression phenomenon in contrastive learning.\n- Well-designed experiments to demonstrate claims made in the paper, e.g. more difficult instance discrimination task makes the model learn more difficult features but at the same time suppressing the original learned features.\n- Simplicity of IFM. No computational overheads, theoretically supported and shown to be effective on a decent variety of datasets.\n- It is also nice to see IFM helps learn robust features.\n- The approach is not tested on larger scale datasets such as ImageNet-1k, probably due to computational constraints.\n- I'm curious about the impact of the approach on larger datasets, where diversity of features and amount of images may naturally help contrastive learning to learn more features.\n- The impact of IFM would be even more if it is shown to be effective for even larger datasets.",
    "review_points_list": [
      "Interesting theoretical analysis to explain the feature suppression phenomenon in contrastive learning.",
      "Well-designed experiments to demonstrate claims made in the paper, e.g. more difficult instance discrimination task makes the model learn more difficult features but at the same time suppressing the original learned features.",
      "Simplicity of IFM. No computational overheads, theoretically supported and shown to be effective on a decent variety of datasets.",
      "It is also nice to see IFM helps learn robust features.",
      "The approach is not tested on larger scale datasets such as ImageNet-1k, probably due to computational constraints.",
      "I'm curious about the impact of the approach on larger datasets, where diversity of features and amount of images may naturally help contrastive learning to learn more features.",
      "The impact of IFM would be even more if it is shown to be effective for even larger datasets."
    ]
  },
  {
    "paper_id": "2106.11230v3",
    "submission_id": "ud-WYSo9JSL",
    "submission_title": "Can contrastive learning avoid shortcut solutions?",
    "review_id": "5sRAvRXIxFN",
    "input": {
      "title": "Can contrastive learning avoid shortcut solutions?",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- While I am not the most familiar with all of the related work in this area, the approach appears novel and the differences between the current work and cited work is clearly explained.\n- The submission appears technically sound.\n- The authors use appropriate methods to make their arguments, provide experimental justification for the claims the paper makes, and provide detailed descriptions of their experimental protocols.\n- The combination of theoretical analysis and empirical results that combine to tell a clear story is compelling.\n- The authors have an explicit limitations and broader impact section that adequately evaluates the strengths and weaknesses of their work.\n- I would, however, appreciate an additional discussion of the computational cost of this approach relative to the overall training process, as this seems a critical component of the work's practical applicability that I do not remember seeing in the paper.\n- I found the paper to be extremely well-written.\n- However, some of the mathematical exposition is notationally dense, and it may be possible to make the paper more accessible by simplifying the presentation.\n- As a practitioner in computer vision, I find these results important and would certainly expect others to use these ideas.\n- The fundamental problem of models that take shortcuts to achieve high levels of performance on a training set, but perform poorly in practice, is extremely common and often addressed only in ad hoc ways.\n- The authors present one of the first methods of which I am aware by which this issue can be systematically addressed, they motivate/analyze it theoretically, and provide compelling empirical results to support its practical significance.\n- The fact that the authors show improvement not only on benchmark datasets, but also on a medical imaging dataset that reflects a real application, is particularly compelling.\n- L 71-75: I very much appreciate the authors' presentation of this point.\n- L 92: What is the 'space U' in 'measure \\nu on a space U'?\n- L 83 - 95: It may be worth describing why the authors set up the problem in this way.\n- L 112: Nit: 'number of negatives m goes to infinity' \u2192 as the reader, I did not know what m was without reading the following lines.\n- L112: It's not immediately clear to me how the LFS \u2192 RHS.\n- L 133 - 135: Another explanatory sentence here may be useful to provide intuition.\n- L 229: Do you evaluate sensitivity to alpha at any point, or is alpha=1 generally a good choice?\n- Fig. 4 caption: Isn't this moving the negative sample towards the anchor (rather than away, as the caption says)?\n- L 294: It seems that the difference in linear readout accuracy b/t IFM and standard SIMCLR is very small (if not overlapping) in many cases.\n- I would soften the statement that it improves linear readout accuracy across all three features for all temperature settings.\n- Fig. 7: What does L_epsilon only mean?\n- Is this just not using the standard InfoNCE loss at all?\n- Why is this better sometimes for MoCo-v2?\n- Potentially worth discussing.\n- Table 1: Please show confidence intervals here or some measure of spread.\n- Point estimates are not sufficient.\n- L 328: Typo in 'previouos'\n- L 337: This should be Appendix C.5 not C.6, I think.\n- Table 2: Some of the bolded numbers are likely not statistically significant (e.g. mMRC column).\n- Please indicate exactly what bold means, and ensure that it accurately reflects statistical significance in some sense.\n- Discussion: Extremely short for a section entitled 'discussion'.\n- I would suggest calling this 'conclusions' and adding a bit more material here to summarize the results presented.",
    "review_points_list": [
      "While I am not the most familiar with all of the related work in this area, the approach appears novel and the differences between the current work and cited work is clearly explained.",
      "The submission appears technically sound.",
      "The authors use appropriate methods to make their arguments, provide experimental justification for the claims the paper makes, and provide detailed descriptions of their experimental protocols.",
      "The combination of theoretical analysis and empirical results that combine to tell a clear story is compelling.",
      "The authors have an explicit limitations and broader impact section that adequately evaluates the strengths and weaknesses of their work.",
      "I would, however, appreciate an additional discussion of the computational cost of this approach relative to the overall training process, as this seems a critical component of the work's practical applicability that I do not remember seeing in the paper.",
      "I found the paper to be extremely well-written.",
      "However, some of the mathematical exposition is notationally dense, and it may be possible to make the paper more accessible by simplifying the presentation.",
      "As a practitioner in computer vision, I find these results important and would certainly expect others to use these ideas.",
      "The fundamental problem of models that take shortcuts to achieve high levels of performance on a training set, but perform poorly in practice, is extremely common and often addressed only in ad hoc ways.",
      "The authors present one of the first methods of which I am aware by which this issue can be systematically addressed, they motivate/analyze it theoretically, and provide compelling empirical results to support its practical significance.",
      "The fact that the authors show improvement not only on benchmark datasets, but also on a medical imaging dataset that reflects a real application, is particularly compelling.",
      "L 71-75: I very much appreciate the authors' presentation of this point.",
      "L 92: What is the 'space U' in 'measure \\nu on a space U'?",
      "L 83 - 95: It may be worth describing why the authors set up the problem in this way.",
      "L 112: Nit: 'number of negatives m goes to infinity' \u2192 as the reader, I did not know what m was without reading the following lines.",
      "L112: It's not immediately clear to me how the LFS \u2192 RHS.",
      "L 133 - 135: Another explanatory sentence here may be useful to provide intuition.",
      "L 229: Do you evaluate sensitivity to alpha at any point, or is alpha=1 generally a good choice?",
      "Fig. 4 caption: Isn't this moving the negative sample towards the anchor (rather than away, as the caption says)?",
      "L 294: It seems that the difference in linear readout accuracy b/t IFM and standard SIMCLR is very small (if not overlapping) in many cases.",
      "I would soften the statement that it improves linear readout accuracy across all three features for all temperature settings.",
      "Fig. 7: What does L_epsilon only mean?",
      "Is this just not using the standard InfoNCE loss at all?",
      "Why is this better sometimes for MoCo-v2?",
      "Potentially worth discussing.",
      "Table 1: Please show confidence intervals here or some measure of spread.",
      "Point estimates are not sufficient.",
      "L 328: Typo in 'previouos'",
      "L 337: This should be Appendix C.5 not C.6, I think.",
      "Table 2: Some of the bolded numbers are likely not statistically significant (e.g. mMRC column).",
      "Please indicate exactly what bold means, and ensure that it accurately reflects statistical significance in some sense.",
      "Discussion: Extremely short for a section entitled 'discussion'.",
      "I would suggest calling this 'conclusions' and adding a bit more material here to summarize the results presented."
    ]
  },
  {
    "paper_id": "2110.13116v1",
    "submission_id": "xkQ4MhLv52X",
    "submission_title": "Learning-Augmented Dynamic Power Management with Multiple States via New Ski Rental Bounds",
    "review_id": "2fMNOk1GMAN",
    "input": {
      "title": "Learning-Augmented Dynamic Power Management with Multiple States via New Ski Rental Bounds",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This work analyzes the consistency vs. prediction error dependence tradeoff, which is modestly different from the previous analysis of consistency vs. robustness tradeoffs.\n- In particular, [35] also gives competitive ratio as a function of error/OPT.\n- It is not entirely clear why the robustness metric is skipped over in this work.\n- So, the authors are encouraged to motivate this new analysis concretely.\n- The proposed ski rental algorithm is fundamentally original, as it is specified by a CDF.\n- This is also the first work that applies the learning-augmented setting to DPM.\n- The submission is technically sound.\n- The submission is overall well organized and written.\n- My main concern is with the presentation of Theorem 5.\n- It is unclear what extended result this provides beyond Theorem 3 by covering all \rho simultaneously, as it was introduced.\n- The experimental results demonstrate that the new algorithm achieves improved performance compared to previous ski rental algorithms in the DPM setting.\n- However, the theoretical results are missing some comparisons against the robustness and consistency of Pareto-optimal randomized ski rental algorithms [35].\n- Also, the broader applicability of this new approach beyond ski-rental and its variants is not clear.",
    "review_points_list": [
      "This work analyzes the consistency vs. prediction error dependence tradeoff, which is modestly different from the previous analysis of consistency vs. robustness tradeoffs.",
      "In particular, [35] also gives competitive ratio as a function of error/OPT.",
      "It is not entirely clear why the robustness metric is skipped over in this work.",
      "So, the authors are encouraged to motivate this new analysis concretely.",
      "The proposed ski rental algorithm is fundamentally original, as it is specified by a CDF.",
      "This is also the first work that applies the learning-augmented setting to DPM.",
      "The submission is technically sound.",
      "The submission is overall well organized and written.",
      "My main concern is with the presentation of Theorem 5.",
      "It is unclear what extended result this provides beyond Theorem 3 by covering all \rho simultaneously, as it was introduced.",
      "The experimental results demonstrate that the new algorithm achieves improved performance compared to previous ski rental algorithms in the DPM setting.",
      "However, the theoretical results are missing some comparisons against the robustness and consistency of Pareto-optimal randomized ski rental algorithms [35].",
      "Also, the broader applicability of this new approach beyond ski-rental and its variants is not clear."
    ]
  },
  {
    "paper_id": "2110.13116v1",
    "submission_id": "xkQ4MhLv52X",
    "submission_title": "Learning-Augmented Dynamic Power Management with Multiple States via New Ski Rental Bounds",
    "review_id": "b-86kN1QfhR",
    "input": {
      "title": "Learning-Augmented Dynamic Power Management with Multiple States via New Ski Rental Bounds",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I enjoyed reading the paper. The results are easy to parse and the proof techniques are clearly presented.\n- The main weakness of the paper, in my view, is that the relation to dynamic power management in environments such as data centers is quite vague.\n- This relation is highlighted in the first few paragraphs of the Introduction but is never revisited afterwards.\n- The specific characteristics of different power-saving modes, the patterns of idle time periods and the extent to which these can be predicted in data centers, etc., are never discussed.\n- Since dynamic power management is supposedly the 'killer app' for the presented algorithms, I think that these issues should be discussed.\n- This also relates to the presented experiments. The evaluation framework is very limited and is quite detached from the motivating example.\n- For instance, the drawing requests uniformly at random and considering predictions that are random perturbations of the actual labels seems overly simple.\n- I realize that this was done in [35], too, but there the key goal was illustrating the usefulness of predictions for the online algorithm, as opposed to tackling a specific problem, as is done here.\n- In light of the above, this paper should, in my view, be evaluated as a theoretical paper about the ski-rental problem.\n- As such, I'm not sure that the results are sufficiently significant.\n- Following the authors' response: Thank you for the detailed answer.\n- I still have an issue with the positioning of this paper.\n- I'm adjusting my score to 5.",
    "review_points_list": [
      "I enjoyed reading the paper. The results are easy to parse and the proof techniques are clearly presented.",
      "The main weakness of the paper, in my view, is that the relation to dynamic power management in environments such as data centers is quite vague.",
      "This relation is highlighted in the first few paragraphs of the Introduction but is never revisited afterwards.",
      "The specific characteristics of different power-saving modes, the patterns of idle time periods and the extent to which these can be predicted in data centers, etc., are never discussed.",
      "Since dynamic power management is supposedly the 'killer app' for the presented algorithms, I think that these issues should be discussed.",
      "This also relates to the presented experiments. The evaluation framework is very limited and is quite detached from the motivating example.",
      "For instance, the drawing requests uniformly at random and considering predictions that are random perturbations of the actual labels seems overly simple.",
      "I realize that this was done in [35], too, but there the key goal was illustrating the usefulness of predictions for the online algorithm, as opposed to tackling a specific problem, as is done here.",
      "In light of the above, this paper should, in my view, be evaluated as a theoretical paper about the ski-rental problem.",
      "As such, I'm not sure that the results are sufficiently significant.",
      "Following the authors' response: Thank you for the detailed answer.",
      "I still have an issue with the positioning of this paper.",
      "I'm adjusting my score to 5."
    ]
  },
  {
    "paper_id": "2110.13116v1",
    "submission_id": "xkQ4MhLv52X",
    "submission_title": "Learning-Augmented Dynamic Power Management with Multiple States via New Ski Rental Bounds",
    "review_id": "SJrmtQJEPPF",
    "input": {
      "title": "Learning-Augmented Dynamic Power Management with Multiple States via New Ski Rental Bounds",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This is a credible and interesting paper.\n- Neither of the two steps -- the ski rental algorithm or the reduction from multi state DPM to 2-state DPM, i.e., ski rental -- is surprising, but each step requires some amount of careful technical work.\n- For instance, in the second case, the idea is to set up the choice of transitioning from a state to its next state as a ski rental decision, and run these ski rental instances in parallel to obtain the overall DPM solution.\n- Similarly, in the ski rental algorithm, the prediction has to be incorporated into the standard randomized algorithm for ski rental that chooses the buying threshold from a distribution with invariant competitive ratio.\n- Overall, this paper adds interesting new ideas to the class of rent or buy problems that have been extensively studied in the learning-augmented setting.",
    "review_points_list": [
      "This is a credible and interesting paper.",
      "Neither of the two steps -- the ski rental algorithm or the reduction from multi state DPM to 2-state DPM, i.e., ski rental -- is surprising, but each step requires some amount of careful technical work.",
      "For instance, in the second case, the idea is to set up the choice of transitioning from a state to its next state as a ski rental decision, and run these ski rental instances in parallel to obtain the overall DPM solution.",
      "Similarly, in the ski rental algorithm, the prediction has to be incorporated into the standard randomized algorithm for ski rental that chooses the buying threshold from a distribution with invariant competitive ratio.",
      "Overall, this paper adds interesting new ideas to the class of rent or buy problems that have been extensively studied in the learning-augmented setting."
    ]
  },
  {
    "paper_id": "2108.09892v3",
    "submission_id": "u14Kuxl8fN",
    "submission_title": "Dynamic Analysis of Higher-Order Coordination in Neuronal Assemblies via De-Sparsified Orthogonal Matching Pursuit",
    "review_id": "TL8-ziGYCLA",
    "input": {
      "title": "Dynamic Analysis of Higher-Order Coordination in Neuronal Assemblies via De-Sparsified Orthogonal Matching Pursuit",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Authors presented a novel approach for analyzing higher-order interactions in a neuron ensemble.\n- The simulation results suggested that the algorithm successfully identify the endogenous components of higher-order coordinated spikes.\n- In application of real neuron ensemble, the algorithm identified brain state modulated higher-order interactions.\n- The paper was well written, and the experiments were carefully designed to demonstrated the power of the current algorithm.\n- I would concern about the scope of application of this model.\n- The anesthesia data has relatively simple structure, that single factor (anesthesia) generated large effects on neuron spiking rates.\n- The authors only tested the model on eight neurons with the highest spiking rate from the ensemble.\n- It is unclear whether the model would converge for a data set with more complication structure and lower spiking rate.\n- The identified higher-order interactions and the history-dependence did not readily interpretable, as the modeling components that generated this knowledge did not have a biology meaning.\n- In many real-world applications, users would not be able to tell whether identified higher-order interactions and history dependence were real or meaningful.",
    "review_points_list": [
      "Authors presented a novel approach for analyzing higher-order interactions in a neuron ensemble.",
      "The simulation results suggested that the algorithm successfully identify the endogenous components of higher-order coordinated spikes.",
      "In application of real neuron ensemble, the algorithm identified brain state modulated higher-order interactions.",
      "The paper was well written, and the experiments were carefully designed to demonstrated the power of the current algorithm.",
      "I would concern about the scope of application of this model.",
      "The anesthesia data has relatively simple structure, that single factor (anesthesia) generated large effects on neuron spiking rates.",
      "The authors only tested the model on eight neurons with the highest spiking rate from the ensemble.",
      "It is unclear whether the model would converge for a data set with more complication structure and lower spiking rate.",
      "The identified higher-order interactions and the history-dependence did not readily interpretable, as the modeling components that generated this knowledge did not have a biology meaning.",
      "In many real-world applications, users would not be able to tell whether identified higher-order interactions and history dependence were real or meaningful."
    ]
  },
  {
    "paper_id": "2108.09892v3",
    "submission_id": "u14Kuxl8fN",
    "submission_title": "Dynamic Analysis of Higher-Order Coordination in Neuronal Assemblies via De-Sparsified Orthogonal Matching Pursuit",
    "review_id": "Kl0vp6u181C",
    "input": {
      "title": "Dynamic Analysis of Higher-Order Coordination in Neuronal Assemblies via De-Sparsified Orthogonal Matching Pursuit",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper extends the multinomial GLM model of Ba et al. (2014, Frontiers in Comp Neuro) to have time-varying parameters.\n- This extension leans heavily on methods described in Sheikhattar et al. (2015, IEEE Transactions on Signal Processing).\n- The goal of this new model is to capture higher-order spike time correlations between simultaneously recorded neurons.\n- The new method does not require repeated trials.\n- My biggest concern with this paper is the difficulty I had in understanding the motivations behind various modeling choices and implementation details.\n- I feel like I only began to understand this paper after reading Ba et al. (2014) and Sheikhattar et al. (2015) in careful detail.\n- For example, a window length W and a forgetting factor \u03b2 control how quickly the model parameters vary over time.\n- how is this avoided if the forgetting factor is close to zero and the window lengths are relatively small?\n- How is this avoided if the forgetting factor is close to one, then the parameters vary only very slowly, potentially resulting in an underfit model?\n- The model can capture a gradual drift in parameters, but potentially it will have trouble accounting for rare, step-like changes in network state, as happens during propofol induced loss of consciousness (investigated in Fig 3).\n- The paper would be stronger if the dynamics of the time-varying parameters were more clearly discussed and illustrated in practice.\n- The assumption of sparsity on GLM parameters is not clearly motivated or discussed.\n- Why not use l2 regularization instead of greedy sparse estimates?\n- The Orthogonal Matching Pursuit algorithm is not reviewed, and terms like 'support set' (refering to the subset of nonzero parameters) are used without a clear definition.\n- On lines 171-172 the authors say they apply a Kalman forward filter and backward smoother control 'abrupt variations' but the details of this smoothing are not present in the main or supplemental text.\n- How were the \u03b2 parameters selected in this analysis?\n- How much sparsity was imposed on the parameter estimates, and how was this tuned?\n- Despite these misgivings, I think the model addresses an interesting topic and I am open to raising my score if the other reviewers were better able to understand the details of the model.\n- On line 318 there is a typo, 'estimate' should be 'estimated'\n- In figures 2 + 3, please label the blue-to-red colorbar\n- On lines 167-169, are the 'u' variables meant to be '\\mu'",
    "review_points_list": [
      "The paper extends the multinomial GLM model of Ba et al. (2014, Frontiers in Comp Neuro) to have time-varying parameters.",
      "This extension leans heavily on methods described in Sheikhattar et al. (2015, IEEE Transactions on Signal Processing).",
      "The goal of this new model is to capture higher-order spike time correlations between simultaneously recorded neurons.",
      "The new method does not require repeated trials.",
      "My biggest concern with this paper is the difficulty I had in understanding the motivations behind various modeling choices and implementation details.",
      "I feel like I only began to understand this paper after reading Ba et al. (2014) and Sheikhattar et al. (2015) in careful detail.",
      "For example, a window length W and a forgetting factor \u03b2 control how quickly the model parameters vary over time.",
      "how is this avoided if the forgetting factor is close to zero and the window lengths are relatively small?",
      "How is this avoided if the forgetting factor is close to one, then the parameters vary only very slowly, potentially resulting in an underfit model?",
      "The model can capture a gradual drift in parameters, but potentially it will have trouble accounting for rare, step-like changes in network state, as happens during propofol induced loss of consciousness (investigated in Fig 3).",
      "The paper would be stronger if the dynamics of the time-varying parameters were more clearly discussed and illustrated in practice.",
      "The assumption of sparsity on GLM parameters is not clearly motivated or discussed.",
      "Why not use l2 regularization instead of greedy sparse estimates?",
      "The Orthogonal Matching Pursuit algorithm is not reviewed, and terms like 'support set' (refering to the subset of nonzero parameters) are used without a clear definition.",
      "On lines 171-172 the authors say they apply a Kalman forward filter and backward smoother control 'abrupt variations' but the details of this smoothing are not present in the main or supplemental text.",
      "How were the \u03b2 parameters selected in this analysis?",
      "How much sparsity was imposed on the parameter estimates, and how was this tuned?",
      "Despite these misgivings, I think the model addresses an interesting topic and I am open to raising my score if the other reviewers were better able to understand the details of the model.",
      "On line 318 there is a typo, 'estimate' should be 'estimated'",
      "In figures 2 + 3, please label the blue-to-red colorbar",
      "On lines 167-169, are the 'u' variables meant to be '\\mu'"
    ]
  },
  {
    "paper_id": "2108.09892v3",
    "submission_id": "u14Kuxl8fN",
    "submission_title": "Dynamic Analysis of Higher-Order Coordination in Neuronal Assemblies via De-Sparsified Orthogonal Matching Pursuit",
    "review_id": "Yyux9ooMg-b",
    "input": {
      "title": "Dynamic Analysis of Higher-Order Coordination in Neuronal Assemblies via De-Sparsified Orthogonal Matching Pursuit",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper gives a comprehensive set of tools to study higher order interactions.\n- The tools would be very valuable for a computational neuroscience audience.\n- Most of my comments are about making some practical/application aspects clearer in the text.\n- While there are no apparent inaccuracies in the text, but the main bulk of the paper is heavy in mathematical symbols and equations.\n- Improving the writing could greatly improve the readership and appeal.\n- Defining the notations in a separate subsection at the beginning, and stating all the modeling assumptions (time-varying models, sparsity assumptions, smoothening steps) at the same place would help.\n- Review of previous works that use marked point process tools for neural activity is missing.\n- For modeling time history dependence, the authors switch from $n^*_t$ (marked representation) to $n_t$ (original neural activity) for computational tractability.\n- This should be explained more carefully since it might have significant implications on results/interpretation.\n- How sensitive are measures/models to timing jitter?\n- Small timing changes in individual spikes could change the assigned mark.\n- Since the mapping from actual spike train to marked point process is highly non-linear, this could significantly affect the results of the methods.\n- While the presented method gives a statistical test to test if there is rth order interaction in a population of C neurons, it does not identify which neurons are interacting.\n- Repeating the test on all subsets of $r$ neurons might not be ideal.\n- Expanding the discussion around this issue would clarify the application for neuroscientific questions.\n- How do the empirical results (especially on human data) change with the smoothening parameter $\beta$?\n- Showing dependence on/robustness to $\beta$ would help understand the time-varying model better.\n- In general, since the approach uses a time-varying model, the methods presented in the paper do not identify higher order effects that occur at very slow time scales.\n- Choice of these hyper-parameters is important for practical application and should be mentioned in the text.\n- Large differences between history-dependent and independent models are revealing, suggesting that large order interactions in simple models can be attributed to simple mechanisms in slightly more complex models.\n- This is explained in the main text associated with Figure 2.\n- However, making these analyses clearer would help with a broader readership, who want to apply these tools to data.",
    "review_points_list": [
      "This paper gives a comprehensive set of tools to study higher order interactions.",
      "The tools would be very valuable for a computational neuroscience audience.",
      "Most of my comments are about making some practical/application aspects clearer in the text.",
      "While there are no apparent inaccuracies in the text, but the main bulk of the paper is heavy in mathematical symbols and equations.",
      "Improving the writing could greatly improve the readership and appeal.",
      "Defining the notations in a separate subsection at the beginning, and stating all the modeling assumptions (time-varying models, sparsity assumptions, smoothening steps) at the same place would help.",
      "Review of previous works that use marked point process tools for neural activity is missing.",
      "For modeling time history dependence, the authors switch from $n^*_t$ (marked representation) to $n_t$ (original neural activity) for computational tractability.",
      "This should be explained more carefully since it might have significant implications on results/interpretation.",
      "How sensitive are measures/models to timing jitter?",
      "Small timing changes in individual spikes could change the assigned mark.",
      "Since the mapping from actual spike train to marked point process is highly non-linear, this could significantly affect the results of the methods.",
      "While the presented method gives a statistical test to test if there is rth order interaction in a population of C neurons, it does not identify which neurons are interacting.",
      "Repeating the test on all subsets of $r$ neurons might not be ideal.",
      "Expanding the discussion around this issue would clarify the application for neuroscientific questions.",
      "How do the empirical results (especially on human data) change with the smoothening parameter $\beta$?",
      "Showing dependence on/robustness to $\beta$ would help understand the time-varying model better.",
      "In general, since the approach uses a time-varying model, the methods presented in the paper do not identify higher order effects that occur at very slow time scales.",
      "Choice of these hyper-parameters is important for practical application and should be mentioned in the text.",
      "Large differences between history-dependent and independent models are revealing, suggesting that large order interactions in simple models can be attributed to simple mechanisms in slightly more complex models.",
      "This is explained in the main text associated with Figure 2.",
      "However, making these analyses clearer would help with a broader readership, who want to apply these tools to data."
    ]
  },
  {
    "paper_id": "2106.05210v2",
    "submission_id": "vllRjSTWcLs",
    "submission_title": "Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Object Segmentation",
    "review_id": "OSD6V2xA8_A",
    "input": {
      "title": "Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Object Segmentation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.\n- The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset. The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).\n- Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.\n- The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.\n- The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.\n- This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.\n- The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.\n- log(k) is an upper bound on the improvement of query complexity for any sampler.\n- The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.\n- The paper is very clear and well organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.\n- The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.",
    "review_points_list": [
      "The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.",
      "The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset. The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).",
      "Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.",
      "The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.",
      "The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.",
      "This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.",
      "The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.",
      "log(k) is an upper bound on the improvement of query complexity for any sampler.",
      "The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.",
      "The paper is very clear and well organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.",
      "The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm."
    ]
  },
  {
    "paper_id": "2106.05210v2",
    "submission_id": "vllRjSTWcLs",
    "submission_title": "Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Object Segmentation",
    "review_id": "tI1LUKXyf7",
    "input": {
      "title": "Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Object Segmentation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I enjoy reading the manuscript, which is well-structured. The ideas are well-presented and easy to follow.\n- The proposed pipeline is clear and reasonable albeit with some minor contradictions in description.\n- I appreciate the analysis and experiments on similarity functions and running time, which help a lot for better understanding the proposed method and potential issues in previous works.\n- The authors promise to release the code, which would be truly valuable.\n- About the counterintuitive result on Memory management, where the short-term consistency seems to be harmful to STCN when applying L2 similarity, I wonder what would happen if cosine similarity and dot product similarity are adopted instead of L2.\n- Additionally, I recommend an ablation on merely maintaining the last frame in memory and provide corresponding qualitative results to prove the drifting assumption in Ln152.\n- I appreciate the assumption that \u2018every pixel counts\u2019 and consent the extra robustness from additional \u2018meaningful\u2019 memory nodes.\n- But I think the proposed method does not explicitly explore the correspondence between background pixels, as [9] did, but just spread the \u2018attention\u2019 to more foreground pixels, and thus introduces the mismatching issues as described in the limitation section.\n- The authors also analyze the different undergoing situations between STCN and other NLP methods or video classification methods, but I could not get the point and the discussion seems a little bit redundant.\n- I would recommend a refinement or some detailed explanation.",
    "review_points_list": [
      "I enjoy reading the manuscript, which is well-structured. The ideas are well-presented and easy to follow.",
      "The proposed pipeline is clear and reasonable albeit with some minor contradictions in description.",
      "I appreciate the analysis and experiments on similarity functions and running time, which help a lot for better understanding the proposed method and potential issues in previous works.",
      "The authors promise to release the code, which would be truly valuable.",
      "About the counterintuitive result on Memory management, where the short-term consistency seems to be harmful to STCN when applying L2 similarity, I wonder what would happen if cosine similarity and dot product similarity are adopted instead of L2.",
      "Additionally, I recommend an ablation on merely maintaining the last frame in memory and provide corresponding qualitative results to prove the drifting assumption in Ln152.",
      "I appreciate the assumption that \u2018every pixel counts\u2019 and consent the extra robustness from additional \u2018meaningful\u2019 memory nodes.",
      "But I think the proposed method does not explicitly explore the correspondence between background pixels, as [9] did, but just spread the \u2018attention\u2019 to more foreground pixels, and thus introduces the mismatching issues as described in the limitation section.",
      "The authors also analyze the different undergoing situations between STCN and other NLP methods or video classification methods, but I could not get the point and the discussion seems a little bit redundant.",
      "I would recommend a refinement or some detailed explanation."
    ]
  },
  {
    "paper_id": "2106.05210v2",
    "submission_id": "vllRjSTWcLs",
    "submission_title": "Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Object Segmentation",
    "review_id": "CDlCyYkecd",
    "input": {
      "title": "Rethinking Space-Time Networks with Improved Memory Coverage for Efficient Video Object Segmentation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is clear and easy to read.\n- The proposed method achieves state-of-the-art accuracy and high efficiency.\n- The proposed STCN is reasonable and effective.\n- The investigation about the similarity computation is meaningful.\n- There may need more intuition for why L2 similarity being better than dot-product similarity.\n- Even though dot-product provides less smooth similarity, it can be relived by the Softmax function.\n- Sec3.1 tries to provide explanations for this, yet the visualization is based on toy examples.\n- It would be better to visualize with real examples.\n- In Fig.4, the numbers of total nodes for Dot product and L2 similarity are different.\n- Shouldn't they be the same?\n- The results in Tab.1 are both based on L2 similarity.\n- If not, this should be clarified.\n- It would be better to report performance for STM with L2 similarity.\n- All the experiments are conducted on the validation sets.\n- It would be better to incorporate results on testing sets into the paper.\n- The model actually performs worse than the previous method on the test-dev\n- This is contradictory to the performance on the validation set.\n- Any explanation?\n- Some related works for fast VOS are missing [a,b].\n- [a] Fast video object segmentation via dynamic targeting network, cvpr19\n- [b] Motion-guided cascaded refinement network for video object segmentation,cvpr18\n- In general, I like this work for its motivation and effective/efficient performance.\n- I would like to see the authors' responses.",
    "review_points_list": [
      "The paper is clear and easy to read.",
      "The proposed method achieves state-of-the-art accuracy and high efficiency.",
      "The proposed STCN is reasonable and effective.",
      "The investigation about the similarity computation is meaningful.",
      "There may need more intuition for why L2 similarity being better than dot-product similarity.",
      "Even though dot-product provides less smooth similarity, it can be relived by the Softmax function.",
      "Sec3.1 tries to provide explanations for this, yet the visualization is based on toy examples.",
      "It would be better to visualize with real examples.",
      "In Fig.4, the numbers of total nodes for Dot product and L2 similarity are different.",
      "Shouldn't they be the same?",
      "The results in Tab.1 are both based on L2 similarity.",
      "If not, this should be clarified.",
      "It would be better to report performance for STM with L2 similarity.",
      "All the experiments are conducted on the validation sets.",
      "It would be better to incorporate results on testing sets into the paper.",
      "The model actually performs worse than the previous method on the test-dev",
      "This is contradictory to the performance on the validation set.",
      "Any explanation?",
      "Some related works for fast VOS are missing [a,b].",
      "[a] Fast video object segmentation via dynamic targeting network, cvpr19",
      "[b] Motion-guided cascaded refinement network for video object segmentation,cvpr18",
      "In general, I like this work for its motivation and effective/efficient performance.",
      "I would like to see the authors' responses."
    ]
  },
  {
    "paper_id": "1801.06267v1",
    "submission_id": "ys6L_NWchCp",
    "submission_title": "Large-Scale Unsupervised Object Discovery",
    "review_id": "RoY1Oa6EEKf",
    "input": {
      "title": "Large-Scale Unsupervised Object Discovery",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- It was very nice to reformulate the existing UOD formulation to be fit to a PageRank solution.\n- First to introduce an UOD approach to be applied in the large-scale dataset (Op1.7M).\n- Reformulation that modifying the binary importance vector y as having a float value to become PageRank vector v is incremental.\n- A more explanation is needed on how this method can be processed in parallel and why other methods can not. P matrix computed on the large-scale dataset must be very large. How can this matrix be divided into multiple chunks?\n- Inherently sequential is a unclear term, please provide more clarification.\n- After reading authors' responses and other reviewers' comments, I raise my rating to 'lean to accept'. My concerns are well addressed.",
    "review_points_list": [
      "It was very nice to reformulate the existing UOD formulation to be fit to a PageRank solution.",
      "First to introduce an UOD approach to be applied in the large-scale dataset (Op1.7M).",
      "Reformulation that modifying the binary importance vector y as having a float value to become PageRank vector v is incremental.",
      "A more explanation is needed on how this method can be processed in parallel and why other methods can not. P matrix computed on the large-scale dataset must be very large. How can this matrix be divided into multiple chunks?",
      "Inherently sequential is a unclear term, please provide more clarification.",
      "After reading authors' responses and other reviewers' comments, I raise my rating to 'lean to accept'. My concerns are well addressed."
    ]
  },
  {
    "paper_id": "1801.06267v1",
    "submission_id": "ys6L_NWchCp",
    "submission_title": "Large-Scale Unsupervised Object Discovery",
    "review_id": "n3QpicMVjl0",
    "input": {
      "title": "Large-Scale Unsupervised Object Discovery",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper is very well written, motivated, and presents a very good case.\n- Object discovery in image collection is indeed a very relevant problem, as we are slowly approaching the limits of the supervised learning paradigm.\n- I see the contribution of methods that can scale well to very large datasets as very valuable to our community.\n- The technical contribution of this paper stands on very solid ground: I love the insight that the formulation by Vo et al., CVPR\u201919 can be re-interpreted as a ranking problem over a fully-connected graph of proposals and establishing the link to well-understood and mature methodology for link analysis.\n- The implications of this insight are important and will allow performing object discovery on (abundant) large-scale unlabelled photo collections.\n- The paper presents solid experimental analysis on COCO dataset (and subsets), as well as the large-scale OpenImage dataset.\n- Analysis shows that the only competitive method [Vo et al., ECCV\u201920] is not applicable to OpenImages (I do have some criticism on this point, though- see the weaknesses section).\n- I also appreciate the detailed discussion on the impact of different object proposals and features (ImageNet-supervised and self-supervised), and the comparison between three variants of this ranking formulation.\n- Besides parallelization, it is also very nice that this formulation is scalable enough that it doesn\u2019t need to limit the number of object proposals per image, which I assume is the main reason behind slightly better performance compared to [Vo et al., ECCV\u201920].\n- At the same time, I would also like to note that it would be nice to discuss this experimentally.\n- The most problematic aspect of this paper is the very vague definition of what \"other top-performing methods cannot handle\" (Tab 1.).\n- This is further related to Sec. 4.1, run time discussion, which states that [32] and [67] did not finish in reasonable time.\n- What is considered to be a reasonable time?\n- One week (par. \"Quantitative evaluation\" mentions that)?\n- For example, training neural networks can easily take one week or more, and if a method needs more than a week (2 weeks?) to finish, I would not say that it is not applicable to such a large dataset.\n- I understand that one cannot wait for the optimization to converge for months, but I am really in the dark here what kind of time spans we are talking about, and I would like to see a discussion on this (also the final version of the paper must be more precise here).\n- Also, let me remark here that \"reasonable time\" will be different in the future with better compute (although it is true that datasets will be growing as well).\n- It can be seen that optimization-based methods scale linearly (i.e., scale very well).\n- Therefore we can also expect that these methods should be very applicable in the future.\n- I definitely see that the major advantage of the proposed method due to the fact that it is nicely parallelizable.\n- But this aspect is related to the core contribution of this paper.\n- Finally, I do not understand why EB runtime is constant?\n- It should be linear wrt. the number of images (when processed serially), or else I dramatically misunderstood something.\n- This might be no an issue with this paper per se, but more general- is AP the right metric for this?\n- In my opinion, it isn\u2019t because object discovery is not well-defined (part vs. whole object ambiguity), and therefore, every (possibly relevant) discovered region that is not labeled would be considered as FP and penalize the performance.\n- Using incorrect metrics may hinder progress in this field.\n- Why not evaluating (average) recall wrt. pre-fixed proposal thresholds instead?\n- This is also a more general comment: object discovery formulation, as tackled in this paper (and formalized by Vo et al., CVPR\u201919), is inherently about finding commonly occurring patterns in the image collection.\n- Wrt. the long-tailed distribution of object classes, this will only be applicable to the \"head\" classes and will dismiss the tail.\n- I am not saying that methods tackling the discovery of frequently occurring objects/patterns are not valuable, but I believe that this venue explicitly encourages discussion of limitations, and this is certainly one of them!\n- I think this paper presents a nice contribution for scalable optimization-based object discovery.\n- Besides having solid theoretical ground, I find this paper well explained and experimentally validated and overall find that it should be a nice contribution to this venue.\n- This is my summary of my thoughts on the other reviews and rebuttals:\n- 3zeH, N6wG express doubts on object discovery using a graph-based formulation that finds common patterns based on connectedness analysis:\n- I find that this approach to object discovery has already been well-motivated and established in the community (Vo et al., CVPR\u201919, and ECCV\u201920).\n- I agree that this is a bit exotic research direction, but I still think it is one worth pursuing, especially given that nowadays, we are collecting large amounts of unlabeled data that \"we don\u2019t know what to do with.\"\n- Moreover, the novelty of this paper is not in proposing to pose discovery as a combinatorial optimization problem, but rather seeing parallels between methods by Vo et al., and link analysis that admits highly parallelizable algorithms.\n- Use of \u2018supervised features\u2019 and on the dependability on object proposals (3zeH):\n- I believe this work follows the experimental protocol proposed in papers by Vo et al., plus analyses performance using both hand-crafted and deep features.\n- I think pretty much all discovery methods depend on object proposals (as do several object detectors).\n- I see no issue here.\n- Finding commonly-occurring patterns will inherently ignore the \u2018long-tail\u2019 \u2014 I\u2019ve had a similar concern as N6wG on this;\n- However, the rebuttal reports a weak correlation with object occurrence frequency.\n- I would like to see a more detailed discussion on this, but either way, I also do believe that the discovery of frequently occurring objects is an open and very challenging problem worthy of new contributions.\n- Re-formulation is incremental:\n- I respectfully disagree with FJwA that establishing this link is of incremental nature;\n- It certainly is obvious in hindsight, but noting the link, re-formulating the objective proposed in Vo et al., and demonstrating experimentally that this yields a highly scalable and parallelizable solution is a solid contribution in my view.\n- Overall, I find this paper relevant and valuable, and I think that the paper should be accepted.",
    "review_points_list": [
      "This paper is very well written, motivated, and presents a very good case.",
      "Object discovery in image collection is indeed a very relevant problem, as we are slowly approaching the limits of the supervised learning paradigm.",
      "I see the contribution of methods that can scale well to very large datasets as very valuable to our community.",
      "The technical contribution of this paper stands on very solid ground: I love the insight that the formulation by Vo et al., CVPR\u201919 can be re-interpreted as a ranking problem over a fully-connected graph of proposals and establishing the link to well-understood and mature methodology for link analysis.",
      "The implications of this insight are important and will allow performing object discovery on (abundant) large-scale unlabelled photo collections.",
      "The paper presents solid experimental analysis on COCO dataset (and subsets), as well as the large-scale OpenImage dataset.",
      "Analysis shows that the only competitive method [Vo et al., ECCV\u201920] is not applicable to OpenImages (I do have some criticism on this point, though- see the weaknesses section).",
      "I also appreciate the detailed discussion on the impact of different object proposals and features (ImageNet-supervised and self-supervised), and the comparison between three variants of this ranking formulation.",
      "Besides parallelization, it is also very nice that this formulation is scalable enough that it doesn\u2019t need to limit the number of object proposals per image, which I assume is the main reason behind slightly better performance compared to [Vo et al., ECCV\u201920].",
      "At the same time, I would also like to note that it would be nice to discuss this experimentally.",
      "The most problematic aspect of this paper is the very vague definition of what \"other top-performing methods cannot handle\" (Tab 1.).",
      "This is further related to Sec. 4.1, run time discussion, which states that [32] and [67] did not finish in reasonable time.",
      "What is considered to be a reasonable time?",
      "One week (par. \"Quantitative evaluation\" mentions that)?",
      "For example, training neural networks can easily take one week or more, and if a method needs more than a week (2 weeks?) to finish, I would not say that it is not applicable to such a large dataset.",
      "I understand that one cannot wait for the optimization to converge for months, but I am really in the dark here what kind of time spans we are talking about, and I would like to see a discussion on this (also the final version of the paper must be more precise here).",
      "Also, let me remark here that \"reasonable time\" will be different in the future with better compute (although it is true that datasets will be growing as well).",
      "It can be seen that optimization-based methods scale linearly (i.e., scale very well).",
      "Therefore we can also expect that these methods should be very applicable in the future.",
      "I definitely see that the major advantage of the proposed method due to the fact that it is nicely parallelizable.",
      "But this aspect is related to the core contribution of this paper.",
      "Finally, I do not understand why EB runtime is constant?",
      "It should be linear wrt. the number of images (when processed serially), or else I dramatically misunderstood something.",
      "This might be no an issue with this paper per se, but more general- is AP the right metric for this?",
      "In my opinion, it isn\u2019t because object discovery is not well-defined (part vs. whole object ambiguity), and therefore, every (possibly relevant) discovered region that is not labeled would be considered as FP and penalize the performance.",
      "Using incorrect metrics may hinder progress in this field.",
      "Why not evaluating (average) recall wrt. pre-fixed proposal thresholds instead?",
      "This is also a more general comment: object discovery formulation, as tackled in this paper (and formalized by Vo et al., CVPR\u201919), is inherently about finding commonly occurring patterns in the image collection.",
      "Wrt. the long-tailed distribution of object classes, this will only be applicable to the \"head\" classes and will dismiss the tail.",
      "I am not saying that methods tackling the discovery of frequently occurring objects/patterns are not valuable, but I believe that this venue explicitly encourages discussion of limitations, and this is certainly one of them!",
      "I think this paper presents a nice contribution for scalable optimization-based object discovery.",
      "Besides having solid theoretical ground, I find this paper well explained and experimentally validated and overall find that it should be a nice contribution to this venue.",
      "This is my summary of my thoughts on the other reviews and rebuttals:",
      "3zeH, N6wG express doubts on object discovery using a graph-based formulation that finds common patterns based on connectedness analysis:",
      "I find that this approach to object discovery has already been well-motivated and established in the community (Vo et al., CVPR\u201919, and ECCV\u201920).",
      "I agree that this is a bit exotic research direction, but I still think it is one worth pursuing, especially given that nowadays, we are collecting large amounts of unlabeled data that \"we don\u2019t know what to do with.\"",
      "Moreover, the novelty of this paper is not in proposing to pose discovery as a combinatorial optimization problem, but rather seeing parallels between methods by Vo et al., and link analysis that admits highly parallelizable algorithms.",
      "Use of \u2018supervised features\u2019 and on the dependability on object proposals (3zeH):",
      "I believe this work follows the experimental protocol proposed in papers by Vo et al., plus analyses performance using both hand-crafted and deep features.",
      "I think pretty much all discovery methods depend on object proposals (as do several object detectors).",
      "I see no issue here.",
      "Finding commonly-occurring patterns will inherently ignore the \u2018long-tail\u2019 \u2014 I\u2019ve had a similar concern as N6wG on this;",
      "However, the rebuttal reports a weak correlation with object occurrence frequency.",
      "I would like to see a more detailed discussion on this, but either way, I also do believe that the discovery of frequently occurring objects is an open and very challenging problem worthy of new contributions.",
      "Re-formulation is incremental:",
      "I respectfully disagree with FJwA that establishing this link is of incremental nature;",
      "It certainly is obvious in hindsight, but noting the link, re-formulating the objective proposed in Vo et al., and demonstrating experimentally that this yields a highly scalable and parallelizable solution is a solid contribution in my view.",
      "Overall, I find this paper relevant and valuable, and I think that the paper should be accepted."
    ]
  },
  {
    "paper_id": "1801.06267v1",
    "submission_id": "ys6L_NWchCp",
    "submission_title": "Large-Scale Unsupervised Object Discovery",
    "review_id": "QtAa1PSgFSS",
    "input": {
      "title": "Large-Scale Unsupervised Object Discovery",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Utilizing ranking for object discovery seems original to me.\n- The paper lacks motivations/discussions of the proposed technology, making it hard to follow why a mathematical method is employed in the framework.\n- Adding intuitive discussions about why ranking is a good technical solution for object discovery would improve the quality of the paper.\n- The paper is technically correct to me.\n- Graph connection density is definitely an implication about the frequently appearing objects.\n- However, it corresponds to discovering the frequent objects.\n- The paper could add more discussion about whether the technology is a good fit for the task of object discovery which looks to discover single/all foreground objects.\n- The paper is of interest to the community.",
    "review_points_list": [
      "Utilizing ranking for object discovery seems original to me.",
      "The paper lacks motivations/discussions of the proposed technology, making it hard to follow why a mathematical method is employed in the framework.",
      "Adding intuitive discussions about why ranking is a good technical solution for object discovery would improve the quality of the paper.",
      "The paper is technically correct to me.",
      "Graph connection density is definitely an implication about the frequently appearing objects.",
      "However, it corresponds to discovering the frequent objects.",
      "The paper could add more discussion about whether the technology is a good fit for the task of object discovery which looks to discover single/all foreground objects.",
      "The paper is of interest to the community."
    ]
  },
  {
    "paper_id": "2106.01947v1",
    "submission_id": "uw4mcO8nz3n",
    "submission_title": "The Semi-Random Satisfaction of Voting Axioms",
    "review_id": "AA-782wR0av",
    "input": {
      "title": "The Semi-Random Satisfaction of Voting Axioms",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I agree that voting axioms are generally quite rigid and oftentimes too coarse.\n- It is also definitely discouraging sometimes to only prove impossibility results.\n- Smoothed analysis makes sense for studying the satisfiability of voting axioms under more realistic models of vote generation.\n- I appreciate the approach taken by the authors in this paper.\n- I found the technical exposition to be quite dense and incredibly notation-heavy.\n- I appreciated the efforts of the authors to provide high-level intuition for many of the results.\n- The tables really help the reader.\n- I was very impressed (and daunted) by the technical content of the paper.\n- I think the authors did a good job cleaning up the presentation and adding intuition for a shorter format.\n- I do think the best fit for this work is in a social choice journal, given the scope of the work.\n- I do not think it is outside the scope of NeurIPS.",
    "review_points_list": [
      "I agree that voting axioms are generally quite rigid and oftentimes too coarse.",
      "It is also definitely discouraging sometimes to only prove impossibility results.",
      "Smoothed analysis makes sense for studying the satisfiability of voting axioms under more realistic models of vote generation.",
      "I appreciate the approach taken by the authors in this paper.",
      "I found the technical exposition to be quite dense and incredibly notation-heavy.",
      "I appreciated the efforts of the authors to provide high-level intuition for many of the results.",
      "The tables really help the reader.",
      "I was very impressed (and daunted) by the technical content of the paper.",
      "I think the authors did a good job cleaning up the presentation and adding intuition for a shorter format.",
      "I do think the best fit for this work is in a social choice journal, given the scope of the work.",
      "I do not think it is outside the scope of NeurIPS."
    ]
  },
  {
    "paper_id": "2106.01947v1",
    "submission_id": "uw4mcO8nz3n",
    "submission_title": "The Semi-Random Satisfaction of Voting Axioms",
    "review_id": "gfGhFI_84Em",
    "input": {
      "title": "The Semi-Random Satisfaction of Voting Axioms",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The smoothed social choice framework was first proposed by Xia, which is a mid-point between the impartial culture setting and the traditional worst-case analysis.\n- In this paper, they use this framework to define smoothed satisfaction and analyze how likely voting axioms satisfied under realistic settings.\n- I believe it is a very important question to ask, and it is a sweet spot for smoothed analysis.\n- This paper demonstrates that some axioms which cannot coexist in worst-case analysis can be satisfied simultaneously in some realistic settings.\n- Major technical contribution of this paper is that authors show several pretty general quantitative results of how likely various voting axioms could coexist in realistic setting.\n- Having that said, I do think the writing of the technical part can be improved.\n- I feel it is just too dense, notations are a bit overwhelming.\n- Overall, it is a very strong paper, it addresses a long-standing (and important) open problem and demonstrate the power of smoothed analysis.\n- The highlight of this paper is that it proposes a pretty general (and sound) framework to analyze satisfaction of voting axioms in somewhat realistic settings.\n- This paper also shows quantitative results for two important axioms (Condorcet and Participation) under many important voting rules.\n- The major concern is that this paper might be too technical to follow, I would strongly recommend the authors to make the body less technical, front-loading some intuition and maybe dumping some results into appendix may help.\n- typos:\n- 1) Line 28, 'exist' -> 'exists'",
    "review_points_list": [
      "The smoothed social choice framework was first proposed by Xia, which is a mid-point between the impartial culture setting and the traditional worst-case analysis.",
      "In this paper, they use this framework to define smoothed satisfaction and analyze how likely voting axioms satisfied under realistic settings.",
      "I believe it is a very important question to ask, and it is a sweet spot for smoothed analysis.",
      "This paper demonstrates that some axioms which cannot coexist in worst-case analysis can be satisfied simultaneously in some realistic settings.",
      "Major technical contribution of this paper is that authors show several pretty general quantitative results of how likely various voting axioms could coexist in realistic setting.",
      "Having that said, I do think the writing of the technical part can be improved.",
      "I feel it is just too dense, notations are a bit overwhelming.",
      "Overall, it is a very strong paper, it addresses a long-standing (and important) open problem and demonstrate the power of smoothed analysis.",
      "The highlight of this paper is that it proposes a pretty general (and sound) framework to analyze satisfaction of voting axioms in somewhat realistic settings.",
      "This paper also shows quantitative results for two important axioms (Condorcet and Participation) under many important voting rules.",
      "The major concern is that this paper might be too technical to follow, I would strongly recommend the authors to make the body less technical, front-loading some intuition and maybe dumping some results into appendix may help.",
      "typos:",
      "1) Line 28, 'exist' -> 'exists'"
    ]
  },
  {
    "paper_id": "2106.01947v1",
    "submission_id": "uw4mcO8nz3n",
    "submission_title": "The Semi-Random Satisfaction of Voting Axioms",
    "review_id": "0YHWA_WPw_t",
    "input": {
      "title": "The Semi-Random Satisfaction of Voting Axioms",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper contains a trove of fascinating results.\n- The main results characterize integer scoring rules and their asymptotic behavior with respect to Condorcet consistency and participation, and the appendix give a range of additional results characterizing participation for other prominent voting rules.\n- The paper makes a convincing case in the introduction that these (fairly abstract) characterizations have plenty of implications that social-choice researchers should care about, such as new results for participation under impartial culture and general take-aways for the relative likelihood of violations of the two properties (where it is known that Condorcet consistency and participation cannot be simultaneously guaranteed for 4 and more items).\n- At least as important is Lemma 1, an abstracted version of the results by Xia 2021, which builds the foundation of the previous results, but is also clearly applicable to axioms other than participation and Condorcet consistency.\n- I cannot judge how much of that generality was already present in Xia 2021, but, if this is indeed new, this seems like a big and valuable contribution that can likely draw a whole string of papers behind it.\n- A first comment that I have is that I think the term 'smoothed analysis' is a misleading description of what the paper does.\n- I realize, of course, that this terminology is taken over from Xia 2020 (where another reviewer pointed out the same thing [1]), but I think it would be a service to the community to adapt the terminology.\n- In smoothed analysis as introduced by Spielman and Teng, (a) a worst-case instance is randomly perturbed and (b) results are analyzed as a function of both n and sigma, the variance of the noise.\n- By contrast, Xia's model presumes a menu of distributions and then has an adversary combine these distributions; and the paper does not analyze the dependency on the 'noise' (here: the epsilon in the definition of a strictly-positive single-agent preference model).\n- I think a better terminology would be to call the model a semi-random model since it interleaves worst-case and probabilistic steps.\n- In the literature on semi-random models, adversarial and probabilistic steps have been interleaved in many different ways (see, for example, Section 2.3 of this paper by Kolla, Makarychev, and Makarychev [2]).\n- None of this should be understood as a critique of the model, and I think that the model indeed is useful for similar reasons as a smoothed-analysis model, which makes sense that both models are semi-random.\n- Still, the term 'smoothed analysis' is misleading and should be avoided.\n- My second concern is with the presentation of the paper.\n- My impression is that the nine-page format does this paper a real disservice.\n- The authors clearly know their craft, but the space constraints riddle the paper with abbreviations, quick sequences of theorem environments, and a lot of the paper 'tells rather than shows', which is natural given the 60 pages of theoretical appendices and the fact that Theorems 3\u20136 don't even fit into the body.\n- While reading, I was missing more signposting of what was up ahead, and more patient discussions relating the results (the introduction does this very well, I just would have liked more of it).\n- Within these constraints, the exposition is clear, but it is a harder read than it would have to be with extra pages, and I am concerned that there is too little space to reflect on the results and make them shine.\n- I don't think this is reason enough to reject the paper, but I think it severely limits the usefulness of the paper as printed at NeurIPS.\n- I strongly encourage the authors to publish a longer, more patient version on arxiv/in a journal to maximize the impact of the work.\n- Smaller comments:\n- I think \u0398(1) /= 1 - \u0398(1) should be spelled out somewhere: for large enough n, the probabilities will be bounded by some constants alpha, beta with 0 < alpha < beta < 1.\n- In Figure 1, the formulation 'other ranking w.p. 1/8' was very misleading to me.\n- After reading a section coming much later, I think this is supposed to mean that 'every other ranking' has probability 1/8 (the adding-up-to-1 constraint was less obvious to me given that your weighted preference profiles don't have normalized weights).\n- Moreover, I'm pretty sure that the weighted majority graph should have weights 1/8 rather than 1/4.\n- In line 254, it wasn't clear to me what in the condition corresponds to the 'small perturbation', this deserves more details.\n- Based on the introduction, I would have expected Lemma 1 to appear before the main results rather than after. I think this should be signposted in the sections where the main results appear.\n- The first paragraph of Section 3 did little to explain what was the goal of the section, and instead paraphrased the immediately following Definition 2.\n- This paraphrase threw me off rather than helping me.\n- A whole range of abbreviations were undefined at first use (there might be some false positives): ANR in line 142, MRSE is used in line 181 before being introduced in line 190, CH in line 240, PMV in line 324 is only defined in line 361.\n- In the equation in line 240, for example, many sets are intersected with A \\ setminus r(\u03c0).\n- It seems easier to just subtract the set r(\u03c0), which is equivalent.\n- Typo: 'Condocetified' in line 336, 'sutdied' in line 379",
    "review_points_list": [
      "The paper contains a trove of fascinating results.",
      "The main results characterize integer scoring rules and their asymptotic behavior with respect to Condorcet consistency and participation, and the appendix give a range of additional results characterizing participation for other prominent voting rules.",
      "The paper makes a convincing case in the introduction that these (fairly abstract) characterizations have plenty of implications that social-choice researchers should care about, such as new results for participation under impartial culture and general take-aways for the relative likelihood of violations of the two properties (where it is known that Condorcet consistency and participation cannot be simultaneously guaranteed for 4 and more items).",
      "At least as important is Lemma 1, an abstracted version of the results by Xia 2021, which builds the foundation of the previous results, but is also clearly applicable to axioms other than participation and Condorcet consistency.",
      "I cannot judge how much of that generality was already present in Xia 2021, but, if this is indeed new, this seems like a big and valuable contribution that can likely draw a whole string of papers behind it.",
      "A first comment that I have is that I think the term 'smoothed analysis' is a misleading description of what the paper does.",
      "I realize, of course, that this terminology is taken over from Xia 2020 (where another reviewer pointed out the same thing [1]), but I think it would be a service to the community to adapt the terminology.",
      "In smoothed analysis as introduced by Spielman and Teng, (a) a worst-case instance is randomly perturbed and (b) results are analyzed as a function of both n and sigma, the variance of the noise.",
      "By contrast, Xia's model presumes a menu of distributions and then has an adversary combine these distributions; and the paper does not analyze the dependency on the 'noise' (here: the epsilon in the definition of a strictly-positive single-agent preference model).",
      "I think a better terminology would be to call the model a semi-random model since it interleaves worst-case and probabilistic steps.",
      "In the literature on semi-random models, adversarial and probabilistic steps have been interleaved in many different ways (see, for example, Section 2.3 of this paper by Kolla, Makarychev, and Makarychev [2]).",
      "None of this should be understood as a critique of the model, and I think that the model indeed is useful for similar reasons as a smoothed-analysis model, which makes sense that both models are semi-random.",
      "Still, the term 'smoothed analysis' is misleading and should be avoided.",
      "My second concern is with the presentation of the paper.",
      "My impression is that the nine-page format does this paper a real disservice.",
      "The authors clearly know their craft, but the space constraints riddle the paper with abbreviations, quick sequences of theorem environments, and a lot of the paper 'tells rather than shows', which is natural given the 60 pages of theoretical appendices and the fact that Theorems 3\u20136 don't even fit into the body.",
      "While reading, I was missing more signposting of what was up ahead, and more patient discussions relating the results (the introduction does this very well, I just would have liked more of it).",
      "Within these constraints, the exposition is clear, but it is a harder read than it would have to be with extra pages, and I am concerned that there is too little space to reflect on the results and make them shine.",
      "I don't think this is reason enough to reject the paper, but I think it severely limits the usefulness of the paper as printed at NeurIPS.",
      "I strongly encourage the authors to publish a longer, more patient version on arxiv/in a journal to maximize the impact of the work.",
      "Smaller comments:",
      "I think \u0398(1) /= 1 - \u0398(1) should be spelled out somewhere: for large enough n, the probabilities will be bounded by some constants alpha, beta with 0 < alpha < beta < 1.",
      "In Figure 1, the formulation 'other ranking w.p. 1/8' was very misleading to me.",
      "After reading a section coming much later, I think this is supposed to mean that 'every other ranking' has probability 1/8 (the adding-up-to-1 constraint was less obvious to me given that your weighted preference profiles don't have normalized weights).",
      "Moreover, I'm pretty sure that the weighted majority graph should have weights 1/8 rather than 1/4.",
      "In line 254, it wasn't clear to me what in the condition corresponds to the 'small perturbation', this deserves more details.",
      "Based on the introduction, I would have expected Lemma 1 to appear before the main results rather than after. I think this should be signposted in the sections where the main results appear.",
      "The first paragraph of Section 3 did little to explain what was the goal of the section, and instead paraphrased the immediately following Definition 2.",
      "This paraphrase threw me off rather than helping me.",
      "A whole range of abbreviations were undefined at first use (there might be some false positives): ANR in line 142, MRSE is used in line 181 before being introduced in line 190, CH in line 240, PMV in line 324 is only defined in line 361.",
      "In the equation in line 240, for example, many sets are intersected with A \\ setminus r(\u03c0).",
      "It seems easier to just subtract the set r(\u03c0), which is equivalent.",
      "Typo: 'Condocetified' in line 336, 'sutdied' in line 379"
    ]
  },
  {
    "paper_id": "2106.01947v1",
    "submission_id": "uw4mcO8nz3n",
    "submission_title": "The Semi-Random Satisfaction of Voting Axioms",
    "review_id": "wdq5lcnHGbl",
    "input": {
      "title": "The Semi-Random Satisfaction of Voting Axioms",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The theoretical contribution of the paper is sound and overall comprehensive to parse.\n- Under certain assumptions, the main results derive the smoothed satisfaction of Condorcet Criterion (for m>3 and sufficiently large n) and PAR, under a wide range of voting rules.\n- There should be a discussion on how brittle the analyses are under the imposed assumptions (Thm 1 to 6),\n- to what generality the results can be argued upon lifting them?\n- How the current analyses could be extended to smoothed satisfaction of other voting axioms?",
    "review_points_list": [
      "The theoretical contribution of the paper is sound and overall comprehensive to parse.",
      "Under certain assumptions, the main results derive the smoothed satisfaction of Condorcet Criterion (for m>3 and sufficiently large n) and PAR, under a wide range of voting rules.",
      "There should be a discussion on how brittle the analyses are under the imposed assumptions (Thm 1 to 6),",
      "to what generality the results can be argued upon lifting them?",
      "How the current analyses could be extended to smoothed satisfaction of other voting axioms?"
    ]
  }
]