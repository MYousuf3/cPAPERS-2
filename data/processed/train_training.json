[
  {
    "paper_id": "2308.07342v1",
    "submission_id": "yq5MYHVaClG",
    "submission_title": "Emergent Communication of Generalizations",
    "review_id": "rTc637UZBPn",
    "input": {
      "title": "Emergent Communication of Generalizations",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper presents a new algorithm for active learning that outperforms state-of-the-art methods in several benchmarks.\n- The authors demonstrate the effectiveness of their algorithm through extensive experiments on various datasets.\n- The paper lacks a clear motivation for the choice of the hyper-parameters and the optimization method.\n- The results are significant and have the potential to impact the field of machine learning.\n- The paper could benefit from a more detailed explanation of the theoretical underpinning of the algorithm.\n- The authors should also provide more information about the computational complexity of the algorithm.\n- The algorithm's strength is in its ability to efficiently identify the most informative labels for active learning.\n- The algorithm's weakness is in its dependency on the initialization of the labels.\n- Are the results reproducible and can they be easily replicated?\n- What is the impact of the algorithm on the active learning process?\n- This is a great paper.\n- The paper would be improved by the inclusion of additional experiments.\n- The algorithm's theoretical foundation is well-established.\n- The experimental results are impressive and demonstrate the effectiveness of the algorithm.\n- The authors should explore the possibility of applying this algorithm to other domains.\n- The paper is well-written, clear, and easy to understand.\n- The algorithm's main strength is its high computational efficiency.\n- The authors should discuss the potential biases and limitations of their approach.\n- How does the paper relate to previous work in the field?\n- What are the limitations of the paper and how can they be addressed?\n- The paper provides a clear motivation for the research.\n- The authors should provide more details about the experimental setup.\n- The paper is significant because it proposes a novel approach.\n- The strengths of the paper include the clarity of the writing, the relevance to the field, and the effectiveness of the proposed algorithm.\n- The authors should also explore the potential applications of the algorithm.\n- The algorithm's weaknesses include the lack of theoretical guarantees and the dependency on the initialization of the labels.\n- The authors should provide more detailed information about the computational complexity of the algorithm.\n- The results are significant because they demonstrate the effectiveness of the proposed algorithm.\n- The authors should discuss the potential biases and limitations of their approach.\n- The algorithm's main strength is its high accuracy.\n- The authors should explore the possibility of applying this algorithm to other domains.\n- The paper is well-written, clear, and easy to understand.\n- The algorithm's main weakness is its dependency on the initialization of the labels.\n- The authors should provide more information about the experimental setup.\n- The results are impressive and demonstrate the effectiveness of the proposed algorithm.\n- Are the results generalizable to other domains?\n- What are the potential applications of the algorithm?\n- How does the algorithm compare to other methods?\n- What are the potential limitations of the algorithm?\n- The authors should provide more information about the training procedure.\n- What are the implications of the results for the field?\n- The paper could benefit from more detailed experimental results.\n- The authors' claim that this is the first paper to explore active learning for image classification is incorrect.\n- The authors should provide more information about the experimental setup.\n- The authors should provide more detailed information about the theoretical foundation of the algorithm.",
    "review_points_list": [
      "The paper presents a new algorithm for active learning that outperforms state-of-the-art methods in several benchmarks.",
      "The authors demonstrate the effectiveness of their algorithm through extensive experiments on various datasets.",
      "The paper lacks a clear motivation for the choice of the hyper-parameters and the optimization method.",
      "The results are significant and have the potential to impact the field of machine learning.",
      "The paper could benefit from a more detailed explanation of the theoretical underpinning of the algorithm.",
      "The authors should also provide more information about the computational complexity of the algorithm.",
      "The algorithm's strength is in its ability to efficiently identify the most informative labels for active learning.",
      "The algorithm's weakness is in its dependency on the initialization of the labels.",
      "Are the results reproducible and can they be easily replicated?",
      "What is the impact of the algorithm on the active learning process?",
      "This is a great paper.",
      "The paper would be improved by the inclusion of additional experiments.",
      "The algorithm's theoretical foundation is well-established.",
      "The experimental results are impressive and demonstrate the effectiveness of the algorithm.",
      "The authors should explore the possibility of applying this algorithm to other domains.",
      "The paper is well-written, clear, and easy to understand.",
      "The algorithm's main strength is its high computational efficiency.",
      "The authors should discuss the potential biases and limitations of their approach.",
      "How does the paper relate to previous work in the field?",
      "What are the limitations of the paper and how can they be addressed?",
      "The paper provides a clear motivation for the research.",
      "The authors should provide more details about the experimental setup.",
      "The paper is significant because it proposes a novel approach.",
      "The strengths of the paper include the clarity of the writing, the relevance to the field, and the effectiveness of the proposed algorithm.",
      "The authors should also explore the potential applications of the algorithm.",
      "The algorithm's weaknesses include the lack of theoretical guarantees and the dependency on the initialization of the labels.",
      "The authors should provide more detailed information about the computational complexity of the algorithm.",
      "The results are significant because they demonstrate the effectiveness of the proposed algorithm.",
      "The authors should discuss the potential biases and limitations of their approach.",
      "The algorithm's main strength is its high accuracy.",
      "The authors should explore the possibility of applying this algorithm to other domains.",
      "The paper is well-written, clear, and easy to understand.",
      "The algorithm's main weakness is its dependency on the initialization of the labels.",
      "The authors should provide more information about the experimental setup.",
      "The results are impressive and demonstrate the effectiveness of the proposed algorithm.",
      "Are the results generalizable to other domains?",
      "What are the potential applications of the algorithm?",
      "How does the algorithm compare to other methods?",
      "What are the potential limitations of the algorithm?",
      "The authors should provide more information about the training procedure.",
      "What are the implications of the results for the field?",
      "The paper could benefit from more detailed experimental results.",
      "The authors' claim that this is the first paper to explore active learning for image classification is incorrect.",
      "The authors should provide more information about the experimental setup.",
      "The authors should provide more detailed information about the theoretical foundation of the algorithm."
    ]
  },
  {
    "paper_id": "2502.14777v1",
    "submission_id": "zmVumB1Flg",
    "submission_title": "Universal Semi-Supervised Learning",
    "review_id": "Y-voBCyaduS",
    "input": {
      "title": "Universal Semi-Supervised Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed universal SSL setting is very realistic and there is no method proposed specifically for this setting so far.\n- The way scoring mechanism for labeled and unlabeled data is computed is interesting and provides insights about relationships of weights between shared and private classes of labeled and unlabeled data.\n- Proposed approach significantly outperforms SSL methods.\n- The proposed approach is very complex and consists of so many design choices that are not clearly motivated and experimentally validated.\n- Why is L_ssl weighted by w_u when it does not consist of only private but also shared classes?\n- What is the effect of pseudo-target calibration by w_c^avg?\n- What is the effect of this besides intuitive explanations that feature representations of shared classes should be closer?\n- There are many parameters that are not explained how they should be scheduled and what is their effect on the performance.\n- How do different values affect performance?\n- Similarly, how to schedule the parameter \u03bb (i.e. alpha in Beta distribution)?\n- How is the separation of the private classes in the unlabeled data guaranteed, or this can not be guaranteed at all and the approach can only guarantee to separate them from shared classes?\n- This should be clearly explained.\n- Where is domain loss in eq (5) utilized?\n- Are the accuracies in Tables 1 and 3 reported only on the shared set of classes?\n- Why do the authors consider 9 classes for CIFAR-10 instead of 10 and 30 classes instead of 31 on the Office dataset?\n- In Figure 5b is this experiment done on CIFAR-10 dataset?\n- Why is the performance of other baseline so low in the case when there are no private classes?\n- How are methods evaluated when all classes are private?\n- Lack of baselines.\n- There is a mistake in the domain similarity paragraph.\n- There is a typo in the number of examples of the Office dataset.",
    "review_points_list": [
      "The proposed universal SSL setting is very realistic and there is no method proposed specifically for this setting so far.",
      "The way scoring mechanism for labeled and unlabeled data is computed is interesting and provides insights about relationships of weights between shared and private classes of labeled and unlabeled data.",
      "Proposed approach significantly outperforms SSL methods.",
      "The proposed approach is very complex and consists of so many design choices that are not clearly motivated and experimentally validated.",
      "Why is L_ssl weighted by w_u when it does not consist of only private but also shared classes?",
      "What is the effect of pseudo-target calibration by w_c^avg?",
      "What is the effect of this besides intuitive explanations that feature representations of shared classes should be closer?",
      "There are many parameters that are not explained how they should be scheduled and what is their effect on the performance.",
      "How do different values affect performance?",
      "Similarly, how to schedule the parameter \u03bb (i.e. alpha in Beta distribution)?",
      "How is the separation of the private classes in the unlabeled data guaranteed, or this can not be guaranteed at all and the approach can only guarantee to separate them from shared classes?",
      "This should be clearly explained.",
      "Where is domain loss in eq (5) utilized?",
      "Are the accuracies in Tables 1 and 3 reported only on the shared set of classes?",
      "Why do the authors consider 9 classes for CIFAR-10 instead of 10 and 30 classes instead of 31 on the Office dataset?",
      "In Figure 5b is this experiment done on CIFAR-10 dataset?",
      "Why is the performance of other baseline so low in the case when there are no private classes?",
      "How are methods evaluated when all classes are private?",
      "Lack of baselines.",
      "There is a mistake in the domain similarity paragraph.",
      "There is a typo in the number of examples of the Office dataset."
    ]
  },
  {
    "paper_id": "2502.14777v1",
    "submission_id": "zmVumB1Flg",
    "submission_title": "Universal Semi-Supervised Learning",
    "review_id": "KrSlzZcDl1",
    "input": {
      "title": "Universal Semi-Supervised Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The main contributions are: 1) to the best of my knowledge, this paper is the first work to investigate the domain difference between labeled and unlabeled data in SSL (in both label and feature domains), and it shows that conducting domain adaptation can address such problem;\n- 2) the proposed domain similarity training which performs Mixup is novel;\n- 3) this work shows that the adversarial perturbation can be utilized to perform OOD data detection, which is novel in open-set SSL.\n- - The problem setting is quite realistic, and the experimental results are also encouraging. I feel that this work will promote the application of semi-supervised learning to more real-world problems.\n- - The writing of this paper is good, and the details of algorithms are clearly stated.\n- - The proposed method is a general framework that can be deployed to many existing methods.\n- - The proposed method is a bit complex. Since it conducts both Mixup training and adversarial training in each round, the method could be computationally expensive.\n- Can the proposed method outperform other SSL methods in the closed-set SSL setting?\n- Is there any deeper analysis on why the closed-set SSL methods would fail in such a feature distribution mismatch setting?\n- Since this work is strongly related to domain adaptation (the subset mismatch is related to partial domain adaptation, the intersectional mismatch is related to open-set domain adaptation, and the proposed setting is related to universal domain adaptation), it would be nice to discuss the difference between this problem and domain adaptation.",
    "review_points_list": [
      "The main contributions are: 1) to the best of my knowledge, this paper is the first work to investigate the domain difference between labeled and unlabeled data in SSL (in both label and feature domains), and it shows that conducting domain adaptation can address such problem;",
      "2) the proposed domain similarity training which performs Mixup is novel;",
      "3) this work shows that the adversarial perturbation can be utilized to perform OOD data detection, which is novel in open-set SSL.",
      "- The problem setting is quite realistic, and the experimental results are also encouraging. I feel that this work will promote the application of semi-supervised learning to more real-world problems.",
      "- The writing of this paper is good, and the details of algorithms are clearly stated.",
      "- The proposed method is a general framework that can be deployed to many existing methods.",
      "- The proposed method is a bit complex. Since it conducts both Mixup training and adversarial training in each round, the method could be computationally expensive.",
      "Can the proposed method outperform other SSL methods in the closed-set SSL setting?",
      "Is there any deeper analysis on why the closed-set SSL methods would fail in such a feature distribution mismatch setting?",
      "Since this work is strongly related to domain adaptation (the subset mismatch is related to partial domain adaptation, the intersectional mismatch is related to open-set domain adaptation, and the proposed setting is related to universal domain adaptation), it would be nice to discuss the difference between this problem and domain adaptation."
    ]
  },
  {
    "paper_id": "2502.14777v1",
    "submission_id": "zmVumB1Flg",
    "submission_title": "Universal Semi-Supervised Learning",
    "review_id": "dpthTcWzTsC",
    "input": {
      "title": "Universal Semi-Supervised Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The problem setting tackled in this paper is quite practical and general for realistic applications.\n- Since the unlabeled can be collected from any resource, there is potential that the unlabeled data have both different class distribution and feature distributions from the labeled data.\n- Also, the problem setting is much more challenging than prior works with no prior knowledge of class distributions.\n- The paper addresses the overfitting problem of domain discriminators by training on mixup samples, which generates more discriminative domain similarities.\n- Label prediction shift with the adversarial perturbation can reflect the quality of the prediction.\n- The experiments are conducted on both semi-supervised learning dataset and domain adaptation datasets, which can demonstrate the effectiveness of the proposed method on the setting with feature distribution shift.\n- In Eqn. (1), the semi-supervised learning loss is performed on all the unlabeled data.\n- As demonstrated in [14,25], if performing semi-supervised learning loss on all the unlabeled data, the performance degraded severely.\n- No variance is reported in the experiment results.\n- On line 109, both samples from p^u and p^l are labeled as '0'.",
    "review_points_list": [
      "The problem setting tackled in this paper is quite practical and general for realistic applications.",
      "Since the unlabeled can be collected from any resource, there is potential that the unlabeled data have both different class distribution and feature distributions from the labeled data.",
      "Also, the problem setting is much more challenging than prior works with no prior knowledge of class distributions.",
      "The paper addresses the overfitting problem of domain discriminators by training on mixup samples, which generates more discriminative domain similarities.",
      "Label prediction shift with the adversarial perturbation can reflect the quality of the prediction.",
      "The experiments are conducted on both semi-supervised learning dataset and domain adaptation datasets, which can demonstrate the effectiveness of the proposed method on the setting with feature distribution shift.",
      "In Eqn. (1), the semi-supervised learning loss is performed on all the unlabeled data.",
      "As demonstrated in [14,25], if performing semi-supervised learning loss on all the unlabeled data, the performance degraded severely.",
      "No variance is reported in the experiment results.",
      "On line 109, both samples from p^u and p^l are labeled as '0'."
    ]
  },
  {
    "paper_id": "2502.14777v1",
    "submission_id": "zmVumB1Flg",
    "submission_title": "Universal Semi-Supervised Learning",
    "review_id": "gKb7T6FRnDn",
    "input": {
      "title": "Universal Semi-Supervised Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper tries to unify SSL and domain adaptation in a single framework.\n- The originality is OK. But authors seem to miss an important reference which proposes the unsupervised open domain recognition problem:\n- [1] Unsupervised Open Domain Recognition by Semantic Discrepancy Minimization. In CVPR, 2019.\n- The key difference between CAFA and [1] lies in the usage of data that does not belong to the shared class.\n- In CAFA, these data is assumed to be discarded, while in [1] these data are encouraged to be predicted to the categories (only in target domain) with equal probability.\n- Authors should discuss the difference between CAFA and UODTN regarding to the problem setting.\n- The quality and clarity of this paper is good.\n- I think this paper has revealed a good point towards the development of SSL.\n- However, the relation among SSL, unsupervised domain adaptation and other related problem setting (e.g., semi-supervised domain adaptation), should be discussed in an comprehensive way.\n- In CAFA, the authors choose to discard those data that does not belong to the shared class.\n- This point still need to be justified in a proper manner, since it has been proved that these private data can be used to enhance the prediction diversity as in [1] and [2].\n- [2] Towards Discriminability and Diversity: Batch Nuclear-norm Maximization under Label Insufficient Situations. CVPR, 2020.\n- Authors should compare CAFA with these methods on these methods under similar setting.\n- How does the wrongly detected class shared data affect the accuracy?\n- I have read the author response, which addressed my concerns appropriately.\n- I stick to my original score and vote for acceptance on this paper.",
    "review_points_list": [
      "This paper tries to unify SSL and domain adaptation in a single framework.",
      "The originality is OK. But authors seem to miss an important reference which proposes the unsupervised open domain recognition problem:",
      "[1] Unsupervised Open Domain Recognition by Semantic Discrepancy Minimization. In CVPR, 2019.",
      "The key difference between CAFA and [1] lies in the usage of data that does not belong to the shared class.",
      "In CAFA, these data is assumed to be discarded, while in [1] these data are encouraged to be predicted to the categories (only in target domain) with equal probability.",
      "Authors should discuss the difference between CAFA and UODTN regarding to the problem setting.",
      "The quality and clarity of this paper is good.",
      "I think this paper has revealed a good point towards the development of SSL.",
      "However, the relation among SSL, unsupervised domain adaptation and other related problem setting (e.g., semi-supervised domain adaptation), should be discussed in an comprehensive way.",
      "In CAFA, the authors choose to discard those data that does not belong to the shared class.",
      "This point still need to be justified in a proper manner, since it has been proved that these private data can be used to enhance the prediction diversity as in [1] and [2].",
      "[2] Towards Discriminability and Diversity: Batch Nuclear-norm Maximization under Label Insufficient Situations. CVPR, 2020.",
      "Authors should compare CAFA with these methods on these methods under similar setting.",
      "How does the wrongly detected class shared data affect the accuracy?",
      "I have read the author response, which addressed my concerns appropriately.",
      "I stick to my original score and vote for acceptance on this paper."
    ]
  },
  {
    "paper_id": "2203.10446v2",
    "submission_id": "yDwfVD_odRo",
    "submission_title": "A 3D Generative Model for Structure-Based Drug Design",
    "review_id": "Iwv104YE0KF",
    "input": {
      "title": "A 3D Generative Model for Structure-Based Drug Design",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The approach is presented clearly and is remarkably simple.\n- The sampling approach provides a natural way to decode the continuous distribution into a discrete molecular structure.\n- The sampling procedure for training of observing masked molecular structures and training the joint distribution through sampling both positive and negative spatial coordinates is procedurally simple (in a good way, in my opinion).\n- The primary criticism of this work would be that it does not provide any significant machine learning advance and lacks quantitative comparisons to plausible alternative approaches, instead focusing exclusively on a comparison to ref [21].\n- However, I do think this is an interesting task from a domain perspective.\n- What are the aspects of the approaches in refs. 8, 30, and 31 that render them unable to handle larger molecules?\n- This does not seem to be a fundamental limitation of the method but perhaps a limitation of the evaluations in those original papers.\n- The statement that 1D/2D methods are unable to be applied to structure-based design tasks seems to be an oversimplification.\n- String-based and graph-based methods have been applied to the optimization of docking scores as a structure-based oracle function (e.g., https://pubs.acs.org/doi/10.1021/acs.jcim.0c00833) While not conditioning generation on a 3D structure explicitly,\n- This may be considered an application to SBDD.\n- There is a family of methods designed for atom-by-atom or fragment-by-fragment ligand generation within a fixed protein pocket (e.g., AutoGrow4).\n- Is it feasible to do any performance comparisons to these non-ML methods?\n- The problem formulation is different, as they use Vina Scores as intermediate signals during generation,\n- but it is realistic to have access to a docking oracle function. The procedure is similar enough to this work that a comparison is warranted.\n- The performance of the model (i.e., Vina Scores) is not reported when the force field refinement is omitted.\n- This paper does not state whether the force field refinement operates on the ligands alone or the ligands and the binding site together, but the reference implies the latter.\n- Ref 21 also states that Vina was used for reoptimization (including of the pose), whereas this work implies that only the Vina scoring function was used.\n- In the evaluation workflow, were structures taken as their 3D conformations or re-optimized?\n- Insufficient details are provided with respect to this evaluation and the dataset used, although the authors do state that code/data will be made available upon publication.\n- In the experiments, evaluation of activity focuses on the average and median values.\n- However, the goal would arguably be to minimize the docking scores.\n- It appears as though the model does not have the ability to learn how to generate the \u201cmost favorable\u201d ligand by considering docking scores during training,\n- but merely generate a representative ligand. Most generated molecules have binding affinity scores that are worse than the reference ligand.\n- It seems surprising that in the top row of Figure 4, so many of the generated compounds have the same heterocyclic motif as the reference compound, not to mention the terminal phosphate group.\n- Did this scaffold appear in the training set for a very similar protein?\n- Or did the model truly rediscover it from scratch.",
    "review_points_list": [
      "The approach is presented clearly and is remarkably simple.",
      "The sampling approach provides a natural way to decode the continuous distribution into a discrete molecular structure.",
      "The sampling procedure for training of observing masked molecular structures and training the joint distribution through sampling both positive and negative spatial coordinates is procedurally simple (in a good way, in my opinion).",
      "The primary criticism of this work would be that it does not provide any significant machine learning advance and lacks quantitative comparisons to plausible alternative approaches, instead focusing exclusively on a comparison to ref [21].",
      "However, I do think this is an interesting task from a domain perspective.",
      "What are the aspects of the approaches in refs. 8, 30, and 31 that render them unable to handle larger molecules?",
      "This does not seem to be a fundamental limitation of the method but perhaps a limitation of the evaluations in those original papers.",
      "The statement that 1D/2D methods are unable to be applied to structure-based design tasks seems to be an oversimplification.",
      "String-based and graph-based methods have been applied to the optimization of docking scores as a structure-based oracle function (e.g., https://pubs.acs.org/doi/10.1021/acs.jcim.0c00833) While not conditioning generation on a 3D structure explicitly,",
      "This may be considered an application to SBDD.",
      "There is a family of methods designed for atom-by-atom or fragment-by-fragment ligand generation within a fixed protein pocket (e.g., AutoGrow4).",
      "Is it feasible to do any performance comparisons to these non-ML methods?",
      "The problem formulation is different, as they use Vina Scores as intermediate signals during generation,",
      "but it is realistic to have access to a docking oracle function. The procedure is similar enough to this work that a comparison is warranted.",
      "The performance of the model (i.e., Vina Scores) is not reported when the force field refinement is omitted.",
      "This paper does not state whether the force field refinement operates on the ligands alone or the ligands and the binding site together, but the reference implies the latter.",
      "Ref 21 also states that Vina was used for reoptimization (including of the pose), whereas this work implies that only the Vina scoring function was used.",
      "In the evaluation workflow, were structures taken as their 3D conformations or re-optimized?",
      "Insufficient details are provided with respect to this evaluation and the dataset used, although the authors do state that code/data will be made available upon publication.",
      "In the experiments, evaluation of activity focuses on the average and median values.",
      "However, the goal would arguably be to minimize the docking scores.",
      "It appears as though the model does not have the ability to learn how to generate the \u201cmost favorable\u201d ligand by considering docking scores during training,",
      "but merely generate a representative ligand. Most generated molecules have binding affinity scores that are worse than the reference ligand.",
      "It seems surprising that in the top row of Figure 4, so many of the generated compounds have the same heterocyclic motif as the reference compound, not to mention the terminal phosphate group.",
      "Did this scaffold appear in the training set for a very similar protein?",
      "Or did the model truly rediscover it from scratch."
    ]
  },
  {
    "paper_id": "2203.10446v2",
    "submission_id": "yDwfVD_odRo",
    "submission_title": "A 3D Generative Model for Structure-Based Drug Design",
    "review_id": "88ppB6K2eP0",
    "input": {
      "title": "A 3D Generative Model for Structure-Based Drug Design",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well motivated and clearly written.\n- They tackle the problem of structure-based drug design which is a very interesting and crucial step for using ml models for drug design.\n- The experiment results show clear improvement over the baselines.\n- They only include one single baseline but I am sure there are many works that exist in this line and should be taken into consideration.\n- For instance the work [30] and [31].\n- In table 1, it is shown that the proposed model has a better score of not only Vina but also SA score and QED score.\n- I can understand the model could lead to a better Vina score as the model is tailored to solve this specific problem but it is not clear what factor of the model leads to a better SA score and QED score when compared to the baseline.",
    "review_points_list": [
      "The paper is well motivated and clearly written.",
      "They tackle the problem of structure-based drug design which is a very interesting and crucial step for using ml models for drug design.",
      "The experiment results show clear improvement over the baselines.",
      "They only include one single baseline but I am sure there are many works that exist in this line and should be taken into consideration.",
      "For instance the work [30] and [31].",
      "In table 1, it is shown that the proposed model has a better score of not only Vina but also SA score and QED score.",
      "I can understand the model could lead to a better Vina score as the model is tailored to solve this specific problem but it is not clear what factor of the model leads to a better SA score and QED score when compared to the baseline."
    ]
  },
  {
    "paper_id": "2203.10446v2",
    "submission_id": "yDwfVD_odRo",
    "submission_title": "A 3D Generative Model for Structure-Based Drug Design",
    "review_id": "USIMrIfBnrR",
    "input": {
      "title": "A 3D Generative Model for Structure-Based Drug Design",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The method presented in the paper is very original.\n- The model can perceive 3D relation between generated ligand and target protein.\n- There are not many generative models that are designed to create molecules that directly fit the 3D space of the binding pocket.\n- The proposed model is certainly unique in the category of structure-based generative models\n- Another method in this category is the shape-based model by Skalic et al. [1], which is missing in the references.\n- This method generates compounds based on the predicted 3D shape that fits the binding pocket.\n- However, also this method uses the SMILES representation instead of working directly on 3D atoms.\n- The presented experimental results are convincing.\n- The authors present qualitative results in Table 1 which could be improved by adding more models to the comparison (e.g. [1]) and adding error bars based on multiple runs of the models.\n- The qualitative results in Figures 4 and 5 clearly show that the proposed method can generate reasonable compounds.\n- What seems a little bit suspicious is that in Figure 4 the generated compounds look very similar to the reference compound.\n- It may suggest data leakage, e.g. compounds that are very similar to the reference one (e.g. the same analog series) are included in the training set.\n- A scaffold split would prevent this from happening.\n- To make these experiments more convincing, the whole protein families that are present in the testing set should be also discarded from the training set.\n- The paper is clearly written, and there are only minor issues that generate confusion.\n- In Equation 1, the notation W^\\ell(d_{ij}) may suggest that W^\\ell is a function, and in the text it is said that \"weight of message from j to i depends only on d_{ij}\".\n- This function is not defined, but instead it is said that W is a learnable matrix.\n- Equations 11 and 12 in the supplemental material are much more precise and do not seem equivalent to what is presented in the paper.\n- The architecture of the frontier network F is not described at all.\n- The proposed method supports multi-modal sampling of valid compounds thanks to a simple (not using a latent space) autoregressive method.\n- The experiments show that the proposed generative model creates compounds that are drug-like and synthetically accessible without directly optimizing for these values.\n- Additionally, a linker prediction task is performed and the results are compared with a popular model for this task, DeLinker.\n- Having considered all that, the method presented in the paper is of high value to the field of computer-aided drug discovery.\n- Why is 'Nothing' not a separate class in the probability vector c, but instead it always artificially gets value 0 by the means of Equation 5?\n- Does the loss in Equation 8 not converge otherwise?\n- In Figure 5, the PDB ID is missing.\n- In Figure 5, the atoms with a red overlay are hardly readable.\n- In Figure 3, it is not clear what the vertical dashed lines signify.\n- I am leaning toward the acceptance of this paper.",
    "review_points_list": [
      "The method presented in the paper is very original.",
      "The model can perceive 3D relation between generated ligand and target protein.",
      "There are not many generative models that are designed to create molecules that directly fit the 3D space of the binding pocket.",
      "The proposed model is certainly unique in the category of structure-based generative models",
      "Another method in this category is the shape-based model by Skalic et al. [1], which is missing in the references.",
      "This method generates compounds based on the predicted 3D shape that fits the binding pocket.",
      "However, also this method uses the SMILES representation instead of working directly on 3D atoms.",
      "The presented experimental results are convincing.",
      "The authors present qualitative results in Table 1 which could be improved by adding more models to the comparison (e.g. [1]) and adding error bars based on multiple runs of the models.",
      "The qualitative results in Figures 4 and 5 clearly show that the proposed method can generate reasonable compounds.",
      "What seems a little bit suspicious is that in Figure 4 the generated compounds look very similar to the reference compound.",
      "It may suggest data leakage, e.g. compounds that are very similar to the reference one (e.g. the same analog series) are included in the training set.",
      "A scaffold split would prevent this from happening.",
      "To make these experiments more convincing, the whole protein families that are present in the testing set should be also discarded from the training set.",
      "The paper is clearly written, and there are only minor issues that generate confusion.",
      "In Equation 1, the notation W^\\ell(d_{ij}) may suggest that W^\\ell is a function, and in the text it is said that \"weight of message from j to i depends only on d_{ij}\".",
      "This function is not defined, but instead it is said that W is a learnable matrix.",
      "Equations 11 and 12 in the supplemental material are much more precise and do not seem equivalent to what is presented in the paper.",
      "The architecture of the frontier network F is not described at all.",
      "The proposed method supports multi-modal sampling of valid compounds thanks to a simple (not using a latent space) autoregressive method.",
      "The experiments show that the proposed generative model creates compounds that are drug-like and synthetically accessible without directly optimizing for these values.",
      "Additionally, a linker prediction task is performed and the results are compared with a popular model for this task, DeLinker.",
      "Having considered all that, the method presented in the paper is of high value to the field of computer-aided drug discovery.",
      "Why is 'Nothing' not a separate class in the probability vector c, but instead it always artificially gets value 0 by the means of Equation 5?",
      "Does the loss in Equation 8 not converge otherwise?",
      "In Figure 5, the PDB ID is missing.",
      "In Figure 5, the atoms with a red overlay are hardly readable.",
      "In Figure 3, it is not clear what the vertical dashed lines signify.",
      "I am leaning toward the acceptance of this paper."
    ]
  },
  {
    "paper_id": "2203.10446v2",
    "submission_id": "yDwfVD_odRo",
    "submission_title": "A 3D Generative Model for Structure-Based Drug Design",
    "review_id": "vu4qqTQFgpz",
    "input": {
      "title": "A 3D Generative Model for Structure-Based Drug Design",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper designs a deep generative model to form a valid drug-like molecule fitting to a specific binding site.\n- The generation procedure is split into two parts: (i) it predicts the probability density of atom occurrence in 3D space of the binding site, where the binding target is used as context and roto-translation invariance neural network is used;\n- (ii) it leverages auto-regressive sampling algorithm for generating valid and multi-modal molecules from the learned atoms\u2019 density.\n- 3D molecule design is an important and popular topic in recent years and is highly valuable.\n- There are some issues in experiments.\n- The docking score (in terms of Vina) of the generated molecules is relatively poor.\n- In Figure 4 and 5, none of the docking scores is better than -10.\n- Also, in Table 1, the average vina score is -6.3, which does not indicate high affinity.\n- During empirical studies, some important baseline methods are missing, e.g., [Masuda et al, Generating 3d molecular structures conditional on a receptor binding site with deep generative models] and [Ragoza et al. Learning a continuous representation of 3d molecular structures with deep generative models].\n- I have read authors' responses and other reviews, and do not change my score.",
    "review_points_list": [
      "The paper designs a deep generative model to form a valid drug-like molecule fitting to a specific binding site.",
      "The generation procedure is split into two parts: (i) it predicts the probability density of atom occurrence in 3D space of the binding site, where the binding target is used as context and roto-translation invariance neural network is used;",
      "(ii) it leverages auto-regressive sampling algorithm for generating valid and multi-modal molecules from the learned atoms\u2019 density.",
      "3D molecule design is an important and popular topic in recent years and is highly valuable.",
      "There are some issues in experiments.",
      "The docking score (in terms of Vina) of the generated molecules is relatively poor.",
      "In Figure 4 and 5, none of the docking scores is better than -10.",
      "Also, in Table 1, the average vina score is -6.3, which does not indicate high affinity.",
      "During empirical studies, some important baseline methods are missing, e.g., [Masuda et al, Generating 3d molecular structures conditional on a receptor binding site with deep generative models] and [Ragoza et al. Learning a continuous representation of 3d molecular structures with deep generative models].",
      "I have read authors' responses and other reviews, and do not change my score."
    ]
  },
  {
    "paper_id": "2312.10900v1",
    "submission_id": "yGKi6deX8bX",
    "submission_title": "Towards understanding retrosynthesis by energy-based models",
    "review_id": "BqgxR-fC0XX",
    "input": {
      "title": "Towards understanding retrosynthesis by energy-based models",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors present a general EBM framework to unify existing sequence-based and graph-based methods.\n- Through investigating different designs of the EMB framework, a dual variant model is proved to achieve the best performance on USPTO-50K dataset.\n- The proposed dual model also trains a forward reaction prediction model, combined with the retrosynthesis prediction, the top-k predictions can be ranked according to the overall prediction scores.\n- While previous methods rank predictions without incorporating forward-prediction scores.\n- One major concern for me is that the authors present their methods and variants with abstract formulations, while implementation details are largely ignored.\n- This makes their method difficult to understand.\n- For example, line #101, p(Xi|X1:i-1, y) is parameterized by the Transformer model h(p, q), how does h(p, q) output a logits vector for each value in vocabulary?\n- Does the formula p(Xi|X1:i-1, y) indicate the input is X1:i-1 and y, and output is Xi?\n- Line 142, could the authors add more details to explain how KL divergence is related to the duality constraints?\n- Another concern for me is the preprocessing of the USPTO-50k dataset.\n- It is found that there is a potential information leak with the dataset reported by the authors of RetroXpert.\n- Have the authors removed the atom mapping and then canonicalized the product SMILES during the inference?\n- Have the authors also run rxnmapper on testing data?\n- It is not necessary to have mapping information for testing data, the authors should remove any mapping information for testing data and then run the inference.\n- Are the authors aware of any potential information leak with the proposed method?\n- The authors claim that 'we propose a unified energy-based model (EBM) framework that integrates sequence- and graph-based models for retrosynthesis.' and I do not think this is a significant contribution.\n- EBM is a general framework and it is not surprising that EBM can be used to explain different models, especially the graph-based method GLN itself is energy-based.\n- The Transformer has been extensively explored for retrosynthesis, the authors did not clarify the difference between their different variants and existing Transformer-based methods.\n- The proposed generalized sequence models at line #216 are similar to the RetroXpert, except that the synthons are directly predicted here.\n- The ordered model at line #98 is similar to the one-stage Transformer methods such as SCROP.\n- Line #223, previous methods infer reaction center from provided atom-mapping information, which is extracted from third-party software like Indigo.\n- The authors use rxnmapper to find the atom-mapping information.\n- I do not think there is an essential difference.\n- What is the difference between formula (4) and (13)?\n- When incorporating templates, what is the difference between the proposed method and GLN except for the sequence and graph-based?\n- Could the authors also report results on USPTO-full as GLN to demonstrate the scalability?\n- Line #250, the explanation of the superscript should be moved to line #173 when it first appears.\n- Line#121, the RHS of the equation in Algorithm 2 should have a minus symbol.",
    "review_points_list": [
      "The authors present a general EBM framework to unify existing sequence-based and graph-based methods.",
      "Through investigating different designs of the EMB framework, a dual variant model is proved to achieve the best performance on USPTO-50K dataset.",
      "The proposed dual model also trains a forward reaction prediction model, combined with the retrosynthesis prediction, the top-k predictions can be ranked according to the overall prediction scores.",
      "While previous methods rank predictions without incorporating forward-prediction scores.",
      "One major concern for me is that the authors present their methods and variants with abstract formulations, while implementation details are largely ignored.",
      "This makes their method difficult to understand.",
      "For example, line #101, p(Xi|X1:i-1, y) is parameterized by the Transformer model h(p, q), how does h(p, q) output a logits vector for each value in vocabulary?",
      "Does the formula p(Xi|X1:i-1, y) indicate the input is X1:i-1 and y, and output is Xi?",
      "Line 142, could the authors add more details to explain how KL divergence is related to the duality constraints?",
      "Another concern for me is the preprocessing of the USPTO-50k dataset.",
      "It is found that there is a potential information leak with the dataset reported by the authors of RetroXpert.",
      "Have the authors removed the atom mapping and then canonicalized the product SMILES during the inference?",
      "Have the authors also run rxnmapper on testing data?",
      "It is not necessary to have mapping information for testing data, the authors should remove any mapping information for testing data and then run the inference.",
      "Are the authors aware of any potential information leak with the proposed method?",
      "The authors claim that 'we propose a unified energy-based model (EBM) framework that integrates sequence- and graph-based models for retrosynthesis.' and I do not think this is a significant contribution.",
      "EBM is a general framework and it is not surprising that EBM can be used to explain different models, especially the graph-based method GLN itself is energy-based.",
      "The Transformer has been extensively explored for retrosynthesis, the authors did not clarify the difference between their different variants and existing Transformer-based methods.",
      "The proposed generalized sequence models at line #216 are similar to the RetroXpert, except that the synthons are directly predicted here.",
      "The ordered model at line #98 is similar to the one-stage Transformer methods such as SCROP.",
      "Line #223, previous methods infer reaction center from provided atom-mapping information, which is extracted from third-party software like Indigo.",
      "The authors use rxnmapper to find the atom-mapping information.",
      "I do not think there is an essential difference.",
      "What is the difference between formula (4) and (13)?",
      "When incorporating templates, what is the difference between the proposed method and GLN except for the sequence and graph-based?",
      "Could the authors also report results on USPTO-full as GLN to demonstrate the scalability?",
      "Line #250, the explanation of the superscript should be moved to line #173 when it first appears.",
      "Line#121, the RHS of the equation in Algorithm 2 should have a minus symbol."
    ]
  },
  {
    "paper_id": "2312.10900v1",
    "submission_id": "yGKi6deX8bX",
    "submission_title": "Towards understanding retrosynthesis by energy-based models",
    "review_id": "-YOMGk1RFTA",
    "input": {
      "title": "Towards understanding retrosynthesis by energy-based models",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- As far as I know, this paper is the first attempt to describe various Retrosynthesis models in a unified manner in EBM, and it is novel in this respect.\n- The bi-directional training of sequence models (Dual in this paper) has been shown to be useful in several previous studies, as cited in the text, and is not novel in itself.\n- However, the use of sampling to stably apply the method to retrosynthesis is a good idea.\n- I find no evident errors in terms of technical content.\n- It is good that the paper carefully introduces the EBM.\n- On the other hand, since many models have to be covered in one paper, the explanation of each model is limited to a minimum.\n- I think that the current manuscript requires the reader to have some expertises in retrosynthesis.\n- In Sec. 2, various existing models are actually formulated by EBM.\n- In the current manuscript, readers have to go back and forth between pages while remembering the formulas to confirm the differences between the model equations.\n- If it is possible, it would be easier for readers if the qualitative characteristics of each formula are summarized in one table in the appendix.\n- Numerical experiments show that a new State-of-the-Art for the one-step retrosynthesis has been achieved, which strongly supports the usefulness of the generalized Dual model proposed in the paper.\n- In addition, the fact that an unsupervised atom mapping transformer can achieve great performance is good news for readers who have difficulty in handling graph data (in fact, it is not an easy task for many ones).\n- The Appendix contains many additional experiments and information to evaluate the model from various points of view, which is useful to help the reader understand it.\n- (+) EBM interpretation of several retrosynthesis models are new\n- (+) Specific formulation for dual (bi-directional) training of generalized sequence models.\n- (+) new SotA\n- (+) appendix informative\n- (-) cumbersome notations and presentations (partially inevitable because this paper covers many models: understandable)\n- Feedbacks from authors and additional experiment report solves many concerns of reviewers.\n- I believe this paper is worth publication in NeurIPS.\n- I keep my positive score.",
    "review_points_list": [
      "As far as I know, this paper is the first attempt to describe various Retrosynthesis models in a unified manner in EBM, and it is novel in this respect.",
      "The bi-directional training of sequence models (Dual in this paper) has been shown to be useful in several previous studies, as cited in the text, and is not novel in itself.",
      "However, the use of sampling to stably apply the method to retrosynthesis is a good idea.",
      "I find no evident errors in terms of technical content.",
      "It is good that the paper carefully introduces the EBM.",
      "On the other hand, since many models have to be covered in one paper, the explanation of each model is limited to a minimum.",
      "I think that the current manuscript requires the reader to have some expertises in retrosynthesis.",
      "In Sec. 2, various existing models are actually formulated by EBM.",
      "In the current manuscript, readers have to go back and forth between pages while remembering the formulas to confirm the differences between the model equations.",
      "If it is possible, it would be easier for readers if the qualitative characteristics of each formula are summarized in one table in the appendix.",
      "Numerical experiments show that a new State-of-the-Art for the one-step retrosynthesis has been achieved, which strongly supports the usefulness of the generalized Dual model proposed in the paper.",
      "In addition, the fact that an unsupervised atom mapping transformer can achieve great performance is good news for readers who have difficulty in handling graph data (in fact, it is not an easy task for many ones).",
      "The Appendix contains many additional experiments and information to evaluate the model from various points of view, which is useful to help the reader understand it.",
      "(+) EBM interpretation of several retrosynthesis models are new",
      "(+) Specific formulation for dual (bi-directional) training of generalized sequence models.",
      "(+) new SotA",
      "(+) appendix informative",
      "(-) cumbersome notations and presentations (partially inevitable because this paper covers many models: understandable)",
      "Feedbacks from authors and additional experiment report solves many concerns of reviewers.",
      "I believe this paper is worth publication in NeurIPS.",
      "I keep my positive score."
    ]
  },
  {
    "paper_id": "2312.10900v1",
    "submission_id": "yGKi6deX8bX",
    "submission_title": "Towards understanding retrosynthesis by energy-based models",
    "review_id": "AI_mdzUmXLs",
    "input": {
      "title": "Towards understanding retrosynthesis by energy-based models",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- the authors unify many recently proposed models for chemical retrosynthesis under the framework of energy based models (ebm) furthermore they propose dual training for re-ranking the predictions\n- the authors report state of the art performance\n- several works (e.g segler 2018, coley 2019) have combined retro-prediction with forward scoring for re-ranking, so the novelty of this aspect is somewhat limited\n- the presentation of the paper is somewhat dense, which mostly due to the length limit\n- overall i think the paper could eventually fit into neurips and is interesting, but there are several open questions which need to be addressed before the publication can be recommended\n- see update after rebuttal\n- the description of the reaction center assignment using schwaller's method is very brief, and in the current form unclear how it is implemented\n- reaction enters can only be assigned to full reactions (you need to have the reactants and product for that). it is unclear how this can actually work during inference\n- i am a bit skeptical how this is actually done, and i would like to see a very clear and long description on what is actually done here\n- i also had a look at the code, but could not find the data, or how this additional step is performed in the code\n- i am looking forward to discuss this in the rebuttal phase\n- this reviewer has raised their score to reflect the improvements the authors will make to the manuscript after discussion with the reviewers\n- this paper should be published in neurips",
    "review_points_list": [
      "the authors unify many recently proposed models for chemical retrosynthesis under the framework of energy based models (ebm) furthermore they propose dual training for re-ranking the predictions",
      "the authors report state of the art performance",
      "several works (e.g segler 2018, coley 2019) have combined retro-prediction with forward scoring for re-ranking, so the novelty of this aspect is somewhat limited",
      "the presentation of the paper is somewhat dense, which mostly due to the length limit",
      "overall i think the paper could eventually fit into neurips and is interesting, but there are several open questions which need to be addressed before the publication can be recommended",
      "see update after rebuttal",
      "the description of the reaction center assignment using schwaller's method is very brief, and in the current form unclear how it is implemented",
      "reaction enters can only be assigned to full reactions (you need to have the reactants and product for that). it is unclear how this can actually work during inference",
      "i am a bit skeptical how this is actually done, and i would like to see a very clear and long description on what is actually done here",
      "i also had a look at the code, but could not find the data, or how this additional step is performed in the code",
      "i am looking forward to discuss this in the rebuttal phase",
      "this reviewer has raised their score to reflect the improvements the authors will make to the manuscript after discussion with the reviewers",
      "this paper should be published in neurips"
    ]
  },
  {
    "paper_id": "2312.10900v1",
    "submission_id": "yGKi6deX8bX",
    "submission_title": "Towards understanding retrosynthesis by energy-based models",
    "review_id": "2RANBdgwI60",
    "input": {
      "title": "Towards understanding retrosynthesis by energy-based models",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The framework presented here is an elegant way to think about the complementarity between retrosynthesis and forward synthesis. It is described well.\n- This is a revised submission from ICLR 2021 where the authors were unfortunately punished for lacking comparisons to SOTA RetroXpert and GraphRetro, both of which ended up having data leakages that inflated performance by a large margin.\n- Please refer to https://github.com/uta-smile/RetroXpert for an explanation of the leak.\n- Were the sequence-based models provided with atom-mapped SMILES or unmapped SMILES?\n- Were the product and reactant SMILES strings recanonicalized after stripping atom mapping using RDKit?\n- The current SOTA top-1 accuracy when reaction type is unknown is closer to ~53% using the revised RetroXpert and GraphRetro results.\n- The high results reported in Table 2 may be explained by the fact that the 'Generalized' model implicitly uses information about the true reactants (see comment below).\n- The notation in Equation 6 is confusing to me; is $p(X|y) = \text{exp}(- E_\\theta(X,y))$ what the authors intended to convey?\n- The categorization of methods into template-based and semi-template based has an unclear role to me.\n- Is there a need to draw these strong distinctions?\n- Atom mapping can be approximated through maximum common substructure heuristics, so it is 'free' in a sense.\n- None of the datasets used for benchmarking these tools relied on manual labeling (cf. line 226).\n- This limitation of methods requiring atom mapping is overstated.\n- The setting displayed in Table 1 where the inferred reaction center is provided is an unusual choice as it does not reflect a real use case for these models in chemistry.\n- Providing the inferred reaction center (which is inferred given knowledge of the true reactants) to the 'Generalized' model makes the comparison to previously reported results invalid, but would explain the 69.9% reported in Table 2 in the absence of the data leak.\n- If the quantitative results are clarified or resolved to ensure that the comparison to prior SOTA is fair (i.e., not using an additional model or leaking data of the ground truth reactants) I believe this paper is deserving of a 7 (accept).\n- I have raised my score to 7, as the authors have addressed the (potential) information leak and atypical evaluation with the generalized model",
    "review_points_list": [
      "The framework presented here is an elegant way to think about the complementarity between retrosynthesis and forward synthesis. It is described well.",
      "This is a revised submission from ICLR 2021 where the authors were unfortunately punished for lacking comparisons to SOTA RetroXpert and GraphRetro, both of which ended up having data leakages that inflated performance by a large margin.",
      "Please refer to https://github.com/uta-smile/RetroXpert for an explanation of the leak.",
      "Were the sequence-based models provided with atom-mapped SMILES or unmapped SMILES?",
      "Were the product and reactant SMILES strings recanonicalized after stripping atom mapping using RDKit?",
      "The current SOTA top-1 accuracy when reaction type is unknown is closer to ~53% using the revised RetroXpert and GraphRetro results.",
      "The high results reported in Table 2 may be explained by the fact that the 'Generalized' model implicitly uses information about the true reactants (see comment below).",
      "The notation in Equation 6 is confusing to me; is $p(X|y) = \text{exp}(- E_\\theta(X,y))$ what the authors intended to convey?",
      "The categorization of methods into template-based and semi-template based has an unclear role to me.",
      "Is there a need to draw these strong distinctions?",
      "Atom mapping can be approximated through maximum common substructure heuristics, so it is 'free' in a sense.",
      "None of the datasets used for benchmarking these tools relied on manual labeling (cf. line 226).",
      "This limitation of methods requiring atom mapping is overstated.",
      "The setting displayed in Table 1 where the inferred reaction center is provided is an unusual choice as it does not reflect a real use case for these models in chemistry.",
      "Providing the inferred reaction center (which is inferred given knowledge of the true reactants) to the 'Generalized' model makes the comparison to previously reported results invalid, but would explain the 69.9% reported in Table 2 in the absence of the data leak.",
      "If the quantitative results are clarified or resolved to ensure that the comparison to prior SOTA is fair (i.e., not using an additional model or leaking data of the ground truth reactants) I believe this paper is deserving of a 7 (accept).",
      "I have raised my score to 7, as the authors have addressed the (potential) information leak and atypical evaluation with the generalized model"
    ]
  },
  {
    "paper_id": "2507.11274v2",
    "submission_id": "zsq86HNvXr6",
    "submission_title": "Last iterate convergence of SGD for Least-Squares in the Interpolation regime.",
    "review_id": "PG5zJQOjvY",
    "input": {
      "title": "Last iterate convergence of SGD for Least-Squares in the Interpolation regime.",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I found the manuscript to be clearly written and technically sound. However,\n- There are still a few points need further clarification:\n- One important setting in this paper is that the covariance operator $H = \\mathbb{E}[X \\times X]$ is not positive definite, namely the least square is not strongly convex.\n- However, in Assumption 1, it assumes that $H \\succeq \\frac{\\mathbb{E}[\\|X\\|^2 XX^T]}{R}$. Does it mean that the covariance operator is actually positive definite? Same question for Assumption 3.\n- In the discussion after Assumption 4, you have the condition $\\lambda_{\\min} > 0$. I think this is also equivalent to assuming the problem is strongly convex.\n- Based on the discussion above, I think although there is some novelty in the problem setting and the corresponding theoretical result.\n- The contribution may not be enough provided there are already some result about the convergence of last iterate from the SGD on strongly convex functions.",
    "review_points_list": [
      "I found the manuscript to be clearly written and technically sound. However,",
      "There are still a few points need further clarification:",
      "One important setting in this paper is that the covariance operator $H = \\mathbb{E}[X \\times X]$ is not positive definite, namely the least square is not strongly convex.",
      "However, in Assumption 1, it assumes that $H \\succeq \\frac{\\mathbb{E}[\\|X\\|^2 XX^T]}{R}$. Does it mean that the covariance operator is actually positive definite? Same question for Assumption 3.",
      "In the discussion after Assumption 4, you have the condition $\\lambda_{\\min} > 0$. I think this is also equivalent to assuming the problem is strongly convex.",
      "Based on the discussion above, I think although there is some novelty in the problem setting and the corresponding theoretical result.",
      "The contribution may not be enough provided there are already some result about the convergence of last iterate from the SGD on strongly convex functions."
    ]
  },
  {
    "paper_id": "2507.11274v2",
    "submission_id": "zsq86HNvXr6",
    "submission_title": "Last iterate convergence of SGD for Least-Squares in the Interpolation regime.",
    "review_id": "517A9zMpndW",
    "input": {
      "title": "Last iterate convergence of SGD for Least-Squares in the Interpolation regime.",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I am not very well familiar with the literature on the infinite-dimensional least-squares problem.\n- My background is mainly in the field of convex optimization, so I will make the comments mainly from this perspective.\n- The assumptions seem strange and hardly interpretable\n- Drawing connections to general convex stochastic optimization would be helpful for non-experts in this area.\n- The paper seems targeted at a very narrow audience.\n- What is the purpose of Assumption 2?\n- If the noiseless problem statement includes the existence of \u03b8_* \u2208 \u210b such that <\u03b8_*, x> = y.\n- How can you use the H^(-1) in Assumption 3?\n- Further, if on page 3 (line 131) it is said that \u201c$H$ is no longer invertible\u201d?\n- The paper is clearly written\n- The \u201crelated work\u201d section seems complete.\n- Excessive details ultimately make it harder to get the broad picture, distinguish the paper's contributions, and compare it to the previous results (especially in terms of technical novelty).\n- To be honest, I do not quite get the point of considering the infinite-dimensional case.\n- The motivation presented by the authors does not seem convincing to me.\n- It is hard to see if the results are valuable for the machine learning community.\n- From the practical viewpoint, the paper seems quite irrelevant.\n- I can not see any helpful insights for practitioners.\n- The synthetic experiments are very basic\n- Although this is clearly not the main focus of the work.",
    "review_points_list": [
      "I am not very well familiar with the literature on the infinite-dimensional least-squares problem.",
      "My background is mainly in the field of convex optimization, so I will make the comments mainly from this perspective.",
      "The assumptions seem strange and hardly interpretable",
      "Drawing connections to general convex stochastic optimization would be helpful for non-experts in this area.",
      "The paper seems targeted at a very narrow audience.",
      "What is the purpose of Assumption 2?",
      "If the noiseless problem statement includes the existence of \u03b8_* \u2208 \u210b such that <\u03b8_*, x> = y.",
      "How can you use the H^(-1) in Assumption 3?",
      "Further, if on page 3 (line 131) it is said that \u201c$H$ is no longer invertible\u201d?",
      "The paper is clearly written",
      "The \u201crelated work\u201d section seems complete.",
      "Excessive details ultimately make it harder to get the broad picture, distinguish the paper's contributions, and compare it to the previous results (especially in terms of technical novelty).",
      "To be honest, I do not quite get the point of considering the infinite-dimensional case.",
      "The motivation presented by the authors does not seem convincing to me.",
      "It is hard to see if the results are valuable for the machine learning community.",
      "From the practical viewpoint, the paper seems quite irrelevant.",
      "I can not see any helpful insights for practitioners.",
      "The synthetic experiments are very basic",
      "Although this is clearly not the main focus of the work."
    ]
  },
  {
    "paper_id": "2507.11274v2",
    "submission_id": "zsq86HNvXr6",
    "submission_title": "Last iterate convergence of SGD for Least-Squares in the Interpolation regime.",
    "review_id": "9fURmmRF8u7",
    "input": {
      "title": "Last iterate convergence of SGD for Least-Squares in the Interpolation regime.",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- + The presented bounds for the last iterates of SGD are the first results that can be applied in the overparameterized setting.\n- + Some of the presented bounds are (nearly) tight and (partly) solve an open question for the rate of SGD last iterate.\n- + Lemma 5 is interesting in its own for bounding the SGD (bias) iterates.\n- + Overall the paper is organized well, but the writing could be improved here and there.\n- - The considered least square problems are noiseless, i.e., the variance error bound is not considered.\n- - The presented bound, e.g., Thm1, requires the true parameter to have a finite \u21132-norm (attainable case), which\n- - The writing could be improved in several places.\n- The paper/section/paragraph title capitalization style should be made consistent.\n- l.7. two folds.\n- l.25. This sentence is quite confusing. Note that a noisy model could also interpolate.\n- ... a decreasing sequence in terms of loss\n- the following two.\n- Everything is known for noisy setting (which covers noiseless setting)? Perhaps you mean the finite-dim setting?\n- This is too confusing... Lots of papers listed in paragraph l.76 explicitly or implicitly discussed how to control SGD last iterate.\n- the claim here is too exaggerative!\n- related works section is quite messy.\n- Perhaps the authors could discuss papers for offline/multi-pass SGD and online/one-pass SGD separately?\n- There are big paper overlaps in the three paragraphs & could find better ways to organize.\n- an arbitrarily...\n- Not only in large dim case, but in any case.\n- a 4th...\n- at least some results in [10] only assume eq (4) instead of something stronger.\n- $C_{ln}$ is not defined. I guess it refers to left-hand side of the above inequality?\n- an eigenvalue...\n- remove the empty space before ?",
    "review_points_list": [
      "+ The presented bounds for the last iterates of SGD are the first results that can be applied in the overparameterized setting.",
      "+ Some of the presented bounds are (nearly) tight and (partly) solve an open question for the rate of SGD last iterate.",
      "+ Lemma 5 is interesting in its own for bounding the SGD (bias) iterates.",
      "+ Overall the paper is organized well, but the writing could be improved here and there.",
      "- The considered least square problems are noiseless, i.e., the variance error bound is not considered.",
      "- The presented bound, e.g., Thm1, requires the true parameter to have a finite \u21132-norm (attainable case), which",
      "- The writing could be improved in several places.",
      "The paper/section/paragraph title capitalization style should be made consistent.",
      "l.7. two folds.",
      "l.25. This sentence is quite confusing. Note that a noisy model could also interpolate.",
      "... a decreasing sequence in terms of loss",
      "the following two.",
      "Everything is known for noisy setting (which covers noiseless setting)? Perhaps you mean the finite-dim setting?",
      "This is too confusing... Lots of papers listed in paragraph l.76 explicitly or implicitly discussed how to control SGD last iterate.",
      "the claim here is too exaggerative!",
      "related works section is quite messy.",
      "Perhaps the authors could discuss papers for offline/multi-pass SGD and online/one-pass SGD separately?",
      "There are big paper overlaps in the three paragraphs & could find better ways to organize.",
      "an arbitrarily...",
      "Not only in large dim case, but in any case.",
      "a 4th...",
      "at least some results in [10] only assume eq (4) instead of something stronger.",
      "$C_{ln}$ is not defined. I guess it refers to left-hand side of the above inequality?",
      "an eigenvalue...",
      "remove the empty space before ?"
    ]
  },
  {
    "paper_id": "2402.00957v4",
    "submission_id": "ypj3xKoRfmr",
    "submission_title": "Credal Self-Supervised Learning",
    "review_id": "IrG624hJxkj",
    "input": {
      "title": "Credal Self-Supervised Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The use of such credal probability and so-called \"possibility distributions\" seems rare in machine learning.\n- The proposed method for learning from credal labels is based on the minimal value of the KL-divergence between probability in the set and the prediction, which originated from existing work (optimistic superset loss, infimum loss).\n- The author then used credal labels in self-supervised learning with FixMatch.\n- To the best of my knowledge, although its components are from existing work (credal label, infimum loss, FixMatch), the application of learning from credal labels in self-supervised learning is new.\n- My major concern is about the usefulness of the concept of credal sets in this setting.\n- Indeed, hard labels may cause problems in neural network training.\n- The author suggested that soft labels, probability distributions, are still not enough.\n- However, the evidence is not convincing enough.\n- In traditional statistical learning, we want to learn a decision function that outputs labels, where both training data and prediction are deterministic (\"hard label\").\n- Since it's NP-hard to optimize it, we can resort to probabilistic models that output probabilities of labels, where the training data is still deterministic.\n- It is possible because the expectation over the empirical distribution converges to the expectation over the true distribution as the size of the sample increases.\n- There are a lot of attempts to let the model provide more uncertainty measures using, for example, Bayesian methods.\n- The supervision may be still deterministic.\n- The direction of this paper is different from the ones above.\n- Here, the uncertainty of the supervision is increased, from labels to probabilities of labels, to sets of probabilities of labels.\n- Meanwhile, if I understand correctly, the output is still a single-point probability.\n- My concern is, is the same effect can be achieved by, for example, regularizations of the weight or the output?\n- Another straightforward approach would be using distributions over distributions of categorical labels, such as Dirichlet distribution, as the format of supervision.\n- What's the advantage of the proposed method using credal labels?\n- Another issue is that this method is verified solely empirically.\n- Theoretical characterization is limited or from existing work.",
    "review_points_list": [
      "The use of such credal probability and so-called \"possibility distributions\" seems rare in machine learning.",
      "The proposed method for learning from credal labels is based on the minimal value of the KL-divergence between probability in the set and the prediction, which originated from existing work (optimistic superset loss, infimum loss).",
      "The author then used credal labels in self-supervised learning with FixMatch.",
      "To the best of my knowledge, although its components are from existing work (credal label, infimum loss, FixMatch), the application of learning from credal labels in self-supervised learning is new.",
      "My major concern is about the usefulness of the concept of credal sets in this setting.",
      "Indeed, hard labels may cause problems in neural network training.",
      "The author suggested that soft labels, probability distributions, are still not enough.",
      "However, the evidence is not convincing enough.",
      "In traditional statistical learning, we want to learn a decision function that outputs labels, where both training data and prediction are deterministic (\"hard label\").",
      "Since it's NP-hard to optimize it, we can resort to probabilistic models that output probabilities of labels, where the training data is still deterministic.",
      "It is possible because the expectation over the empirical distribution converges to the expectation over the true distribution as the size of the sample increases.",
      "There are a lot of attempts to let the model provide more uncertainty measures using, for example, Bayesian methods.",
      "The supervision may be still deterministic.",
      "The direction of this paper is different from the ones above.",
      "Here, the uncertainty of the supervision is increased, from labels to probabilities of labels, to sets of probabilities of labels.",
      "Meanwhile, if I understand correctly, the output is still a single-point probability.",
      "My concern is, is the same effect can be achieved by, for example, regularizations of the weight or the output?",
      "Another straightforward approach would be using distributions over distributions of categorical labels, such as Dirichlet distribution, as the format of supervision.",
      "What's the advantage of the proposed method using credal labels?",
      "Another issue is that this method is verified solely empirically.",
      "Theoretical characterization is limited or from existing work."
    ]
  },
  {
    "paper_id": "2402.00957v4",
    "submission_id": "ypj3xKoRfmr",
    "submission_title": "Credal Self-Supervised Learning",
    "review_id": "0v4n-ONPLFB",
    "input": {
      "title": "Credal Self-Supervised Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The central idea is clear, and the experiments demonstrate improvements over the SOTA method Fixmatch.\n- The techniques seem like empirical hacks and lacks theoretical support.\n- Can the authors demonstrate the advantage of the proposed method on a simple data generative model?\n- No ablations on the choice of $\beta_i$. Equation 6 seems especially ad hoc and requires justification.\n- An important missing baseline is 'Sinkhorn Label Allocation: Semi-Supervised Classification via Annealed Self-Training' by Tai et al.\n- It is not clear to me why distributional matching doesn't work, whereas credal self-training does.",
    "review_points_list": [
      "The central idea is clear, and the experiments demonstrate improvements over the SOTA method Fixmatch.",
      "The techniques seem like empirical hacks and lacks theoretical support.",
      "Can the authors demonstrate the advantage of the proposed method on a simple data generative model?",
      "No ablations on the choice of $\beta_i$. Equation 6 seems especially ad hoc and requires justification.",
      "An important missing baseline is 'Sinkhorn Label Allocation: Semi-Supervised Classification via Annealed Self-Training' by Tai et al.",
      "It is not clear to me why distributional matching doesn't work, whereas credal self-training does."
    ]
  },
  {
    "paper_id": "2402.00957v4",
    "submission_id": "ypj3xKoRfmr",
    "submission_title": "Credal Self-Supervised Learning",
    "review_id": "6yGyW3uVUYx",
    "input": {
      "title": "Credal Self-Supervised Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well-written and technically sound.\n- The novelty of the paper is enough.\n- Although the improvements in accuracy are not impressive, the contribution can be of interest to a wide range of NeurIPS participants.\n- The ablation study could include an analysis of the importance of the weighting in Eq (6) to the final results.\n- What would be the results with the straightforward alphas?",
    "review_points_list": [
      "The paper is well-written and technically sound.",
      "The novelty of the paper is enough.",
      "Although the improvements in accuracy are not impressive, the contribution can be of interest to a wide range of NeurIPS participants.",
      "The ablation study could include an analysis of the importance of the weighting in Eq (6) to the final results.",
      "What would be the results with the straightforward alphas?"
    ]
  },
  {
    "paper_id": "2110.06267v1",
    "submission_id": "x00mCNwbH8Q",
    "submission_title": "Twice regularized MDPs and the equivalence between robustness and regularization",
    "review_id": "syz8GOUDlJz",
    "input": {
      "title": "Twice regularized MDPs and the equivalence between robustness and regularization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- In lines 58-64, many quantities like v, \\mathcal{U}, \\mu etc. start appearing from no where. They were not defined before. This section needs reorganization making sure that everything is defined before referred or used.\n- It is possible to solve the reward robust MDP as a linear programming problem. The paper presents a policy gradient algorithm for the same purpose. How do they compare?\n- The theories presented in the paper look good from a high level. Though a rigorous verification of the correctness was not possible due to time constraint.\n- It is understandable that the paper is mostly theoretical, but one big weak point is not having any empirical analysis of the methods. How about having an empirical evaluation for robust and proposed regularized methods, possibly with different RL regularizers?",
    "review_points_list": [
      "In lines 58-64, many quantities like v, \\mathcal{U}, \\mu etc. start appearing from no where. They were not defined before. This section needs reorganization making sure that everything is defined before referred or used.",
      "It is possible to solve the reward robust MDP as a linear programming problem. The paper presents a policy gradient algorithm for the same purpose. How do they compare?",
      "The theories presented in the paper look good from a high level. Though a rigorous verification of the correctness was not possible due to time constraint.",
      "It is understandable that the paper is mostly theoretical, but one big weak point is not having any empirical analysis of the methods. How about having an empirical evaluation for robust and proposed regularized methods, possibly with different RL regularizers?"
    ]
  },
  {
    "paper_id": "2110.06267v1",
    "submission_id": "x00mCNwbH8Q",
    "submission_title": "Twice regularized MDPs and the equivalence between robustness and regularization",
    "review_id": "uZC2TpeS_u1",
    "input": {
      "title": "Twice regularized MDPs and the equivalence between robustness and regularization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Strengths:\n- The paper is well-contained. I am not familiar with Robust RL and even less familiar with work in theoretical RL. Still, I had no difficulty reading the paper and understanding its central claims/contributions.  Kudos to the authors.\n- I think the theoretical contributions are substantial and useful - connecting regularized MDPs to robust MDPs, extending the approach for uncertain dynamics function, etc. Though I should highlight that robustness/theory is not my area of expertise, so I might be over-estimating this contribution.\n- Questions / suggestions for improvement:\n- 1. Line 170 mentions a nominal model. How do we get access to this model? Is it part of the problem formulation, or is it learned using the sampled trajectories? If it is learned, how do we ensure that the nominal model is correct?\n- 2. The paper mentioned that one of the limitations of existing approaches is that they are computationally demanding. I may have missed it, but it seems that the paper did not include any evidence for the twin regularized MDPs to be computationally more efficient.\n- Line 177 mentions that 'policy iteration on reward-robust MDPs has the same convergence rate as regularized MDPs, which in turn is the same as standard MDPs.' Still, it would be helpful to include both the convergence rates and error bounds in the main paper (for both the proposed approach and the standard robustness-based approaches) to provide a complete comparison.\n- For example, regularized MDPs are a particular case of robust MDPs. So other robustness methods may have a slower convergence rate but achieve better performance.\n- The paper can be improved by including these tradeoffs explicitly.\n- 3. Missing empirical evidence - I understand that this paper is focusing on theoretical contributions.\n- It may strengthen the paper to include some experimental results as well (even if it is on simplistic grid worlds).",
    "review_points_list": [
      "Strengths:",
      "The paper is well-contained. I am not familiar with Robust RL and even less familiar with work in theoretical RL. Still, I had no difficulty reading the paper and understanding its central claims/contributions.  Kudos to the authors.",
      "I think the theoretical contributions are substantial and useful - connecting regularized MDPs to robust MDPs, extending the approach for uncertain dynamics function, etc. Though I should highlight that robustness/theory is not my area of expertise, so I might be over-estimating this contribution.",
      "Questions / suggestions for improvement:",
      "1. Line 170 mentions a nominal model. How do we get access to this model? Is it part of the problem formulation, or is it learned using the sampled trajectories? If it is learned, how do we ensure that the nominal model is correct?",
      "2. The paper mentioned that one of the limitations of existing approaches is that they are computationally demanding. I may have missed it, but it seems that the paper did not include any evidence for the twin regularized MDPs to be computationally more efficient.",
      "Line 177 mentions that 'policy iteration on reward-robust MDPs has the same convergence rate as regularized MDPs, which in turn is the same as standard MDPs.' Still, it would be helpful to include both the convergence rates and error bounds in the main paper (for both the proposed approach and the standard robustness-based approaches) to provide a complete comparison.",
      "For example, regularized MDPs are a particular case of robust MDPs. So other robustness methods may have a slower convergence rate but achieve better performance.",
      "The paper can be improved by including these tradeoffs explicitly.",
      "3. Missing empirical evidence - I understand that this paper is focusing on theoretical contributions.",
      "It may strengthen the paper to include some experimental results as well (even if it is on simplistic grid worlds)."
    ]
  },
  {
    "paper_id": "2110.06267v1",
    "submission_id": "x00mCNwbH8Q",
    "submission_title": "Twice regularized MDPs and the equivalence between robustness and regularization",
    "review_id": "KKtcVKvvG1K",
    "input": {
      "title": "Twice regularized MDPs and the equivalence between robustness and regularization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I am not familiar with the literature in this area, but the paper claims all 3 main results as original.\n- Related work is covered thoroughly.\n- I don't have the mathematical background to verify the analysis.\n- The statements of the results are precise and seem to include all required assumptions.\n- The work addresses both the narrower case of reward-robust MDPs as well as the case of general robust MDPs, and provides both a construction of the equivalent regularized problems and a solution algorithm.\n- The paper is clearly-written but is fairly dense.\n- Mathematical notation is precise.\n- Each of the main results seems to be significant on its own.\n- The connection between regularization and robustness seems like it will be fertile for further analyses.\n- The MPI algorithm for R^2 MDPs is significant in that it establishes that R^2 MDPs with appropriate assumptions have the same complexity as ordinary MDPs, making them a tractable subset of robust MDPs.",
    "review_points_list": [
      "I am not familiar with the literature in this area, but the paper claims all 3 main results as original.",
      "Related work is covered thoroughly.",
      "I don't have the mathematical background to verify the analysis.",
      "The statements of the results are precise and seem to include all required assumptions.",
      "The work addresses both the narrower case of reward-robust MDPs as well as the case of general robust MDPs, and provides both a construction of the equivalent regularized problems and a solution algorithm.",
      "The paper is clearly-written but is fairly dense.",
      "Mathematical notation is precise.",
      "Each of the main results seems to be significant on its own.",
      "The connection between regularization and robustness seems like it will be fertile for further analyses.",
      "The MPI algorithm for R^2 MDPs is significant in that it establishes that R^2 MDPs with appropriate assumptions have the same complexity as ordinary MDPs, making them a tractable subset of robust MDPs."
    ]
  },
  {
    "paper_id": "2205.14109v3",
    "submission_id": "v_4XcXsAZUn",
    "submission_title": "Robustness of Graph Neural Networks at Scale",
    "review_id": "M9nCcpvgMoI",
    "input": {
      "title": "Robustness of Graph Neural Networks at Scale",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Compared to existing robustness studies that mostly deal with smaller graphs, this paper provides valuable insights on robustness of large-scale graphs.\n- The proposed attack methods can attack entire 2 million nodes at once.\n- The defense method can reduce the strength of attacks on large and even small graphs, while requiring minimal complexities.\n- This paper is well written and well polished, and especially most of the claims are supported with empirical results.\n- A theoretical definition of the global optimum of surrogate loss, and the proposed loss function under this theoretical ground are technically strong.\n- The proposed surrogate loss can be further used for general purposes, since it shows good performances on even small graphs.\n- The authors provide a well-structured source code.\n- While the authors claim that the proposed Masked Cross Entropy and tanh Margin losses improve the strength of attacks more on larger graph cases, the empirical results do not support this.\n- The results of surrogate loss in Figure 6 are obtained by the smallest graph in the paper.\n- Additional experiments in the supplementary file (Figure 15) show that existing losses, such as NC and elu Margin, are more effective compared to the proposed losses on some datasets (CoraML and Citeseer with FGSM and arXiv ML with PR-GCN).\n- Regarding defense, while the proposed Soft Median coupled with PPRGo clearly shows good robustness performances, the Soft Median coupled with GDC is generally weak compared to the baseline, Soft Medoid coupled with GDC.\n- I agree with effective scalability of the authors' method, but it would be better to clearly discuss the result and reason of degenerating performances of authors' one.\n- I am curious about why the authors do not experimentally compare their method against the existing large-scale adversarial attack method [1].\n- While Li et al. [1] only consider local attacks, it could be directly compared with the authors' local adversarial attack method in the Robustness w.r.t. local attacks paragraph of Section 5.\n- I am confused about the relationship between density, perturbation, and margin in section 2 associated with figure 2.\n- It would be better to have few explicit sentences for explaining the intrinsic meaning of the figure.\n- In figure 3 (b), the block size is most small for 1.0E+07. Is it correct?\n- It is hard to understand equation 6. There are no details on \u03c0 function, encoder, and combination of PPRGo.\n- It would be better to more formally explain it in the supplementary file, if there is a space issue.\n- In figure 8, the caption indicates (d), (e), and (f), while the actual figure only includes two sub-figures: (a) and (b).",
    "review_points_list": [
      "Compared to existing robustness studies that mostly deal with smaller graphs, this paper provides valuable insights on robustness of large-scale graphs.",
      "The proposed attack methods can attack entire 2 million nodes at once.",
      "The defense method can reduce the strength of attacks on large and even small graphs, while requiring minimal complexities.",
      "This paper is well written and well polished, and especially most of the claims are supported with empirical results.",
      "A theoretical definition of the global optimum of surrogate loss, and the proposed loss function under this theoretical ground are technically strong.",
      "The proposed surrogate loss can be further used for general purposes, since it shows good performances on even small graphs.",
      "The authors provide a well-structured source code.",
      "While the authors claim that the proposed Masked Cross Entropy and tanh Margin losses improve the strength of attacks more on larger graph cases, the empirical results do not support this.",
      "The results of surrogate loss in Figure 6 are obtained by the smallest graph in the paper.",
      "Additional experiments in the supplementary file (Figure 15) show that existing losses, such as NC and elu Margin, are more effective compared to the proposed losses on some datasets (CoraML and Citeseer with FGSM and arXiv ML with PR-GCN).",
      "Regarding defense, while the proposed Soft Median coupled with PPRGo clearly shows good robustness performances, the Soft Median coupled with GDC is generally weak compared to the baseline, Soft Medoid coupled with GDC.",
      "I agree with effective scalability of the authors' method, but it would be better to clearly discuss the result and reason of degenerating performances of authors' one.",
      "I am curious about why the authors do not experimentally compare their method against the existing large-scale adversarial attack method [1].",
      "While Li et al. [1] only consider local attacks, it could be directly compared with the authors' local adversarial attack method in the Robustness w.r.t. local attacks paragraph of Section 5.",
      "I am confused about the relationship between density, perturbation, and margin in section 2 associated with figure 2.",
      "It would be better to have few explicit sentences for explaining the intrinsic meaning of the figure.",
      "In figure 3 (b), the block size is most small for 1.0E+07. Is it correct?",
      "It is hard to understand equation 6. There are no details on \u03c0 function, encoder, and combination of PPRGo.",
      "It would be better to more formally explain it in the supplementary file, if there is a space issue.",
      "In figure 8, the caption indicates (d), (e), and (f), while the actual figure only includes two sub-figures: (a) and (b)."
    ]
  },
  {
    "paper_id": "2205.14109v3",
    "submission_id": "v_4XcXsAZUn",
    "submission_title": "Robustness of Graph Neural Networks at Scale",
    "review_id": "1kQpjQay5_Q",
    "input": {
      "title": "Robustness of Graph Neural Networks at Scale",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Threat model: The paper studies white-box attacks, which is not practical from my perspective.\n- From Figure 2, both tanh margin and cross entropy spend a lot of budgets on misclassified nodes. What\u2019s the takeaway of Figure 2?\n- Is Assumption 1 satisfied when performing global attacks, as they aim to reduce the performance of all nodes and could largely perturb the graph (given enough budget) which involves a substantial number of nodes?\n- What\u2019s the key difference between the proposed PR-BCD attack in Algorithm 1 and the optimization-based attack in [36]?\n- PR-BCD needs to sort the probability mass before removing entries with the lowest probability mass. Sorting a huge vector is time-consuming. How could this sorting be scalable to huge graphs?\n- How is the PPR matrix calculated in huge graphs, as it needs to compute the inverse of a huge matrix?\n- What\u2019s $\\\rho(v)_u$ in Eqn (6)?\n- My main concern is that the proposed soft median based defense is empirical and does not have theoretical guarantees. As the paper mainly focuses \u201crobustness\u201d of GNNs, I doubt that empirical defenses provide a false sense of robustness.\n- The term \u201cperturbed accuracy\u201d makes me confused.\n- No global attack results on Papers 100M.\n- In conclusion, our novel Soft Median which is differentiable as well as provably robust. => This is inaccurate.",
    "review_points_list": [
      "Threat model: The paper studies white-box attacks, which is not practical from my perspective.",
      "From Figure 2, both tanh margin and cross entropy spend a lot of budgets on misclassified nodes. What\u2019s the takeaway of Figure 2?",
      "Is Assumption 1 satisfied when performing global attacks, as they aim to reduce the performance of all nodes and could largely perturb the graph (given enough budget) which involves a substantial number of nodes?",
      "What\u2019s the key difference between the proposed PR-BCD attack in Algorithm 1 and the optimization-based attack in [36]?",
      "PR-BCD needs to sort the probability mass before removing entries with the lowest probability mass. Sorting a huge vector is time-consuming. How could this sorting be scalable to huge graphs?",
      "How is the PPR matrix calculated in huge graphs, as it needs to compute the inverse of a huge matrix?",
      "What\u2019s $\\\rho(v)_u$ in Eqn (6)?",
      "My main concern is that the proposed soft median based defense is empirical and does not have theoretical guarantees. As the paper mainly focuses \u201crobustness\u201d of GNNs, I doubt that empirical defenses provide a false sense of robustness.",
      "The term \u201cperturbed accuracy\u201d makes me confused.",
      "No global attack results on Papers 100M.",
      "In conclusion, our novel Soft Median which is differentiable as well as provably robust. => This is inaccurate."
    ]
  },
  {
    "paper_id": "2205.14109v3",
    "submission_id": "v_4XcXsAZUn",
    "submission_title": "Robustness of Graph Neural Networks at Scale",
    "review_id": "FzjO7HyGbV",
    "input": {
      "title": "Robustness of Graph Neural Networks at Scale",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- In this paper, the authors tackle the problem of GNN robustness in a large graph, which is important for GNN robustness but not addressed so far.\n- This paper first points out the problem of existing attacks with their weakness in a large graph and suggests a theoretically guaranteed method with improved surrogate loss and scalable optimization method.\n- This paper also provides the cue of scalable defense for a large graph.\n- The method sound convincing and the theoretical foundation seems solid.\n- There are diverse comprehensive analyses that are helpful to understand the claim of the paper.\n- The experimental setup covers the diverse sizes of graphs ranging from 2.8k to 111M against various attack and defense methods.\n- In experiments, they show that their attack and defenses are reasonably fast and require much less memory that can cover sufficiently large graphs like Papers 100M.\n- In quantitative analysis, they show that the proposed attack significantly drops the performance against other margin losses in Figure 6 and Table 2 and the proposed Soft Median defense resists the attacks much better than the baselines.\n- The problem and method are generally well-motivated and clear.\n- However, the overall presentation is disappointing.\n- In methodology sections (Section 2,3,4), subsections are rarely used and most topics are divided by only paragraph and bold title.\n- It makes the paper looks fuzzy.\n- There is no abstractive description of the overall methods.\n- I suggest authors add the comprehensive figure to outline the entire method to help authors better understand the overall methods.\n- The caption of Figure 7 is insufficient and Figure 7 is not referenced in the main paper.\n- I think most of the presentation issues are due to the page limit of the main paper.\n- I hope it will be more clarified in revision.",
    "review_points_list": [
      "In this paper, the authors tackle the problem of GNN robustness in a large graph, which is important for GNN robustness but not addressed so far.",
      "This paper first points out the problem of existing attacks with their weakness in a large graph and suggests a theoretically guaranteed method with improved surrogate loss and scalable optimization method.",
      "This paper also provides the cue of scalable defense for a large graph.",
      "The method sound convincing and the theoretical foundation seems solid.",
      "There are diverse comprehensive analyses that are helpful to understand the claim of the paper.",
      "The experimental setup covers the diverse sizes of graphs ranging from 2.8k to 111M against various attack and defense methods.",
      "In experiments, they show that their attack and defenses are reasonably fast and require much less memory that can cover sufficiently large graphs like Papers 100M.",
      "In quantitative analysis, they show that the proposed attack significantly drops the performance against other margin losses in Figure 6 and Table 2 and the proposed Soft Median defense resists the attacks much better than the baselines.",
      "The problem and method are generally well-motivated and clear.",
      "However, the overall presentation is disappointing.",
      "In methodology sections (Section 2,3,4), subsections are rarely used and most topics are divided by only paragraph and bold title.",
      "It makes the paper looks fuzzy.",
      "There is no abstractive description of the overall methods.",
      "I suggest authors add the comprehensive figure to outline the entire method to help authors better understand the overall methods.",
      "The caption of Figure 7 is insufficient and Figure 7 is not referenced in the main paper.",
      "I think most of the presentation issues are due to the page limit of the main paper.",
      "I hope it will be more clarified in revision."
    ]
  },
  {
    "paper_id": "2205.14109v3",
    "submission_id": "v_4XcXsAZUn",
    "submission_title": "Robustness of Graph Neural Networks at Scale",
    "review_id": "eOUYqvyuU7V",
    "input": {
      "title": "Robustness of Graph Neural Networks at Scale",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Overall, this paper is clearly-written.\n- As far as I know, adversarial attack and defense for large-scale GNNs have not been well-explored and this is an interesting topic.\n- I find the analysis of the surrogate losses very interesting.\n- The insight that the loss should guide the attack to focus on the correctly-classified boundary points could be helpful for the development of future attack methods.\n- This paper has an extensive empirical evaluation.\n- The proposed attack is a white-box attack assuming almost everything (labels, gradients, etc) is available to the attacker.\n- A white-box attack under the large-scale setup is rarely practical, which makes the proposed attack method less interesting.\n- The assumption 2 is very unrealistic.\n- The budget needed to flip the prediction of a node depends on the node features and its neighborhoods.\n- Assumption 2 (and the proof of Proposition 1) assumes a uniform function g across all nodes.\n- This is impossible, even approximately.\n- With that said, while the significance of Proposition 1 is weakened due to the unrealistic assumption, the two properties defined in Definition 1 are still intuitively desirable.\n- A table summarizing the theoretical computation complexity of the proposed methods and previous methods will be helpful.\n- The study of surrogate losses does not seem to be relevant to the scale of GNNs.\n- Is there anything that I missed?\n- Could you elaborate on the reasons why MCE does not work well for PGD?\n- Property (II) and property (B) essentially indicate a 'diminishing-return' for the decrease of loss when the margin grows larger.\n- This seems to align with the results in [22].\n- However, in A.2 the authors state that they mismatch.\n- Could you elaborate more on the reasons?\n- The authors mention in A.2 that 'our analysis suggests that the CW loss should be effective once the budget is large enough', but I did not find the relevant analysis.\n- Could you point out where it is located?\n- The naming of 'budget-aware' loss in Definition 1 is a little bit confusing, since the definition itself does not involve the budget.\n- Losses of this type favor correctly-classified boundary points, and has a diminishing slope when going further from the boundary.\n- A more straightforward name such as 'diminishing-slope' loss would be more informative.\n- A typo: line 124, the subscript n should be i.",
    "review_points_list": [
      "Overall, this paper is clearly-written.",
      "As far as I know, adversarial attack and defense for large-scale GNNs have not been well-explored and this is an interesting topic.",
      "I find the analysis of the surrogate losses very interesting.",
      "The insight that the loss should guide the attack to focus on the correctly-classified boundary points could be helpful for the development of future attack methods.",
      "This paper has an extensive empirical evaluation.",
      "The proposed attack is a white-box attack assuming almost everything (labels, gradients, etc) is available to the attacker.",
      "A white-box attack under the large-scale setup is rarely practical, which makes the proposed attack method less interesting.",
      "The assumption 2 is very unrealistic.",
      "The budget needed to flip the prediction of a node depends on the node features and its neighborhoods.",
      "Assumption 2 (and the proof of Proposition 1) assumes a uniform function g across all nodes.",
      "This is impossible, even approximately.",
      "With that said, while the significance of Proposition 1 is weakened due to the unrealistic assumption, the two properties defined in Definition 1 are still intuitively desirable.",
      "A table summarizing the theoretical computation complexity of the proposed methods and previous methods will be helpful.",
      "The study of surrogate losses does not seem to be relevant to the scale of GNNs.",
      "Is there anything that I missed?",
      "Could you elaborate on the reasons why MCE does not work well for PGD?",
      "Property (II) and property (B) essentially indicate a 'diminishing-return' for the decrease of loss when the margin grows larger.",
      "This seems to align with the results in [22].",
      "However, in A.2 the authors state that they mismatch.",
      "Could you elaborate more on the reasons?",
      "The authors mention in A.2 that 'our analysis suggests that the CW loss should be effective once the budget is large enough', but I did not find the relevant analysis.",
      "Could you point out where it is located?",
      "The naming of 'budget-aware' loss in Definition 1 is a little bit confusing, since the definition itself does not involve the budget.",
      "Losses of this type favor correctly-classified boundary points, and has a diminishing slope when going further from the boundary.",
      "A more straightforward name such as 'diminishing-slope' loss would be more informative.",
      "A typo: line 124, the subscript n should be i."
    ]
  },
  {
    "paper_id": "2205.14109v3",
    "submission_id": "v_4XcXsAZUn",
    "submission_title": "Robustness of Graph Neural Networks at Scale",
    "review_id": "K4OIl3rnnkb",
    "input": {
      "title": "Robustness of Graph Neural Networks at Scale",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The major focus of this paper is to study the adversarial robustness of GNNs on a larger scale. This is important since most of the existing attack and defense methods for GNNs are limited to very small data.\n- The instigation and discussion on the ineffective of CE loss in the global attack of GNNs are interesting. It points out that attacking methods based on CE loss might waste attacking budgets, which provides useful insight for the development of stronger attacking methods.\n- The proposed scalable attacking method seems quite efficient and experiments support its effective and efficiency.\n- The author doesn't provide a sufficient explanation for the proposed tanh Margin loss so that this loss design is unclear.\n- Moreover, it is unclear why PGD algorithm doesn't improve over CE. The explanation due to the learning dynamics of PGD and independence assumption (line 129-133) are confusing and vague.\n- It is better to make it more precise and clear.\n- The proposed attacking algorithm is a bit heuristic and doesn't provide any theoretical justification.\n- It is hard to understand the scalable defense in Section 4.\n- The proposed Soft Median method is based on Soft Medoid but the paper doesn't provide sufficient detail to demonstrate the idea.\n- Therefore, it is unclear how the proposed method improves the efficiency of Soft Medoid.\n- In particular, note that the dimension-wise median has been explored and showed to be worse than Soft Medoid in Soft Medoid paper, which should be discussed.\n- The idea of the differentiable relaxation of the median is unclear.\n- Some important related works are missing.\n- For example, it is stated that the authors are not aware of any defense that scales to graphs significantly larger than PubMed.\n- However, the defense on datasets such as obgn-arxiv and DP has been explored in the paper 'GNNGUARD: Defending Graph Neural Networks against Adversarial Attacks', which needs to be discussed and even compared.\n- Overall, the paper provides insightful investigations on the attacking and defense of GNNs.\n- The proposed methods push the research in this area to a much larger scale, which is a very important direction.\n- However, the writing can be significantly improved to make every part more precise and clear.",
    "review_points_list": [
      "The major focus of this paper is to study the adversarial robustness of GNNs on a larger scale. This is important since most of the existing attack and defense methods for GNNs are limited to very small data.",
      "The instigation and discussion on the ineffective of CE loss in the global attack of GNNs are interesting. It points out that attacking methods based on CE loss might waste attacking budgets, which provides useful insight for the development of stronger attacking methods.",
      "The proposed scalable attacking method seems quite efficient and experiments support its effective and efficiency.",
      "The author doesn't provide a sufficient explanation for the proposed tanh Margin loss so that this loss design is unclear.",
      "Moreover, it is unclear why PGD algorithm doesn't improve over CE. The explanation due to the learning dynamics of PGD and independence assumption (line 129-133) are confusing and vague.",
      "It is better to make it more precise and clear.",
      "The proposed attacking algorithm is a bit heuristic and doesn't provide any theoretical justification.",
      "It is hard to understand the scalable defense in Section 4.",
      "The proposed Soft Median method is based on Soft Medoid but the paper doesn't provide sufficient detail to demonstrate the idea.",
      "Therefore, it is unclear how the proposed method improves the efficiency of Soft Medoid.",
      "In particular, note that the dimension-wise median has been explored and showed to be worse than Soft Medoid in Soft Medoid paper, which should be discussed.",
      "The idea of the differentiable relaxation of the median is unclear.",
      "Some important related works are missing.",
      "For example, it is stated that the authors are not aware of any defense that scales to graphs significantly larger than PubMed.",
      "However, the defense on datasets such as obgn-arxiv and DP has been explored in the paper 'GNNGUARD: Defending Graph Neural Networks against Adversarial Attacks', which needs to be discussed and even compared.",
      "Overall, the paper provides insightful investigations on the attacking and defense of GNNs.",
      "The proposed methods push the research in this area to a much larger scale, which is a very important direction.",
      "However, the writing can be significantly improved to make every part more precise and clear."
    ]
  },
  {
    "paper_id": "2102.04050v2",
    "submission_id": "wFuWSdCD7BN",
    "submission_title": "A Constant Approximation Algorithm for Sequential Random-Order No-Substitution k-Median Clustering",
    "review_id": "ilGy9qDbvtV",
    "input": {
      "title": "A Constant Approximation Algorithm for Sequential Random-Order No-Substitution k-Median Clustering",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The problem of the paper is interesting and has a strong practical relevance.\n- It has already been studied in the literature and the results of the paper yield a substantial progress.\n- The idea of the algorithm is novel to me and the analysis seems sound and correct (I checked the proof sketches and large parts of the proofs in the appendix).\n- Some minor comments:\n- please provide the constant of the approximation in the theorem statement (something like $728$) instead of a 'universal constant $C$'\n- large parts of the clustering community call the objective value the 'clustering cost', I have seen that some of the related work also speak of 'clustering risk', but you may consider switching to 'cost' (I don't see any reason to call it risk here)\n- the symbol $\text{\u2261}$ is used very rarely in mathematics (mainly in the context of logic) and can be substituted by $=$ in any case in your paper (standard notation improves comprehendability)\n- line 131: write $\rvert T_{out} \rvert = O(k \text{log}^2(k/\text{delta}))",
    "review_points_list": [
      "The problem of the paper is interesting and has a strong practical relevance.",
      "It has already been studied in the literature and the results of the paper yield a substantial progress.",
      "The idea of the algorithm is novel to me and the analysis seems sound and correct (I checked the proof sketches and large parts of the proofs in the appendix).",
      "Some minor comments:",
      "please provide the constant of the approximation in the theorem statement (something like $728$) instead of a 'universal constant $C$'",
      "large parts of the clustering community call the objective value the 'clustering cost', I have seen that some of the related work also speak of 'clustering risk', but you may consider switching to 'cost' (I don't see any reason to call it risk here)",
      "the symbol $\text{\u2261}$ is used very rarely in mathematics (mainly in the context of logic) and can be substituted by $=$ in any case in your paper (standard notation improves comprehendability)",
      "line 131: write $\rvert T_{out} \rvert = O(k \text{log}^2(k/\text{delta}))"
    ]
  },
  {
    "paper_id": "2102.04050v2",
    "submission_id": "wFuWSdCD7BN",
    "submission_title": "A Constant Approximation Algorithm for Sequential Random-Order No-Substitution k-Median Clustering",
    "review_id": "mTBENld9Rzg",
    "input": {
      "title": "A Constant Approximation Algorithm for Sequential Random-Order No-Substitution k-Median Clustering",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- From a theoretical perspective, the algorithm is intuitive,\n- and is well explained by the paper, with a lot of insight.\n- But the bulk of the analysis is left for the supplement.\n- The algorithm however, appears far from practical.\n- As the most comparable work is an ALT 2021 paper that uses O(k log k) centers, but has approximation factor exponential in k (under all of the same model/data assumptions),\n- I do not see the improvement as that substantial.\n- Ultimately, I'd be ok if this paper is accepted for NeurIPS.\n- The work is high quality.\n- However, the improvement, I believe is small and theoretical, and may not have a high impact.",
    "review_points_list": [
      "From a theoretical perspective, the algorithm is intuitive,",
      "and is well explained by the paper, with a lot of insight.",
      "But the bulk of the analysis is left for the supplement.",
      "The algorithm however, appears far from practical.",
      "As the most comparable work is an ALT 2021 paper that uses O(k log k) centers, but has approximation factor exponential in k (under all of the same model/data assumptions),",
      "I do not see the improvement as that substantial.",
      "Ultimately, I'd be ok if this paper is accepted for NeurIPS.",
      "The work is high quality.",
      "However, the improvement, I believe is small and theoretical, and may not have a high impact."
    ]
  },
  {
    "paper_id": "2102.04050v2",
    "submission_id": "wFuWSdCD7BN",
    "submission_title": "A Constant Approximation Algorithm for Sequential Random-Order No-Substitution k-Median Clustering",
    "review_id": "kLWxXBSdfL1",
    "input": {
      "title": "A Constant Approximation Algorithm for Sequential Random-Order No-Substitution k-Median Clustering",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The problem setup is as follows. The points to be clustered arrive one by one in a random order stream.\n- A point arriving in a stream may or may not be chosen as a center, but if it is chosen as a center, it cannot be substituted later.\n- The authors design a subroutine SelectProc that divides the stream into three phases, the length of each phase is a constant factor of the length of the stream.\n- At the end of the first phase, using an offline algorithm for k-median on the points in the first phase, a set of centers is computed.\n- This set of centers is used in the second phase to estimate the cost of clustering of the points in the second phase.\n- In the third phase, the actual centers are selected by the subroutine.\n- The algorithm runs O(log k/\u03b4) instances of the subroutine SelectProc in parallel where each instance of the subroutine works on a different prefix of the stream, and the algorithm outputs all centers chosen by these subroutines.\n- This set of centers give constant factor approximation with high probability for the k-median problem.\n- Overall, I believe this to be a nice result for a fairly important problem.\n- I recommend acceptance of this paper.\n- My only comments are regarding the writing and the presentation of the paper.\n- Since the description of the algorithm uses a number of parameters, it would be helpful to define the notations appropriately.\n- For example, k_+ is used in the description of the algorithm but it is defined only in Section 4.2.\n- The authors should highlight that the performance of an algorithm in this setting is evaluated using the notion of competitive analysis of online algorithms.\n- This additional comment is to acknowledge reading author response. There is no other changes.",
    "review_points_list": [
      "The problem setup is as follows. The points to be clustered arrive one by one in a random order stream.",
      "A point arriving in a stream may or may not be chosen as a center, but if it is chosen as a center, it cannot be substituted later.",
      "The authors design a subroutine SelectProc that divides the stream into three phases, the length of each phase is a constant factor of the length of the stream.",
      "At the end of the first phase, using an offline algorithm for k-median on the points in the first phase, a set of centers is computed.",
      "This set of centers is used in the second phase to estimate the cost of clustering of the points in the second phase.",
      "In the third phase, the actual centers are selected by the subroutine.",
      "The algorithm runs O(log k/\u03b4) instances of the subroutine SelectProc in parallel where each instance of the subroutine works on a different prefix of the stream, and the algorithm outputs all centers chosen by these subroutines.",
      "This set of centers give constant factor approximation with high probability for the k-median problem.",
      "Overall, I believe this to be a nice result for a fairly important problem.",
      "I recommend acceptance of this paper.",
      "My only comments are regarding the writing and the presentation of the paper.",
      "Since the description of the algorithm uses a number of parameters, it would be helpful to define the notations appropriately.",
      "For example, k_+ is used in the description of the algorithm but it is defined only in Section 4.2.",
      "The authors should highlight that the performance of an algorithm in this setting is evaluated using the notion of competitive analysis of online algorithms.",
      "This additional comment is to acknowledge reading author response. There is no other changes."
    ]
  },
  {
    "paper_id": "2102.04050v2",
    "submission_id": "wFuWSdCD7BN",
    "submission_title": "A Constant Approximation Algorithm for Sequential Random-Order No-Substitution k-Median Clustering",
    "review_id": "Sk5n6CxVJ8M",
    "input": {
      "title": "A Constant Approximation Algorithm for Sequential Random-Order No-Substitution k-Median Clustering",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well structured and well written.\n- The claims made in the paper seem sound.\n- The problem itself is a relatively well-studied theoretical problem and they manage to give a constant factor approximation algorithm that only has a log^2 k multiplicative overhead under the random order setting, which is a relatively significant improvement on the existing research.\n- They introduce a new concept of linear bin division to complete the analysis of the algorithm.\n- Overall, the paper looks good.\n- How does the Phase 1 and Phase 2 selection of $P_1, P_2$ (of size $\\alpha n$ each) affect the memory requirements (could it lead to memory requirement of order $n$)?",
    "review_points_list": [
      "The paper is well structured and well written.",
      "The claims made in the paper seem sound.",
      "The problem itself is a relatively well-studied theoretical problem and they manage to give a constant factor approximation algorithm that only has a log^2 k multiplicative overhead under the random order setting, which is a relatively significant improvement on the existing research.",
      "They introduce a new concept of linear bin division to complete the analysis of the algorithm.",
      "Overall, the paper looks good.",
      "How does the Phase 1 and Phase 2 selection of $P_1, P_2$ (of size $\\alpha n$ each) affect the memory requirements (could it lead to memory requirement of order $n$)?"
    ]
  },
  {
    "paper_id": "2507.11901v1",
    "submission_id": "wnAN2ZU7br",
    "submission_title": "Pipeline Combinators for Gradual AutoML",
    "review_id": "n7lwRqyQvKf",
    "input": {
      "title": "Pipeline Combinators for Gradual AutoML",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Important problem\n- Easy-to-use system for gradual AutoML\n- Very clear writing\n- Well-thought-out arguments for the benefit of gradual automation and how Lale enables this\n- Limited novelty\n- Conclusions from the experiments are not laid out as clearly as I would like\n- The proposed system appears to achieve this goal well\n- It is easy to understand how to use the three combinators to construct pipelines\n- It is also easy to use their proposed schemas to specify a space of hyperparameters\n- The authors' Lale library seems like a great way to enable gradual AutoML for users already familiar with sklearn\n- I was able to understand the system quickly\n- and from the user study, it appears that other new Lale users were able to pick it up easily as well\n- Whether the translation scheme from Lale syntax (combinators and schemas) to a form that can be given to an optimizer is as novel as the authors claim\n- The normalization step is quite common when dealing with conjunctions and disjunctions\n- The combine step is straightforward as well, simply putting the schemas into the hierarchical pipeline structure defined by the combinators\n- Once we have a hierarchical nesting of search spaces, flattening and discretizing are \u201cobvious\u201d steps to take if a particular optimizer requires a flattened and/or discretized representation\n- It is good that the paper describes these steps in detail, and providing such detail can count as a contribution of the paper\n- but I would not describe the translation process as \u201cnovel\u201d\n- The authors came up with a well-designed and easy to use syntax for enabling gradual AutoML in sklearn\n- although the ideas behind this syntax (the pipe/and/or combinators, schemas for hyperparameters) are quite straightforward\n- which is a good thing for usability!\n- The Lale system appears to be technically sound\n- My only concern is about the empirical results, where I would like more detailed analysis of the results, what conclusions we can draw, and discussion about why those conclusions make sense\n- See my questions below\n- The work is significant, since it enables more users to easily use gradual AutoML, which will then improve whatever work those users end up doing\n- I am unsure about the significance of the empirical results though, since Lale appears to perform slightly worse than the SOTA auto-sklearn\n- It is currently not clear whether Lale produces better or worse accuracies than auto-sklearn",
    "review_points_list": [
      "Important problem",
      "Easy-to-use system for gradual AutoML",
      "Very clear writing",
      "Well-thought-out arguments for the benefit of gradual automation and how Lale enables this",
      "Limited novelty",
      "Conclusions from the experiments are not laid out as clearly as I would like",
      "The proposed system appears to achieve this goal well",
      "It is easy to understand how to use the three combinators to construct pipelines",
      "It is also easy to use their proposed schemas to specify a space of hyperparameters",
      "The authors' Lale library seems like a great way to enable gradual AutoML for users already familiar with sklearn",
      "I was able to understand the system quickly",
      "and from the user study, it appears that other new Lale users were able to pick it up easily as well",
      "Whether the translation scheme from Lale syntax (combinators and schemas) to a form that can be given to an optimizer is as novel as the authors claim",
      "The normalization step is quite common when dealing with conjunctions and disjunctions",
      "The combine step is straightforward as well, simply putting the schemas into the hierarchical pipeline structure defined by the combinators",
      "Once we have a hierarchical nesting of search spaces, flattening and discretizing are \u201cobvious\u201d steps to take if a particular optimizer requires a flattened and/or discretized representation",
      "It is good that the paper describes these steps in detail, and providing such detail can count as a contribution of the paper",
      "but I would not describe the translation process as \u201cnovel\u201d",
      "The authors came up with a well-designed and easy to use syntax for enabling gradual AutoML in sklearn",
      "although the ideas behind this syntax (the pipe/and/or combinators, schemas for hyperparameters) are quite straightforward",
      "which is a good thing for usability!",
      "The Lale system appears to be technically sound",
      "My only concern is about the empirical results, where I would like more detailed analysis of the results, what conclusions we can draw, and discussion about why those conclusions make sense",
      "See my questions below",
      "The work is significant, since it enables more users to easily use gradual AutoML, which will then improve whatever work those users end up doing",
      "I am unsure about the significance of the empirical results though, since Lale appears to perform slightly worse than the SOTA auto-sklearn",
      "It is currently not clear whether Lale produces better or worse accuracies than auto-sklearn"
    ]
  },
  {
    "paper_id": "2507.11901v1",
    "submission_id": "wnAN2ZU7br",
    "submission_title": "Pipeline Combinators for Gradual AutoML",
    "review_id": "N3FbrPaSPZX",
    "input": {
      "title": "Pipeline Combinators for Gradual AutoML",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Operators could be an intuitive approach to modeling pipelines\n- Conceptual differences to other libraries are made clear\n- The concept of gradual AutoML not fully convincing, experimental results do not fully back claims\n- The paper thoroughly introduces the concept of available/implemented combinators, execution modes as well as the developed schema\n- The design of the framework is qualitative, elegantly enabling to model complex pipelines in nested structures\n- The authors also provide a detailed related frameworks and libraries, as well as key differences in design decisions\n- The clarity of the framework components and differences to related works is therefore high\n- The originality of the framework is also sufficiently high, as it gives practical value to AutoML end-users\n- I have problems to grasp the 'gradual' aspect of the approach, which is part of the key message of the paper\n- The concept is introduced and explained, and a mapping to individual framework functionalities is available, but the latter merely enable manipulation on different abstraction levels\n- It would be beneficial to clearly state the novelty here, if it is a central claim\n- While the paper maps different gradual AutoML stages to library functionalities, the evaluation does not attempt to compare them to frameworks other than scikit-learn\n- Why was no other library, as described in the related work section, chosen in addition?\n- scikit-learn is surely a good baseline, but comparing it to other libraries which enable easier / more interactive modeling might help to support the claims\n- I thank the authors for their answers to my questions for which I do not have any follow-ups\n- After reading the other reviews and discussions, I raised my score to a weak accept, as I agree that the paper does not need to show superior performance to other AutoML tools\n- I still believe that it would be beneficial for the venue to better quantify the added value of the proposed 'gradual' property, e.g. in the user study",
    "review_points_list": [
      "Operators could be an intuitive approach to modeling pipelines",
      "Conceptual differences to other libraries are made clear",
      "The concept of gradual AutoML not fully convincing, experimental results do not fully back claims",
      "The paper thoroughly introduces the concept of available/implemented combinators, execution modes as well as the developed schema",
      "The design of the framework is qualitative, elegantly enabling to model complex pipelines in nested structures",
      "The authors also provide a detailed related frameworks and libraries, as well as key differences in design decisions",
      "The clarity of the framework components and differences to related works is therefore high",
      "The originality of the framework is also sufficiently high, as it gives practical value to AutoML end-users",
      "I have problems to grasp the 'gradual' aspect of the approach, which is part of the key message of the paper",
      "The concept is introduced and explained, and a mapping to individual framework functionalities is available, but the latter merely enable manipulation on different abstraction levels",
      "It would be beneficial to clearly state the novelty here, if it is a central claim",
      "While the paper maps different gradual AutoML stages to library functionalities, the evaluation does not attempt to compare them to frameworks other than scikit-learn",
      "Why was no other library, as described in the related work section, chosen in addition?",
      "scikit-learn is surely a good baseline, but comparing it to other libraries which enable easier / more interactive modeling might help to support the claims",
      "I thank the authors for their answers to my questions for which I do not have any follow-ups",
      "After reading the other reviews and discussions, I raised my score to a weak accept, as I agree that the paper does not need to show superior performance to other AutoML tools",
      "I still believe that it would be beneficial for the venue to better quantify the added value of the proposed 'gradual' property, e.g. in the user study"
    ]
  },
  {
    "paper_id": "2507.11901v1",
    "submission_id": "wnAN2ZU7br",
    "submission_title": "Pipeline Combinators for Gradual AutoML",
    "review_id": "aagZCLuD4YD",
    "input": {
      "title": "Pipeline Combinators for Gradual AutoML",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- point 1\n- point 2",
    "review_points_list": [
      "point 1",
      "point 2"
    ]
  },
  {
    "paper_id": "2507.11901v1",
    "submission_id": "wnAN2ZU7br",
    "submission_title": "Pipeline Combinators for Gradual AutoML",
    "review_id": "_WlYhUm6n90",
    "input": {
      "title": "Pipeline Combinators for Gradual AutoML",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The contribution of this work as an AutoML system, to the automated composition of complex models, is incremental.\n- This work may benefit by focusing on the user study, specifically on human-model interaction.\n- The work is missing: - Comparisons with other types of AutoML systems that are not pipeline oriented, such as AutoGluon which focuses on generating complex ensembles and stacking, OBOE which focuses on collaborative filtering and fast recommendations.\n- Computation times of the system.\n- The work may reference the D3M project which is composed of three tiers: (i) TA1 ML primitives, (ii) TA2 AutoML systems, (iii) TA3 human in the loop and user studies.\n- The paper is missing multiple references to work on the interface between (ii) and (iii) and systems which focus on user studies: See https://datadrivendiscovery.org/d3m-interfaces",
    "review_points_list": [
      "The contribution of this work as an AutoML system, to the automated composition of complex models, is incremental.",
      "This work may benefit by focusing on the user study, specifically on human-model interaction.",
      "The work is missing: - Comparisons with other types of AutoML systems that are not pipeline oriented, such as AutoGluon which focuses on generating complex ensembles and stacking, OBOE which focuses on collaborative filtering and fast recommendations.",
      "Computation times of the system.",
      "The work may reference the D3M project which is composed of three tiers: (i) TA1 ML primitives, (ii) TA2 AutoML systems, (iii) TA3 human in the loop and user studies.",
      "The paper is missing multiple references to work on the interface between (ii) and (iii) and systems which focus on user studies: See https://datadrivendiscovery.org/d3m-interfaces"
    ]
  },
  {
    "paper_id": "2507.11901v1",
    "submission_id": "uFORMPcA_b",
    "submission_title": "Pipeline Combinators for Gradual AutoML",
    "review_id": "n7ivTK7ITDY",
    "input": {
      "title": "Pipeline Combinators for Gradual AutoML",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The novelty part can be narrowed down to the unified translation schema, which is the first work in the domain of AutoML to my knowledge.\n- However, it is not clear to me whether this is more novelty in the sense of engineering some useful software or whether this is sufficient scientific novelty in the method directly.\n- The advantages for Lale over existing AutoML frameworks are especially advantageous for inexperienced users due to two reasons.\n- (i) The unified interface makes it easy to quickly set up an AutoML pipeline for any implemented optimizer.\n- (ii) Graph overviews are a helpful and easy way to check whether the search space is defined correctly.\n- However, experts in ML and AutoML tend to work as closely to the optimizer interfaces as possible to have full control over the optimizer.\n- Since defining search spaces is transparent and easily understandable in several frameworks too, e.g. SMAC and Hyperopt, Lale would not give many advantages over these.\n- Full AutoML systems such as AutoSklearn, on the other hand, would definitely benefit from Lale.\n- Overall, I\u2019m not fully convinced that there will be many users of Lale at the end of the day.\n- Furthermore, I don\u2019t see a clear path for scientific future work building on top of Lale.\n- Overall, it is uncertain whether Lale will have a great impact in the community.\n- The authors described their method and experiments detailedly and the concept is sound.\n- I appreciate the overall idea of having several API levels which allow to gradually build up expertise in using AutoML tools.\n- Depending also on the level of the user\u2019s expertise, this should allow to find an appropriate API without switching between different packages.\n- However, I have the impression that conceptually this is a very high-level idea of software engineering and unclear how this scientifically contributes to the NeurIPS community.\n- Related work covers both combinators in general and in the AutoML domain.\n- The domain is sufficiently covered.\n- The authors introduced their AutoML library in a sorted, logical way.\n- Using Lale still requires a decent background on machine learning.\n- Calling methods and Interpreting graphs (Figure 11) may not be straight forward for inexperienced users.\n- As already mentioned in the author\u2019s limitations, the user studies only include 9 participants, making statements not very meaningful.\n- Additionally, the survey might even be biased towards Lale.\n- Figure 6 shows a default routine with the only difference of \u201cencode search space\u201d.\n- There\u2019s no novelty aspect at all.\n- Table 1 would not convince me to use Lale over Auto-Sklearn.\n- Table 2: It seems like Auto-Sklearn outperforms Lale-Auto.\n- What are the reasons for that?",
    "review_points_list": [
      "The novelty part can be narrowed down to the unified translation schema, which is the first work in the domain of AutoML to my knowledge.",
      "However, it is not clear to me whether this is more novelty in the sense of engineering some useful software or whether this is sufficient scientific novelty in the method directly.",
      "The advantages for Lale over existing AutoML frameworks are especially advantageous for inexperienced users due to two reasons.",
      "(i) The unified interface makes it easy to quickly set up an AutoML pipeline for any implemented optimizer.",
      "(ii) Graph overviews are a helpful and easy way to check whether the search space is defined correctly.",
      "However, experts in ML and AutoML tend to work as closely to the optimizer interfaces as possible to have full control over the optimizer.",
      "Since defining search spaces is transparent and easily understandable in several frameworks too, e.g. SMAC and Hyperopt, Lale would not give many advantages over these.",
      "Full AutoML systems such as AutoSklearn, on the other hand, would definitely benefit from Lale.",
      "Overall, I\u2019m not fully convinced that there will be many users of Lale at the end of the day.",
      "Furthermore, I don\u2019t see a clear path for scientific future work building on top of Lale.",
      "Overall, it is uncertain whether Lale will have a great impact in the community.",
      "The authors described their method and experiments detailedly and the concept is sound.",
      "I appreciate the overall idea of having several API levels which allow to gradually build up expertise in using AutoML tools.",
      "Depending also on the level of the user\u2019s expertise, this should allow to find an appropriate API without switching between different packages.",
      "However, I have the impression that conceptually this is a very high-level idea of software engineering and unclear how this scientifically contributes to the NeurIPS community.",
      "Related work covers both combinators in general and in the AutoML domain.",
      "The domain is sufficiently covered.",
      "The authors introduced their AutoML library in a sorted, logical way.",
      "Using Lale still requires a decent background on machine learning.",
      "Calling methods and Interpreting graphs (Figure 11) may not be straight forward for inexperienced users.",
      "As already mentioned in the author\u2019s limitations, the user studies only include 9 participants, making statements not very meaningful.",
      "Additionally, the survey might even be biased towards Lale.",
      "Figure 6 shows a default routine with the only difference of \u201cencode search space\u201d.",
      "There\u2019s no novelty aspect at all.",
      "Table 1 would not convince me to use Lale over Auto-Sklearn.",
      "Table 2: It seems like Auto-Sklearn outperforms Lale-Auto.",
      "What are the reasons for that?"
    ]
  },
  {
    "paper_id": "2507.11901v1",
    "submission_id": "uFORMPcA_b",
    "submission_title": "Pipeline Combinators for Gradual AutoML",
    "review_id": "5ahnEpsJ71",
    "input": {
      "title": "Pipeline Combinators for Gradual AutoML",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- AutoML is a useful tool to help novices apply machine learning in their domains, thus, to design easy-to-use and efficient autoML system is an interesting research topic.\n- This paper proposes a system with some new formalizations under its software layout.\n- The motivation is clear: to make the utilization of the system as easy as possible while enabling efficient optimization of the hyper-parameters demanded by different machine learning pipelines.\n- I am confused by the design philosophy  of the formalization of combinator in Section 2.\n- Essentially, why do we need these formalizations?\n- The author keeps mentioning that there are some roughly equivalent operators within the sklearn toolkit.\n- Does this section just offer some more formal definition of a language, or is the syntax defined in this section more expressive than the existing systems?\n- It would be better to have a more explicit description about the motivation of the design.\n- W.r.t the grammar of 'pipeline', I am wondering if this could make the formalization be able to be used for neural network architecture search?\n- It seems there is no such discussion.\n- The presentation of the empirical study should be organized better.\n- For RQ1, even though there is limited number of participants (which is fine due to the difficulty of organizing the user study), there still should be some formal description about the null hypothesis in this user study, then there should be some statistical analysis about the statistical significance of the result, e.g., one can consider bootstrap based methods to report the p-value w.r.t the hypothesis.\n- Further, this section should be self-contained, there should be some brief introduction about the tasks.\n- For RQ2 and RQ3, it seems that only the end-to-end performance boost is reported, on the other hand, it is important to understand where the performance gain comes from (perhaps based on some micro-benchmarks).\n- In other words, the section should answer the question why the formalization of the combinators is effective for the black-box optimizer.\n- I really appreciate the great effort the author has made to address my concerns.\n- On the other hand, I hope during this procedure, the author would also feel that both my comments and comments from other reviewers could help to make it a better paper.\n- To be more clear about the scientific contribution from the very beginning of the paper, e.g., a more expressive formalization of the AutoML system.\n- To organize the presentation of the empirical study following the general scientific principles;\n- To recruit more participants if possible so that one could draw some statistically significant conclusions.\n- To provide some analysis about the performance gain and to discuss how the gain relates to the proposed design---at the end of the day, as scientists, we not only want to know if something works, we want to know why it works as well.",
    "review_points_list": [
      "AutoML is a useful tool to help novices apply machine learning in their domains, thus, to design easy-to-use and efficient autoML system is an interesting research topic.",
      "This paper proposes a system with some new formalizations under its software layout.",
      "The motivation is clear: to make the utilization of the system as easy as possible while enabling efficient optimization of the hyper-parameters demanded by different machine learning pipelines.",
      "I am confused by the design philosophy  of the formalization of combinator in Section 2.",
      "Essentially, why do we need these formalizations?",
      "The author keeps mentioning that there are some roughly equivalent operators within the sklearn toolkit.",
      "Does this section just offer some more formal definition of a language, or is the syntax defined in this section more expressive than the existing systems?",
      "It would be better to have a more explicit description about the motivation of the design.",
      "W.r.t the grammar of 'pipeline', I am wondering if this could make the formalization be able to be used for neural network architecture search?",
      "It seems there is no such discussion.",
      "The presentation of the empirical study should be organized better.",
      "For RQ1, even though there is limited number of participants (which is fine due to the difficulty of organizing the user study), there still should be some formal description about the null hypothesis in this user study, then there should be some statistical analysis about the statistical significance of the result, e.g., one can consider bootstrap based methods to report the p-value w.r.t the hypothesis.",
      "Further, this section should be self-contained, there should be some brief introduction about the tasks.",
      "For RQ2 and RQ3, it seems that only the end-to-end performance boost is reported, on the other hand, it is important to understand where the performance gain comes from (perhaps based on some micro-benchmarks).",
      "In other words, the section should answer the question why the formalization of the combinators is effective for the black-box optimizer.",
      "I really appreciate the great effort the author has made to address my concerns.",
      "On the other hand, I hope during this procedure, the author would also feel that both my comments and comments from other reviewers could help to make it a better paper.",
      "To be more clear about the scientific contribution from the very beginning of the paper, e.g., a more expressive formalization of the AutoML system.",
      "To organize the presentation of the empirical study following the general scientific principles;",
      "To recruit more participants if possible so that one could draw some statistically significant conclusions.",
      "To provide some analysis about the performance gain and to discuss how the gain relates to the proposed design---at the end of the day, as scientists, we not only want to know if something works, we want to know why it works as well."
    ]
  },
  {
    "paper_id": "2507.11901v1",
    "submission_id": "uFORMPcA_b",
    "submission_title": "Pipeline Combinators for Gradual AutoML",
    "review_id": "GNuZexsVC3",
    "input": {
      "title": "Pipeline Combinators for Gradual AutoML",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I really enjoyed reading this paper! The paper is extremely well-written and well-organized---it was easy to understand both low-level details and high-level ideas clearly.\n- In particular, the paper succeeds at abstracting out unimportant details and explaining core ideas succinctly.\n- Moreover, the technical contents of the paper look novel and sound to me.\n- The paper considers a very important problem and provides a very satisfactory solution both in technical and practical point of view.\n- Technically, the paper introduces three combinators important for compositional gradual AutoML, among which the or combinator is particularly novel.\n- Also the entire system (including combinators, hyperparameter schema, and translation scheme) seems to be designed and engineered in a principled way, and the paper describes some important design principles.\n- Practically, learning and using Lale look easy to me (which is confirmed by user studies) in that it is implemented in Python and based on popular frameworks (sklearn and JSON Schema).\n- Also Lale supports various pipeline structures and optimizer backends.\n- For these reasons, I think Lale will have a huge positive impact on the NeurIPS community.\n- I really enjoyed reading this paper! The paper is extremely well-written and well-organized---it was easy to understand both low-level details and high-level ideas clearly.\n- In particular, the paper succeeds at abstracting out unimportant details and explaining core ideas succinctly.\n- Moreover, the technical contents of the paper look novel and sound to me.\n- The paper considers a very important problem and provides a very satisfactory solution both in technical and practical point of view.\n- Technically, the paper introduces three combinators important for compositional gradual AutoML, among which the or combinator is particularly novel.\n- Also the entire system (including combinators, hyperparameter schema, and translation scheme) seems to be designed and engineered in a principled way, and the paper describes some important design principles.\n- Practically, learning and using Lale look easy to me (which is confirmed by user studies) in that it is implemented in Python and based on popular frameworks (sklearn and JSON Schema).\n- Also Lale supports various pipeline structures and optimizer backends.\n- For these reasons, I think Lale will have a huge positive impact on the NeurIPS community.",
    "review_points_list": [
      "I really enjoyed reading this paper! The paper is extremely well-written and well-organized---it was easy to understand both low-level details and high-level ideas clearly.",
      "In particular, the paper succeeds at abstracting out unimportant details and explaining core ideas succinctly.",
      "Moreover, the technical contents of the paper look novel and sound to me.",
      "The paper considers a very important problem and provides a very satisfactory solution both in technical and practical point of view.",
      "Technically, the paper introduces three combinators important for compositional gradual AutoML, among which the or combinator is particularly novel.",
      "Also the entire system (including combinators, hyperparameter schema, and translation scheme) seems to be designed and engineered in a principled way, and the paper describes some important design principles.",
      "Practically, learning and using Lale look easy to me (which is confirmed by user studies) in that it is implemented in Python and based on popular frameworks (sklearn and JSON Schema).",
      "Also Lale supports various pipeline structures and optimizer backends.",
      "For these reasons, I think Lale will have a huge positive impact on the NeurIPS community.",
      "I really enjoyed reading this paper! The paper is extremely well-written and well-organized---it was easy to understand both low-level details and high-level ideas clearly.",
      "In particular, the paper succeeds at abstracting out unimportant details and explaining core ideas succinctly.",
      "Moreover, the technical contents of the paper look novel and sound to me.",
      "The paper considers a very important problem and provides a very satisfactory solution both in technical and practical point of view.",
      "Technically, the paper introduces three combinators important for compositional gradual AutoML, among which the or combinator is particularly novel.",
      "Also the entire system (including combinators, hyperparameter schema, and translation scheme) seems to be designed and engineered in a principled way, and the paper describes some important design principles.",
      "Practically, learning and using Lale look easy to me (which is confirmed by user studies) in that it is implemented in Python and based on popular frameworks (sklearn and JSON Schema).",
      "Also Lale supports various pipeline structures and optimizer backends.",
      "For these reasons, I think Lale will have a huge positive impact on the NeurIPS community."
    ]
  },
  {
    "paper_id": "2507.11901v1",
    "submission_id": "uFORMPcA_b",
    "submission_title": "Pipeline Combinators for Gradual AutoML",
    "review_id": "ogiUYIbxm2k",
    "input": {
      "title": "Pipeline Combinators for Gradual AutoML",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- AutoML is an important application, and if successful, can greatly reduce data scientists' effort.\n- It looks like a significant engineering effort and mature tool. They support many backend for the optimizers.\n- Besides reporting testing accuracies for 14 OpenML classification tasks, they also reported results of an user study demonstrating usefulness of the tool.\n- The high-level scientific contribution is missing. The paper provides too many low level details without describing what are the main challenges to implement combinators.\n- All the datasets used in this paper seem rather small, and it is not clear whether the underlying framework can support diverse model architectures.\n- It is not clear why the proposed method is contributing to AutoML. It seems like it is just combining existing AutoML approaches with the combinators.",
    "review_points_list": [
      "AutoML is an important application, and if successful, can greatly reduce data scientists' effort.",
      "It looks like a significant engineering effort and mature tool. They support many backend for the optimizers.",
      "Besides reporting testing accuracies for 14 OpenML classification tasks, they also reported results of an user study demonstrating usefulness of the tool.",
      "The high-level scientific contribution is missing. The paper provides too many low level details without describing what are the main challenges to implement combinators.",
      "All the datasets used in this paper seem rather small, and it is not clear whether the underlying framework can support diverse model architectures.",
      "It is not clear why the proposed method is contributing to AutoML. It seems like it is just combining existing AutoML approaches with the combinators."
    ]
  },
  {
    "paper_id": "2112.03257v1",
    "submission_id": "uTqvj8i3xv",
    "submission_title": "Functional Regularization for Reinforcement Learning via Learned Fourier Features",
    "review_id": "HGQYICQdhEG",
    "input": {
      "title": "Functional Regularization for Reinforcement Learning via Learned Fourier Features",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Although it proposes an interesting method, this work does not really prove its hypothesis.\n- The central hypotheses of this work are that (A) RL methods are susceptible to target noise and (B) LF2 reduces noise in the Bellman update.\n- (A) is used as a premise here and is never shown to be true, and although it is 'common wisdom' in the deep RL community, it is contrary to some existing empirical literature.\n- (B) is also never measured directly, and so never shown to be true.\n- While it appears correct to claim that LF2 improves performance in some cases, it is impossible to link that improvement to the noise reduction hypothesis.\n- The theoretical part of this paper is interesting, and is probably a valuable contribution.\n- Unfortunately, results in this section do not trivially transfer to hypotheses (A) & (B).\n- I am only superficially familiar with Fourier features literature.\n- Training Fourier features appears to be something that isn't normally done, and while lots of papers have proposed regularizations to value functions, I am unaware of frequency-domain methods.\n- The paper itself is well written and was easy to understand.\n- Although I find the method interesting and in-line with many intuitions that deep RL researchers have, this paper does not teach us much, and relies too heavily on proxies to 'prove' its hypothesis.\n- More work needs to be done for this paper to be impactful, and to really teach us something about deep RL.\n- l.32 Farebrother et al. [1] successfully apply dropout to DQN\n- Section 3, Some unusual notation: using \\gamma for the frequency mapping, and \\tau for the activation function.\n- l.245 'with the shaded region denoting 68% confidence interval'. 68%? This seems like a rather odd choice.\n- I wonder what justified this choice? You may want to refer to papers such as [2] for guidance.\n- l.248 'LF2 does clearly better than MLPs in 6 out of 8 environments'. My _subjective_ reading of Figure 5 does not suggest so, but a statistical test would provide a quantitative assessment of superiority.\n- How statistically significant are these improvements?\n- Figure 8, I again doubt that any of these curves are significantly different from each other.\n- l.285 'This validates our hypothesis that Bellman updates remain noisy [..] and that LF2 reduces [noise]'.\n- I'm not convinced by this experiment.\n- Not only are the results of Figure 8 probably marginal, noise has not been measured.\n- It would be much more convincing to actually measure this noise, if it exists at all (current literature suggests instead that deep value networks _underfit_ severely, thus what is badly propagated is not noisy memorized estimates but underfit overgeneralized value estimates, see [3]; [6] may be relevant as well, and touches on the correlation between Bellman noise and agent performance in Atari).\n- I find the choice of using SAC as a baseline to improve over quite odd.\n- Presumably, the proposed method stabilizes the value function, but SAC is a policy gradient method -- one can only expect marginal improvements from improving the value function.\n- Why not compare to a value-based method?\n- Baselines: A number of functional regularizations for deep RL have been proposed recently, but none appear here.\n- For references, see e.g. [3,4] and Section 5 of [5].\n- Update\n- I thank the authors for their answers, updates and additional experiments,\n- I think that these more convincingly explain why the proposed method is advantageous.\n- My main problem with the paper was connecting the hypothesis behind the method with the improvements, but this connection is much better now.\n- I will update my score.\n- To be clear, validating all hypotheses should be a main feature of papers like this one, not just showing improvements.\n- I encourage the authors to feature this prominently when updating this paper.\n- It does additionally seem like the improvements in the paper are consistent.\n- Their magnitude is limited, but could be valuable in certain environments where target noise can become a significant issue.",
    "review_points_list": [
      "Although it proposes an interesting method, this work does not really prove its hypothesis.",
      "The central hypotheses of this work are that (A) RL methods are susceptible to target noise and (B) LF2 reduces noise in the Bellman update.",
      "(A) is used as a premise here and is never shown to be true, and although it is 'common wisdom' in the deep RL community, it is contrary to some existing empirical literature.",
      "(B) is also never measured directly, and so never shown to be true.",
      "While it appears correct to claim that LF2 improves performance in some cases, it is impossible to link that improvement to the noise reduction hypothesis.",
      "The theoretical part of this paper is interesting, and is probably a valuable contribution.",
      "Unfortunately, results in this section do not trivially transfer to hypotheses (A) & (B).",
      "I am only superficially familiar with Fourier features literature.",
      "Training Fourier features appears to be something that isn't normally done, and while lots of papers have proposed regularizations to value functions, I am unaware of frequency-domain methods.",
      "The paper itself is well written and was easy to understand.",
      "Although I find the method interesting and in-line with many intuitions that deep RL researchers have, this paper does not teach us much, and relies too heavily on proxies to 'prove' its hypothesis.",
      "More work needs to be done for this paper to be impactful, and to really teach us something about deep RL.",
      "l.32 Farebrother et al. [1] successfully apply dropout to DQN",
      "Section 3, Some unusual notation: using \\gamma for the frequency mapping, and \\tau for the activation function.",
      "l.245 'with the shaded region denoting 68% confidence interval'. 68%? This seems like a rather odd choice.",
      "I wonder what justified this choice? You may want to refer to papers such as [2] for guidance.",
      "l.248 'LF2 does clearly better than MLPs in 6 out of 8 environments'. My _subjective_ reading of Figure 5 does not suggest so, but a statistical test would provide a quantitative assessment of superiority.",
      "How statistically significant are these improvements?",
      "Figure 8, I again doubt that any of these curves are significantly different from each other.",
      "l.285 'This validates our hypothesis that Bellman updates remain noisy [..] and that LF2 reduces [noise]'.",
      "I'm not convinced by this experiment.",
      "Not only are the results of Figure 8 probably marginal, noise has not been measured.",
      "It would be much more convincing to actually measure this noise, if it exists at all (current literature suggests instead that deep value networks _underfit_ severely, thus what is badly propagated is not noisy memorized estimates but underfit overgeneralized value estimates, see [3]; [6] may be relevant as well, and touches on the correlation between Bellman noise and agent performance in Atari).",
      "I find the choice of using SAC as a baseline to improve over quite odd.",
      "Presumably, the proposed method stabilizes the value function, but SAC is a policy gradient method -- one can only expect marginal improvements from improving the value function.",
      "Why not compare to a value-based method?",
      "Baselines: A number of functional regularizations for deep RL have been proposed recently, but none appear here.",
      "For references, see e.g. [3,4] and Section 5 of [5].",
      "Update",
      "I thank the authors for their answers, updates and additional experiments,",
      "I think that these more convincingly explain why the proposed method is advantageous.",
      "My main problem with the paper was connecting the hypothesis behind the method with the improvements, but this connection is much better now.",
      "I will update my score.",
      "To be clear, validating all hypotheses should be a main feature of papers like this one, not just showing improvements.",
      "I encourage the authors to feature this prominently when updating this paper.",
      "It does additionally seem like the improvements in the paper are consistent.",
      "Their magnitude is limited, but could be valuable in certain environments where target noise can become a significant issue."
    ]
  },
  {
    "paper_id": "2112.03257v1",
    "submission_id": "uTqvj8i3xv",
    "submission_title": "Functional Regularization for Reinforcement Learning via Learned Fourier Features",
    "review_id": "7ccT87NFZgv",
    "input": {
      "title": "Functional Regularization for Reinforcement Learning via Learned Fourier Features",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper can be considered as a small modification on top of existing ideas.\n- Building on prior work[1] that introduced a fixed fourier feature basis to capture high frequency functions, the paper proposes LF2 which learns the fourier feature basis  as randomly initialized features can be quite limited.\n- Although the related work is cited generally well, the paper doesn\u2019t have an explicit section but could benefit from one.\n- One point which is not discussed much is why the inherent spectral bias of deep networks towards learning low-frequency functions [1] is not sufficient for learning in deep RL.\n- Recent work shows that this spectral bias can lead to too low effective rank of the learned features in deep RL [2] with theoretical results in the NTK regime.\n- [3] also confirmed such findings for online RL.\n- While Figure 2 takes a simulation attempt at it but can possibly be alleviated with deeper networks like ResNets or just using L2-regularization.\n- Also,\n- The submission seems to be technically sound.\n- I did not go through the proofs but the lemma presented in the paper made sense.\n- The empirical evaluation currently seems to indicate LF2 only results in tiny improvements and could be somewhat stronger.\n- Some concerns I have are listed below:\n- - The empirical results in Figure 5 indicate that LF2 gains are marginal compared to standard MLPs (and might have just resulted from randomness in evaluation on some tasks).\n- Furthermore, l2-weight decay performs reasonably well on most of the domains (and even outperforms LF2 on certain domains).\n- Same is found to be true for PPO-based agents in the appendix.\n- The results on image-based domains in Figure 6 seem moderate too and are evaluated only in a smaller subset of 4 environments reported in Figure 5 (which may seem to be cherry-picked?)\n- Furthermore, no other baseline is evaluated on such image-based domains including the l2-reg baseline in Fig 5.\n- If the improvement is coming from learning smoother functions, another way to impose such constraints is to impose spectral normalization which is also reported to work quite well in RL [3] (and even on DM control tasks[4]).\n- The ablation study in Sec 6.2 cripples the standard SAC agent by removing the target network and adding a noise value of \u201c11\u201d and shows that LF2 works well.\n- However, in practice, target networks are almost always used.\n- So, how does LF2 compare to standard SAC when the target network is added back \u2013 are target networks sufficient for handling the noise?\n- Also, why was a specific noise value of 11 picked \u2013 why not smaller/larger (or better a range of values on a log scale?)\n- How much of the improvement in LF2 is just coming from the concatenation of the input?  It was not clear to me whether the ablation studies answer this question (as there was no baseline which uses concatenated inputs with MLP/conv architecture with the same parameter count).\n- Specifically, what if I use the same architecture for the baseline as used currently but with the inputs concatenated on the first layer output as done for the LF2 architecture?\n- The paper seems to be well written and organized.\n- A minor comment: Instead of reporting the 68% confidence intervals, it might be better to report the standard deviation as 68% CIs may not have a true coverage of 68% as the reported results are only with 5 seeds.\n- The results seem to indicate that LF2 architecture may be better than standard MLPs on certain hard tasks such as humanoid.\n- However, it is unclear when LF2 should be used or why it should be preferred over other existing methods like using ResNets or spectral normalization.\n- That said, the example pointed in the appendix about learning overly complex Q-functions was quite neat and shows that LF2 might be useful in certain scenarios (but the main paper focuses on the other scenario).\n- Overall, the paper in its current form may not be that exciting to the community.",
    "review_points_list": [
      "The paper can be considered as a small modification on top of existing ideas.",
      "Building on prior work[1] that introduced a fixed fourier feature basis to capture high frequency functions, the paper proposes LF2 which learns the fourier feature basis  as randomly initialized features can be quite limited.",
      "Although the related work is cited generally well, the paper doesn\u2019t have an explicit section but could benefit from one.",
      "One point which is not discussed much is why the inherent spectral bias of deep networks towards learning low-frequency functions [1] is not sufficient for learning in deep RL.",
      "Recent work shows that this spectral bias can lead to too low effective rank of the learned features in deep RL [2] with theoretical results in the NTK regime.",
      "[3] also confirmed such findings for online RL.",
      "While Figure 2 takes a simulation attempt at it but can possibly be alleviated with deeper networks like ResNets or just using L2-regularization.",
      "Also,",
      "The submission seems to be technically sound.",
      "I did not go through the proofs but the lemma presented in the paper made sense.",
      "The empirical evaluation currently seems to indicate LF2 only results in tiny improvements and could be somewhat stronger.",
      "Some concerns I have are listed below:",
      "- The empirical results in Figure 5 indicate that LF2 gains are marginal compared to standard MLPs (and might have just resulted from randomness in evaluation on some tasks).",
      "Furthermore, l2-weight decay performs reasonably well on most of the domains (and even outperforms LF2 on certain domains).",
      "Same is found to be true for PPO-based agents in the appendix.",
      "The results on image-based domains in Figure 6 seem moderate too and are evaluated only in a smaller subset of 4 environments reported in Figure 5 (which may seem to be cherry-picked?)",
      "Furthermore, no other baseline is evaluated on such image-based domains including the l2-reg baseline in Fig 5.",
      "If the improvement is coming from learning smoother functions, another way to impose such constraints is to impose spectral normalization which is also reported to work quite well in RL [3] (and even on DM control tasks[4]).",
      "The ablation study in Sec 6.2 cripples the standard SAC agent by removing the target network and adding a noise value of \u201c11\u201d and shows that LF2 works well.",
      "However, in practice, target networks are almost always used.",
      "So, how does LF2 compare to standard SAC when the target network is added back \u2013 are target networks sufficient for handling the noise?",
      "Also, why was a specific noise value of 11 picked \u2013 why not smaller/larger (or better a range of values on a log scale?)",
      "How much of the improvement in LF2 is just coming from the concatenation of the input?  It was not clear to me whether the ablation studies answer this question (as there was no baseline which uses concatenated inputs with MLP/conv architecture with the same parameter count).",
      "Specifically, what if I use the same architecture for the baseline as used currently but with the inputs concatenated on the first layer output as done for the LF2 architecture?",
      "The paper seems to be well written and organized.",
      "A minor comment: Instead of reporting the 68% confidence intervals, it might be better to report the standard deviation as 68% CIs may not have a true coverage of 68% as the reported results are only with 5 seeds.",
      "The results seem to indicate that LF2 architecture may be better than standard MLPs on certain hard tasks such as humanoid.",
      "However, it is unclear when LF2 should be used or why it should be preferred over other existing methods like using ResNets or spectral normalization.",
      "That said, the example pointed in the appendix about learning overly complex Q-functions was quite neat and shows that LF2 might be useful in certain scenarios (but the main paper focuses on the other scenario).",
      "Overall, the paper in its current form may not be that exciting to the community."
    ]
  },
  {
    "paper_id": "2112.03257v1",
    "submission_id": "uTqvj8i3xv",
    "submission_title": "Functional Regularization for Reinforcement Learning via Learned Fourier Features",
    "review_id": "BTMX405u4Q",
    "input": {
      "title": "Functional Regularization for Reinforcement Learning via Learned Fourier Features",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- While the idea of using base layers that learn a representation in some harmonic domain is not new, to the best of my knowledge no prior application to target networks is present in the literature.\n- I suggest to expand the introduction with some of this references, mentioning that the base idea is not new.\n- The theoretical analysis is interesting in principle, but it does not offer a strong insight on the proposed method.\n- Specifically, Neural Tangent Kernel analysis makes the assumption that the network does not change significantly from the initialization, which is in-line with the idea that the initialization variance of the Fourier layers matters.\n- However, if that is true, is it even worth training those layers? I invite the authors to investigate more the impact of early layers focusing on certain representations, either fixed or learned.\n- Another suggestion would be to use alternative tools for analyzing the behaviour of the network, not at initialization but at convergence (e.g. Approximate Inference Turns Deep Networks into Gaussian Processes - 2018), or studying the stability of the Bellman operator when using such layers (e.g. see Towards Characterizing Divergence in Deep Q-Learning - 2019).\n- While the analysis has shortcomings, the proposed approach is investigated thoroughly in the experimental section, which constitutes the more relevant part of the work.\n- The experimental set-up look adequate and the results are good, albeit not groundbreaking in terms of performance.\n- I appreciate that the authors not only validated the overall performance in terms of reward but also the stability during training.\n- Overall, the paper is clear and well-structured.\n- Because I deem the fundamental questions investigated by this paper to be very relevant for the RL community, either in theoretical or empirical form, I think its shortcomings could be overshadowed by its positive effect on the RL community.",
    "review_points_list": [
      "While the idea of using base layers that learn a representation in some harmonic domain is not new, to the best of my knowledge no prior application to target networks is present in the literature.",
      "I suggest to expand the introduction with some of this references, mentioning that the base idea is not new.",
      "The theoretical analysis is interesting in principle, but it does not offer a strong insight on the proposed method.",
      "Specifically, Neural Tangent Kernel analysis makes the assumption that the network does not change significantly from the initialization, which is in-line with the idea that the initialization variance of the Fourier layers matters.",
      "However, if that is true, is it even worth training those layers? I invite the authors to investigate more the impact of early layers focusing on certain representations, either fixed or learned.",
      "Another suggestion would be to use alternative tools for analyzing the behaviour of the network, not at initialization but at convergence (e.g. Approximate Inference Turns Deep Networks into Gaussian Processes - 2018), or studying the stability of the Bellman operator when using such layers (e.g. see Towards Characterizing Divergence in Deep Q-Learning - 2019).",
      "While the analysis has shortcomings, the proposed approach is investigated thoroughly in the experimental section, which constitutes the more relevant part of the work.",
      "The experimental set-up look adequate and the results are good, albeit not groundbreaking in terms of performance.",
      "I appreciate that the authors not only validated the overall performance in terms of reward but also the stability during training.",
      "Overall, the paper is clear and well-structured.",
      "Because I deem the fundamental questions investigated by this paper to be very relevant for the RL community, either in theoretical or empirical form, I think its shortcomings could be overshadowed by its positive effect on the RL community."
    ]
  },
  {
    "paper_id": "2002.06143v1",
    "submission_id": "zwkj1_pxFM",
    "submission_title": "A nonparametric method for gradual change problems with statistical guarantees",
    "review_id": "QcWJFjA00op",
    "input": {
      "title": "A nonparametric method for gradual change problems with statistical guarantees",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed framework shows good results on the benchmark datasets,\n- But the authors do not discuss the limitations of their approach.\n- The paper lacks a detailed description of the experimental setup, which makes it difficult to understand the results.\n- The authors could have provided more details about the hyperparameters used in the experiments.\n- The paper is well-written and easy to follow.",
    "review_points_list": [
      "The proposed framework shows good results on the benchmark datasets,",
      "But the authors do not discuss the limitations of their approach.",
      "The paper lacks a detailed description of the experimental setup, which makes it difficult to understand the results.",
      "The authors could have provided more details about the hyperparameters used in the experiments.",
      "The paper is well-written and easy to follow."
    ]
  },
  {
    "paper_id": "2002.06143v1",
    "submission_id": "zwkj1_pxFM",
    "submission_title": "A nonparametric method for gradual change problems with statistical guarantees",
    "review_id": "mkuGwgZD2jQ",
    "input": {
      "title": "A nonparametric method for gradual change problems with statistical guarantees",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Paper has some strong points\n- - Careful analysis showing statistical guarantee of the methods and the comparison of the existing method is carefully carried out.\n- - The proposed method has wide range of the potential applications due to its non-parametric nature\n- - Author addressed the positive bias issue and proposed solutions\n- In general a good piece of theoretical work that could shed lights on future methodology development\n- Paper provided interesting angle to tackle the problem and analyse the theoretical properties\n- Some points of improvement:\n- - Line 56: $[x]$ is usually representing $\t{1,2,\tldots,x}$ instead of the integer part.\n- - Line 111: sum of Gaussian is a Gaussian.\n- - Thm4.10: we have convergence on the scale of 0 to 1, and this is time compressed, meaning all the time is divided by T.\n- When T increases, is the convergence still holds true? E.g. when there is a sample\n- Will the following hold $$\rto^* - \that{\rto} = o(1/T)$$  This will ensure that the localization going close the place of change.\n- At lease you don't want the  $T(\rto^* - \that{\rto}) \to \ty$ happen, which you may be far off eventually while still converging in the 0,1 scale.\n- Even if this is a non-parametric method, the kernel choice is still depending on some structure assumptions.\n- Can we have comparison between kernel choices (e.g. inner product on $\bb{R}^n$ versus general Gaussian kernel) so that we can get some insights on how the kernel choice affect the output?",
    "review_points_list": [
      "Paper has some strong points",
      "- Careful analysis showing statistical guarantee of the methods and the comparison of the existing method is carefully carried out.",
      "- The proposed method has wide range of the potential applications due to its non-parametric nature",
      "- Author addressed the positive bias issue and proposed solutions",
      "In general a good piece of theoretical work that could shed lights on future methodology development",
      "Paper provided interesting angle to tackle the problem and analyse the theoretical properties",
      "Some points of improvement:",
      "- Line 56: $[x]$ is usually representing $\t{1,2,\tldots,x}$ instead of the integer part.",
      "- Line 111: sum of Gaussian is a Gaussian.",
      "- Thm4.10: we have convergence on the scale of 0 to 1, and this is time compressed, meaning all the time is divided by T.",
      "When T increases, is the convergence still holds true? E.g. when there is a sample",
      "Will the following hold $$\rto^* - \that{\rto} = o(1/T)$$  This will ensure that the localization going close the place of change.",
      "At lease you don't want the  $T(\rto^* - \that{\rto}) \to \ty$ happen, which you may be far off eventually while still converging in the 0,1 scale.",
      "Even if this is a non-parametric method, the kernel choice is still depending on some structure assumptions.",
      "Can we have comparison between kernel choices (e.g. inner product on $\bb{R}^n$ versus general Gaussian kernel) so that we can get some insights on how the kernel choice affect the output?"
    ]
  },
  {
    "paper_id": "2002.06143v1",
    "submission_id": "zwkj1_pxFM",
    "submission_title": "A nonparametric method for gradual change problems with statistical guarantees",
    "review_id": "C25YES-5hTo",
    "input": {
      "title": "A nonparametric method for gradual change problems with statistical guarantees",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper tackles a very interesting problem.\n- This seems to be a good place to raise the larger issue I mentioned above re: related work.\n- As the authors acknowledge in the paper, their proposal is very similar to that of Vogt et al. (2015).\n- However, to me, it also appears to be very similar to that of Harchaoui et al., 2008, i.e., the method called 'KCpA' by the authors (essentially just without the covariance scaling of KCpA).\n- Therefore, I am a bit confused as to why KCpA performs so poorly in the experiments of Section 5.\n- Can the authors explain?\n- The authors mention that 'for fairness, we use the same kernel for [their two method(s) as well as KCPA]'; but that actually doesn't seem entirely fair to me, as different methods certainly have different operating characteristics.\n- At the very least, different bandwidths should probably be used, but I assume this did not happen, either.\n- On the technical side of the originality question, it seems to me that the proofs largely combine ideas that can already be found in the literature.\n- Overall, the paper is reasonably thorough and well put together, which I appreciate.\n- However, here are a few questions / issues that would be nice to see fixed, in any final version of the paper:\n- It seems that if allowing the $Y_t$, $t=1, ...\n- You could/should also report/study type 1 error, in your simulations.\n- That is, of course, an important part of the evaluation of any method.\n- How much does setting $\\rho^* = 1/3$ in Section 5 matter?\n- What if one does not know the value of the upper endpoint of the interval that contains $u$ (i.e., what if the '1' is unknown, in the display below line 48)?\n- Section 1: you might want to look into + cite 'trend filtering' methods here; they are very related.\n- Line 339: maybe a kind of combined method makes sense here, i.e., to get the advantages of both the abrupt and gradual changepoint methods.\n- The paper is well written.\n- As I mentioned above, I believe the paper certainly tackles an important (and under-investigated) problem.\n- It's not totally clear to me (yet) how novel the authors' contributions actually are, though.",
    "review_points_list": [
      "The paper tackles a very interesting problem.",
      "This seems to be a good place to raise the larger issue I mentioned above re: related work.",
      "As the authors acknowledge in the paper, their proposal is very similar to that of Vogt et al. (2015).",
      "However, to me, it also appears to be very similar to that of Harchaoui et al., 2008, i.e., the method called 'KCpA' by the authors (essentially just without the covariance scaling of KCpA).",
      "Therefore, I am a bit confused as to why KCpA performs so poorly in the experiments of Section 5.",
      "Can the authors explain?",
      "The authors mention that 'for fairness, we use the same kernel for [their two method(s) as well as KCPA]'; but that actually doesn't seem entirely fair to me, as different methods certainly have different operating characteristics.",
      "At the very least, different bandwidths should probably be used, but I assume this did not happen, either.",
      "On the technical side of the originality question, it seems to me that the proofs largely combine ideas that can already be found in the literature.",
      "Overall, the paper is reasonably thorough and well put together, which I appreciate.",
      "However, here are a few questions / issues that would be nice to see fixed, in any final version of the paper:",
      "It seems that if allowing the $Y_t$, $t=1, ...",
      "You could/should also report/study type 1 error, in your simulations.",
      "That is, of course, an important part of the evaluation of any method.",
      "How much does setting $\\rho^* = 1/3$ in Section 5 matter?",
      "What if one does not know the value of the upper endpoint of the interval that contains $u$ (i.e., what if the '1' is unknown, in the display below line 48)?",
      "Section 1: you might want to look into + cite 'trend filtering' methods here; they are very related.",
      "Line 339: maybe a kind of combined method makes sense here, i.e., to get the advantages of both the abrupt and gradual changepoint methods.",
      "The paper is well written.",
      "As I mentioned above, I believe the paper certainly tackles an important (and under-investigated) problem.",
      "It's not totally clear to me (yet) how novel the authors' contributions actually are, though."
    ]
  },
  {
    "paper_id": "1412.0156v1",
    "submission_id": "yehlf2AvSD_",
    "submission_title": "Mean-Square Analysis with An Application to Optimal Dimension Dependence of Langevin Monte Carlo",
    "review_id": "tsOugZ5MKwb",
    "input": {
      "title": "Mean-Square Analysis with An Application to Optimal Dimension Dependence of Langevin Monte Carlo",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This work is interesting; certainly the idea of reducing the problem of proving mixing time bounds to a simple computation of one step of discretization is quite appealing.\n- However, I do not find the results in this paper entirely convincing.\n- Without a higher-smoothness condition, the approach of this paper does not improve upon prior analyses of Langevin (in fact, the proof technique appears to be more brittle since it relies heavily on contractivity).\n- The main new result claimed in this paper is an improved dimension dependence under third-order smoothness condition, but it is possible that the third-order smoothness parameter hides some dimension dependence (see further comments below).\n- Abstract should be modified from \u201ca growth condition on the potential of target measures\u201d to \u201ca growth condition on the third derivative of the potential of target measures.\u201d\n- No attempt is made to compare the third-order derivative condition used in this paper with the Hessian Lipschitz condition used in prior works.\n- Although it may not be possible to compare these conditions in full generality, there should at least be some discussion of it.\n- The Hessian Lipschitz condition at least has the nice property that it \u201ctensorizes\u201d, in the sense that if f(x) = sum_i f_i(x_i) is coordinate-wise separable, with each f_i satisfying the Hessian Lipschitz condition with constant L, then the function f does too with the same constant L (and hence it is a \u201cdimension-independent\u201d condition); this is not true for the third-order condition in this paper.\n- From this it is not difficult to build examples where the constant G in this paper is much larger than the Hessian Lipschitz constant.\n- For example, we can take the coordinate-wise separable function f where each f_i is of the form f_i(x) = (x^2 + sin x)/2, and then the Hessian Lipschitz constant is O(1) whereas the parameter G of this paper scales as d^{\u00bd}.\n- These considerations make the claim of \u201coptimal dimension dependence of Langevin Monte Carlo\u201d rather unclear.\n- It seems premature to compare the dimension dependence of LMC with underdamped Langevin and MALA, both of which attain their dimension dependence without third-order conditions.\n- The authors seem to think that the third-order condition is a technical artefact which can be removed, but this is simply speculation at this point (it is possible that in the future we may see a lower bound construction which shows that the O(d) mixing time of LMC using only strong log-concavity and log-smoothness is in fact tight).\n- On Thm. 4.3 (lower bound on mixing time): Since m is set to 1 and L is set to 4, introducing the variables m and L makes the proof unnecessarily confusing (e.g. going from eq. (26) to (27) where all the m\u2019s disappear).\n- As another note, an alternative way to deduce (27) would be to use the expression for the bias of Langevin (computed in e.g. Example 2 of https://arxiv.org/abs/1802.08089) and to deduce that the step size cannot be set too large; this should hopefully simplify the calculation to the point where the lower bound can capture some dependence on the condition number (by considering a potential whose potential has d-1 eigenvalues which are m and 1 eigenvalue which is L), which would be interesting.\n- The experiments are not convincing since they do not plot the Wasserstein distance but rather the difference in means, which seems like an especially poor proxy for the Wasserstein distance.\n- Is it possible to at least plot an approximation of the Wasserstein distance, e.g. entropically-regularized Wasserstein distance?",
    "review_points_list": [
      "This work is interesting; certainly the idea of reducing the problem of proving mixing time bounds to a simple computation of one step of discretization is quite appealing.",
      "However, I do not find the results in this paper entirely convincing.",
      "Without a higher-smoothness condition, the approach of this paper does not improve upon prior analyses of Langevin (in fact, the proof technique appears to be more brittle since it relies heavily on contractivity).",
      "The main new result claimed in this paper is an improved dimension dependence under third-order smoothness condition, but it is possible that the third-order smoothness parameter hides some dimension dependence (see further comments below).",
      "Abstract should be modified from \u201ca growth condition on the potential of target measures\u201d to \u201ca growth condition on the third derivative of the potential of target measures.\u201d",
      "No attempt is made to compare the third-order derivative condition used in this paper with the Hessian Lipschitz condition used in prior works.",
      "Although it may not be possible to compare these conditions in full generality, there should at least be some discussion of it.",
      "The Hessian Lipschitz condition at least has the nice property that it \u201ctensorizes\u201d, in the sense that if f(x) = sum_i f_i(x_i) is coordinate-wise separable, with each f_i satisfying the Hessian Lipschitz condition with constant L, then the function f does too with the same constant L (and hence it is a \u201cdimension-independent\u201d condition); this is not true for the third-order condition in this paper.",
      "From this it is not difficult to build examples where the constant G in this paper is much larger than the Hessian Lipschitz constant.",
      "For example, we can take the coordinate-wise separable function f where each f_i is of the form f_i(x) = (x^2 + sin x)/2, and then the Hessian Lipschitz constant is O(1) whereas the parameter G of this paper scales as d^{\u00bd}.",
      "These considerations make the claim of \u201coptimal dimension dependence of Langevin Monte Carlo\u201d rather unclear.",
      "It seems premature to compare the dimension dependence of LMC with underdamped Langevin and MALA, both of which attain their dimension dependence without third-order conditions.",
      "The authors seem to think that the third-order condition is a technical artefact which can be removed, but this is simply speculation at this point (it is possible that in the future we may see a lower bound construction which shows that the O(d) mixing time of LMC using only strong log-concavity and log-smoothness is in fact tight).",
      "On Thm. 4.3 (lower bound on mixing time): Since m is set to 1 and L is set to 4, introducing the variables m and L makes the proof unnecessarily confusing (e.g. going from eq. (26) to (27) where all the m\u2019s disappear).",
      "As another note, an alternative way to deduce (27) would be to use the expression for the bias of Langevin (computed in e.g. Example 2 of https://arxiv.org/abs/1802.08089) and to deduce that the step size cannot be set too large; this should hopefully simplify the calculation to the point where the lower bound can capture some dependence on the condition number (by considering a potential whose potential has d-1 eigenvalues which are m and 1 eigenvalue which is L), which would be interesting.",
      "The experiments are not convincing since they do not plot the Wasserstein distance but rather the difference in means, which seems like an especially poor proxy for the Wasserstein distance.",
      "Is it possible to at least plot an approximation of the Wasserstein distance, e.g. entropically-regularized Wasserstein distance?"
    ]
  },
  {
    "paper_id": "1412.0156v1",
    "submission_id": "yehlf2AvSD_",
    "submission_title": "Mean-Square Analysis with An Application to Optimal Dimension Dependence of Langevin Monte Carlo",
    "review_id": "9M2d031YDVe",
    "input": {
      "title": "Mean-Square Analysis with An Application to Optimal Dimension Dependence of Langevin Monte Carlo",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Great customer service\n- Fast delivery\n- High-quality products\n- Easy to navigate website",
    "review_points_list": [
      "Great customer service",
      "Fast delivery",
      "High-quality products",
      "Easy to navigate website"
    ]
  },
  {
    "paper_id": "1412.0156v1",
    "submission_id": "yehlf2AvSD_",
    "submission_title": "Mean-Square Analysis with An Application to Optimal Dimension Dependence of Langevin Monte Carlo",
    "review_id": "DfJwlmlJOG7",
    "input": {
      "title": "Mean-Square Analysis with An Application to Optimal Dimension Dependence of Langevin Monte Carlo",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Looking at Theorem 4.1, the main result for the LMC, the authors establish an O(sqrt{d}) error bound.\n- They claim that this bound improves the best known O(d) bound established in several references.\n- However, looking at Theorem 8 of Durmus et al (2019b) (as referenced in Table 1), the error bound is derived in that paper is in terms of squared Wasserstein-2 (W_2^2) rather than Wasserstein 2 as in Theorem 4.1 of this paper.\n- Taking square roots in Theorem 8 of Durmus et al (2019b) gives a O(sqrt{d}) bound.\n- This is also confusing regarding the claims that underdamped MCMC is better than ULA.\n- I would really appreciate the clarification regarding this point and why the bound derived in this paper is better than Theorem 8 of Durmus et al (2019b) once a square root is taken.\n- Since this is the main claim of the paper, if this is incorrect, then the whole story needs to be rewritten.\n- My final evaluation will mostly depend on this and I am open to increase it given a clear rebuttal.\n- An obvious question is the verifiability of A2, i.e., for the examples considered, can you verify A2 and prove that it holds for simple scenarios, e.g., the one considered in Sec. 5?",
    "review_points_list": [
      "Looking at Theorem 4.1, the main result for the LMC, the authors establish an O(sqrt{d}) error bound.",
      "They claim that this bound improves the best known O(d) bound established in several references.",
      "However, looking at Theorem 8 of Durmus et al (2019b) (as referenced in Table 1), the error bound is derived in that paper is in terms of squared Wasserstein-2 (W_2^2) rather than Wasserstein 2 as in Theorem 4.1 of this paper.",
      "Taking square roots in Theorem 8 of Durmus et al (2019b) gives a O(sqrt{d}) bound.",
      "This is also confusing regarding the claims that underdamped MCMC is better than ULA.",
      "I would really appreciate the clarification regarding this point and why the bound derived in this paper is better than Theorem 8 of Durmus et al (2019b) once a square root is taken.",
      "Since this is the main claim of the paper, if this is incorrect, then the whole story needs to be rewritten.",
      "My final evaluation will mostly depend on this and I am open to increase it given a clear rebuttal.",
      "An obvious question is the verifiability of A2, i.e., for the examples considered, can you verify A2 and prove that it holds for simple scenarios, e.g., the one considered in Sec. 5?"
    ]
  },
  {
    "paper_id": "2105.12806v4",
    "submission_id": "z71OSKqTFh7",
    "submission_title": "A Universal Law of Robustness via Isoperimetry",
    "review_id": "zZ8gCQz5KJk",
    "input": {
      "title": "A Universal Law of Robustness via Isoperimetry",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors' use of visual aids is impressive and helps to clarify complex concepts.\n- The experimental results are well-presented and easy to understand.\n- The proposed method is novel and shows promising results.\n- The authors provide a clear overview of the state-of-the-art methods and how their proposed method differs.\n- The paper lacks a clear motivation for the proposed method.\n- The authors do not provide enough details about the experimental setup and the choice of hyperparameters.\n- The paper would benefit from a more extensive discussion of the limitations of the proposed method.\n- The authors do",
    "review_points_list": [
      "The authors' use of visual aids is impressive and helps to clarify complex concepts.",
      "The experimental results are well-presented and easy to understand.",
      "The proposed method is novel and shows promising results.",
      "The authors provide a clear overview of the state-of-the-art methods and how their proposed method differs.",
      "The paper lacks a clear motivation for the proposed method.",
      "The authors do not provide enough details about the experimental setup and the choice of hyperparameters.",
      "The paper would benefit from a more extensive discussion of the limitations of the proposed method.",
      "The authors do"
    ]
  },
  {
    "paper_id": "2105.12806v4",
    "submission_id": "z71OSKqTFh7",
    "submission_title": "A Universal Law of Robustness via Isoperimetry",
    "review_id": "gJQbFBdCN0p",
    "input": {
      "title": "A Universal Law of Robustness via Isoperimetry",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think this is a good paper and vote to accept it.\n- I find the result interesting\n- the paper proves a prior conjecture in the case of polynomially bounded weights.\n- I think the proof is intuitive\n- the paper clearly presented.",
    "review_points_list": [
      "I think this is a good paper and vote to accept it.",
      "I find the result interesting",
      "the paper proves a prior conjecture in the case of polynomially bounded weights.",
      "I think the proof is intuitive",
      "the paper clearly presented."
    ]
  },
  {
    "paper_id": "2105.12806v4",
    "submission_id": "z71OSKqTFh7",
    "submission_title": "A Universal Law of Robustness via Isoperimetry",
    "review_id": "20PNSice_9D",
    "input": {
      "title": "A Universal Law of Robustness via Isoperimetry",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The tasks and/or methods are not new.\n- The work is a direct follow-up of [BLN21] and the proof techniques regarding isometry and concentration are not new.\n- The main result is new and fairly interesting.\n- The submission is technically sound and the main theorems make sense.\n- A part that may need more explanation or refinement is the speculative discussion with MNIST and ImageNet.\n- The main results are stated with constants, and even though the law of robustness 'predicts any such model must have at least nd parameters', it is not clear if it is 100nd or 0.1nd; perhaps some additional clarification on the constant would be helpful.\n- Another part that I feel can be beneficial to add in the paper is a discussion on cases where the main results are tight; i.e., conditions where an if and only if result holds.\n- Additional discussion on the weaknesses of the work would also be helpful.\n- The paper is nicely written and organized.\n- I would think it would be more beneficial to use more of the pages to discuss the implications/significance of the results and put the proof in the supplementary (since the proof takes up almost half of the main text).\n- Some additional comments regarding typos are included in the Section 5 of this main review.\n- Two minor comments on clarity:\n- a. In Theorem 1, where perhaps it would be nice to add the dependence of epsilon in the equation.\n- b. In the abstract, particularly the last two sentences, 'We prove this universal law of robustness... this law was conjectured in prior work by Bubeck, Li and Nagaraj' gave me the impression that the work confirmed this conjecture for 2-layer NNs and Gaussian covariates, however, in Section 1.2 the authors clarify that 'Our results does not actually prove their conjecture,...'\n- I think it may be a good idea to change the text in the abstract to prevent this kind of subtle misinterpretation.\n- The results continues work on conjectures from prior work due to Bubeck, Li and Nagaraj, and from this theoretical perspective the results are important.\n- However, due to the pure theoretical nature of this work and plenty of the main text occupied by the proof, practical significance is a bit lacking, and perhaps this may be addressed in further revisions.\n- A minor typo is in Line 36, 'theoreof' perhaps should be 'thereof'.",
    "review_points_list": [
      "The tasks and/or methods are not new.",
      "The work is a direct follow-up of [BLN21] and the proof techniques regarding isometry and concentration are not new.",
      "The main result is new and fairly interesting.",
      "The submission is technically sound and the main theorems make sense.",
      "A part that may need more explanation or refinement is the speculative discussion with MNIST and ImageNet.",
      "The main results are stated with constants, and even though the law of robustness 'predicts any such model must have at least nd parameters', it is not clear if it is 100nd or 0.1nd; perhaps some additional clarification on the constant would be helpful.",
      "Another part that I feel can be beneficial to add in the paper is a discussion on cases where the main results are tight; i.e., conditions where an if and only if result holds.",
      "Additional discussion on the weaknesses of the work would also be helpful.",
      "The paper is nicely written and organized.",
      "I would think it would be more beneficial to use more of the pages to discuss the implications/significance of the results and put the proof in the supplementary (since the proof takes up almost half of the main text).",
      "Some additional comments regarding typos are included in the Section 5 of this main review.",
      "Two minor comments on clarity:",
      "a. In Theorem 1, where perhaps it would be nice to add the dependence of epsilon in the equation.",
      "b. In the abstract, particularly the last two sentences, 'We prove this universal law of robustness... this law was conjectured in prior work by Bubeck, Li and Nagaraj' gave me the impression that the work confirmed this conjecture for 2-layer NNs and Gaussian covariates, however, in Section 1.2 the authors clarify that 'Our results does not actually prove their conjecture,...'",
      "I think it may be a good idea to change the text in the abstract to prevent this kind of subtle misinterpretation.",
      "The results continues work on conjectures from prior work due to Bubeck, Li and Nagaraj, and from this theoretical perspective the results are important.",
      "However, due to the pure theoretical nature of this work and plenty of the main text occupied by the proof, practical significance is a bit lacking, and perhaps this may be addressed in further revisions.",
      "A minor typo is in Line 36, 'theoreof' perhaps should be 'thereof'."
    ]
  },
  {
    "paper_id": "2105.12806v4",
    "submission_id": "z71OSKqTFh7",
    "submission_title": "A Universal Law of Robustness via Isoperimetry",
    "review_id": "kcs6OcQ-fwt",
    "input": {
      "title": "A Universal Law of Robustness via Isoperimetry",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Establishing fundamental limits on adversarial robustness of function classes is an important open problem. This paper makes progress towards this mathematically challenging goal (albeit by lower bounding the global Lipschitz constant, whose precise relationship to the adversarial error remains unclear).\n- The proof technique is relatively elementary, but innovative. In particular it makes elegant use of the isoperimetry property (which by definition is connected to Lipschitz-ness). Because of the ultimate application of parameter counting, it is also very generally applicable to arbitrary parametric function classes and shows insightfully that the number of parameters fundamentally bottlenecks a smoothness guarantee subject to fitting a non-zero amount of noise.\n- This proof technique could be useful to study the generalization error of interpolating solutions for generic function classes beyond the adversarial examples problem.\n- As discussed in Section 1.1 of the paper, it is very unclear whether the global Lipschitz constant is fundamentally related to the adversarial generalization error: intuitively, their relationship would depend on more fine-grained quantities such as the distribution of the Lipschitz constant over the data domain.\n- In fact one can construct toy scenarios using 1-D data and polynomial features for which the global Lipschitz constant could worsen with overparameterization, but generalization error (clean or adversarial) might improve depending on the overall distribution of the local Lipschitz constants.\n- Question for authors: do you think there is any possibility of studying these more fine-grained properties in the future, that might be more reflective of adversarial error, as a consequence of this approach?\n- The results would also be stronger if matching, or at least close upper bounds could be provided, i.e. there exists a function within the function class that has sufficiently small Lipschitz constant that decays with overparameterization.\n- This would be required to make the definitive case that overparameterization actually allows us to find functions with a small global Lipschitz constant (which is in fact sufficient for low adversarial error).\n- Alternatively, this would shed light on whether a low Lipschitz constant is reasonable to expect and necessary for adversarial robustness; either way, it would be of interest.\n- Perhaps this is possible via an anti-concentration approach, but it would also require characterizing the size of the set of globally L-smooth functions in the function class (which is not needed for the lower bound as one can simply upper bound this by the size of the function class itself).\n- Do the authors think their techniques could be used for an upper bound in the future for the same problem; if so, how?\n- The techniques are currently presented for Lipschitz constant with respect to l2-norm: the more standard quantity in the adversarial robustness literature is the infinity-norm.\n- The authors mention in Section 1.1 that they believe that a variant of the law of robustness would also hold for the infinity-norm, but they do not provide details on this (in particular I am not sure if the techniques will be similar for the case of distributions over manifolds).\n- The minor caveats/additional context that could be added in the paper: because of the centrality of the union bounding approach to the proof, the techniques appear unlikely to shed light on the smoothness of specific functions that interpolate training data and arise in practice (e.g. variously regularized neural nets such as minimum-norm, minimum-path-norm, etc).\n- The results critically constrain the function class to be fitting a non-zero amount of noise, which may not always be the case in practice.\n- A short discussion on whether these results might imply a small Lipschitz constant on regularized function classes and/or noiseless data might be a good addition to the paper.",
    "review_points_list": [
      "Establishing fundamental limits on adversarial robustness of function classes is an important open problem. This paper makes progress towards this mathematically challenging goal (albeit by lower bounding the global Lipschitz constant, whose precise relationship to the adversarial error remains unclear).",
      "The proof technique is relatively elementary, but innovative. In particular it makes elegant use of the isoperimetry property (which by definition is connected to Lipschitz-ness). Because of the ultimate application of parameter counting, it is also very generally applicable to arbitrary parametric function classes and shows insightfully that the number of parameters fundamentally bottlenecks a smoothness guarantee subject to fitting a non-zero amount of noise.",
      "This proof technique could be useful to study the generalization error of interpolating solutions for generic function classes beyond the adversarial examples problem.",
      "As discussed in Section 1.1 of the paper, it is very unclear whether the global Lipschitz constant is fundamentally related to the adversarial generalization error: intuitively, their relationship would depend on more fine-grained quantities such as the distribution of the Lipschitz constant over the data domain.",
      "In fact one can construct toy scenarios using 1-D data and polynomial features for which the global Lipschitz constant could worsen with overparameterization, but generalization error (clean or adversarial) might improve depending on the overall distribution of the local Lipschitz constants.",
      "Question for authors: do you think there is any possibility of studying these more fine-grained properties in the future, that might be more reflective of adversarial error, as a consequence of this approach?",
      "The results would also be stronger if matching, or at least close upper bounds could be provided, i.e. there exists a function within the function class that has sufficiently small Lipschitz constant that decays with overparameterization.",
      "This would be required to make the definitive case that overparameterization actually allows us to find functions with a small global Lipschitz constant (which is in fact sufficient for low adversarial error).",
      "Alternatively, this would shed light on whether a low Lipschitz constant is reasonable to expect and necessary for adversarial robustness; either way, it would be of interest.",
      "Perhaps this is possible via an anti-concentration approach, but it would also require characterizing the size of the set of globally L-smooth functions in the function class (which is not needed for the lower bound as one can simply upper bound this by the size of the function class itself).",
      "Do the authors think their techniques could be used for an upper bound in the future for the same problem; if so, how?",
      "The techniques are currently presented for Lipschitz constant with respect to l2-norm: the more standard quantity in the adversarial robustness literature is the infinity-norm.",
      "The authors mention in Section 1.1 that they believe that a variant of the law of robustness would also hold for the infinity-norm, but they do not provide details on this (in particular I am not sure if the techniques will be similar for the case of distributions over manifolds).",
      "The minor caveats/additional context that could be added in the paper: because of the centrality of the union bounding approach to the proof, the techniques appear unlikely to shed light on the smoothness of specific functions that interpolate training data and arise in practice (e.g. variously regularized neural nets such as minimum-norm, minimum-path-norm, etc).",
      "The results critically constrain the function class to be fitting a non-zero amount of noise, which may not always be the case in practice.",
      "A short discussion on whether these results might imply a small Lipschitz constant on regularized function classes and/or noiseless data might be a good addition to the paper."
    ]
  },
  {
    "paper_id": "2305.14454v1",
    "submission_id": "y7l4h5xtaqQ",
    "submission_title": "A variational approximate posterior for the deep Wishart process",
    "review_id": "bfLbMklY6rs",
    "input": {
      "title": "A variational approximate posterior for the deep Wishart process",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- DKPs have a good property of preserving the symmetries in latent features that standard variational inference for DGPs does not.\n- Earlier work developed variational inference method for deep inverse Wishart processes which has a different prior distribution from deep GPs.\n- This work provides a variational inference method for deep Wishard processes so that one can compare the performance of DWPs with DGPs side by side.\n- This is a nice contribution to the research in DKPs.\n- The main novelty of this inference method is introducing the generalised Wishart distribution, while the application of doubly-stochstic inducing-point inference is mostly standard.\n- To better assess the significance of introducing the inference algorithm for DWPs, I think it would be useful to compare also the result of DIWPs.\n- After all, we would like to find a flexible probabilistic model to have a high log-likelihood (or approximately ELBO) on train and test set.\n- The derivation of the generalised Wishart distribution based on Bartlett decomposition and its application in the variational inference algorithm looks good to me although I haven't checked the detailed derivation in the appendix.\n- I have a question about the use of generalised Wishart distribution as the approximate posterior distribution.\n- Do we know if the true posterior distribution of the Gram matrix has at most \\nu ranks or it could actually be higher than that?\n- If the rank in the posterior could go higher, shall we consider the \\nu parameter in Q as another hyper-parameter to tune?\n- Besides, could the authors comment on the capacity of the generalised Wishart distribution?\n- How does the flexibility / capacity compare with the Gaussian approximation in DGPs besides its ability to model symmetries?\n- The authors provide sufficient background to understand deep Wishart processes and the proposed approximate posterior distribution.\n- The methods section also provides an appropriate level of details in the main text to understand its algorithm.\n- For the experiment section, I would appreciate more analysis of the inference results beyond simply comparing the ELBO and test log-likelihood.\n- It would be very helpful if the authors could show the difference in the inferred posterior using DWP and DGP.\n- After all, the advantage of using DWPs versus DIWPs is that we can have a more direct comparison with DGPs but Table 1 doesn't give much information beside a better ELBO score.\n- The authors mentioned the computational complexity is lower than the for DGPs because it doesn't have to sample for each latent feature dimension separately.\n- Does it mean the runtime of the proposed method is indeed lower than that for DGPs?\n- If so, it would also be nice to show the improvement of the runtime in the experiments.",
    "review_points_list": [
      "DKPs have a good property of preserving the symmetries in latent features that standard variational inference for DGPs does not.",
      "Earlier work developed variational inference method for deep inverse Wishart processes which has a different prior distribution from deep GPs.",
      "This work provides a variational inference method for deep Wishard processes so that one can compare the performance of DWPs with DGPs side by side.",
      "This is a nice contribution to the research in DKPs.",
      "The main novelty of this inference method is introducing the generalised Wishart distribution, while the application of doubly-stochstic inducing-point inference is mostly standard.",
      "To better assess the significance of introducing the inference algorithm for DWPs, I think it would be useful to compare also the result of DIWPs.",
      "After all, we would like to find a flexible probabilistic model to have a high log-likelihood (or approximately ELBO) on train and test set.",
      "The derivation of the generalised Wishart distribution based on Bartlett decomposition and its application in the variational inference algorithm looks good to me although I haven't checked the detailed derivation in the appendix.",
      "I have a question about the use of generalised Wishart distribution as the approximate posterior distribution.",
      "Do we know if the true posterior distribution of the Gram matrix has at most \\nu ranks or it could actually be higher than that?",
      "If the rank in the posterior could go higher, shall we consider the \\nu parameter in Q as another hyper-parameter to tune?",
      "Besides, could the authors comment on the capacity of the generalised Wishart distribution?",
      "How does the flexibility / capacity compare with the Gaussian approximation in DGPs besides its ability to model symmetries?",
      "The authors provide sufficient background to understand deep Wishart processes and the proposed approximate posterior distribution.",
      "The methods section also provides an appropriate level of details in the main text to understand its algorithm.",
      "For the experiment section, I would appreciate more analysis of the inference results beyond simply comparing the ELBO and test log-likelihood.",
      "It would be very helpful if the authors could show the difference in the inferred posterior using DWP and DGP.",
      "After all, the advantage of using DWPs versus DIWPs is that we can have a more direct comparison with DGPs but Table 1 doesn't give much information beside a better ELBO score.",
      "The authors mentioned the computational complexity is lower than the for DGPs because it doesn't have to sample for each latent feature dimension separately.",
      "Does it mean the runtime of the proposed method is indeed lower than that for DGPs?",
      "If so, it would also be nice to show the improvement of the runtime in the experiments."
    ]
  },
  {
    "paper_id": "2305.14454v1",
    "submission_id": "y7l4h5xtaqQ",
    "submission_title": "A variational approximate posterior for the deep Wishart process",
    "review_id": "Z7c3U_aDF-E",
    "input": {
      "title": "A variational approximate posterior for the deep Wishart process",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think that the manuscript has certain contributions, one of which is developing the variational inference method for the DWP by proposing a distribution over positive semi-definite matrices based on the singular Bartlett decomposition.\n- Although the propose method is not super new, the method does not seem to be trivial.\n- I did not check every derivation but the method looks technically sound.\n- However, I am concerned that this work might not attract broad interest.\n- The manuscript proposes an inference method (which is not entirely different or new from previous work) to a specific model formulation.\n- In addition, the experimental results section includes only toy datasets and a DGP as a comparison method.\n- It is understandable that the manuscript attempts comparing the proposed method to the corresponding DGP model based on the connection between both formulations, but at the same time this approach would limit the significance of the proposed work.\n- Readers cannot be convinced about the effectiveness of the proposed method to real-world problems.\n- It was at the first read a little bit difficult to understand how the proposed distribution (eq. 27) works since the scale parameter \\bSigma does not appear in the distribution.\n- It would be helpful if there was a reminder that the Cholesky \\bL is calculated from the scale parameter around eq. 27.",
    "review_points_list": [
      "I think that the manuscript has certain contributions, one of which is developing the variational inference method for the DWP by proposing a distribution over positive semi-definite matrices based on the singular Bartlett decomposition.",
      "Although the propose method is not super new, the method does not seem to be trivial.",
      "I did not check every derivation but the method looks technically sound.",
      "However, I am concerned that this work might not attract broad interest.",
      "The manuscript proposes an inference method (which is not entirely different or new from previous work) to a specific model formulation.",
      "In addition, the experimental results section includes only toy datasets and a DGP as a comparison method.",
      "It is understandable that the manuscript attempts comparing the proposed method to the corresponding DGP model based on the connection between both formulations, but at the same time this approach would limit the significance of the proposed work.",
      "Readers cannot be convinced about the effectiveness of the proposed method to real-world problems.",
      "It was at the first read a little bit difficult to understand how the proposed distribution (eq. 27) works since the scale parameter \\bSigma does not appear in the distribution.",
      "It would be helpful if there was a reminder that the Cholesky \\bL is calculated from the scale parameter around eq. 27."
    ]
  },
  {
    "paper_id": "2305.14454v1",
    "submission_id": "y7l4h5xtaqQ",
    "submission_title": "A variational approximate posterior for the deep Wishart process",
    "review_id": "ysCA7pOZW4-",
    "input": {
      "title": "A variational approximate posterior for the deep Wishart process",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The motivation for why the DWP is superior to the DGP seems to be that the variational posterior that it has access to can encode the symmetry constraint in the posterior.\n- Excluding this initial motivation and the introduced methods, there is very little theory giving any kind of theoretical guarantees.\n- I am also not convinced that this motivation is sufficient to justify an entirely new inference scheme, given that the current empirical evaluation is a bit limited.\n- Are there any other reasons why we would prefer to do inference with a DWP versus a DGP?\n- As currently written, the paper seems to assume a certain familiarity with the original deep kernel processes in its motivation, which is not (yet) a mainstream model.\n- In order to make the message more direct to the reader I would suggest only briefly mentioning deep kernel processes and then focussing on the DWP.\n- The paper is not the easiest to read.\n- I enjoyed section 2.\n- In section 3, I would prefer a self-contained theorem characterising the generalised singular Wishart distribution, which for the reader doing their first pass, could be used as a abstract tool to understand the rest of the paper.\n- Do all the equations need to be numbered? It seems like many are never referred to in the main text.\n- You only compared the DWP to a DGP with squared exponential kernel.\n- Arguably you have removed the flexibility that the DGP has in that it can use non-isotropic kernels.\n- For a fair comparison, the DGP should have access to non-isotropic kernels.\n- I believe the authors should be more upfront about the requirement that the kernel is isotropic in the abstract, as this is a relatively strong constraint.\n- The authors state that 'We mainly consider isotropic kernels', but as far as I can tell, they exclusively consider isotropic kernels.",
    "review_points_list": [
      "The motivation for why the DWP is superior to the DGP seems to be that the variational posterior that it has access to can encode the symmetry constraint in the posterior.",
      "Excluding this initial motivation and the introduced methods, there is very little theory giving any kind of theoretical guarantees.",
      "I am also not convinced that this motivation is sufficient to justify an entirely new inference scheme, given that the current empirical evaluation is a bit limited.",
      "Are there any other reasons why we would prefer to do inference with a DWP versus a DGP?",
      "As currently written, the paper seems to assume a certain familiarity with the original deep kernel processes in its motivation, which is not (yet) a mainstream model.",
      "In order to make the message more direct to the reader I would suggest only briefly mentioning deep kernel processes and then focussing on the DWP.",
      "The paper is not the easiest to read.",
      "I enjoyed section 2.",
      "In section 3, I would prefer a self-contained theorem characterising the generalised singular Wishart distribution, which for the reader doing their first pass, could be used as a abstract tool to understand the rest of the paper.",
      "Do all the equations need to be numbered? It seems like many are never referred to in the main text.",
      "You only compared the DWP to a DGP with squared exponential kernel.",
      "Arguably you have removed the flexibility that the DGP has in that it can use non-isotropic kernels.",
      "For a fair comparison, the DGP should have access to non-isotropic kernels.",
      "I believe the authors should be more upfront about the requirement that the kernel is isotropic in the abstract, as this is a relatively strong constraint.",
      "The authors state that 'We mainly consider isotropic kernels', but as far as I can tell, they exclusively consider isotropic kernels."
    ]
  },
  {
    "paper_id": "2305.14454v1",
    "submission_id": "y7l4h5xtaqQ",
    "submission_title": "A variational approximate posterior for the deep Wishart process",
    "review_id": "GSNAZCqv0Lz",
    "input": {
      "title": "A variational approximate posterior for the deep Wishart process",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The submission is interesting and technically sound.\n- The clarity of exposition is generally high and the work is contextualized with respect to related lines of work in the literature.\n- The empirical benefits w.r.t. predictive performance of the proposed model and inference scheme are limited when compared to Deep Gaussian Processes.\n- The fully kernelized approach is taken, which is interesting.\n- The resulting scheme differs in a non-trivial way from more featurized representation commonly used in various approaches to deep Bayesian models.\n- The computational complexity does not depend on layer width.\n- Some notation in the paper is unclear.\n- The notation 'V_' should be changed to uppercase 'V' everywhere.\n- Equation (163) has a potential mistake.\n- Section 3.1 might be too detailed.\n- It might be better to move some details to the supplementary material.\n- The sampling scheme has a high gradient variance.\n- The gradient variance is a direct consequence of maintaining a kernelized approach.\n- The comment about Salimbeni & Deisenroth (2017) is unclear.\n- It's unclear if the problem is with model specification or inference.\n- The issue should be disentangled.\n- Sufficiently deep DWP models may exhibit pathologies similar to those in e.g. 'Avoiding pathologies in very deep networks' by Duvenaud et. al.",
    "review_points_list": [
      "The submission is interesting and technically sound.",
      "The clarity of exposition is generally high and the work is contextualized with respect to related lines of work in the literature.",
      "The empirical benefits w.r.t. predictive performance of the proposed model and inference scheme are limited when compared to Deep Gaussian Processes.",
      "The fully kernelized approach is taken, which is interesting.",
      "The resulting scheme differs in a non-trivial way from more featurized representation commonly used in various approaches to deep Bayesian models.",
      "The computational complexity does not depend on layer width.",
      "Some notation in the paper is unclear.",
      "The notation 'V_' should be changed to uppercase 'V' everywhere.",
      "Equation (163) has a potential mistake.",
      "Section 3.1 might be too detailed.",
      "It might be better to move some details to the supplementary material.",
      "The sampling scheme has a high gradient variance.",
      "The gradient variance is a direct consequence of maintaining a kernelized approach.",
      "The comment about Salimbeni & Deisenroth (2017) is unclear.",
      "It's unclear if the problem is with model specification or inference.",
      "The issue should be disentangled.",
      "Sufficiently deep DWP models may exhibit pathologies similar to those in e.g. 'Avoiding pathologies in very deep networks' by Duvenaud et. al."
    ]
  },
  {
    "paper_id": "2111.04295v1",
    "submission_id": "ulqMdBThHsC",
    "submission_title": "The Hardness Analysis of Thompson Sampling for Combinatorial Semi-bandits with Greedy Oracle",
    "review_id": "hE5Q4gVx_kJ",
    "input": {
      "title": "The Hardness Analysis of Thompson Sampling for Combinatorial Semi-bandits with Greedy Oracle",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper addresses an interesting theoretical question and presents nice results: a regret lower bound together with an almost matching upper bound.\n- The results are interesting, and the paper is well written.\n- I'm not fully convinced that it is de facto standard to use greedy approximation oracles in each round of combinatorial semi-bandit.\n- For example, most online submodular maximization algorithms do not simply use offline greedy oracles; they are tailored to the online setting.\n- Therefore, I cannot see how significant the hardness result is, which focuses only on the case with greedy oracles (In my opinion, the hardness result would be stronger if lower bounds are obtained for general cases where offline oracles with certain approximation guarantees are available).\n- The original definition of the greedy regret in [22] does not have $\\\text{max}(\\ast, 0)$.\n- It seems that making the instantaneous regret in each $t$-th round non-negative makes it easier to prove the hardness result.\n- Is it possible to obtain the lower bound for the original greedy regret without $\\text{max}(\\ast, 0)$?",
    "review_points_list": [
      "This paper addresses an interesting theoretical question and presents nice results: a regret lower bound together with an almost matching upper bound.",
      "The results are interesting, and the paper is well written.",
      "I'm not fully convinced that it is de facto standard to use greedy approximation oracles in each round of combinatorial semi-bandit.",
      "For example, most online submodular maximization algorithms do not simply use offline greedy oracles; they are tailored to the online setting.",
      "Therefore, I cannot see how significant the hardness result is, which focuses only on the case with greedy oracles (In my opinion, the hardness result would be stronger if lower bounds are obtained for general cases where offline oracles with certain approximation guarantees are available).",
      "The original definition of the greedy regret in [22] does not have $\\\text{max}(\\ast, 0)$.",
      "It seems that making the instantaneous regret in each $t$-th round non-negative makes it easier to prove the hardness result.",
      "Is it possible to obtain the lower bound for the original greedy regret without $\\text{max}(\\ast, 0)$?"
    ]
  },
  {
    "paper_id": "2111.04295v1",
    "submission_id": "ulqMdBThHsC",
    "submission_title": "The Hardness Analysis of Thompson Sampling for Combinatorial Semi-bandits with Greedy Oracle",
    "review_id": "TgIKjd6Ncv2",
    "input": {
      "title": "The Hardness Analysis of Thompson Sampling for Combinatorial Semi-bandits with Greedy Oracle",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper has two notable contributions: first, it provides stronger guarantees for the Cluster-Margin algorithm compared to standard CMAB guarantees.\n- The derived bounds compare the played action to the best greedy action, which is always better than $(1-1/e)OPT$.\n- Therefore, the provided guarantees are stronger than the standard CMAB guarantees.\n- To the best of my knowledge, the only paper that derives such guarantees is [22], where the algorithm is intractable.\n- A notable contribution of this paper is in analyzing a tractable algorithm (CTS) for this performance criterion.\n- This kind of guarantee adds an \u2018oracle-problem dependent\u2019 flavor, i.e., compares to the performance of the oracle on the specific problem and not its worst-case guarantees.\n- The second contribution of this work is that the authors prove these guarantees to CTS.\n- In particular, it shows that the linear regret lower bounds of [30] do not hold for any approximation oracle and breaks the misconception that CTS cannot be used with approximation oracles.\n- On the other hand, there are a few issues with this work.\n- First, I believe that the lower bound doesn\u2019t hold specifically to TS and that similar arguments should allow deriving lower bound to any (reasonable) algorithm.\n- This is not discussed in the paper and creates the (possibly wrong) impression that TS-based algorithms are inherently worse than UCB-based algorithms for CMABs.\n- In some sense, I am not convinced that the \u2018story\u2019 of the paper is the hardness of TS in the standard CMAB setting (with approximation regret), but rather a positive result on the greedy regret.\n- I think this might be an interesting alternative story, but it requires drastic changes in the paper.\n- As a side effect, I think that the lower bound is weaker than it should be.\n- The lower bound is proven on a small-scale problem.\n- Therefore, it does not allow understanding the right dependence in problem-constants.\n- Another issue is the specific combination of TS with a greedy oracle.\n- As I see it, the main advantage of TS in CMAB problems is that it allows working with non-monotone reward functions.\n- As far as I know, greedy oracles have provable guarantees mainly (only?) for monotone (and submodular) combinatorial functions.\n- Therefore, even though this is probably the most common family of oracles, the results do not allow using one of the greatest advantages of TS in this setting.\n- Finally, the requirement that $\bs{{\textstyle\boldsymbol{\boldsymbol{\textstyle\boldsymbol{\boldsymbol \boldsymbol{\boldsymbol \boldsymbol{\boldsymbol{\bs{\textstyle\bs{\boldsymbol{\textstyle \bs{\boldsymbol{\bs \textstyle\bs{\textstyle \bs{\bs{\bs{\bs{\bs{\bs{\bs{\bs\bs{\bs\bs{\bs{\bs\bs\bs\bs{\bs\bs\bs\bs\bs\bs\bs\bs\bs ...\n- The paper is well written and I didn\u2019t see any critical issues.\n- I find it hard to compare the resulting bounds to previous works, as the gaps are differently defined.\n- One interesting thing that got my attention is that the bound does not directly depend on K, in contrast to the \u2018classical\u2019 bounds of [7].\n- Do you think that it stems from the different regret definition, gap definition, the maximization over $k$, or maybe from the dominating effect of $1/\bs{\boldsymbol\boldsymbol{\bs{\boldsymbol\bs\bs{\bs{\bs\bs{\bs{\bs{\bs{ ...\n- I would love to see a more thorough comparison of the bounds to previous work (including the lower bounds of [22] that I already mentioned and their upper bounds).\n- The set of all possible actions seems a bit nonstandard \u2013 can you say something about its relation to standard sets (e.g., it contains the uniform matroid, but what about other matroids/standard sets?)\n- In multiple places, there are references to the OIM and PMC problems.\n- First, I think that many readers would require some additional explanation on the problems (and maybe writing explicit reward functions).\n- Moreover, even though OIM is mentioned numerous times, the authors only actually work with the PMC problem.\n- Also, to the best of my knowledge, OIM usually requires probabilistically triggered arms.\n- Thus, for clarity\u2019s sake, I think it would be beneficial to either only write on PMC problems or give a more concrete example of a different instance of OIM.",
    "review_points_list": [
      "This paper has two notable contributions: first, it provides stronger guarantees for the Cluster-Margin algorithm compared to standard CMAB guarantees.",
      "The derived bounds compare the played action to the best greedy action, which is always better than $(1-1/e)OPT$.",
      "Therefore, the provided guarantees are stronger than the standard CMAB guarantees.",
      "To the best of my knowledge, the only paper that derives such guarantees is [22], where the algorithm is intractable.",
      "A notable contribution of this paper is in analyzing a tractable algorithm (CTS) for this performance criterion.",
      "This kind of guarantee adds an \u2018oracle-problem dependent\u2019 flavor, i.e., compares to the performance of the oracle on the specific problem and not its worst-case guarantees.",
      "The second contribution of this work is that the authors prove these guarantees to CTS.",
      "In particular, it shows that the linear regret lower bounds of [30] do not hold for any approximation oracle and breaks the misconception that CTS cannot be used with approximation oracles.",
      "On the other hand, there are a few issues with this work.",
      "First, I believe that the lower bound doesn\u2019t hold specifically to TS and that similar arguments should allow deriving lower bound to any (reasonable) algorithm.",
      "This is not discussed in the paper and creates the (possibly wrong) impression that TS-based algorithms are inherently worse than UCB-based algorithms for CMABs.",
      "In some sense, I am not convinced that the \u2018story\u2019 of the paper is the hardness of TS in the standard CMAB setting (with approximation regret), but rather a positive result on the greedy regret.",
      "I think this might be an interesting alternative story, but it requires drastic changes in the paper.",
      "As a side effect, I think that the lower bound is weaker than it should be.",
      "The lower bound is proven on a small-scale problem.",
      "Therefore, it does not allow understanding the right dependence in problem-constants.",
      "Another issue is the specific combination of TS with a greedy oracle.",
      "As I see it, the main advantage of TS in CMAB problems is that it allows working with non-monotone reward functions.",
      "As far as I know, greedy oracles have provable guarantees mainly (only?) for monotone (and submodular) combinatorial functions.",
      "Therefore, even though this is probably the most common family of oracles, the results do not allow using one of the greatest advantages of TS in this setting.",
      "Finally, the requirement that $\bs{{\textstyle\boldsymbol{\boldsymbol{\textstyle\boldsymbol{\boldsymbol \boldsymbol{\boldsymbol \boldsymbol{\boldsymbol{\bs{\textstyle\bs{\boldsymbol{\textstyle \bs{\boldsymbol{\bs \textstyle\bs{\textstyle \bs{\bs{\bs{\bs{\bs{\bs{\bs{\bs\bs{\bs\bs{\bs{\bs\bs\bs\bs{\bs\bs\bs\bs\bs\bs\bs\bs\bs ...",
      "The paper is well written and I didn\u2019t see any critical issues.",
      "I find it hard to compare the resulting bounds to previous works, as the gaps are differently defined.",
      "One interesting thing that got my attention is that the bound does not directly depend on K, in contrast to the \u2018classical\u2019 bounds of [7].",
      "Do you think that it stems from the different regret definition, gap definition, the maximization over $k$, or maybe from the dominating effect of $1/\bs{\boldsymbol\boldsymbol{\bs{\boldsymbol\bs\bs{\bs{\bs\bs{\bs{\bs{\bs{ ...",
      "I would love to see a more thorough comparison of the bounds to previous work (including the lower bounds of [22] that I already mentioned and their upper bounds).",
      "The set of all possible actions seems a bit nonstandard \u2013 can you say something about its relation to standard sets (e.g., it contains the uniform matroid, but what about other matroids/standard sets?)",
      "In multiple places, there are references to the OIM and PMC problems.",
      "First, I think that many readers would require some additional explanation on the problems (and maybe writing explicit reward functions).",
      "Moreover, even though OIM is mentioned numerous times, the authors only actually work with the PMC problem.",
      "Also, to the best of my knowledge, OIM usually requires probabilistically triggered arms.",
      "Thus, for clarity\u2019s sake, I think it would be beneficial to either only write on PMC problems or give a more concrete example of a different instance of OIM."
    ]
  },
  {
    "paper_id": "2111.04295v1",
    "submission_id": "ulqMdBThHsC",
    "submission_title": "The Hardness Analysis of Thompson Sampling for Combinatorial Semi-bandits with Greedy Oracle",
    "review_id": "NrMTCEoDiXp",
    "input": {
      "title": "The Hardness Analysis of Thompson Sampling for Combinatorial Semi-bandits with Greedy Oracle",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Almost all analyses of TS under the CMAB setting consider exact oracles. This paper is first to show theoretically that TS is still a viable algorithm for such CMAB applications, which is a highly valuable contribution.\n- The paper shows an upper bound of O(log T/\u0394^2) for TS with a greedy oracle.\n- While upper bounds of the form O(log T/\u0394) are more common in the bandit literature, Theorem 1 shows that this bound is actually tight with respect to \u0394.\n- The paper does not actually reveal anything regarding the hardness of optimizing greedy regret while the paper is phrased like it does.\n- It is still not clear whether O(log T/\u0394^2) is the best possible greedy regret achievable by any algorithm, or a UCB-based algorithm can still achieve O(log T/\u0394) greedy regret.\n- As authors have already pointed out in their paper, when a greedy oracle also happens to be an \u03b1-approximation oracle, the greedy regret would be larger than the \u03b1-approximation regret, meaning existing upper bounds on the \u03b1-approximation regret of UCB-based algorithms do not answer this question.\n- Knowing TS with a greedy oracle can achieve O(log T/\u0394^2) greedy regret does not imply it can also achieve O(log T/\u0394) \u03b1-approximation regret, when the greedy oracle also happens to be an \u03b1-approximation oracle.\n- Having said that, I still believe a tight upper bound on the greedy regret of TS for CMAB is still a significant enough contribution on its own.\n- Until this paper, whether TS with a greedy oracle is even effective in solving CMAB problems was unknown theoretically.\n- Now, the new question is whether TS with a greedy oracle is as effective as UCB-based algorithms, which is probably outside the scope of this paper.\n- My only concern is about Section 6.2, extending the analysis in Theorem 2 to the multiple-solution case.\n- It is true that S_g always being the solution with the minimum reward would be the worst case if we were to evaluate performance in terms of actual regret measured with respect to the actual optimal solution.\n- When considering the greedy regret instead, if we assume S_g is always the minimum reward solution, then we would also be measuring performance with respect to argmin_{S\frac{in\theta K} r(S,\u03bc).\n- This is not necessarily the case when the regret is the largest (for instance when S_g is such that S_g=argmax_{S in \theta K} r(S,\u03bc) and S_g=argmin_{S in \theta K} r(S,theta) for all theta\u2260\u03bc, the greedy regret would be larger).\n- However, I think the same analysis in Section 6.2 should also be possible for any deterministic function f such that S_g=f(\theta K).",
    "review_points_list": [
      "Almost all analyses of TS under the CMAB setting consider exact oracles. This paper is first to show theoretically that TS is still a viable algorithm for such CMAB applications, which is a highly valuable contribution.",
      "The paper shows an upper bound of O(log T/\u0394^2) for TS with a greedy oracle.",
      "While upper bounds of the form O(log T/\u0394) are more common in the bandit literature, Theorem 1 shows that this bound is actually tight with respect to \u0394.",
      "The paper does not actually reveal anything regarding the hardness of optimizing greedy regret while the paper is phrased like it does.",
      "It is still not clear whether O(log T/\u0394^2) is the best possible greedy regret achievable by any algorithm, or a UCB-based algorithm can still achieve O(log T/\u0394) greedy regret.",
      "As authors have already pointed out in their paper, when a greedy oracle also happens to be an \u03b1-approximation oracle, the greedy regret would be larger than the \u03b1-approximation regret, meaning existing upper bounds on the \u03b1-approximation regret of UCB-based algorithms do not answer this question.",
      "Knowing TS with a greedy oracle can achieve O(log T/\u0394^2) greedy regret does not imply it can also achieve O(log T/\u0394) \u03b1-approximation regret, when the greedy oracle also happens to be an \u03b1-approximation oracle.",
      "Having said that, I still believe a tight upper bound on the greedy regret of TS for CMAB is still a significant enough contribution on its own.",
      "Until this paper, whether TS with a greedy oracle is even effective in solving CMAB problems was unknown theoretically.",
      "Now, the new question is whether TS with a greedy oracle is as effective as UCB-based algorithms, which is probably outside the scope of this paper.",
      "My only concern is about Section 6.2, extending the analysis in Theorem 2 to the multiple-solution case.",
      "It is true that S_g always being the solution with the minimum reward would be the worst case if we were to evaluate performance in terms of actual regret measured with respect to the actual optimal solution.",
      "When considering the greedy regret instead, if we assume S_g is always the minimum reward solution, then we would also be measuring performance with respect to argmin_{S\frac{in\theta K} r(S,\u03bc).",
      "This is not necessarily the case when the regret is the largest (for instance when S_g is such that S_g=argmax_{S in \theta K} r(S,\u03bc) and S_g=argmin_{S in \theta K} r(S,theta) for all theta\u2260\u03bc, the greedy regret would be larger).",
      "However, I think the same analysis in Section 6.2 should also be possible for any deterministic function f such that S_g=f(\theta K)."
    ]
  },
  {
    "paper_id": "2111.04295v1",
    "submission_id": "ulqMdBThHsC",
    "submission_title": "The Hardness Analysis of Thompson Sampling for Combinatorial Semi-bandits with Greedy Oracle",
    "review_id": "yqvQ-mBvmf-",
    "input": {
      "title": "The Hardness Analysis of Thompson Sampling for Combinatorial Semi-bandits with Greedy Oracle",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well-written.\n- The research question is well-motivated and practically relevant (as greedy algorithms are common choices for approximately solving hard combinatorial optimization problems).\n- While a similar research question has already been studied in Lin et al. [22], the framework considered in that paper is different from the framework studied in this paper, and the two papers focus on different types of algorithms (UCB vs. Thompson sampling).\n- The results of this paper seem to be technically correct.\n- I have the following questions/concerns:\n- 1. The lower bound is algorithm-dependent, which means that it only holds for the CTS algorithm.\n- While this result does provide interesting insights on the behavior of CTS, a natural question is whether such a fundamental limit also exists for other algorithms.\n- In other words, I feel that an information-theoretic lower bound could greatly improve the quality of the paper and provide more insights on the proposed framework.\n- 2. Currently, the algorithm uses a Beta prior (to obtain the upper bound), but the lower bound is shown for the Gaussian prior.\n- This seems like a limitation.\n- Can the authors provide matching upper and lower bounds for the same prior, or provide some explanations on deriving upper and lower bounds using different priors is not an issue?\n- 2. A main insight of this paper is that using TS-type algorithms to solve CMAB with a greedy oracle may necessarily lead to a larger regret bound (with worse dependence on the reward gap)\n- I note that the paper considers the worst-case regret.\n- Can the authors provide some insights on whether such phenomena still exist when the Bayesian regret is considered?\n- I note that the current lower bound does not directly imply a Bayesian regret lower bound (as the constructed instance is not \"Gaussian\")",
    "review_points_list": [
      "The paper is well-written.",
      "The research question is well-motivated and practically relevant (as greedy algorithms are common choices for approximately solving hard combinatorial optimization problems).",
      "While a similar research question has already been studied in Lin et al. [22], the framework considered in that paper is different from the framework studied in this paper, and the two papers focus on different types of algorithms (UCB vs. Thompson sampling).",
      "The results of this paper seem to be technically correct.",
      "I have the following questions/concerns:",
      "1. The lower bound is algorithm-dependent, which means that it only holds for the CTS algorithm.",
      "While this result does provide interesting insights on the behavior of CTS, a natural question is whether such a fundamental limit also exists for other algorithms.",
      "In other words, I feel that an information-theoretic lower bound could greatly improve the quality of the paper and provide more insights on the proposed framework.",
      "2. Currently, the algorithm uses a Beta prior (to obtain the upper bound), but the lower bound is shown for the Gaussian prior.",
      "This seems like a limitation.",
      "Can the authors provide matching upper and lower bounds for the same prior, or provide some explanations on deriving upper and lower bounds using different priors is not an issue?",
      "2. A main insight of this paper is that using TS-type algorithms to solve CMAB with a greedy oracle may necessarily lead to a larger regret bound (with worse dependence on the reward gap)",
      "I note that the paper considers the worst-case regret.",
      "Can the authors provide some insights on whether such phenomena still exist when the Bayesian regret is considered?",
      "I note that the current lower bound does not directly imply a Bayesian regret lower bound (as the constructed instance is not \"Gaussian\")"
    ]
  },
  {
    "paper_id": "2106.07263v3",
    "submission_id": "w5fW0TNWPyc",
    "submission_title": "Machine Learning for Variance Reduction in Online Experiments",
    "review_id": "m7JLiY2y8jX",
    "input": {
      "title": "Machine Learning for Variance Reduction in Online Experiments",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper does a good job of placing itself within the existing literature and improving one part of existing methods.\n- Existing work [18] already presented an OLS estimate of the average treatment effect; this work adds additional flexibility to the terms of the OLS estimate, to allow for arbitrary predictors of $Y_i$ using the features $X_i$.\n- The paper is well-scoped, discussing both the theoretical aspects of the estimator (asymptotic properties, correct confidence intervals) and demonstrating success empirically.\n- I particularly liked how the exposition and notation clearly emphasized the important parts of the asymptotic analysis: specifically, the convergence of functions of $\text{hat{g}}_k$ to functions of $g_0$.\n- The only aspect of the estimator that I would have liked to see discussed in more detail was the choice of the cross-fitting hyperparameter $K$.\n- The authors note in Remark 4 that the choice of $K$ may matter in finite samples although it isn't important asymptotically.\n- I had imagined that the choice $K=N$ would have given the largest variance reduction (since the most data is then used to train each $\text{hat{g}}_k$), so I was surprised to see that $K=2$ was the only choice considered for the experiments.\n- I would appreciate some discussion of the tradeoffs in choosing $K$ in finite samples - are there any downsides to increasing $K$ besides increased computation?\n- I also have several smaller comments for the authors:\n- - In both the simulated and real data results, the proposed method is compared to the differences-in-means baseline and the CUPED baseline. My reading of the experiments section is that the baselines got to use all $N$ data points (ie, they were not subject to cross-fitting), whereas the MLRATE estimator trained each $\text{hat{g}}_k$ on $N/2$ data points.\n- I just wanted to confirm that this is how the experiment was run, since it has implications for the interpretation of the later claim that 'the univariate procedure would require sample sizes 1.56 times as large'.\n- On line 188, the word 'the' is repeated.\n- Figure 1a really only shows three numbers (the CI can be derived from the variance and vice versa).\n- I wonder if there is a more meaningful way to show the data in Figure 1.\n- For example, you could extend Figure 1b to 'facet' in two directions, 'estimator' ~ 'baseline', and then there would be a blank plot in 'CUPED' x 'CUPED'.\n- This is just one suggestion, and by no means the only one, but I would encourage you to think about how to best use the space you have available to communicate your results.\n- I found the paper very readable, thank you for spending time on the writing.\n- Thank you for your thoughtful response, especially regarding the choice of $K$. I appreciated your detailed consideration of this question, and remain supportive of the work.",
    "review_points_list": [
      "This paper does a good job of placing itself within the existing literature and improving one part of existing methods.",
      "Existing work [18] already presented an OLS estimate of the average treatment effect; this work adds additional flexibility to the terms of the OLS estimate, to allow for arbitrary predictors of $Y_i$ using the features $X_i$.",
      "The paper is well-scoped, discussing both the theoretical aspects of the estimator (asymptotic properties, correct confidence intervals) and demonstrating success empirically.",
      "I particularly liked how the exposition and notation clearly emphasized the important parts of the asymptotic analysis: specifically, the convergence of functions of $\text{hat{g}}_k$ to functions of $g_0$.",
      "The only aspect of the estimator that I would have liked to see discussed in more detail was the choice of the cross-fitting hyperparameter $K$.",
      "The authors note in Remark 4 that the choice of $K$ may matter in finite samples although it isn't important asymptotically.",
      "I had imagined that the choice $K=N$ would have given the largest variance reduction (since the most data is then used to train each $\text{hat{g}}_k$), so I was surprised to see that $K=2$ was the only choice considered for the experiments.",
      "I would appreciate some discussion of the tradeoffs in choosing $K$ in finite samples - are there any downsides to increasing $K$ besides increased computation?",
      "I also have several smaller comments for the authors:",
      "- In both the simulated and real data results, the proposed method is compared to the differences-in-means baseline and the CUPED baseline. My reading of the experiments section is that the baselines got to use all $N$ data points (ie, they were not subject to cross-fitting), whereas the MLRATE estimator trained each $\text{hat{g}}_k$ on $N/2$ data points.",
      "I just wanted to confirm that this is how the experiment was run, since it has implications for the interpretation of the later claim that 'the univariate procedure would require sample sizes 1.56 times as large'.",
      "On line 188, the word 'the' is repeated.",
      "Figure 1a really only shows three numbers (the CI can be derived from the variance and vice versa).",
      "I wonder if there is a more meaningful way to show the data in Figure 1.",
      "For example, you could extend Figure 1b to 'facet' in two directions, 'estimator' ~ 'baseline', and then there would be a blank plot in 'CUPED' x 'CUPED'.",
      "This is just one suggestion, and by no means the only one, but I would encourage you to think about how to best use the space you have available to communicate your results.",
      "I found the paper very readable, thank you for spending time on the writing.",
      "Thank you for your thoughtful response, especially regarding the choice of $K$. I appreciated your detailed consideration of this question, and remain supportive of the work."
    ]
  },
  {
    "paper_id": "2106.07263v3",
    "submission_id": "w5fW0TNWPyc",
    "submission_title": "Machine Learning for Variance Reduction in Online Experiments",
    "review_id": "TUYmV7aOQLw",
    "input": {
      "title": "Machine Learning for Variance Reduction in Online Experiments",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Great service and friendly staff\n- Excellent food quality\n- Cozy atmosphere\n- Reasonable prices\n- Will definitely visit again",
    "review_points_list": [
      "Great service and friendly staff",
      "Excellent food quality",
      "Cozy atmosphere",
      "Reasonable prices",
      "Will definitely visit again"
    ]
  },
  {
    "paper_id": "2106.07263v3",
    "submission_id": "w5fW0TNWPyc",
    "submission_title": "Machine Learning for Variance Reduction in Online Experiments",
    "review_id": "5ZIhfppoSi6",
    "input": {
      "title": "Machine Learning for Variance Reduction in Online Experiments",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is extremely well-written and is a pleasure to read. The motivation, the estimation strategy, the assumptions, and the theoretical results are presented very clearly.\n- The authors have spent a lot of time polishing this paper.\n- I liked the discussion about implementation issues at Facebook.\n- Nevertheless, I am a bit hesitant about this paper, for the following reason.\n- This specific research area (improving estimates from randomized controlled trials using potentially high-dimensional adjustments) has been congested for a few years already.\n- The authors explain in the related work section, what is new in their proposal compared to existing works.\n- However, I believe that stronger practical and/or theoretical evidence would be required to demonstrate that the new estimator is not just a minor variation of all these existing works.\n- On the practical side, the new method is only compared against simple baselines (difference in means and CUPED).\n- What about all the other estimators that use adjustments based on ML methods?\n- On the theory side, it appears to me that the assumptions are made that simplify the proofs as much as possible, and are not the ones that would make a strong case for the advantages of the new method.\n- The most important motivation for this work appears to be the fact that the method works well even if the predictive models are bad.\n- The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.\n- The paper is very clear and well organized.\n- The authors detail the hyper-parameters and compute details used for the experiments.\n- The Cluster-Margin algorithm is also explained in detail.\n- The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods.\n- The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.\n- The most important motivation for this work appears to be the fact that the method works well even if the predictive models are bad.\n- Finite-sample theory (ala Berry\u2013Esseen) that does not require that the models settle down asymptotically would be very elegant in the present setting.\n- Would it be possible to give a more concrete condition that implies the (uniformly) minimum eigenvalue condition on $Z(g)Z(g)^\top$, using the specific structure of the studied model (randomized controlled trial)?\n- The model studied is a superpopulation model with $(Y_i, X_i, T_i)$ drawn as independent and identically distributed samples from a superpopulation distribution.\n- My sense of the field studying randomized controlled trials is that this model is typically considered to be a starting point in which results are 'easy' to prove.\n- The ultimate goal for inferential validity (Athey and Imbens, 2017, The econometrics of randomized experiments) however often is to provide inferential guarantees treating the potential outcomes and covariates as fixed, and conducting inference using only the randomness in the treatment assignment mechanism.\n- The fact that here a superpopulation model is studied, is an important limitation compared to these other recent works.\n- Could the results also be generalized when only treatment assignment is random?\n- After reading the response, I have raised my score to 5 from 4.\n- I particularly appreciate simplifying the assumption I mentioned in question 3) above; the simplification is elegant and interpretable.\n- Also I appreciate the clarifications to some of my other questions.\n- I still however am not convinced that the new method would outperform existing methods in practice (e.g., in the application at Facebook),\n- The only argument in favor of MLRATE as far as I can tell is the fact that it is never worse (asymptotically) than difference-in-means.\n- I am not convinced of the practical importance of this result (it seems that it would only be relevant if the ML engineers/data scientists fitting the ML model did a really bad job,",
    "review_points_list": [
      "The paper is extremely well-written and is a pleasure to read. The motivation, the estimation strategy, the assumptions, and the theoretical results are presented very clearly.",
      "The authors have spent a lot of time polishing this paper.",
      "I liked the discussion about implementation issues at Facebook.",
      "Nevertheless, I am a bit hesitant about this paper, for the following reason.",
      "This specific research area (improving estimates from randomized controlled trials using potentially high-dimensional adjustments) has been congested for a few years already.",
      "The authors explain in the related work section, what is new in their proposal compared to existing works.",
      "However, I believe that stronger practical and/or theoretical evidence would be required to demonstrate that the new estimator is not just a minor variation of all these existing works.",
      "On the practical side, the new method is only compared against simple baselines (difference in means and CUPED).",
      "What about all the other estimators that use adjustments based on ML methods?",
      "On the theory side, it appears to me that the assumptions are made that simplify the proofs as much as possible, and are not the ones that would make a strong case for the advantages of the new method.",
      "The most important motivation for this work appears to be the fact that the method works well even if the predictive models are bad.",
      "The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.",
      "The paper is very clear and well organized.",
      "The authors detail the hyper-parameters and compute details used for the experiments.",
      "The Cluster-Margin algorithm is also explained in detail.",
      "The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods.",
      "The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.",
      "The most important motivation for this work appears to be the fact that the method works well even if the predictive models are bad.",
      "Finite-sample theory (ala Berry\u2013Esseen) that does not require that the models settle down asymptotically would be very elegant in the present setting.",
      "Would it be possible to give a more concrete condition that implies the (uniformly) minimum eigenvalue condition on $Z(g)Z(g)^\top$, using the specific structure of the studied model (randomized controlled trial)?",
      "The model studied is a superpopulation model with $(Y_i, X_i, T_i)$ drawn as independent and identically distributed samples from a superpopulation distribution.",
      "My sense of the field studying randomized controlled trials is that this model is typically considered to be a starting point in which results are 'easy' to prove.",
      "The ultimate goal for inferential validity (Athey and Imbens, 2017, The econometrics of randomized experiments) however often is to provide inferential guarantees treating the potential outcomes and covariates as fixed, and conducting inference using only the randomness in the treatment assignment mechanism.",
      "The fact that here a superpopulation model is studied, is an important limitation compared to these other recent works.",
      "Could the results also be generalized when only treatment assignment is random?",
      "After reading the response, I have raised my score to 5 from 4.",
      "I particularly appreciate simplifying the assumption I mentioned in question 3) above; the simplification is elegant and interpretable.",
      "Also I appreciate the clarifications to some of my other questions.",
      "I still however am not convinced that the new method would outperform existing methods in practice (e.g., in the application at Facebook),",
      "The only argument in favor of MLRATE as far as I can tell is the fact that it is never worse (asymptotically) than difference-in-means.",
      "I am not convinced of the practical importance of this result (it seems that it would only be relevant if the ML engineers/data scientists fitting the ML model did a really bad job,"
    ]
  },
  {
    "paper_id": "2106.07263v3",
    "submission_id": "w5fW0TNWPyc",
    "submission_title": "Machine Learning for Variance Reduction in Online Experiments",
    "review_id": "iRNA5VNUyJZ",
    "input": {
      "title": "Machine Learning for Variance Reduction in Online Experiments",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper combines several existing elements to construct a method that has multiple advantages.\n- The main novelty is this crafty combination.\n- The individual concepts, on the other hand, are all viewed as known to an extent.\n- The use of cross-fitting to avoid overfitting is widely known.\n- The main structure of their estimator which first estimates a nonlinear model (i.e., the machine learning step) and then calibrates it in a linear regression is motivated from Cohen and Fogarty (2020).\n- The proposed estimator appears advantageous on multiple fronts, all justified by theory.\n- First it allows for general prediction models.\n- Second, the estimator is easy to implement, including the confidence interval.\n- Third, the estimator is robust which is important for practical use:\n- If the prediction model is good, then the estimator could reduce the variance compared to the baseline estimator; if the prediction model is bad, the asymptotic behavior is no worse than the baseline.\n- This paper is well organized.\n- All the theoretical results are stated clearly and easy to read, and the authors also provide good intuition before presenting the technical details.\n- The proposed estimator appears significant, theoretically sound and easy to use, and the experimental results further support its practical merits.\n- In the statement of Corollary 1 and Proposition 3, the assumption $0<p<1$ in Proposition 2 seems to be also needed.\n- In line 216 on page 6, I'm not sure how the quantity $\text{\textsigma}^{2}/[\text{\textsigma}_{Y_{C}}/(1-p)+\text{\textsigma}_{Y_{T}}^{2}/p]$ is simplified as $1-\text{Corr}(Y,g_{0}(X))^{2}$ in the special case considered in this paragraph.\n- The authors should clarify or correct it.\n- At the end of Section 3, the authors say their algorithm applies equally to the high-dimensional regime, but without evidence.\n- The authors may want to provide high-dimensional experimental results or tone down this claim.\n- Page 4, footnote: constant$\rightarrow$ deterministic",
    "review_points_list": [
      "The paper combines several existing elements to construct a method that has multiple advantages.",
      "The main novelty is this crafty combination.",
      "The individual concepts, on the other hand, are all viewed as known to an extent.",
      "The use of cross-fitting to avoid overfitting is widely known.",
      "The main structure of their estimator which first estimates a nonlinear model (i.e., the machine learning step) and then calibrates it in a linear regression is motivated from Cohen and Fogarty (2020).",
      "The proposed estimator appears advantageous on multiple fronts, all justified by theory.",
      "First it allows for general prediction models.",
      "Second, the estimator is easy to implement, including the confidence interval.",
      "Third, the estimator is robust which is important for practical use:",
      "If the prediction model is good, then the estimator could reduce the variance compared to the baseline estimator; if the prediction model is bad, the asymptotic behavior is no worse than the baseline.",
      "This paper is well organized.",
      "All the theoretical results are stated clearly and easy to read, and the authors also provide good intuition before presenting the technical details.",
      "The proposed estimator appears significant, theoretically sound and easy to use, and the experimental results further support its practical merits.",
      "In the statement of Corollary 1 and Proposition 3, the assumption $0<p<1$ in Proposition 2 seems to be also needed.",
      "In line 216 on page 6, I'm not sure how the quantity $\text{\textsigma}^{2}/[\text{\textsigma}_{Y_{C}}/(1-p)+\text{\textsigma}_{Y_{T}}^{2}/p]$ is simplified as $1-\text{Corr}(Y,g_{0}(X))^{2}$ in the special case considered in this paragraph.",
      "The authors should clarify or correct it.",
      "At the end of Section 3, the authors say their algorithm applies equally to the high-dimensional regime, but without evidence.",
      "The authors may want to provide high-dimensional experimental results or tone down this claim.",
      "Page 4, footnote: constant$\rightarrow$ deterministic"
    ]
  },
  {
    "paper_id": "2108.07387v1",
    "submission_id": "uOxe0CHI5dq",
    "submission_title": "Contextual Similarity Aggregation with Self-attention for Visual Re-ranking",
    "review_id": "1gTe94iEO6a",
    "input": {
      "title": "Contextual Similarity Aggregation with Self-attention for Visual Re-ranking",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- A new re-ranking method is proposed in this paper, the proposed method differs to previous works by extracting contextual similarity from top-K images and refining them with an attention-based model.\n- Different kinds of re-ranking methods have been included in the related work, but the discussion about the relationship between the proposed work and previous works is missing.\n- The proposed method is clearly described, the contribution of each component is well demonstrated in the ablation studies.\n- Comparison with state-of-the-art methods have also been given to support the effectiveness and generality of the proposed method.\n- Time and memory complexity comparison is provided.\n- Overall, the paper is super clear and well structured.\n- What is the dimension of the learnable projection matrix $W_M$, and what is the size of vector $h_i$ ? (L154-156)\n- What is $S' and how do we initialize it ? (L163)\n- What does the entry of *Affinity Feature* means? And maybe merge the second block and the third block of QE methods by having two lines for each QE such as AQE and AQE + DBA.\n- Seeing the importance of this parameter in the contrastive loss, maybe include an ablation study of this hyper-parameter to show how robust is the method against this hyper-param.\n- The well-designed and easy-to-use re-ranking method could benefit many related applications.\n- Besides, the usage of affinity feature and attention-based encoder could help the community understands better the effectiveness of transformer-based architecture in retrieval tasks.",
    "review_points_list": [
      "A new re-ranking method is proposed in this paper, the proposed method differs to previous works by extracting contextual similarity from top-K images and refining them with an attention-based model.",
      "Different kinds of re-ranking methods have been included in the related work, but the discussion about the relationship between the proposed work and previous works is missing.",
      "The proposed method is clearly described, the contribution of each component is well demonstrated in the ablation studies.",
      "Comparison with state-of-the-art methods have also been given to support the effectiveness and generality of the proposed method.",
      "Time and memory complexity comparison is provided.",
      "Overall, the paper is super clear and well structured.",
      "What is the dimension of the learnable projection matrix $W_M$, and what is the size of vector $h_i$ ? (L154-156)",
      "What is $S' and how do we initialize it ? (L163)",
      "What does the entry of *Affinity Feature* means? And maybe merge the second block and the third block of QE methods by having two lines for each QE such as AQE and AQE + DBA.",
      "Seeing the importance of this parameter in the contrastive loss, maybe include an ablation study of this hyper-parameter to show how robust is the method against this hyper-param.",
      "The well-designed and easy-to-use re-ranking method could benefit many related applications.",
      "Besides, the usage of affinity feature and attention-based encoder could help the community understands better the effectiveness of transformer-based architecture in retrieval tasks."
    ]
  },
  {
    "paper_id": "2108.07387v1",
    "submission_id": "uOxe0CHI5dq",
    "submission_title": "Contextual Similarity Aggregation with Self-attention for Visual Re-ranking",
    "review_id": "aOnevVzTtR1",
    "input": {
      "title": "Contextual Similarity Aggregation with Self-attention for Visual Re-ranking",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper introduces a re-ranking algorithm for content-based image retrieval.\n- As mentioned above, the proposed procedure yields performance improvements both in terms of precision and computational complexity.\n- These improvements were shown in several benchmark datasets.\n- The proposed method is interesting as it seeks to *learn* how to best aggregate and re-rank the outputs of a similarity-based retrieval system.\n- I am overall positive about the paper.\n- Nevertheless, I hope the authors can clarify/address the two following points.\n- I will adjust my final recommendation based on that.\n- The paper claims to introduce a new data augmentation technique for training the re-ranking model.\n- However, this seems to be using different CNN backbones to generate multiple features for each image, and treat these features as augmentations.\n- This technique does improve performance significantly.\n- However, I'm wondering if the improvements are mostly due to the use of multiple backbones, as in the case of ensembles (often used for competitions)?\n- Is the proposed method using all backbones at test time, or only one?\n- If only one, which one?\n- If not, how did you ensure a fair comparison to other methods (since it would be similar to an ensemble)?\n- The fixed number of anchors reduces the time complexity of the proposed procedure without affecting its precision.\n- Table 2 also shows that the method is not too sensitive to this parameter.\n- However, I'm concerned whether this is because evaluations are being done on datasets with a relatively low number of concepts, and so a small set of anchors can cover all the concepts.\n- Would there be a significant performance hit if the method was applied to datasets with a large number of concepts like ImageNet?\n- Would the method need a much large number of anchors in order to maintain high performance?\n- And if so, wouldn't the computational gains be diminished?\n- After carefully considering all inputs on the paper, I will increase my rating to 7.\n- The paper makes progress in content-based image retrieval, both in terms of precision and computational complexity, by improving upon prior re-ranking algorithms.\n- The authors also addressed my main concerns about the fairness of their comparisons.\n- I strongly suggest the authors to clearly articulate in the paper how the algorithm operates during deployment (in order to avoid such confusions in the future).",
    "review_points_list": [
      "The paper introduces a re-ranking algorithm for content-based image retrieval.",
      "As mentioned above, the proposed procedure yields performance improvements both in terms of precision and computational complexity.",
      "These improvements were shown in several benchmark datasets.",
      "The proposed method is interesting as it seeks to *learn* how to best aggregate and re-rank the outputs of a similarity-based retrieval system.",
      "I am overall positive about the paper.",
      "Nevertheless, I hope the authors can clarify/address the two following points.",
      "I will adjust my final recommendation based on that.",
      "The paper claims to introduce a new data augmentation technique for training the re-ranking model.",
      "However, this seems to be using different CNN backbones to generate multiple features for each image, and treat these features as augmentations.",
      "This technique does improve performance significantly.",
      "However, I'm wondering if the improvements are mostly due to the use of multiple backbones, as in the case of ensembles (often used for competitions)?",
      "Is the proposed method using all backbones at test time, or only one?",
      "If only one, which one?",
      "If not, how did you ensure a fair comparison to other methods (since it would be similar to an ensemble)?",
      "The fixed number of anchors reduces the time complexity of the proposed procedure without affecting its precision.",
      "Table 2 also shows that the method is not too sensitive to this parameter.",
      "However, I'm concerned whether this is because evaluations are being done on datasets with a relatively low number of concepts, and so a small set of anchors can cover all the concepts.",
      "Would there be a significant performance hit if the method was applied to datasets with a large number of concepts like ImageNet?",
      "Would the method need a much large number of anchors in order to maintain high performance?",
      "And if so, wouldn't the computational gains be diminished?",
      "After carefully considering all inputs on the paper, I will increase my rating to 7.",
      "The paper makes progress in content-based image retrieval, both in terms of precision and computational complexity, by improving upon prior re-ranking algorithms.",
      "The authors also addressed my main concerns about the fairness of their comparisons.",
      "I strongly suggest the authors to clearly articulate in the paper how the algorithm operates during deployment (in order to avoid such confusions in the future)."
    ]
  },
  {
    "paper_id": "2108.07387v1",
    "submission_id": "uOxe0CHI5dq",
    "submission_title": "Contextual Similarity Aggregation with Self-attention for Visual Re-ranking",
    "review_id": "9-0TexqGK5I",
    "input": {
      "title": "Contextual Similarity Aggregation with Self-attention for Visual Re-ranking",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper proposes to aggregate the contextual similarities between the query image and the top-ranked candidates for image reranking using a transformer based model.\n- The proposed method is technically sound.\n- The proposed method is also more flexible in the sense that only the affinity vector for each image is used.\n- It also enables cross-feature based data augmentation.\n- The paper is easy to follow.\n- The proposed method is shown to be superior or at least complementary to state-of-the-art query expansion/diffusion based reranking methods.\n- Ablations on several components (e.g. # of images to be reranked, # of anchor images, data augmentation, etc) are also included.\n- For the comparisons shown in Table 5, I wonder if the scores of the baselines are from their original papers or re-training/re-testing/re-implementation?\n- For example, the mAP for GSS[22] on RParis Medium is {92.4}/{88.9} in {the original paper}/{this paper}.\n- For the comparisons shown in Table 5, I wonder if the proposed method and the baselines are evaluated under similar settings?\n- For example, i) are they using the same initial ranking lists?\n- ii) are they using the same feature extractor, i.e. R-GeM?\n- Given the concerns listed above, I\u2019d like to rate the paper as \u201cmarginally below the acceptance threshold\u201d at this moment.\n- Table 5, DSM [9] \u2192 DSM [40]\n- I have read the reviews and the authors' replies.\n- In general, I think the idea of using only the affinity vectors for reranking is interesting.\n- It makes it possible to reuse the pretrained reranking model for different feature extractors.\n- The authors also addressed my concerns on the evaluation: if all the methods were tested under the same setting.\n- Therefore, I raise my score and vote for accepting the paper.",
    "review_points_list": [
      "The paper proposes to aggregate the contextual similarities between the query image and the top-ranked candidates for image reranking using a transformer based model.",
      "The proposed method is technically sound.",
      "The proposed method is also more flexible in the sense that only the affinity vector for each image is used.",
      "It also enables cross-feature based data augmentation.",
      "The paper is easy to follow.",
      "The proposed method is shown to be superior or at least complementary to state-of-the-art query expansion/diffusion based reranking methods.",
      "Ablations on several components (e.g. # of images to be reranked, # of anchor images, data augmentation, etc) are also included.",
      "For the comparisons shown in Table 5, I wonder if the scores of the baselines are from their original papers or re-training/re-testing/re-implementation?",
      "For example, the mAP for GSS[22] on RParis Medium is {92.4}/{88.9} in {the original paper}/{this paper}.",
      "For the comparisons shown in Table 5, I wonder if the proposed method and the baselines are evaluated under similar settings?",
      "For example, i) are they using the same initial ranking lists?",
      "ii) are they using the same feature extractor, i.e. R-GeM?",
      "Given the concerns listed above, I\u2019d like to rate the paper as \u201cmarginally below the acceptance threshold\u201d at this moment.",
      "Table 5, DSM [9] \u2192 DSM [40]",
      "I have read the reviews and the authors' replies.",
      "In general, I think the idea of using only the affinity vectors for reranking is interesting.",
      "It makes it possible to reuse the pretrained reranking model for different feature extractors.",
      "The authors also addressed my concerns on the evaluation: if all the methods were tested under the same setting.",
      "Therefore, I raise my score and vote for accepting the paper."
    ]
  },
  {
    "paper_id": "2108.07387v1",
    "submission_id": "uOxe0CHI5dq",
    "submission_title": "Contextual Similarity Aggregation with Self-attention for Visual Re-ranking",
    "review_id": "HoyoTMbtch0",
    "input": {
      "title": "Contextual Similarity Aggregation with Self-attention for Visual Re-ranking",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is somewhat incremental from the work of [16].\n- The paper is barely above the threshold.\n- The paper is generally easy to follow.\n- There are some technical details I could not understand completely.\n- I'm asking some clarifying questions to the authors below.\n- The proposed method and decisions seem reasonable as well.\n- There are some decisions I find somewhat surprising, though.\n- I'll ask clarifying questions below.\n- The method clearly outperforms existing approaches by a significant margin on two standard benchmarks (plus augmented versions).\n- The model achieves good results both on rOxford and rParis using the same model.\n- This is not common (typically, models that work on one dataset tend to fail in the other due to differences in statistics within the datasets, for example number of relevant images per query)!\n- On the negative side, I wish the authors could have reported results on more datasets (e.g. Instre).\n- I've seen many papers accepted reporting results only on rOxford and rParis, so this is not grounds for rejection, but I wish the authors would consider including those results as well.\n- Pytorch code was provided, which will help other researchers build on top of this work.\n- Thank you authors for making the code available.\n- It seems to me (and please authors correct me if I'm wrong) that some hyper parameters are validated directly on test.\n- This is a barely-discussed, dark standard practice in the retrieval community.\n- I am not going to strongly penalize the authors for this when essentially every other paper gets away with it.\n- However, I'd urge the authors to reconsider validating the hyper parameters in rSfM120k or other dataset (and perhaps add the results validating in rOxf in the supplementary material)\n- It was unclear under which circumstances different features were used.\n- Was this used only to augment the training data by generating different lists of top-k results, or was it also used to generate different affinity features?\n- Also, does this happen only at training time, or also at test time?\n- I understand that no form of database augmentation (e.g. DBA) is happening, is that correct?\n- Can you elaborate a bit more about the need for the MSE loss?\n- It is unclear to me why we'd want the refined features to be similar to the original features (condition on an MLP transformation).\n- Seems like an adhoc decision.\n- Did you experiment training this reranking model in GL18 (since that's where the features seem to be coming from)?\n- Not asking the authors to do this experiment if they didn't, just wondering if they actually did it and if there's any insight (e.g. performing worse because of more overfit).",
    "review_points_list": [
      "The paper is somewhat incremental from the work of [16].",
      "The paper is barely above the threshold.",
      "The paper is generally easy to follow.",
      "There are some technical details I could not understand completely.",
      "I'm asking some clarifying questions to the authors below.",
      "The proposed method and decisions seem reasonable as well.",
      "There are some decisions I find somewhat surprising, though.",
      "I'll ask clarifying questions below.",
      "The method clearly outperforms existing approaches by a significant margin on two standard benchmarks (plus augmented versions).",
      "The model achieves good results both on rOxford and rParis using the same model.",
      "This is not common (typically, models that work on one dataset tend to fail in the other due to differences in statistics within the datasets, for example number of relevant images per query)!",
      "On the negative side, I wish the authors could have reported results on more datasets (e.g. Instre).",
      "I've seen many papers accepted reporting results only on rOxford and rParis, so this is not grounds for rejection, but I wish the authors would consider including those results as well.",
      "Pytorch code was provided, which will help other researchers build on top of this work.",
      "Thank you authors for making the code available.",
      "It seems to me (and please authors correct me if I'm wrong) that some hyper parameters are validated directly on test.",
      "This is a barely-discussed, dark standard practice in the retrieval community.",
      "I am not going to strongly penalize the authors for this when essentially every other paper gets away with it.",
      "However, I'd urge the authors to reconsider validating the hyper parameters in rSfM120k or other dataset (and perhaps add the results validating in rOxf in the supplementary material)",
      "It was unclear under which circumstances different features were used.",
      "Was this used only to augment the training data by generating different lists of top-k results, or was it also used to generate different affinity features?",
      "Also, does this happen only at training time, or also at test time?",
      "I understand that no form of database augmentation (e.g. DBA) is happening, is that correct?",
      "Can you elaborate a bit more about the need for the MSE loss?",
      "It is unclear to me why we'd want the refined features to be similar to the original features (condition on an MLP transformation).",
      "Seems like an adhoc decision.",
      "Did you experiment training this reranking model in GL18 (since that's where the features seem to be coming from)?",
      "Not asking the authors to do this experiment if they didn't, just wondering if they actually did it and if there's any insight (e.g. performing worse because of more overfit)."
    ]
  },
  {
    "paper_id": "2007.08792v4",
    "submission_id": "wg_kD_nyAF",
    "submission_title": "Uncertainty Quantification and Deep Ensembles",
    "review_id": "Mpi_u_spOcS",
    "input": {
      "title": "Uncertainty Quantification and Deep Ensembles",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The author response clarifies some of the issues I had raised -- I therefore increase my score from weak rejection (5) to weak acceptance (6).\n- I am still hesitant to recommend acceptance more enthusiastically due to the remaining issue of a low methodological contribution.\n- This paper tackles an important open problem in practical deep learning (which is of significant interest to the NeurIPS community), namely how to obtain models that are well calibrated and therefore robust.\n- It provides a comprehensive and well-executed empirical study with conclusive results and actionable suggestions that will be useful to deep learning practitioners.\n- The manuscript is also very well-written and easy to follow.\n- However, the methodological contribution and novelty is rather low, and the scope of the evaluation somewhat limited (by focusing on the low-data regime).\n- Importantly, while the empirical results and resulting practical suggestions are certainly interesting and useful, previously published work has made very similar observations.\n- I view this paper as borderline, and am tending to recommend rejection \u2014 but I am happy to change my judgement and increase my score if the authors can convincingly address my concerns.\n- The methodological contribution is rather low; the paper does not introduce a new method, but rather conducts a study to assess the interaction between different existing approaches, namely deep ensembling, Mixup regularization/augmentation and temperature scaling;\n- The empirical evaluation is generally well-executed and fairly comprehensive.\n- The main conclusions are convincingly supported by the results and provide clear suggestions for practitioners.\n- The paper is generally very well written and enjoyable to read.\n- While the results are certainly interesting and useful, the main issue I see with this work is that previously papers have made very similar observations.\n- [1] also studied the interaction between ensembling and Mixup, reaching the same conclusion that they both individually reduce confidence, and that combining them therefore yields compounded underconfidence which deteriorates calibration.\n- [1] then continues to argue that this is caused by the conflation of model and data uncertainty, and proposes CAMixup, which improves upon Mixup by adaptively adjusting the mixing parameter on a class-wise basis.\n- However, I cannot comment on that, and would suggest the authors to clarify this directly with the area chair.\n- [2] has a different goal to this paper, but their empirical evaluation ultimately ends up with the same recommendation as this work, namely that applying temperature scaling on top of the ensemble predictive is beneficial to calibration.\n- One could argue that by focusing on the small-data regime, the scope of the evaluation becomes somewhat narrow.\n- However, I believe that the small-data regime is important and therefore welcome studies focusing on it, as most other papers typically look at the large-data regime.\n- That being said, it is clear that some of the conclusions drawn from this work do not translate beyond the small-data setting, which perhaps could be clarified even more.\n- The authors acknowledge that for large datasets, the differences in performance between the methods assessed are relatively minor (l 291-293).\n- It would be great if the authors could clarify what exactly they mean by that (ideally by showing the larger-scale experiments that were conducted to reach this conclusion).\n- In l.115-118 you state that \u2018in the low-data regime, [\u2026] we have empirically observed that [\u2026] Vector and Matrix scaling post-processing calibration methods do not offer any significant advantage over the simple and robust temperature scaling approach.\u2019; I did not find those experiments in the paper or appendix, were these just preliminary results that you did not intend to share?\n- It might be clearer to describe the setup and implementation details (l. 285-293) at the beginning of the experiments, rather than at the end.\n- Some of the figure captions just describe the plots, but do not state the conclusions drawn from them.\n- In Fig. 2, for the unscaled ensemble, why is mixup with alpha=0.2 much more confident than the rest (e.g. when looking at entropy)?\n- Typo in l.249: \u2018As regards the\u2018 \u2014> \u2018With regards to the\u2018 / \u2018Regarding the\u2018\n- The plot labels/legends are not consistent (compare e.g. Fig 2 and Fig 3/6, where the mixup parameters are labeled in different ways).\n- In l. 287, you mention that you took the 5th place solution from the Kaggle challenge for the Diabetic Retinopathy dataset; it would be great to have a justification for this.\n- Typo in l. 311: \u2018Designing\u2018 \u2014> \u2018designing\u2018\n- In the references, paper [2] and [3] are identical and should be merged into a single reference.",
    "review_points_list": [
      "The author response clarifies some of the issues I had raised -- I therefore increase my score from weak rejection (5) to weak acceptance (6).",
      "I am still hesitant to recommend acceptance more enthusiastically due to the remaining issue of a low methodological contribution.",
      "This paper tackles an important open problem in practical deep learning (which is of significant interest to the NeurIPS community), namely how to obtain models that are well calibrated and therefore robust.",
      "It provides a comprehensive and well-executed empirical study with conclusive results and actionable suggestions that will be useful to deep learning practitioners.",
      "The manuscript is also very well-written and easy to follow.",
      "However, the methodological contribution and novelty is rather low, and the scope of the evaluation somewhat limited (by focusing on the low-data regime).",
      "Importantly, while the empirical results and resulting practical suggestions are certainly interesting and useful, previously published work has made very similar observations.",
      "I view this paper as borderline, and am tending to recommend rejection \u2014 but I am happy to change my judgement and increase my score if the authors can convincingly address my concerns.",
      "The methodological contribution is rather low; the paper does not introduce a new method, but rather conducts a study to assess the interaction between different existing approaches, namely deep ensembling, Mixup regularization/augmentation and temperature scaling;",
      "The empirical evaluation is generally well-executed and fairly comprehensive.",
      "The main conclusions are convincingly supported by the results and provide clear suggestions for practitioners.",
      "The paper is generally very well written and enjoyable to read.",
      "While the results are certainly interesting and useful, the main issue I see with this work is that previously papers have made very similar observations.",
      "[1] also studied the interaction between ensembling and Mixup, reaching the same conclusion that they both individually reduce confidence, and that combining them therefore yields compounded underconfidence which deteriorates calibration.",
      "[1] then continues to argue that this is caused by the conflation of model and data uncertainty, and proposes CAMixup, which improves upon Mixup by adaptively adjusting the mixing parameter on a class-wise basis.",
      "However, I cannot comment on that, and would suggest the authors to clarify this directly with the area chair.",
      "[2] has a different goal to this paper, but their empirical evaluation ultimately ends up with the same recommendation as this work, namely that applying temperature scaling on top of the ensemble predictive is beneficial to calibration.",
      "One could argue that by focusing on the small-data regime, the scope of the evaluation becomes somewhat narrow.",
      "However, I believe that the small-data regime is important and therefore welcome studies focusing on it, as most other papers typically look at the large-data regime.",
      "That being said, it is clear that some of the conclusions drawn from this work do not translate beyond the small-data setting, which perhaps could be clarified even more.",
      "The authors acknowledge that for large datasets, the differences in performance between the methods assessed are relatively minor (l 291-293).",
      "It would be great if the authors could clarify what exactly they mean by that (ideally by showing the larger-scale experiments that were conducted to reach this conclusion).",
      "In l.115-118 you state that \u2018in the low-data regime, [\u2026] we have empirically observed that [\u2026] Vector and Matrix scaling post-processing calibration methods do not offer any significant advantage over the simple and robust temperature scaling approach.\u2019; I did not find those experiments in the paper or appendix, were these just preliminary results that you did not intend to share?",
      "It might be clearer to describe the setup and implementation details (l. 285-293) at the beginning of the experiments, rather than at the end.",
      "Some of the figure captions just describe the plots, but do not state the conclusions drawn from them.",
      "In Fig. 2, for the unscaled ensemble, why is mixup with alpha=0.2 much more confident than the rest (e.g. when looking at entropy)?",
      "Typo in l.249: \u2018As regards the\u2018 \u2014> \u2018With regards to the\u2018 / \u2018Regarding the\u2018",
      "The plot labels/legends are not consistent (compare e.g. Fig 2 and Fig 3/6, where the mixup parameters are labeled in different ways).",
      "In l. 287, you mention that you took the 5th place solution from the Kaggle challenge for the Diabetic Retinopathy dataset; it would be great to have a justification for this.",
      "Typo in l. 311: \u2018Designing\u2018 \u2014> \u2018designing\u2018",
      "In the references, paper [2] and [3] are identical and should be merged into a single reference."
    ]
  },
  {
    "paper_id": "2007.08792v4",
    "submission_id": "wg_kD_nyAF",
    "submission_title": "Uncertainty Quantification and Deep Ensembles",
    "review_id": "O3ji-Z7DNcz",
    "input": {
      "title": "Uncertainty Quantification and Deep Ensembles",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- A well motivated and very well written paper for which the main claims would benefit from more thorough / rigorous proofs to be more convincing.\n- The paper is very easy to read throughout -- all key terms are adequately defined, the work is adequately structured and flows naturally.\n- The work draws conclusions and provides guidance based on (sometimes limited) empirical evidence only (no theoretical proof; empirical analyses limited to 4 datasets, single model architecture for each).\n- Some aspects of the experimental design might be problematic (see below).\n- The interplay between ensembling, calibration and data augmentation has been understudied to date -- this paper provides some interesting elements of response.\n- limited to a couple insightful takeaways (the one about calibration vs aggregation ordering needs some clarification) \n- Please clarify what you mean by \u201clow data regime\u201d -- this may mean different things to different people.\n- In the descriptions of all experiments, you seem to only reference a training set (on which models are trained) and a validation set (on which the temperature scaling is tuned) but no test set.\n- Are all results reported in Fig2-5 reported on the same validation set on which you perform the temperature scaling tuning?\n- If so, the claim that \u201cpool-then-calibrate\u201d is better than \u201ccalibrate-then-pool\u201d approach seems trivial.\n- Conclusions drawn in section 4 (Fig5 in particular) would only be meaningful if results are reported on a separate test set\n- Did you look into other types of aggregation (e.g., geometric or harmonic mean)?\n- This \u201crelated work\u201d section feels a bit contrived as such.\n- Would suggest expanding a bit more\n- adapting (typo)\n- augmentations (typo)\n- drop \u201ca\u201d after \u201cas well as\u201d (typo)\n- \u201cWhen datasets are large, the differences in calibration performances between  the several methods are relatively minor\u201d -- please cite\n- drop capital letter for \u201cDesigning\u201d",
    "review_points_list": [
      "A well motivated and very well written paper for which the main claims would benefit from more thorough / rigorous proofs to be more convincing.",
      "The paper is very easy to read throughout -- all key terms are adequately defined, the work is adequately structured and flows naturally.",
      "The work draws conclusions and provides guidance based on (sometimes limited) empirical evidence only (no theoretical proof; empirical analyses limited to 4 datasets, single model architecture for each).",
      "Some aspects of the experimental design might be problematic (see below).",
      "The interplay between ensembling, calibration and data augmentation has been understudied to date -- this paper provides some interesting elements of response.",
      "limited to a couple insightful takeaways (the one about calibration vs aggregation ordering needs some clarification) ",
      "Please clarify what you mean by \u201clow data regime\u201d -- this may mean different things to different people.",
      "In the descriptions of all experiments, you seem to only reference a training set (on which models are trained) and a validation set (on which the temperature scaling is tuned) but no test set.",
      "Are all results reported in Fig2-5 reported on the same validation set on which you perform the temperature scaling tuning?",
      "If so, the claim that \u201cpool-then-calibrate\u201d is better than \u201ccalibrate-then-pool\u201d approach seems trivial.",
      "Conclusions drawn in section 4 (Fig5 in particular) would only be meaningful if results are reported on a separate test set",
      "Did you look into other types of aggregation (e.g., geometric or harmonic mean)?",
      "This \u201crelated work\u201d section feels a bit contrived as such.",
      "Would suggest expanding a bit more",
      "adapting (typo)",
      "augmentations (typo)",
      "drop \u201ca\u201d after \u201cas well as\u201d (typo)",
      "\u201cWhen datasets are large, the differences in calibration performances between  the several methods are relatively minor\u201d -- please cite",
      "drop capital letter for \u201cDesigning\u201d"
    ]
  },
  {
    "paper_id": "2007.08792v4",
    "submission_id": "wg_kD_nyAF",
    "submission_title": "Uncertainty Quantification and Deep Ensembles",
    "review_id": "K5Bw7OlWs5",
    "input": {
      "title": "Uncertainty Quantification and Deep Ensembles",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Both mixup and temperature scaling are prevailing methods to improve deep neural networks calibration.\n- However, their interactions with deep ensembles received only little attention.\n- This paper is a step towards understanding these interactions.\n- It identifies that the compounding underconfidence is the core issue of worse calibration.\n- Temperature scaling is generally used without extra caution but the authors showed that it need to be tweaked when combined with ensembles.\n- In particular, the order of pooling and scaling affects the calibration of deep ensembles and the authors found that the Pool-Then-Calibrate approach gives the best result.\n- I also have several concerns, one of the major concern is that the paper focuses on the empirical interaction between mixup, temperature scaling and deep ensembles.\n- However, both mixup and temperature scaling are studied before (although not with deep ensembles).\n- The fix proposed by this paper is tweaking the order of pooling and temperature scaling rather than any fundamentally different idea.\n- Although some new insights are discovered, the algorithmic contribution is still limited.\n- The empirical evaluation is limited in the vision domain.\n- The paper would be more convincing if it can show its conclusion can be extended to transformer models in the NLP domain.\n- Moreover, one of the important benefits of ensembles is it can improve uncertainty estimation on out-of-distribution dataset.\n- The paper can also be convincing if the authors can show consistent conclusion on CIFAR-10C and CIFAR-100C dataset.\n- The authors didn't state which neural network architectures are studied (it is in the appendix saying 30 ensembles of ResNet-18).\n- It would be interesting if the paper can study the case for a small number of ensembles such as 4.\n- At the current moment, the cons outweigh the pros so I consider the paper is marginally below the boarderline.",
    "review_points_list": [
      "Both mixup and temperature scaling are prevailing methods to improve deep neural networks calibration.",
      "However, their interactions with deep ensembles received only little attention.",
      "This paper is a step towards understanding these interactions.",
      "It identifies that the compounding underconfidence is the core issue of worse calibration.",
      "Temperature scaling is generally used without extra caution but the authors showed that it need to be tweaked when combined with ensembles.",
      "In particular, the order of pooling and scaling affects the calibration of deep ensembles and the authors found that the Pool-Then-Calibrate approach gives the best result.",
      "I also have several concerns, one of the major concern is that the paper focuses on the empirical interaction between mixup, temperature scaling and deep ensembles.",
      "However, both mixup and temperature scaling are studied before (although not with deep ensembles).",
      "The fix proposed by this paper is tweaking the order of pooling and temperature scaling rather than any fundamentally different idea.",
      "Although some new insights are discovered, the algorithmic contribution is still limited.",
      "The empirical evaluation is limited in the vision domain.",
      "The paper would be more convincing if it can show its conclusion can be extended to transformer models in the NLP domain.",
      "Moreover, one of the important benefits of ensembles is it can improve uncertainty estimation on out-of-distribution dataset.",
      "The paper can also be convincing if the authors can show consistent conclusion on CIFAR-10C and CIFAR-100C dataset.",
      "The authors didn't state which neural network architectures are studied (it is in the appendix saying 30 ensembles of ResNet-18).",
      "It would be interesting if the paper can study the case for a small number of ensembles such as 4.",
      "At the current moment, the cons outweigh the pros so I consider the paper is marginally below the boarderline."
    ]
  },
  {
    "paper_id": "2407.12629v1",
    "submission_id": "vCWztO0ppL",
    "submission_title": "A Convergence Analysis of Gradient Descent on Graph Neural Networks",
    "review_id": "oONh5NWB2G",
    "input": {
      "title": "A Convergence Analysis of Gradient Descent on Graph Neural Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This is an interesting paper, that extends to (simple) GNNs a now well-furnished line of works on the convergence of deep NNs in the realizable case.\n- The paper is well-written and includes a sketch of proof.\n- The proof method is (as far as I know) rather classic, the graph only appearing mostly through its degrees, but some computations are non-trivial.\n- My main comment is that, while the authors make an appreciable effort to discuss the simplifications made for this analysis, the most striking one is not discussed: unless I am missing something, the authors minimize the *expected* risk, with the expectation taken with respect to the random node features.\n- At first glance, I was wondering why the authors don't extend the analysis to the minimization of the empirical risk as is usually done, but in fact this is here highly unrealistic: it would assume that, for each sample graph, the graph structure is the same!\n- This deserves at least a highly emphasized remark in the paper.\n- A potential solution would be to 'create' an empirical risk by dividing the coordinates of the Gaussian node features into subgroups, create each sample graph with a different subgroup of coordinates, and average over them.\n- This would effectively correspond to having several copies of the same graph structure but with several independent node features, which would allow approaching the expected risk. Do the authors think that this could be feasible, via classical concentration arguments?\n- Another possibility would be to assume that, for each sample, the graph structure itself depend on the node features like in the random graph literature (see eg the works of Ruiz, Ribeiro et al, or Keriven, Bietti and Vaiter for links between GNN and random graphs) but the analysis seems fairly different in this case, and probably significantly more involved.\n- With this in mind, the numerical experiments do not make much sense.\n- The minimized risk involves only one graph sample, and is probably very far from the expected risk.\n- Is there an argument that allows to go from one to the other?\n- Other comments/typos:\n- - The deep linear GNN seems to have the same weights at each layer, being effectively a 'recurrent' network.\n- - in the sketch of proof of the one layer case, additional efforts could be dedicated to 'high-level' explanations of the proof rather than hand-on computations.\n- - in section 3.1 (at least), the index j is used both for the weight and as a summation index, while it should be a different index.\n- - two spurious parenthesis in the first line of eq (9).\n- To conclude, this paper has merits, but a very significant blind spot on the expected/empirical risk aspect.\n- My note may change quite a lot after discussion.\n- I thank the authors for their clear response.\n- Although the 'fixed graph' settings still remain a big limitation of their work, they acknowledge it and put forth convincing arguments.\n- I am confident that they will clarify these limitations in the paper, as well as emphasize future directions to alleviate them.\n- I thus believe that this paper might be an interesting first step.\n- I increased my score.",
    "review_points_list": [
      "This is an interesting paper, that extends to (simple) GNNs a now well-furnished line of works on the convergence of deep NNs in the realizable case.",
      "The paper is well-written and includes a sketch of proof.",
      "The proof method is (as far as I know) rather classic, the graph only appearing mostly through its degrees, but some computations are non-trivial.",
      "My main comment is that, while the authors make an appreciable effort to discuss the simplifications made for this analysis, the most striking one is not discussed: unless I am missing something, the authors minimize the *expected* risk, with the expectation taken with respect to the random node features.",
      "At first glance, I was wondering why the authors don't extend the analysis to the minimization of the empirical risk as is usually done, but in fact this is here highly unrealistic: it would assume that, for each sample graph, the graph structure is the same!",
      "This deserves at least a highly emphasized remark in the paper.",
      "A potential solution would be to 'create' an empirical risk by dividing the coordinates of the Gaussian node features into subgroups, create each sample graph with a different subgroup of coordinates, and average over them.",
      "This would effectively correspond to having several copies of the same graph structure but with several independent node features, which would allow approaching the expected risk. Do the authors think that this could be feasible, via classical concentration arguments?",
      "Another possibility would be to assume that, for each sample, the graph structure itself depend on the node features like in the random graph literature (see eg the works of Ruiz, Ribeiro et al, or Keriven, Bietti and Vaiter for links between GNN and random graphs) but the analysis seems fairly different in this case, and probably significantly more involved.",
      "With this in mind, the numerical experiments do not make much sense.",
      "The minimized risk involves only one graph sample, and is probably very far from the expected risk.",
      "Is there an argument that allows to go from one to the other?",
      "Other comments/typos:",
      "- The deep linear GNN seems to have the same weights at each layer, being effectively a 'recurrent' network.",
      "- in the sketch of proof of the one layer case, additional efforts could be dedicated to 'high-level' explanations of the proof rather than hand-on computations.",
      "- in section 3.1 (at least), the index j is used both for the weight and as a summation index, while it should be a different index.",
      "- two spurious parenthesis in the first line of eq (9).",
      "To conclude, this paper has merits, but a very significant blind spot on the expected/empirical risk aspect.",
      "My note may change quite a lot after discussion.",
      "I thank the authors for their clear response.",
      "Although the 'fixed graph' settings still remain a big limitation of their work, they acknowledge it and put forth convincing arguments.",
      "I am confident that they will clarify these limitations in the paper, as well as emphasize future directions to alleviate them.",
      "I thus believe that this paper might be an interesting first step.",
      "I increased my score."
    ]
  },
  {
    "paper_id": "2407.12629v1",
    "submission_id": "vCWztO0ppL",
    "submission_title": "A Convergence Analysis of Gradient Descent on Graph Neural Networks",
    "review_id": "JVOnKt1OD-A",
    "input": {
      "title": "A Convergence Analysis of Gradient Descent on Graph Neural Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper presents an original convergence analysis for GD on GNNs.\n- The analysis builds on a similar convergence analysis developed for fully connected neural networks.\n- The contribution has some significance and the analysis seems to be technically sound.\n- The quality of the paper is limited by the fact that the authors don't discuss the limitations of the models they consider.\n- The authors don't discuss convexity.\n- The first limitation that I see is that the analyzed models are not very useful in practice.\n- Multi-layer GNNs without nonlinearities are just linear (over)parametrizations that could be written much more simply as one linear layer, and 1-layer ReLU GNNs are too small for most applications.\n- The authors should have better stressed the limitations of their approach.\n- The ERM problem with quadratic loss is convex for the 1-layer ReLU GNN.\n- This alone implies convergence of gradient descent.\n- The writing is clear but the organization of the paper could be improved.\n- The authors discuss related work in Section 2, but also include some of it in Section 3 where they put more emphasis on contrasting their results with prior work than on discussing Theorem 1.\n- The authors could have discussed the Polyak condition in more detail.\n- There is a slight problem with notation---\\sigma is used in three different places to mean three different things---and a few typos here and there.\n- Subject to a more detailed discussion on the limitations of the models considered and on improvements in the organization of the paper (as per my original review), I am increasing my score to a 6.",
    "review_points_list": [
      "This paper presents an original convergence analysis for GD on GNNs.",
      "The analysis builds on a similar convergence analysis developed for fully connected neural networks.",
      "The contribution has some significance and the analysis seems to be technically sound.",
      "The quality of the paper is limited by the fact that the authors don't discuss the limitations of the models they consider.",
      "The authors don't discuss convexity.",
      "The first limitation that I see is that the analyzed models are not very useful in practice.",
      "Multi-layer GNNs without nonlinearities are just linear (over)parametrizations that could be written much more simply as one linear layer, and 1-layer ReLU GNNs are too small for most applications.",
      "The authors should have better stressed the limitations of their approach.",
      "The ERM problem with quadratic loss is convex for the 1-layer ReLU GNN.",
      "This alone implies convergence of gradient descent.",
      "The writing is clear but the organization of the paper could be improved.",
      "The authors discuss related work in Section 2, but also include some of it in Section 3 where they put more emphasis on contrasting their results with prior work than on discussing Theorem 1.",
      "The authors could have discussed the Polyak condition in more detail.",
      "There is a slight problem with notation---\\sigma is used in three different places to mean three different things---and a few typos here and there.",
      "Subject to a more detailed discussion on the limitations of the models considered and on improvements in the organization of the paper (as per my original review), I am increasing my score to a 6."
    ]
  },
  {
    "paper_id": "2407.12629v1",
    "submission_id": "vCWztO0ppL",
    "submission_title": "A Convergence Analysis of Gradient Descent on Graph Neural Networks",
    "review_id": "eq3OyaaEZ1i",
    "input": {
      "title": "A Convergence Analysis of Gradient Descent on Graph Neural Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- To the best of my knowledge, this is the first paper to show the global convergence of non-linear GNNs at a linear rate by exploiting the realizability condition.\n- The problem is setting is different from usual node prediction tasks (see the Soundness section).\n- In addition, there are substantial restrictions on data distribution and GNN architecture. (For example, deep GNNs are linear and use weight-sharing.)\n- I have some questions about the soundness of the experiment (see the Soundness section).\n- I think the problem setting considered in this paper is different from the usual node prediction tasks.\n- The deep linear GNN used in this paper shares weights across layers. l.79 pointed out that GCN is such an architecture. But I think this is not true -- GCN uses different weights for each layer.\n- I have a question about whether the discussion in the experiment section is appropriate.\n- Regarding the second objective of the experiment (behavior of GNNs in the regime of $d=O(n)$), I recognized its soundness.\n- As far as I checked, there were no major errors in the proof.\n- I have one question about the proof of Theorem 1.\n- The strategy of using the PL condition to show linear convergence is a standard one. However, the proof has novelty in proving the satisfiability of the PL condition.\n- As far as I know, this is the first paper that showed the linear convergence of non-linear GNN to a global optimum under realizability conditions.\n- For GNN optimization, [Oono & Suzuki, NeurIPS2020] and [Xu et al., ICML2021] considered the optimization performance of GNNs.\n- This paper claimed that there is no convergence analysis of gradient descent for feed-forward NNs with more than two hidden layers in the non-NTK regime.\n- The paper is easy to read. I was able to understand the proof without much difficulty.\n- I would suggest the overview of the proof strategy for the proof for deep linear GNNs in the main paper.",
    "review_points_list": [
      "To the best of my knowledge, this is the first paper to show the global convergence of non-linear GNNs at a linear rate by exploiting the realizability condition.",
      "The problem is setting is different from usual node prediction tasks (see the Soundness section).",
      "In addition, there are substantial restrictions on data distribution and GNN architecture. (For example, deep GNNs are linear and use weight-sharing.)",
      "I have some questions about the soundness of the experiment (see the Soundness section).",
      "I think the problem setting considered in this paper is different from the usual node prediction tasks.",
      "The deep linear GNN used in this paper shares weights across layers. l.79 pointed out that GCN is such an architecture. But I think this is not true -- GCN uses different weights for each layer.",
      "I have a question about whether the discussion in the experiment section is appropriate.",
      "Regarding the second objective of the experiment (behavior of GNNs in the regime of $d=O(n)$), I recognized its soundness.",
      "As far as I checked, there were no major errors in the proof.",
      "I have one question about the proof of Theorem 1.",
      "The strategy of using the PL condition to show linear convergence is a standard one. However, the proof has novelty in proving the satisfiability of the PL condition.",
      "As far as I know, this is the first paper that showed the linear convergence of non-linear GNN to a global optimum under realizability conditions.",
      "For GNN optimization, [Oono & Suzuki, NeurIPS2020] and [Xu et al., ICML2021] considered the optimization performance of GNNs.",
      "This paper claimed that there is no convergence analysis of gradient descent for feed-forward NNs with more than two hidden layers in the non-NTK regime.",
      "The paper is easy to read. I was able to understand the proof without much difficulty.",
      "I would suggest the overview of the proof strategy for the proof for deep linear GNNs in the main paper."
    ]
  },
  {
    "paper_id": "2407.12629v1",
    "submission_id": "vCWztO0ppL",
    "submission_title": "A Convergence Analysis of Gradient Descent on Graph Neural Networks",
    "review_id": "QIm9eS4H8tq",
    "input": {
      "title": "A Convergence Analysis of Gradient Descent on Graph Neural Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Originality: Previous optimization analysis usually consider fully connected networks or residual networks, and this paper considers GNNs that are proposed from applications with few theoretical results.\n- The theorems in the paper are supported by mathematical proofs.\n- The authors consider some simplified settings: there exists a set of true weights;\n- the gradient descent is taken on the population loss instead of empirical loss.\n- Nevertheless, I think the proofs are not just trivial extension of fully connected networks, and it is a good starting point in this direction.\n- The statements of the theorems and proofs are clear to me.",
    "review_points_list": [
      "Originality: Previous optimization analysis usually consider fully connected networks or residual networks, and this paper considers GNNs that are proposed from applications with few theoretical results.",
      "The theorems in the paper are supported by mathematical proofs.",
      "The authors consider some simplified settings: there exists a set of true weights;",
      "the gradient descent is taken on the population loss instead of empirical loss.",
      "Nevertheless, I think the proofs are not just trivial extension of fully connected networks, and it is a good starting point in this direction.",
      "The statements of the theorems and proofs are clear to me."
    ]
  },
  {
    "paper_id": "2110.13048v1",
    "submission_id": "v4vuGbNIv71",
    "submission_title": "Nonuniform Negative Sampling and Log Odds Correction with Rare Events Data",
    "review_id": "yo5fzk-ff0v",
    "input": {
      "title": "Nonuniform Negative Sampling and Log Odds Correction with Rare Events Data",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Since we often encounter imbalanced datasets, subsampling strategy is very important for them. The proposed method is theoretically proved to be effective, including the setups for practical uses. Experimental results supported the results.\n- The reviewer felt that the paper was not well organized in the sense that the paper's contribution is not clear.\n- The reviewer hopes the paper that the following points to be clearer: what is based on conventional methods, and what is new in the proposed method.\n- In the appendix there are references if existing analyses are employed for the proposed method, but the reviewer hopes references in the main paper in order to discuss the novelty of the paper.\n- What is main updates of the proposed method from the negative sampling strategy in [28] and the IPW? Does the paper just combines them (as well as providing with some new analyses)?\n- The reviewer felt that the result of Theorem 1 for simpler case seem to be proved by someone else. Please refer to conventional related analyses and their relationships to Theorem 1 in the main paper (not only the appendix) if any: For example, balanced case with (without) Assumptions 1 or 2, or imbalanced case with different assumptions.\n- Please provide, if any, the intuitive interpretation of $M^{-1}_f$ since it is essential to discuss the performance of the proposed method.\n- Since main theorems discuss the convergence rate against the number of samples in Theorem 1, perhaps experiment on it will support the paper's analysis more.",
    "review_points_list": [
      "Since we often encounter imbalanced datasets, subsampling strategy is very important for them. The proposed method is theoretically proved to be effective, including the setups for practical uses. Experimental results supported the results.",
      "The reviewer felt that the paper was not well organized in the sense that the paper's contribution is not clear.",
      "The reviewer hopes the paper that the following points to be clearer: what is based on conventional methods, and what is new in the proposed method.",
      "In the appendix there are references if existing analyses are employed for the proposed method, but the reviewer hopes references in the main paper in order to discuss the novelty of the paper.",
      "What is main updates of the proposed method from the negative sampling strategy in [28] and the IPW? Does the paper just combines them (as well as providing with some new analyses)?",
      "The reviewer felt that the result of Theorem 1 for simpler case seem to be proved by someone else. Please refer to conventional related analyses and their relationships to Theorem 1 in the main paper (not only the appendix) if any: For example, balanced case with (without) Assumptions 1 or 2, or imbalanced case with different assumptions.",
      "Please provide, if any, the intuitive interpretation of $M^{-1}_f$ since it is essential to discuss the performance of the proposed method.",
      "Since main theorems discuss the convergence rate against the number of samples in Theorem 1, perhaps experiment on it will support the paper's analysis more."
    ]
  },
  {
    "paper_id": "2110.13048v1",
    "submission_id": "v4vuGbNIv71",
    "submission_title": "Nonuniform Negative Sampling and Log Odds Correction with Rare Events Data",
    "review_id": "GrlpgpZQNX",
    "input": {
      "title": "Nonuniform Negative Sampling and Log Odds Correction with Rare Events Data",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper gives a very comprehensive modeling and treatment of rare positive instances in binary response: motivating sub-sampling, revisiting key sub-sampling methods, optimizing these methods to perform well, analyzing the presented variants, giving practical implementation tweaks, analyzing those tweaks, and finally testing on meaningful experiments.\n- Each of these steps is a worthwhile contribution to share with the community.\n- The scaling regime is somewhat limiting, because it requires the logits to decay uniformly over all features.\n- This is definitely an acceptable and useful simplifying assumption for theoretical work, but it\u2019s not clear why this is the right model to capture rare positives.\n- Some discussion on this matter would be appreciated.\n- The paper is theory-intense, which is not a problem, but this is presented in a dry and dense fashion which makes it a heavy read.\n- More signpost paragraphs to maintain the high-level picture can make this a more pleasant read.\n- Some claims need a little care for nuance.\n- On line line 86, does the MLE remain the most efficient estimator (among asymptotically unbiased ones), even in this scaling regime?\n- Saying the number of positive instances is what matters line 98, is obviously not true, because the result hinges on N1/N\to 0.\n- Of course, down the line with the subsampling results, it\u2019s clear we need to include enough negative samples to get the same asymptotic behavior as the full sample.\n- On line 117 saying that will happen at c=0 should be emphasized to be just conceptual, since at that point Theorem 2 no longer holds.\n- It\u2019s worthwhile to do a grammatical pass on the text, since there are several incorrect English phrases.\n- These don\u2019t deter from the quality of the work, but the polish would be appreciated.",
    "review_points_list": [
      "The paper gives a very comprehensive modeling and treatment of rare positive instances in binary response: motivating sub-sampling, revisiting key sub-sampling methods, optimizing these methods to perform well, analyzing the presented variants, giving practical implementation tweaks, analyzing those tweaks, and finally testing on meaningful experiments.",
      "Each of these steps is a worthwhile contribution to share with the community.",
      "The scaling regime is somewhat limiting, because it requires the logits to decay uniformly over all features.",
      "This is definitely an acceptable and useful simplifying assumption for theoretical work, but it\u2019s not clear why this is the right model to capture rare positives.",
      "Some discussion on this matter would be appreciated.",
      "The paper is theory-intense, which is not a problem, but this is presented in a dry and dense fashion which makes it a heavy read.",
      "More signpost paragraphs to maintain the high-level picture can make this a more pleasant read.",
      "Some claims need a little care for nuance.",
      "On line line 86, does the MLE remain the most efficient estimator (among asymptotically unbiased ones), even in this scaling regime?",
      "Saying the number of positive instances is what matters line 98, is obviously not true, because the result hinges on N1/N\to 0.",
      "Of course, down the line with the subsampling results, it\u2019s clear we need to include enough negative samples to get the same asymptotic behavior as the full sample.",
      "On line 117 saying that will happen at c=0 should be emphasized to be just conceptual, since at that point Theorem 2 no longer holds.",
      "It\u2019s worthwhile to do a grammatical pass on the text, since there are several incorrect English phrases.",
      "These don\u2019t deter from the quality of the work, but the polish would be appreciated."
    ]
  },
  {
    "paper_id": "2110.13048v1",
    "submission_id": "v4vuGbNIv71",
    "submission_title": "Nonuniform Negative Sampling and Log Odds Correction with Rare Events Data",
    "review_id": "GM5ZcykizS",
    "input": {
      "title": "Nonuniform Negative Sampling and Log Odds Correction with Rare Events Data",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I enjoyed reading this paper.\n- It is well-written, considers a practically meaningful question, and provides precise answers.\n- It also does not contain any spurious or unsubstantiated claims or decorative results.\n- I appreciate the interesting adjusted MLE estimator based on the likelihood of selected data, and in particular its comparison with the IPW.\n- The results also provide a coherent picture and naturally complement each other.\n- I am therefore strongly in favor of acceptance of this paper, and would also suggest considering it for a spotlight or oral presentation, as it could potentially be of interest to many NeurIPS attendees.\n- I would also encourage the authors to consider publishing a final version of this work to a suitable statistics journal.\n- I should mention, however, that I am not familiar with the literature on the topic, in the sense that I have read none of the papers listed in the references.\n- I am therefore not in a very good position to gauge the level of originality (though I somehow doubt that related work could warrant rejection, unless the same results were obtained before).\n- I might also be slightly biased by the fact that many of the ideas are new to me, although some might be more routine in this topic.\n- I would suggest (maybe in a final version) to put the results (asymptotic covariance matrices) in more explicit or simple form in the specific case of logistic regression, which is arguably one of the most standard and relevant ones.\n- It would perhaps be helpful to comment the results in connection with the asymptotic distribution of the MLE (given by the Fisher distribution) or the Cramer-Rao lower bound/asymptotic optimality of MLE.\n- It actually seems that these standard result do not apply, as the data distribution changes with N (since the fraction of positive instances vanishes), which justifies a specific analysis as in this paper.\n- It seems that, as noted in the paper, the misspecified case could also be considered in future work.\n- Asymptotic normality should also hold there (with a covariance depending on the distribution), with the true parameter replaced by the best KL approximation.",
    "review_points_list": [
      "I enjoyed reading this paper.",
      "It is well-written, considers a practically meaningful question, and provides precise answers.",
      "It also does not contain any spurious or unsubstantiated claims or decorative results.",
      "I appreciate the interesting adjusted MLE estimator based on the likelihood of selected data, and in particular its comparison with the IPW.",
      "The results also provide a coherent picture and naturally complement each other.",
      "I am therefore strongly in favor of acceptance of this paper, and would also suggest considering it for a spotlight or oral presentation, as it could potentially be of interest to many NeurIPS attendees.",
      "I would also encourage the authors to consider publishing a final version of this work to a suitable statistics journal.",
      "I should mention, however, that I am not familiar with the literature on the topic, in the sense that I have read none of the papers listed in the references.",
      "I am therefore not in a very good position to gauge the level of originality (though I somehow doubt that related work could warrant rejection, unless the same results were obtained before).",
      "I might also be slightly biased by the fact that many of the ideas are new to me, although some might be more routine in this topic.",
      "I would suggest (maybe in a final version) to put the results (asymptotic covariance matrices) in more explicit or simple form in the specific case of logistic regression, which is arguably one of the most standard and relevant ones.",
      "It would perhaps be helpful to comment the results in connection with the asymptotic distribution of the MLE (given by the Fisher distribution) or the Cramer-Rao lower bound/asymptotic optimality of MLE.",
      "It actually seems that these standard result do not apply, as the data distribution changes with N (since the fraction of positive instances vanishes), which justifies a specific analysis as in this paper.",
      "It seems that, as noted in the paper, the misspecified case could also be considered in future work.",
      "Asymptotic normality should also hold there (with a covariance depending on the distribution), with the true parameter replaced by the best KL approximation."
    ]
  },
  {
    "paper_id": "2110.13502v1",
    "submission_id": "yRTebElmilN",
    "submission_title": "Shared Independent Component Analysis for Multi-Subject Neuroimaging",
    "review_id": "yFGU1vSDGAR",
    "input": {
      "title": "Shared Independent Component Analysis for Multi-Subject Neuroimaging",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The manuscript is well written and considers a well studied problem with an extensive review of the existing approaches well positioning the current approach within the relevant literature on independent vector analysis, group ICA, multiview ICA and multiset canonical correlation analysis.\n- The approach is rather straightforward however the mathematical derivations of properties appear non-trivial.\n- In particular, the result of identifiability even facing Gaussian sources through properties of the individual noise covariance matrices \u03a3_i is useful and differentiates this approach in general from conventional methods.\n- Furthermore, the experimental evaluation is solid and the approach found to be meritable providing enhanced recovery.\n- All in all the mathematical rigour and the convincing experimental section can warrant publication of this manuscript.\n- The manuscript is well written and sound.\n- The experimentation is convincing and includes an extensive synthetic analysis as well as an analysis of real magneto-encephalography (MEG) data.\n- The results are promising and the proposed approach appears both efficient and accurate in terms of component recovery.\n- The manuscript is well written and clear in its presentation.\n- In proof of theorem 2 note:that s + n^i should be s + n_i\n- It is unclear to me how the approach relates and differ to the approach of Klami, Arto, Seppo Virtanen, and Samuel Kaski.\n- In particular, this approach also accounts for view specific covariances and seems very related to the current approach when not including also individual factors but only shared factors and not imposing the mixture of two Gaussian prior.\n- The authors thus need to relate their approach to this work.\n- The manuscript falls within a large literature on decomposition approaches accounting for individual variability while preserving shared component extraction.\n- The work is carefully positioned within this literature and forms a promising although rather straightforward framework.\n- However, the merits in terms of model identifiability are interesting and admits Gaussian component extraction providing efficiency and favorable results as demonstrated in the experimental validation which warrents publication.",
    "review_points_list": [
      "The manuscript is well written and considers a well studied problem with an extensive review of the existing approaches well positioning the current approach within the relevant literature on independent vector analysis, group ICA, multiview ICA and multiset canonical correlation analysis.",
      "The approach is rather straightforward however the mathematical derivations of properties appear non-trivial.",
      "In particular, the result of identifiability even facing Gaussian sources through properties of the individual noise covariance matrices \u03a3_i is useful and differentiates this approach in general from conventional methods.",
      "Furthermore, the experimental evaluation is solid and the approach found to be meritable providing enhanced recovery.",
      "All in all the mathematical rigour and the convincing experimental section can warrant publication of this manuscript.",
      "The manuscript is well written and sound.",
      "The experimentation is convincing and includes an extensive synthetic analysis as well as an analysis of real magneto-encephalography (MEG) data.",
      "The results are promising and the proposed approach appears both efficient and accurate in terms of component recovery.",
      "The manuscript is well written and clear in its presentation.",
      "In proof of theorem 2 note:that s + n^i should be s + n_i",
      "It is unclear to me how the approach relates and differ to the approach of Klami, Arto, Seppo Virtanen, and Samuel Kaski.",
      "In particular, this approach also accounts for view specific covariances and seems very related to the current approach when not including also individual factors but only shared factors and not imposing the mixture of two Gaussian prior.",
      "The authors thus need to relate their approach to this work.",
      "The manuscript falls within a large literature on decomposition approaches accounting for individual variability while preserving shared component extraction.",
      "The work is carefully positioned within this literature and forms a promising although rather straightforward framework.",
      "However, the merits in terms of model identifiability are interesting and admits Gaussian component extraction providing efficiency and favorable results as demonstrated in the experimental validation which warrents publication."
    ]
  },
  {
    "paper_id": "2110.13502v1",
    "submission_id": "yRTebElmilN",
    "submission_title": "Shared Independent Component Analysis for Multi-Subject Neuroimaging",
    "review_id": "LNwBh9PGHV",
    "input": {
      "title": "Shared Independent Component Analysis for Multi-Subject Neuroimaging",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- In this paper, the empirical studies are reported using Amari distance and R2 score. It makes the produced results unclear.\n- We cannot compare the performance of the proposed method with the previous studies (e.g., Chen et al. 2015) that evaluated the related methods with the same datasets.\n- I cannot find clear information about the experiment scheme, including how cross-validation is applied (across subjects or instances), how the neural responses are learned after mapping to the shared space (in the same order, or in shuffled form), etc.\n- I would like to compare the performance of the proposed method with other approaches using the regular metrics like classification accuracy and in the form of different schemes proposed in other related studies, including Chen et al. 2015, etc.\n- Performances of the various techniques are reported by manually selecting the hyperparameters --- e.g., number of components in Figure 5.\n- The optimum values for each hyperparameter should be learned using internal cross-validation or a grid search.\n- In the current format, we cannot have any inference from the empirical studies.\n- There is no guarantee that different techniques will produce the same performance with the same number of components.\n- You must evaluate each technique with its best performance, obviously using the optimum hyperparameters.\n- It seems that the performances of most techniques are increasing when the number of components is increasing.\n- You have to show us when this tendency is not consistent anymore.\n- Handling non-Gaussian noise is described as a novelty of the proposed method in comparison with CCA-based approaches such as SRM.\n- However, I did not find an explanation to see why it is important?\n- In fMRI datasets, each voxel shows the BOLD signal as a proxy to trace the oxygen usage of around 10000 neurons.\n- We can assume that the distribution of one voxel (the BOLD signal) is related to the aggregation of all distributions corresponding to the oxygen usage of the associated neurons.\n- Although we obviously do not have each of these distributions, the central limit theorem clearly explains that the Gaussian distribution may be the best assumption on the voxel (aggregated) distribution.\n- To keep the procedure conjugate during the factor analysis, assuming the Gaussian noise in the other techniques makes more sense --- for instance, it can even help us to control SNR.\n- There are several related works that should be compared with the proposed method.\n- For instance, SRM has been published in 2015 and there are several new extensions of SRM that can produce better performances in comparison with SRM, including MN-SRM (AISTAT 2018) and RSRM (ICASSP 2018).",
    "review_points_list": [
      "In this paper, the empirical studies are reported using Amari distance and R2 score. It makes the produced results unclear.",
      "We cannot compare the performance of the proposed method with the previous studies (e.g., Chen et al. 2015) that evaluated the related methods with the same datasets.",
      "I cannot find clear information about the experiment scheme, including how cross-validation is applied (across subjects or instances), how the neural responses are learned after mapping to the shared space (in the same order, or in shuffled form), etc.",
      "I would like to compare the performance of the proposed method with other approaches using the regular metrics like classification accuracy and in the form of different schemes proposed in other related studies, including Chen et al. 2015, etc.",
      "Performances of the various techniques are reported by manually selecting the hyperparameters --- e.g., number of components in Figure 5.",
      "The optimum values for each hyperparameter should be learned using internal cross-validation or a grid search.",
      "In the current format, we cannot have any inference from the empirical studies.",
      "There is no guarantee that different techniques will produce the same performance with the same number of components.",
      "You must evaluate each technique with its best performance, obviously using the optimum hyperparameters.",
      "It seems that the performances of most techniques are increasing when the number of components is increasing.",
      "You have to show us when this tendency is not consistent anymore.",
      "Handling non-Gaussian noise is described as a novelty of the proposed method in comparison with CCA-based approaches such as SRM.",
      "However, I did not find an explanation to see why it is important?",
      "In fMRI datasets, each voxel shows the BOLD signal as a proxy to trace the oxygen usage of around 10000 neurons.",
      "We can assume that the distribution of one voxel (the BOLD signal) is related to the aggregation of all distributions corresponding to the oxygen usage of the associated neurons.",
      "Although we obviously do not have each of these distributions, the central limit theorem clearly explains that the Gaussian distribution may be the best assumption on the voxel (aggregated) distribution.",
      "To keep the procedure conjugate during the factor analysis, assuming the Gaussian noise in the other techniques makes more sense --- for instance, it can even help us to control SNR.",
      "There are several related works that should be compared with the proposed method.",
      "For instance, SRM has been published in 2015 and there are several new extensions of SRM that can produce better performances in comparison with SRM, including MN-SRM (AISTAT 2018) and RSRM (ICASSP 2018)."
    ]
  },
  {
    "paper_id": "2110.13502v1",
    "submission_id": "yRTebElmilN",
    "submission_title": "Shared Independent Component Analysis for Multi-Subject Neuroimaging",
    "review_id": "YMIPM7vd7T",
    "input": {
      "title": "Shared Independent Component Analysis for Multi-Subject Neuroimaging",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper does an excellent job of clearly identifying the current methods used in independent component extraction from multiple views (in section 5, Related work).\n- Although the reviewer sees why the related methods are added right before the results section (to provide benchmarks), he was not certain as to the main contributions of the model until reading this section.\n- It would be useful to add a clearer description in the introduction as to the main limitations of the current methods and how ShICA addresses these.\n- A short paragraph explaining this would do.\n- The reviewer also appreciates the candid explanation of limitations for the current ShICA method.\n- The presentation of the results are clear, which show that ShICA has a clear advantage in regards to separation performance, computation time, robustness with respect to intra-subject variability in MEG, reconstructing the BOLD signal of missing subjects.\n- The paper is very excellent and clearly presents the methodology and results in a way that convince the reader the advantages of the method.\n- The main suggestion from the reviewer is to make some of the advantages of ShICA more clear in the paper (add a paragraph in the introduction to explain the main contributions of ShICA and maybe even ShICA-ML).\n- However, after reading some other reviewer comments, I have some concerns about the methodology and originality of the paper.\n- Therefore, I must give a lower score.",
    "review_points_list": [
      "The paper does an excellent job of clearly identifying the current methods used in independent component extraction from multiple views (in section 5, Related work).",
      "Although the reviewer sees why the related methods are added right before the results section (to provide benchmarks), he was not certain as to the main contributions of the model until reading this section.",
      "It would be useful to add a clearer description in the introduction as to the main limitations of the current methods and how ShICA addresses these.",
      "A short paragraph explaining this would do.",
      "The reviewer also appreciates the candid explanation of limitations for the current ShICA method.",
      "The presentation of the results are clear, which show that ShICA has a clear advantage in regards to separation performance, computation time, robustness with respect to intra-subject variability in MEG, reconstructing the BOLD signal of missing subjects.",
      "The paper is very excellent and clearly presents the methodology and results in a way that convince the reader the advantages of the method.",
      "The main suggestion from the reviewer is to make some of the advantages of ShICA more clear in the paper (add a paragraph in the introduction to explain the main contributions of ShICA and maybe even ShICA-ML).",
      "However, after reading some other reviewer comments, I have some concerns about the methodology and originality of the paper.",
      "Therefore, I must give a lower score."
    ]
  },
  {
    "paper_id": "2108.01368v2",
    "submission_id": "wHoIjrT6MMb",
    "submission_title": "Robust Compressed Sensing MRI with Deep Generative Priors",
    "review_id": "LuyaV6A6-tt",
    "input": {
      "title": "Robust Compressed Sensing MRI with Deep Generative Priors",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper considers a measurement agnostic approach to inverting compressively sensed images under deep generative prior.\n- Specifically authors use the model NCSNv2 from [74] for this purpose, which is a score based generative model.\n- This paper uses an annealed Langevin dynamics algorithm to sample from posterior $\\nu$ and show experimentally that this approach works better in terms of SSIM to prior art on both in-distribution and out-of-distribution reconstructions at various acceleration rates (under sampling rates).\n- Through theorem 3.3, the authors present a theoretical result for $\\hat{x}$ estimated according distribution $\\nu$, assuming a distributional shift from the true distribution $\\mu$ of $x^*$ under gaussian measurements $A$.\n- The main claim of this result is that if $\\mu,\\nu$ are Wasserstein close by factor $\\epsilon$, then the $\\ell_2$ estimation error between $x^*$ and $\\hat{x}$ is lower bounded with high probability.\n- Through theorem 3.4, the authors show that this posterior sampling procedure produces a reconstruction within an additional $\\epsilon$-error  ($2\\epsilon$) of any other reconstruction procedure that is bounded by $\\epsilon$ with high probability (for any sampling process A).\n- The main contributions of this paper are theoretical results and the application of annealed langevin dynamics to CSGM via posteriori sampling (the algorithm itself is incremental in terms of derivation from prior art).\n- The paper is very well written highlighting the key contributions which is backed by their theorem statements and experiments.\n- Experiments on Fast MRI are convincing as well.\n- The paper can benefit from some minor changes as follows.\n- Figure 1 can benefit from presenting reconstruction SSIM or MSE.\n- Section 2.1. is the regime of experiments compressive? Since CSGM typically refers to M<N. Please make the relation between samples M and dimensionality N explicit.\n- Line 113 is N_c \\cdot L = M?\n- Prior to Line 220, the exact formulation of the deep generative model isn't clear or explicit. Please introduce a paragraph discussing choice of deep generative prior.",
    "review_points_list": [
      "This paper considers a measurement agnostic approach to inverting compressively sensed images under deep generative prior.",
      "Specifically authors use the model NCSNv2 from [74] for this purpose, which is a score based generative model.",
      "This paper uses an annealed Langevin dynamics algorithm to sample from posterior $\\nu$ and show experimentally that this approach works better in terms of SSIM to prior art on both in-distribution and out-of-distribution reconstructions at various acceleration rates (under sampling rates).",
      "Through theorem 3.3, the authors present a theoretical result for $\\hat{x}$ estimated according distribution $\\nu$, assuming a distributional shift from the true distribution $\\mu$ of $x^*$ under gaussian measurements $A$.",
      "The main claim of this result is that if $\\mu,\\nu$ are Wasserstein close by factor $\\epsilon$, then the $\\ell_2$ estimation error between $x^*$ and $\\hat{x}$ is lower bounded with high probability.",
      "Through theorem 3.4, the authors show that this posterior sampling procedure produces a reconstruction within an additional $\\epsilon$-error  ($2\\epsilon$) of any other reconstruction procedure that is bounded by $\\epsilon$ with high probability (for any sampling process A).",
      "The main contributions of this paper are theoretical results and the application of annealed langevin dynamics to CSGM via posteriori sampling (the algorithm itself is incremental in terms of derivation from prior art).",
      "The paper is very well written highlighting the key contributions which is backed by their theorem statements and experiments.",
      "Experiments on Fast MRI are convincing as well.",
      "The paper can benefit from some minor changes as follows.",
      "Figure 1 can benefit from presenting reconstruction SSIM or MSE.",
      "Section 2.1. is the regime of experiments compressive? Since CSGM typically refers to M<N. Please make the relation between samples M and dimensionality N explicit.",
      "Line 113 is N_c \\cdot L = M?",
      "Prior to Line 220, the exact formulation of the deep generative model isn't clear or explicit. Please introduce a paragraph discussing choice of deep generative prior."
    ]
  },
  {
    "paper_id": "2108.01368v2",
    "submission_id": "wHoIjrT6MMb",
    "submission_title": "Robust Compressed Sensing MRI with Deep Generative Priors",
    "review_id": "tyeRP-wFydI",
    "input": {
      "title": "Robust Compressed Sensing MRI with Deep Generative Priors",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed method is based on a generative adversarial network (GAN) with a novel architecture that allows it to learn the complex patterns in the brain signals.\n- The idea of using a GAN to learn brain signals is original, and it is interesting to see how the authors apply it to the problem of EEG-based brain-computer interfaces.\n- This work has the potential to revolutionize the field of brain-computer interfaces by allowing people to control devices with their thoughts. This could have a significant impact on the lives of people with paralysis or other motor disorders.\n- The paper is well-written and easy to follow. The authors do a good job of explaining the background and methodology, and the results are presented clearly and concisely.\n- This research has the potential to revolutionize the field of computer vision by proposing a novel approach that can tackle the problem of class imbalance in multi-class classification tasks.\n- The approach is novel and the results are impressive, but the authors should provide more details about the underlying mechanisms and how they achieved such good performance.\n- The proposed approach has the potential to significantly improve the performance of multi-class classification models, especially for those with class imbalance issues.\n- The paper is well-written, and the authors do a good job of explaining the background and methodology, but the figures and tables could be improved for better visualization.",
    "review_points_list": [
      "The proposed method is based on a generative adversarial network (GAN) with a novel architecture that allows it to learn the complex patterns in the brain signals.",
      "The idea of using a GAN to learn brain signals is original, and it is interesting to see how the authors apply it to the problem of EEG-based brain-computer interfaces.",
      "This work has the potential to revolutionize the field of brain-computer interfaces by allowing people to control devices with their thoughts. This could have a significant impact on the lives of people with paralysis or other motor disorders.",
      "The paper is well-written and easy to follow. The authors do a good job of explaining the background and methodology, and the results are presented clearly and concisely.",
      "This research has the potential to revolutionize the field of computer vision by proposing a novel approach that can tackle the problem of class imbalance in multi-class classification tasks.",
      "The approach is novel and the results are impressive, but the authors should provide more details about the underlying mechanisms and how they achieved such good performance.",
      "The proposed approach has the potential to significantly improve the performance of multi-class classification models, especially for those with class imbalance issues.",
      "The paper is well-written, and the authors do a good job of explaining the background and methodology, but the figures and tables could be improved for better visualization."
    ]
  },
  {
    "paper_id": "2108.01368v2",
    "submission_id": "wHoIjrT6MMb",
    "submission_title": "Robust Compressed Sensing MRI with Deep Generative Priors",
    "review_id": "TtKu4NK8Z5",
    "input": {
      "title": "Robust Compressed Sensing MRI with Deep Generative Priors",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The ranking of algorithms on in-distribution images (Section 4.1, Figure 4(a)) is inconsistent with the results in the literature.\n- Perhaps the reason is that the paper evaluates on MVUE images, but uses the VarNet pre-trained on RSS images (but fine-tuned on MVUE images).\n- In any case, it is important to understand where this difference comes from, because if in fact, the Varnet outperforms ConvDecoder as consistently reported in the literature, then Varnet would outperform Lagevian (i.e., the method in the paper), since ConvDecoder is very close to Lagevian.\n- This in turn would change a major conclusion of the paper saying that 'we achieve competitive performance compared to end-to-end deep learning methods when the test-time data are sampled within the distribution'.\n- Overall the experimental setup is very good and well described.\n- However, why use MVUE images instead of RSS as the ground truth?\n- The paper's numerical results are based on the FastMRI dataset and the FastMRI competition and all associated results are based on using the RSS images as groundtruth.\n- Choosing MVUE as the groundtruth makes a comparison to the literature difficult and also leads to the complication that the VarNet used in the paper under review is trained on the RSS images, but then applied to a MVUE images (albeit it is fine-tuned on MVUE images).\n- In the distribution shift section: It would be interesting to specify whether the results are obtained by applying the CSGM method with the same hyperparameters for changing sampling patterns, or if the paper tunes the hyperparameters of the methods on the new sampling patterns.\n- This is important to know, as [20] has shown that hyperparameter tuning on the target distribution significantly impacts the performance on out-of-distribution data.\n- The paper emphasizes that the Lagevian sampling method can obtain multiple reconstructions with different random initializations which can be used to quantify the uncertainty of the reconstructions.\n- The paper writes in the corresponding Section 4.3 'as shown in Fig. 3, the pixel-wise standard deviation is a good estimate of the ground truth error': I really don't see this conclusion from Figure 3.\n- It would be great to have a quantitative result for this statement.\n- Theorem 3.4 states that if there is an algorithm that reconstructs $x^\text{ast}$ drawn from some distribution $\text{mu}$ from $y = A(x^\text{ast})$ with $\text{epsilon}$ accuracy, then posterior sampling succeeds with $2\text{epsilon}$-accuracy.\n- That's an interesting statement, but it would be good to also discuss the catch: for a given forward operator, it is typically difficult to check whether an $\text{epsilon}$-accurate algorithm exists, and we don't have access to the distribution of $\text{mu}$, but only to an estimate through the generative model.",
    "review_points_list": [
      "The ranking of algorithms on in-distribution images (Section 4.1, Figure 4(a)) is inconsistent with the results in the literature.",
      "Perhaps the reason is that the paper evaluates on MVUE images, but uses the VarNet pre-trained on RSS images (but fine-tuned on MVUE images).",
      "In any case, it is important to understand where this difference comes from, because if in fact, the Varnet outperforms ConvDecoder as consistently reported in the literature, then Varnet would outperform Lagevian (i.e., the method in the paper), since ConvDecoder is very close to Lagevian.",
      "This in turn would change a major conclusion of the paper saying that 'we achieve competitive performance compared to end-to-end deep learning methods when the test-time data are sampled within the distribution'.",
      "Overall the experimental setup is very good and well described.",
      "However, why use MVUE images instead of RSS as the ground truth?",
      "The paper's numerical results are based on the FastMRI dataset and the FastMRI competition and all associated results are based on using the RSS images as groundtruth.",
      "Choosing MVUE as the groundtruth makes a comparison to the literature difficult and also leads to the complication that the VarNet used in the paper under review is trained on the RSS images, but then applied to a MVUE images (albeit it is fine-tuned on MVUE images).",
      "In the distribution shift section: It would be interesting to specify whether the results are obtained by applying the CSGM method with the same hyperparameters for changing sampling patterns, or if the paper tunes the hyperparameters of the methods on the new sampling patterns.",
      "This is important to know, as [20] has shown that hyperparameter tuning on the target distribution significantly impacts the performance on out-of-distribution data.",
      "The paper emphasizes that the Lagevian sampling method can obtain multiple reconstructions with different random initializations which can be used to quantify the uncertainty of the reconstructions.",
      "The paper writes in the corresponding Section 4.3 'as shown in Fig. 3, the pixel-wise standard deviation is a good estimate of the ground truth error': I really don't see this conclusion from Figure 3.",
      "It would be great to have a quantitative result for this statement.",
      "Theorem 3.4 states that if there is an algorithm that reconstructs $x^\text{ast}$ drawn from some distribution $\text{mu}$ from $y = A(x^\text{ast})$ with $\text{epsilon}$ accuracy, then posterior sampling succeeds with $2\text{epsilon}$-accuracy.",
      "That's an interesting statement, but it would be good to also discuss the catch: for a given forward operator, it is typically difficult to check whether an $\text{epsilon}$-accurate algorithm exists, and we don't have access to the distribution of $\text{mu}$, but only to an estimate through the generative model."
    ]
  },
  {
    "paper_id": "2108.01368v2",
    "submission_id": "wHoIjrT6MMb",
    "submission_title": "Robust Compressed Sensing MRI with Deep Generative Priors",
    "review_id": "qh0xo1T-Ysn",
    "input": {
      "title": "Robust Compressed Sensing MRI with Deep Generative Priors",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The main contribution of this paper seems to be in using score-based generative models for MRI.\n- The main approach/algorithm is based on prior work that uses a score-based generative model to perform Langevian dynamics for posterior sampling.\n- The paper claims that they are the first to apply CSGM framework on clinical MRI data. This seems to be a strong claim because several other paper have used fastMRI data with generative model-based reconstruction.\n- The paper also discussed the challenges related to shifts in the distribution of images and measurements.\n- The challenge of shift in image distribution at train and test times seems real and important to me, but I do not understand why measurement distribution is of any concern/relevance.\n- It seems obvious to me that the generative model-based methods can work with any measurement pattern. This is different from end-to-end networks that learn to map measurements to the images, and difference between measurement patterns at training and testing is a concern.\n- The problem of mismatch between train and test images of generative models is important. This paper provides empirical results that show the proposed method is robust to such mismatch.\n- At the same time, most of other methods they compare against in Figure 4c also see robust to such image distribution mismatch. I wonder what is the significance of the proposed method in that case?\n- The paper does not compare with the original CSGM framework in which you use a trained generative model and solve an optimization problem similar to the one in Eq. 2.\n- SSIM is a metric often used for natural image quality assessment. It is not necessarily a good metric for MR images. Please report PSNR as well.\n- Theoretical results: I feel there is a mismatch between the theoretical and empirical results in the paper.\n- Gaussian measurements do not exist in MRI, so what is the purpose of discussing those results?\n- Theorem 3.4 talks about general operators, but it is also a generic result that does not take into account any specific component of the proposed generative model-based method.",
    "review_points_list": [
      "The main contribution of this paper seems to be in using score-based generative models for MRI.",
      "The main approach/algorithm is based on prior work that uses a score-based generative model to perform Langevian dynamics for posterior sampling.",
      "The paper claims that they are the first to apply CSGM framework on clinical MRI data. This seems to be a strong claim because several other paper have used fastMRI data with generative model-based reconstruction.",
      "The paper also discussed the challenges related to shifts in the distribution of images and measurements.",
      "The challenge of shift in image distribution at train and test times seems real and important to me, but I do not understand why measurement distribution is of any concern/relevance.",
      "It seems obvious to me that the generative model-based methods can work with any measurement pattern. This is different from end-to-end networks that learn to map measurements to the images, and difference between measurement patterns at training and testing is a concern.",
      "The problem of mismatch between train and test images of generative models is important. This paper provides empirical results that show the proposed method is robust to such mismatch.",
      "At the same time, most of other methods they compare against in Figure 4c also see robust to such image distribution mismatch. I wonder what is the significance of the proposed method in that case?",
      "The paper does not compare with the original CSGM framework in which you use a trained generative model and solve an optimization problem similar to the one in Eq. 2.",
      "SSIM is a metric often used for natural image quality assessment. It is not necessarily a good metric for MR images. Please report PSNR as well.",
      "Theoretical results: I feel there is a mismatch between the theoretical and empirical results in the paper.",
      "Gaussian measurements do not exist in MRI, so what is the purpose of discussing those results?",
      "Theorem 3.4 talks about general operators, but it is also a generic result that does not take into account any specific component of the proposed generative model-based method."
    ]
  },
  {
    "paper_id": "2005.11741v2",
    "submission_id": "vDo__0UwFNo",
    "submission_title": "Bayesian Optimization with High-Dimensional Outputs",
    "review_id": "AQ09Qb4gt8N",
    "input": {
      "title": "Bayesian Optimization with High-Dimensional Outputs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper reads well but the methodological part is too short.\n- Crucial points are left in the supplementary while this material raises some concerns and needs proof-reading.\n- The main problem is that I don\u2019t see how to implement the method and reproduce the results without resorting to the authors' code.\n- Actual Kronecker solves, determinant expressions are not given (just a reference to [41] in supplementary).\n- Only statements about complexity are provided (e.g., L221).\n- Several cases are described, e.g., input-varying noise (or correlation in the noise), that is, not \u03c3^2 I but generic T_l as discussed in C.1, while it is unclear which ones can really be done (**).\n- I think this can be solved by providing a detailed (complete) pseudo-code of the approach that should be in the main text (the one for HOGPs can be in supplementary).\n- If space is needed, some of the applications can be entirely moved to supplementary as they are direct applications of existing MC acquisition functions.\n- The limitations discussed in supplementary A should be included in the main text.\n- In fact, from C.1.1: some of these options are more like ideas for future research than actual results:  \u201cWe do not know of an efficient solve of sums of more than two Kronecker products, and we do not have a strong implementation of approximation methods or specialized preconditioners for solves of the form (K train + T_l ) \u22121 z\u201d.\n- It is contradicting previous statements.\n- Either really show that it works or leave it as a perspective (the supplemental is already long enough).\n- Typos : - B.1: there are i indices in sums but that\u2019s it.\n- L729: strucutre\n- I would like to thank the authors for their detailed response, which I think should be fully integrated in the paper and its supplementary to be more self-contained.\n- I appreciate the addition of the Matheron's rule Posterior Sampling for MTGPs algorithm (requiring expressions that where not referenced or given before).\n- Assuming that all the changes proposed on the reviews will be made (perhaps adding another round of proof-reading on the inevitably numerous notations), I am happy to increase my score.",
    "review_points_list": [
      "The paper reads well but the methodological part is too short.",
      "Crucial points are left in the supplementary while this material raises some concerns and needs proof-reading.",
      "The main problem is that I don\u2019t see how to implement the method and reproduce the results without resorting to the authors' code.",
      "Actual Kronecker solves, determinant expressions are not given (just a reference to [41] in supplementary).",
      "Only statements about complexity are provided (e.g., L221).",
      "Several cases are described, e.g., input-varying noise (or correlation in the noise), that is, not \u03c3^2 I but generic T_l as discussed in C.1, while it is unclear which ones can really be done (**).",
      "I think this can be solved by providing a detailed (complete) pseudo-code of the approach that should be in the main text (the one for HOGPs can be in supplementary).",
      "If space is needed, some of the applications can be entirely moved to supplementary as they are direct applications of existing MC acquisition functions.",
      "The limitations discussed in supplementary A should be included in the main text.",
      "In fact, from C.1.1: some of these options are more like ideas for future research than actual results:  \u201cWe do not know of an efficient solve of sums of more than two Kronecker products, and we do not have a strong implementation of approximation methods or specialized preconditioners for solves of the form (K train + T_l ) \u22121 z\u201d.",
      "It is contradicting previous statements.",
      "Either really show that it works or leave it as a perspective (the supplemental is already long enough).",
      "Typos : - B.1: there are i indices in sums but that\u2019s it.",
      "L729: strucutre",
      "I would like to thank the authors for their detailed response, which I think should be fully integrated in the paper and its supplementary to be more self-contained.",
      "I appreciate the addition of the Matheron's rule Posterior Sampling for MTGPs algorithm (requiring expressions that where not referenced or given before).",
      "Assuming that all the changes proposed on the reviews will be made (perhaps adding another round of proof-reading on the inevitably numerous notations), I am happy to increase my score."
    ]
  },
  {
    "paper_id": "2005.11741v2",
    "submission_id": "vDo__0UwFNo",
    "submission_title": "Bayesian Optimization with High-Dimensional Outputs",
    "review_id": "84h8fPQZCpg",
    "input": {
      "title": "Bayesian Optimization with High-Dimensional Outputs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Accuracy\n- Format\n- Completeness",
    "review_points_list": [
      "Accuracy",
      "Format",
      "Completeness"
    ]
  },
  {
    "paper_id": "2005.11741v2",
    "submission_id": "vDo__0UwFNo",
    "submission_title": "Bayesian Optimization with High-Dimensional Outputs",
    "review_id": "oO3a44_qDhz",
    "input": {
      "title": "Bayesian Optimization with High-Dimensional Outputs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors set out to solve the problem of multi-task BO with an extremely large number of tasks, i.e. correlated outputs.\n- While this idea is a known and important problem, I am not aware of any work that has attempted to solve multi-task BO with this many tasks.\n- The authors combine two known techniques, i.e. that of exploiting Kronecker structures in covariances and using Matheron's identity, and apply them to the domain of multi-task GPs, yielding impressive results for posterior sampling times.\n- The authors adequately cited related work in Section 1 and 2, but I believe this could have been improved by having a separate section that summarises related approaches more concisely.\n- The derivations appear technically sound to me, with well-supported theoretical claims, in particular with regards to sampling time costs.\n- The experimental results were extensive and impressive. The authors tested their method on a variety of problems that each showcased different strengths of their method, e.g. sampling efficiency, applicability for multi-objective and constrained BO problems, as well as extremely large output dimensions.\n- This paper was clearly-written and well-motivated.\n- The results are important, in my opinion, as they allow practitioners to perform BO in settings where there are an extremely large number of output dimensions.\n- I believe this allows practitioners to start thinking about using BO in such settings which were previously infeasible.\n- Minor comments: - The 'Single-Output' time cost for Matheron's rule in Table 1 seems to be missing a bracket, or some symbols.\n- Although the color schemes used in the experimental section look good, I think some of the colors are hard to distinguish. E.g. the purple and magenta lines in Figure 1, the Random, qParego-Batch and qEHVI-Batch lines in Figure 3, as well as the Random and EI lines in Figure 5.\n- You don't say what the shaded area represents, e.g. is it 1 or 2 standard deviations?",
    "review_points_list": [
      "The authors set out to solve the problem of multi-task BO with an extremely large number of tasks, i.e. correlated outputs.",
      "While this idea is a known and important problem, I am not aware of any work that has attempted to solve multi-task BO with this many tasks.",
      "The authors combine two known techniques, i.e. that of exploiting Kronecker structures in covariances and using Matheron's identity, and apply them to the domain of multi-task GPs, yielding impressive results for posterior sampling times.",
      "The authors adequately cited related work in Section 1 and 2, but I believe this could have been improved by having a separate section that summarises related approaches more concisely.",
      "The derivations appear technically sound to me, with well-supported theoretical claims, in particular with regards to sampling time costs.",
      "The experimental results were extensive and impressive. The authors tested their method on a variety of problems that each showcased different strengths of their method, e.g. sampling efficiency, applicability for multi-objective and constrained BO problems, as well as extremely large output dimensions.",
      "This paper was clearly-written and well-motivated.",
      "The results are important, in my opinion, as they allow practitioners to perform BO in settings where there are an extremely large number of output dimensions.",
      "I believe this allows practitioners to start thinking about using BO in such settings which were previously infeasible.",
      "Minor comments: - The 'Single-Output' time cost for Matheron's rule in Table 1 seems to be missing a bracket, or some symbols.",
      "Although the color schemes used in the experimental section look good, I think some of the colors are hard to distinguish. E.g. the purple and magenta lines in Figure 1, the Random, qParego-Batch and qEHVI-Batch lines in Figure 3, as well as the Random and EI lines in Figure 5.",
      "You don't say what the shaded area represents, e.g. is it 1 or 2 standard deviations?"
    ]
  },
  {
    "paper_id": "2005.11741v2",
    "submission_id": "vDo__0UwFNo",
    "submission_title": "Bayesian Optimization with High-Dimensional Outputs",
    "review_id": "23dwu-8YNCw",
    "input": {
      "title": "Bayesian Optimization with High-Dimensional Outputs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The introduction provided a clear overview of the research problem.\n- The methodology section was well-structured and detailed.\n- The usage of diagrams and charts enhanced the presentation of results.\n- More detailed discussion and analysis would strengthen the paper.\n- The conclusion could be more conclusive in emphasizing the research contributions.",
    "review_points_list": [
      "The introduction provided a clear overview of the research problem.",
      "The methodology section was well-structured and detailed.",
      "The usage of diagrams and charts enhanced the presentation of results.",
      "More detailed discussion and analysis would strengthen the paper.",
      "The conclusion could be more conclusive in emphasizing the research contributions."
    ]
  },
  {
    "paper_id": "2010.10670v2",
    "submission_id": "vuFJO_W85VU",
    "submission_title": "Iterative Amortized Policy Optimization",
    "review_id": "5faDgw3kUQ",
    "input": {
      "title": "Iterative Amortized Policy Optimization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The application of iterative amortization to policy optimization for RL is interesting and novel to the best of my knowledge.\n- The connections between variational inference and RL with function approximation are deep yet not fully explored, and this is an excellent example of the interesting insights that can be gained through the lens of this relationship.\n- The relationship to previous work and associated citations appear thorough.\n- The submission appears technically sound, and the claims seem to be supported.\n- It would be helpful if the authors discussed the tradeoffs inherent in iterative amortization (e.g., how is performance improvement balanced by increased computational expense?)\n- iterative amortization appears to help on some tasks and not at all on others.\n- What properties of an environment make iterative amortization more or less useful?\n- How do these properties vary among the tasks used in the paper?\n- These are important questions from both a practical and theoretical standpoint.\n- The analysis of the contribution of multimodality to performance is likely a good first step in this direction.\n- There are also a number of supporting results in the appendix.\n- For eq. 2, should there be a $rho(s_1)$ prefixed to the righthand side of the equation?\n- And shouldn't the upper limit of the products in both eqs. 1 and 2 be $T-1$?\n- The paper is mostly clear and well-organized.\n- The background section and discussion of value overestimation were particularly enjoyable to read.\n- Minor: Figure 7b is difficult to parse--I'm unclear as to what takeaway is intended.\n- It also would be helpful to mark the exact section of the appendix in which supplementary results appear.\n- The magnitude of the performance gain on the majority of Mujoco tasks is not significant.\n- It's difficult to gauge the significance of reducing the amortization gap--why this gap appear to grow over the course of training (Figure 8, right)?\n- While the raw performance improvement due to the proposed approach is not generally notable, I think the main significance of this work is captured by results like the ability to flexibly adapt to new objectives, such as to model-based value estimation.\n- Namely, its significance lies in its novelty and the potential for follow-up work.\n- Some theoretical analysis would be helpful in developing a deeper understanding.\n- I recommend acceptance.",
    "review_points_list": [
      "The application of iterative amortization to policy optimization for RL is interesting and novel to the best of my knowledge.",
      "The connections between variational inference and RL with function approximation are deep yet not fully explored, and this is an excellent example of the interesting insights that can be gained through the lens of this relationship.",
      "The relationship to previous work and associated citations appear thorough.",
      "The submission appears technically sound, and the claims seem to be supported.",
      "It would be helpful if the authors discussed the tradeoffs inherent in iterative amortization (e.g., how is performance improvement balanced by increased computational expense?)",
      "iterative amortization appears to help on some tasks and not at all on others.",
      "What properties of an environment make iterative amortization more or less useful?",
      "How do these properties vary among the tasks used in the paper?",
      "These are important questions from both a practical and theoretical standpoint.",
      "The analysis of the contribution of multimodality to performance is likely a good first step in this direction.",
      "There are also a number of supporting results in the appendix.",
      "For eq. 2, should there be a $rho(s_1)$ prefixed to the righthand side of the equation?",
      "And shouldn't the upper limit of the products in both eqs. 1 and 2 be $T-1$?",
      "The paper is mostly clear and well-organized.",
      "The background section and discussion of value overestimation were particularly enjoyable to read.",
      "Minor: Figure 7b is difficult to parse--I'm unclear as to what takeaway is intended.",
      "It also would be helpful to mark the exact section of the appendix in which supplementary results appear.",
      "The magnitude of the performance gain on the majority of Mujoco tasks is not significant.",
      "It's difficult to gauge the significance of reducing the amortization gap--why this gap appear to grow over the course of training (Figure 8, right)?",
      "While the raw performance improvement due to the proposed approach is not generally notable, I think the main significance of this work is captured by results like the ability to flexibly adapt to new objectives, such as to model-based value estimation.",
      "Namely, its significance lies in its novelty and the potential for follow-up work.",
      "Some theoretical analysis would be helpful in developing a deeper understanding.",
      "I recommend acceptance."
    ]
  },
  {
    "paper_id": "2010.10670v2",
    "submission_id": "vuFJO_W85VU",
    "submission_title": "Iterative Amortized Policy Optimization",
    "review_id": "4Vfdb53YyZD",
    "input": {
      "title": "Iterative Amortized Policy Optimization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors leverage a known connection between variational inference and reinforcement learning to motivate their problem (which is known in the VI literature). Although the techniques are not novel, they are novel in their application to the RL setting.\n- The submission is technically sound, with authors leveraging known techniques from the generative modeling literature.\n- Furthermore, the authors present a very thorough experimental evaluation of their claims, with very interesting results.\n- Although the performance gains in some of the tasks are not substantial, the demonstrated reduction in the amortization gap, inherent multi-modal behavior, and transferability between different value estimation methods are worthy of note.\n- As an additional experiment, it would be interesting to see whether the learned policy is robust to slight changes in the environment (e.g. changing weight/friction parameters of the MuJoCo simulation) as an extension of the generalization experiment.\n- The paper is mostly clear, although as someone who is not as familiar with the generative modeling literature, a few parts of the paper were a bit confusing from my perspective.\n- For example, in the context of RL, what is estimation referring to in lines 112-116 (I assume in this case that it is the process of choosing an action distribution)? I think it would be really helpful to have these connections explicitly mentioned.\n- The paper introduces really interesting ideas, including having a trained policy which includes a trained optimizer that improves upon an initial action based on predicted returns.\n- The work suggests several venues for future work, including across-task generalization, better policies for existing algorithms, among others.",
    "review_points_list": [
      "The authors leverage a known connection between variational inference and reinforcement learning to motivate their problem (which is known in the VI literature). Although the techniques are not novel, they are novel in their application to the RL setting.",
      "The submission is technically sound, with authors leveraging known techniques from the generative modeling literature.",
      "Furthermore, the authors present a very thorough experimental evaluation of their claims, with very interesting results.",
      "Although the performance gains in some of the tasks are not substantial, the demonstrated reduction in the amortization gap, inherent multi-modal behavior, and transferability between different value estimation methods are worthy of note.",
      "As an additional experiment, it would be interesting to see whether the learned policy is robust to slight changes in the environment (e.g. changing weight/friction parameters of the MuJoCo simulation) as an extension of the generalization experiment.",
      "The paper is mostly clear, although as someone who is not as familiar with the generative modeling literature, a few parts of the paper were a bit confusing from my perspective.",
      "For example, in the context of RL, what is estimation referring to in lines 112-116 (I assume in this case that it is the process of choosing an action distribution)? I think it would be really helpful to have these connections explicitly mentioned.",
      "The paper introduces really interesting ideas, including having a trained policy which includes a trained optimizer that improves upon an initial action based on predicted returns.",
      "The work suggests several venues for future work, including across-task generalization, better policies for existing algorithms, among others."
    ]
  },
  {
    "paper_id": "2010.10670v2",
    "submission_id": "vuFJO_W85VU",
    "submission_title": "Iterative Amortized Policy Optimization",
    "review_id": "65v7oyiXRbt",
    "input": {
      "title": "Iterative Amortized Policy Optimization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper is very insightful.\n- It brings forward many interesting ideas which helps to bridge the gap between inference and RL.\n- The paper was very easy to read.\n- The authors did a good job of explaining the issues of direct amortization and presenting their novel technique.\n- The diagrams were also very helpful!\n- The discussion on amortization gap is particularly interesting and to the best of my knowledge not something that has previously been explored by the RL community.\n- The experiments in this paper are very well designed in explaining the iterative amortization approach.\n- Could you elaborate on this claim a little further? Why are more powerful policies more prone to overestimation of the Q function? This seems to be a fairly central point to Section 3.3.\n- Empirical performance of the iterative amortization approach does not seem to be that strong.\n- While there are some improvements on some of the simpler environments.\n- Performance on the most challenging MuJoCo environments (Ant, Humanoid, HumanoidStandup) appear to be on par with the direct amortization method.\n- Any sense why the iterative approach does not result in any improvement on these environments?",
    "review_points_list": [
      "This paper is very insightful.",
      "It brings forward many interesting ideas which helps to bridge the gap between inference and RL.",
      "The paper was very easy to read.",
      "The authors did a good job of explaining the issues of direct amortization and presenting their novel technique.",
      "The diagrams were also very helpful!",
      "The discussion on amortization gap is particularly interesting and to the best of my knowledge not something that has previously been explored by the RL community.",
      "The experiments in this paper are very well designed in explaining the iterative amortization approach.",
      "Could you elaborate on this claim a little further? Why are more powerful policies more prone to overestimation of the Q function? This seems to be a fairly central point to Section 3.3.",
      "Empirical performance of the iterative amortization approach does not seem to be that strong.",
      "While there are some improvements on some of the simpler environments.",
      "Performance on the most challenging MuJoCo environments (Ant, Humanoid, HumanoidStandup) appear to be on par with the direct amortization method.",
      "Any sense why the iterative approach does not result in any improvement on these environments?"
    ]
  },
  {
    "paper_id": "2010.10670v2",
    "submission_id": "vuFJO_W85VU",
    "submission_title": "Iterative Amortized Policy Optimization",
    "review_id": "qX4uPo4ByVV",
    "input": {
      "title": "Iterative Amortized Policy Optimization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- To the best of my knowledge, the idea is novel and original.\n- The paper is generally well-written and easy to follow.\n- I appreciate the authors making a detailed, aligned, and symmetric comparison of direct amortization and iterative amortization.\n- The empirical experiments are quite comprehensive, which includes quite some qualitative analysis of the claimed properties.\n- The proposed method is validated by the learning curves in MuJoCo continuous control tasks benchmark.\n- The proposed method outperforms and matches direct amortization in most continuous control tasks.\n- Could you talk more about what's the added complexity of the proposed method?\n- In Fig.5 (c), while direct amortization seems to be very stable, iterative amortization seems to have two moments with sudden performance collapse, is there any reason why?\n- The increase on performance gains on MuJoCo tasks (Fig.5) and the corresponding decrease in amortization gap (Fig.6) do not seem to be be consistent, e.g. there is a significant decrease in amortization gap on Ant, while the expected reward is almost the same.\n- So maybe it's good to investigate what brings the performance gains?\n- For exploration, it's also helpful to test the proposed algorithm in MuJoCo tasks with sparse rewards.",
    "review_points_list": [
      "To the best of my knowledge, the idea is novel and original.",
      "The paper is generally well-written and easy to follow.",
      "I appreciate the authors making a detailed, aligned, and symmetric comparison of direct amortization and iterative amortization.",
      "The empirical experiments are quite comprehensive, which includes quite some qualitative analysis of the claimed properties.",
      "The proposed method is validated by the learning curves in MuJoCo continuous control tasks benchmark.",
      "The proposed method outperforms and matches direct amortization in most continuous control tasks.",
      "Could you talk more about what's the added complexity of the proposed method?",
      "In Fig.5 (c), while direct amortization seems to be very stable, iterative amortization seems to have two moments with sudden performance collapse, is there any reason why?",
      "The increase on performance gains on MuJoCo tasks (Fig.5) and the corresponding decrease in amortization gap (Fig.6) do not seem to be be consistent, e.g. there is a significant decrease in amortization gap on Ant, while the expected reward is almost the same.",
      "So maybe it's good to investigate what brings the performance gains?",
      "For exploration, it's also helpful to test the proposed algorithm in MuJoCo tasks with sparse rewards."
    ]
  },
  {
    "paper_id": "2107.12815v1",
    "submission_id": "vmJs9dyUeWQYe",
    "submission_title": "Adaptive Denoising via GainTuning",
    "review_id": "qTXoHzTzpkW",
    "input": {
      "title": "Adaptive Denoising via GainTuning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The idea is simple and easy to understand.\n- I have the following concerns:\n- I think one crucial usage for training a denoising network in an unsupervised way is for the noises whose distributions are unknown.\n- For Gaussian noises with unknown noise levels, we can simply train a network to cover a large range of variance and achieve good performance which is shown in the first table in Fig. 4.\n- However, almost all the experiments are for removing Gaussian noises except for the atomic-resolution transmission electron microscope image.\n- There is plenty of real nature image denoising datasets currently, the authors should validate their method in these datasets.\n- The improvement of the proposed method is marginal.\n- In Fig. 3, the differences between 'Pre-trained' with 'GainTunning' are at most 0.12dB and most of the improvements are less than 0.1dB.\n- As to Fig.4, 'Gaintunning' does not perform better than 'Trained on [0,100]'.\n- Even though 'Gaintunning' performs better than 'Pre-trained', the comparison is unfair.\n- Since 'Pre-trained' is trained with smaller noise variance.\n- To avoid overfitting during finetune, the authors propose to use GainTunning.\n- However, there are many other ways to only adjust fewer parameters in the network.\n- For example, we can only finetune some layers in the network.\n- Can the authors explain why GainTunning is the best choice?\n- Also, can the authors provide some visual results to demonstrate how Gain Tunning works after finetuning?\n- Sec. 4 is not relevant to this paper.\n- These losses are proposed by existing arts.\n- Also, the authors do not analyze the pros and cons of these losses in the proposed method.\n- In Ln. 177, should '(3)' be '(2)'?",
    "review_points_list": [
      "The idea is simple and easy to understand.",
      "I have the following concerns:",
      "I think one crucial usage for training a denoising network in an unsupervised way is for the noises whose distributions are unknown.",
      "For Gaussian noises with unknown noise levels, we can simply train a network to cover a large range of variance and achieve good performance which is shown in the first table in Fig. 4.",
      "However, almost all the experiments are for removing Gaussian noises except for the atomic-resolution transmission electron microscope image.",
      "There is plenty of real nature image denoising datasets currently, the authors should validate their method in these datasets.",
      "The improvement of the proposed method is marginal.",
      "In Fig. 3, the differences between 'Pre-trained' with 'GainTunning' are at most 0.12dB and most of the improvements are less than 0.1dB.",
      "As to Fig.4, 'Gaintunning' does not perform better than 'Trained on [0,100]'.",
      "Even though 'Gaintunning' performs better than 'Pre-trained', the comparison is unfair.",
      "Since 'Pre-trained' is trained with smaller noise variance.",
      "To avoid overfitting during finetune, the authors propose to use GainTunning.",
      "However, there are many other ways to only adjust fewer parameters in the network.",
      "For example, we can only finetune some layers in the network.",
      "Can the authors explain why GainTunning is the best choice?",
      "Also, can the authors provide some visual results to demonstrate how Gain Tunning works after finetuning?",
      "Sec. 4 is not relevant to this paper.",
      "These losses are proposed by existing arts.",
      "Also, the authors do not analyze the pros and cons of these losses in the proposed method.",
      "In Ln. 177, should '(3)' be '(2)'?"
    ]
  },
  {
    "paper_id": "2107.12815v1",
    "submission_id": "vmJs9dyUeWQYe",
    "submission_title": "Adaptive Denoising via GainTuning",
    "review_id": "B03sw6ZbC1R",
    "input": {
      "title": "Adaptive Denoising via GainTuning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The work is a combination of known techniques, however with limited novelty.\n- To some extent it differs from other methods by the set of parameters it chooses to learn at test time.\n- The submission is technically sound but lacks theoretical analysis/justification and somewhat in terms of the experimental results provided in the main manuscript.\n- Some experimental details also need to be added (see comments).\n- The submission is clearly written and well organized but could benefit from extended details around the \u2018gain\u2019 parameters that are manipulated for various methods.\n- There are also a few typos (see comments).\n- The submission does address a difficult task but the importance of the results is limited and the advancement of the state of the art not demonstrable.\n- For in-distribution data, the majority of improvements are smaller than 0.03dB-0.04dB on the BSD68 dataset which is the main benchmark for the BSD400 training set.\n- And such an improvement would be expected since the method is an incremental fine-tuning over pre-trained models.\n- For out-of-distribution noise, simply using the original denoiser pretrained blindly (full range of noise levels up to 100) is better than using the proposed method (which also requires some extra test time optimization).\n- And similarly using the bias free model of [35] is also better.\n- For out-of-distribution data, the chosen settings are not very relevant.\n- Urban/natural images are easily obtainable and AWGN is easy to synthesize, so models can be easily pretrained on these distributions.\n- Piecewise constant images as well.\n- The improvements here are more interesting, up to 0.71dB for natural images to scanned documents for instance, however, please add the information on the pretrained model that was used and how it was fine-tuned.\n- The application to TEM is the most interesting one in my opinion as it comes close to what can be needed in real applications, but it is lightly addressed in the main manuscript.\n- Conclusions are drawn based on one shown visual example and we have no quantitative measures.\n- Is GainTuning done exactly the same way for all experiments?\n- For all denoiser networks?\n- Can you provide more results on real image denoising where ground-truth cannot be easily obtained (unlike AWGN)?\n- For instance microscopy imaging.\n- Lastly, as the authors rightfully mention in their limitations, choosing to fine-tune the gains, or any other subset of parameters, is quite arbitrary, and because the authors provide little support for why they made that choice, the theoretical justification is less strong.\n- How many parameters should be fine-tuned and where is the limit between overfitting and adaptation, is in fact a key question.\n- The whole concept of a \u201cprior\u201d learned from a distribution is questioned by methods that adapt to test images and this should not be taken lightly when merging \u201cprior-based methods\u201d and \u201cself-supervised\u201d methods that work at test time.\n- It would be interesting if the authors look into denoising (or any image restoration) methods that study blind denoising, and priors in denoising.\n- Mixing this with self-supervised techniques is not straight-forward from a theoretical ground.\n- As it stands, the paper exploits an interesting idea but develops it in a somewhat empirical manner, which to me is the main weakness next to the experiments provided in the main manuscript.\n- Figure 4 (Sec 5.2 & 5.3), all your comparisons are against a \u201cpre-trained CNN\u201d denoiser, please specify exactly which denoiser it is, and how it was trained, this information is critical there.\n- Typo: Figure 4 caption \u201con test imageS with noise outside\u201d\n- Typo: L201: \u201c(see Figure 4 and)\u201d there is something missing, you say comparison to pretrained denoisers (plural) while there is only one in Fig 4, so I assume the \u2018and\u2019 should refer to SM there.\n- Typo: L277 \u201cfor different architectureS\u201d\n- Sec 5.2 Why is the \u2018gold-standard\u2019 a blind model, rather than a model trained on the same noise level as the test noise level for instance?",
    "review_points_list": [
      "The work is a combination of known techniques, however with limited novelty.",
      "To some extent it differs from other methods by the set of parameters it chooses to learn at test time.",
      "The submission is technically sound but lacks theoretical analysis/justification and somewhat in terms of the experimental results provided in the main manuscript.",
      "Some experimental details also need to be added (see comments).",
      "The submission is clearly written and well organized but could benefit from extended details around the \u2018gain\u2019 parameters that are manipulated for various methods.",
      "There are also a few typos (see comments).",
      "The submission does address a difficult task but the importance of the results is limited and the advancement of the state of the art not demonstrable.",
      "For in-distribution data, the majority of improvements are smaller than 0.03dB-0.04dB on the BSD68 dataset which is the main benchmark for the BSD400 training set.",
      "And such an improvement would be expected since the method is an incremental fine-tuning over pre-trained models.",
      "For out-of-distribution noise, simply using the original denoiser pretrained blindly (full range of noise levels up to 100) is better than using the proposed method (which also requires some extra test time optimization).",
      "And similarly using the bias free model of [35] is also better.",
      "For out-of-distribution data, the chosen settings are not very relevant.",
      "Urban/natural images are easily obtainable and AWGN is easy to synthesize, so models can be easily pretrained on these distributions.",
      "Piecewise constant images as well.",
      "The improvements here are more interesting, up to 0.71dB for natural images to scanned documents for instance, however, please add the information on the pretrained model that was used and how it was fine-tuned.",
      "The application to TEM is the most interesting one in my opinion as it comes close to what can be needed in real applications, but it is lightly addressed in the main manuscript.",
      "Conclusions are drawn based on one shown visual example and we have no quantitative measures.",
      "Is GainTuning done exactly the same way for all experiments?",
      "For all denoiser networks?",
      "Can you provide more results on real image denoising where ground-truth cannot be easily obtained (unlike AWGN)?",
      "For instance microscopy imaging.",
      "Lastly, as the authors rightfully mention in their limitations, choosing to fine-tune the gains, or any other subset of parameters, is quite arbitrary, and because the authors provide little support for why they made that choice, the theoretical justification is less strong.",
      "How many parameters should be fine-tuned and where is the limit between overfitting and adaptation, is in fact a key question.",
      "The whole concept of a \u201cprior\u201d learned from a distribution is questioned by methods that adapt to test images and this should not be taken lightly when merging \u201cprior-based methods\u201d and \u201cself-supervised\u201d methods that work at test time.",
      "It would be interesting if the authors look into denoising (or any image restoration) methods that study blind denoising, and priors in denoising.",
      "Mixing this with self-supervised techniques is not straight-forward from a theoretical ground.",
      "As it stands, the paper exploits an interesting idea but develops it in a somewhat empirical manner, which to me is the main weakness next to the experiments provided in the main manuscript.",
      "Figure 4 (Sec 5.2 & 5.3), all your comparisons are against a \u201cpre-trained CNN\u201d denoiser, please specify exactly which denoiser it is, and how it was trained, this information is critical there.",
      "Typo: Figure 4 caption \u201con test imageS with noise outside\u201d",
      "Typo: L201: \u201c(see Figure 4 and)\u201d there is something missing, you say comparison to pretrained denoisers (plural) while there is only one in Fig 4, so I assume the \u2018and\u2019 should refer to SM there.",
      "Typo: L277 \u201cfor different architectureS\u201d",
      "Sec 5.2 Why is the \u2018gold-standard\u2019 a blind model, rather than a model trained on the same noise level as the test noise level for instance?"
    ]
  },
  {
    "paper_id": "2107.12815v1",
    "submission_id": "vmJs9dyUeWQYe",
    "submission_title": "Adaptive Denoising via GainTuning",
    "review_id": "ke8Nn9TMHq8",
    "input": {
      "title": "Adaptive Denoising via GainTuning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- It would be better if the paper presents qualitative analysis on real noisy images\n- Could authors explain why the improvements are minor in the table3 and table 4\n- It would be better if the paper presents changes in runtime and parameter comparisons due to GainTuning.\n- Is there any specific reason for why in the GainTuning only multiplicative scaling parameters are used why not other types of parameters?",
    "review_points_list": [
      "It would be better if the paper presents qualitative analysis on real noisy images",
      "Could authors explain why the improvements are minor in the table3 and table 4",
      "It would be better if the paper presents changes in runtime and parameter comparisons due to GainTuning.",
      "Is there any specific reason for why in the GainTuning only multiplicative scaling parameters are used why not other types of parameters?"
    ]
  },
  {
    "paper_id": "2106.01854v3",
    "submission_id": "xXYjxli-2i",
    "submission_title": "Optimization-Based Algebraic Multigrid Coarsening Using Reinforcement Learning",
    "review_id": "5wG8tpfha0X",
    "input": {
      "title": "Optimization-Based Algebraic Multigrid Coarsening Using Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The presented algorithm is only tested on 2D Poisson problem and they admit that they do not know how the algorithm will behave on other systems.\n- This is a big hurdle in the acceptance of the paper.\n- The contributions in the abstract and in section 1 are not formulated to support the view described earlier.\n- A normal reader is prone to believe that the algorithm...\n- can coarsen arbitrary unstructured grids, including those much larger than the training grid\n- or is able to...\n- learn to perform graph coarsening on small training graphs and then be applied to unstructured large graphs\n- It is assumed that the structural bias learned by RL during the training will not allow it to be used in different scenarios.\n- So the algorithm may have shown good result for one set of problems, but it may need to be trained from scratch for any other type of problem.\n- Although, the authors claim that the algorithm is faster than any other technique, but there is no performance comparison present in the article.\n- The code provided by the authors is not useful.\n- It is hard to know the dependencies and even after that effort one comes to know that there are missing files in the code.\n- For example, this line produces error in 'from DuelingNet2 import Net as Net_MPNN' in MG_Agent.py\n- I do not agree with the authors that the complexity of Algorithm 2 is O(n).\n- The Complexity of Algorithm 2 depends on the structure of matrix A.\n- Finding arg max could itself have a complexity of O(n) in normal circumstances.\n- So the whole algorithm may have the complexity of O(n^2).\n- It is not mentioned how the accuracy of the result is affected after grid coarsening.\n- More coarse graph may also lead to bad results.",
    "review_points_list": [
      "The presented algorithm is only tested on 2D Poisson problem and they admit that they do not know how the algorithm will behave on other systems.",
      "This is a big hurdle in the acceptance of the paper.",
      "The contributions in the abstract and in section 1 are not formulated to support the view described earlier.",
      "A normal reader is prone to believe that the algorithm...",
      "can coarsen arbitrary unstructured grids, including those much larger than the training grid",
      "or is able to...",
      "learn to perform graph coarsening on small training graphs and then be applied to unstructured large graphs",
      "It is assumed that the structural bias learned by RL during the training will not allow it to be used in different scenarios.",
      "So the algorithm may have shown good result for one set of problems, but it may need to be trained from scratch for any other type of problem.",
      "Although, the authors claim that the algorithm is faster than any other technique, but there is no performance comparison present in the article.",
      "The code provided by the authors is not useful.",
      "It is hard to know the dependencies and even after that effort one comes to know that there are missing files in the code.",
      "For example, this line produces error in 'from DuelingNet2 import Net as Net_MPNN' in MG_Agent.py",
      "I do not agree with the authors that the complexity of Algorithm 2 is O(n).",
      "The Complexity of Algorithm 2 depends on the structure of matrix A.",
      "Finding arg max could itself have a complexity of O(n) in normal circumstances.",
      "So the whole algorithm may have the complexity of O(n^2).",
      "It is not mentioned how the accuracy of the result is affected after grid coarsening.",
      "More coarse graph may also lead to bad results."
    ]
  },
  {
    "paper_id": "2106.01854v3",
    "submission_id": "xXYjxli-2i",
    "submission_title": "Optimization-Based Algebraic Multigrid Coarsening Using Reinforcement Learning",
    "review_id": "GFFY3Kz_D_A",
    "input": {
      "title": "Optimization-Based Algebraic Multigrid Coarsening Using Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Can the proposed Reinforcement Learning (RL) solution be used as starting value for the NP hard problem (4) when solved as an integer programming?\n- How is an optimal agent defined in Thm 1?\n- Sec 4.2 - line 204: Please give more details about the 'random convex triangular mesh' and its FEM discretisation.\n- Please explain briefly how Lloyd aggregation works and why it would result in an O(n) cost.\n- Fig 3: Add other metrics like AMG grid complexity and convergence factor.\n- Fig 2: add the type of mesh in the legend.\n- While I find the results of Poisson on unstructured meshes very impressive, more experiments should be done truly assess the novelty and viability of the proposed ideas.\n- 3D (un)structured meshes should be tested.\n- Variable coefficients (smooth and discontinuous) elliptic on 2D/3D tests are recommended.\n- Helmholtz problems should be tested.\n- Compare to state-of-the-art and not only to the greedy approach: standard AMG with heuristic coarsening and other ML optimized MG.\n- Actually solve the PDE and compare time, cost, maybe not needed but nice.\n- Putting much more experiments in the appendix is recommended.\n- It is probably not feasible to perform all these tests, but I find doing at least a few of them necessary to make the submission acceptable for Neurips.",
    "review_points_list": [
      "Can the proposed Reinforcement Learning (RL) solution be used as starting value for the NP hard problem (4) when solved as an integer programming?",
      "How is an optimal agent defined in Thm 1?",
      "Sec 4.2 - line 204: Please give more details about the 'random convex triangular mesh' and its FEM discretisation.",
      "Please explain briefly how Lloyd aggregation works and why it would result in an O(n) cost.",
      "Fig 3: Add other metrics like AMG grid complexity and convergence factor.",
      "Fig 2: add the type of mesh in the legend.",
      "While I find the results of Poisson on unstructured meshes very impressive, more experiments should be done truly assess the novelty and viability of the proposed ideas.",
      "3D (un)structured meshes should be tested.",
      "Variable coefficients (smooth and discontinuous) elliptic on 2D/3D tests are recommended.",
      "Helmholtz problems should be tested.",
      "Compare to state-of-the-art and not only to the greedy approach: standard AMG with heuristic coarsening and other ML optimized MG.",
      "Actually solve the PDE and compare time, cost, maybe not needed but nice.",
      "Putting much more experiments in the appendix is recommended.",
      "It is probably not feasible to perform all these tests, but I find doing at least a few of them necessary to make the submission acceptable for Neurips."
    ]
  },
  {
    "paper_id": "2106.01854v3",
    "submission_id": "xXYjxli-2i",
    "submission_title": "Optimization-Based Algebraic Multigrid Coarsening Using Reinforcement Learning",
    "review_id": "v3odeNuFb0J",
    "input": {
      "title": "Optimization-Based Algebraic Multigrid Coarsening Using Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Overall the paper clearly proposes a useful improvement of the AMG algorithm.\n- The novelty here is in combining RL with another AMG technique which I'm not familiar with in prior work.\n- The authors give sufficient empirical validation to the advantage of the suggested combination.\n- The results are clearly of interest to practitioners who use AMG solvers in a variety of settings from solving PDEs to other general systems in 2D grids.\n- The authors clearly (and honestly) state that the generalization to other problems is still unknown.\n- I assume that the Lloyd based aggregation is essentially a k-means method; hence, the question is how to determine K so that the partition will still be linear but the size of each cluster will be approximately similar to that of the other clusters to allow faithful sampling from each.\n- In this context, for example, I would expect the family of aspect ratio to be fairly challenging. For some reason (could be a typo), the blue points for that family are not given in Fig. 3-right. Can you please elaborate on what type of grids, (and most importantly why) the Lloyd could be a limiting factor? And please report the aspect ratio location in Fig 3-right.\n- For Figure 1, what is the greedy dominance factor?\n- In Figure 2, can we also see the greedy baseline?",
    "review_points_list": [
      "Overall the paper clearly proposes a useful improvement of the AMG algorithm.",
      "The novelty here is in combining RL with another AMG technique which I'm not familiar with in prior work.",
      "The authors give sufficient empirical validation to the advantage of the suggested combination.",
      "The results are clearly of interest to practitioners who use AMG solvers in a variety of settings from solving PDEs to other general systems in 2D grids.",
      "The authors clearly (and honestly) state that the generalization to other problems is still unknown.",
      "I assume that the Lloyd based aggregation is essentially a k-means method; hence, the question is how to determine K so that the partition will still be linear but the size of each cluster will be approximately similar to that of the other clusters to allow faithful sampling from each.",
      "In this context, for example, I would expect the family of aspect ratio to be fairly challenging. For some reason (could be a typo), the blue points for that family are not given in Fig. 3-right. Can you please elaborate on what type of grids, (and most importantly why) the Lloyd could be a limiting factor? And please report the aspect ratio location in Fig 3-right.",
      "For Figure 1, what is the greedy dominance factor?",
      "In Figure 2, can we also see the greedy baseline?"
    ]
  },
  {
    "paper_id": "2106.01854v3",
    "submission_id": "xXYjxli-2i",
    "submission_title": "Optimization-Based Algebraic Multigrid Coarsening Using Reinforcement Learning",
    "review_id": "daj-oI1fDhZ",
    "input": {
      "title": "Optimization-Based Algebraic Multigrid Coarsening Using Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Using reinforcement learning to solve large sparse linear systems of equations is a very interesting problem.\n- The authors introduce the graph and GNN as the tools to investigate them.\n- However, the quality is not enough and the content is not clear.\n- The experiments look very good, but the theories are not very clear.\n- If the authors can show strong theories, I would like to change my grade.\n- Furthermore, the authors still need to show the significance of their work to the readers.",
    "review_points_list": [
      "Using reinforcement learning to solve large sparse linear systems of equations is a very interesting problem.",
      "The authors introduce the graph and GNN as the tools to investigate them.",
      "However, the quality is not enough and the content is not clear.",
      "The experiments look very good, but the theories are not very clear.",
      "If the authors can show strong theories, I would like to change my grade.",
      "Furthermore, the authors still need to show the significance of their work to the readers."
    ]
  },
  {
    "paper_id": "1807.00392v1",
    "submission_id": "yRfsADObu18",
    "submission_title": "Gradient Driven Rewards to Guarantee Fairness in Collaborative Machine Learning",
    "review_id": "qxvK2WO8A6",
    "input": {
      "title": "Gradient Driven Rewards to Guarantee Fairness in Collaborative Machine Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper is well-written and well-organized.\n- The empirical section considers an adequate amount of datasets.\n- The proposed algorithm can correct misidentified agent (who was originally mistaken to have low contribution).\n- The technique/theoretical results are correct to me.\n- I am worried about the convergence behavior.\n- The authors should clearly discuss this limitation.\n- What is the intuition behind this? Is there any theoretical justification?\n- It is not clear to me how to reasonably sparsify the gradient.\n- This vicious cycle will continue and situations will become worse and worse.\n- Is this still fair?\n- The experimental setup for results in Table 1 is not clear.\n- Authors mentioned that 'we expect the agents with more classes to receive better models'. This is fundamentally an unfair argument for fairness, even though the goal is collaborative fairness.\n- Under this scenario, what if a local device with a large amount of high-quality data is unwilling to collaborate with others and providing a fake gradient?\n- Will this local device significantly affect other devices and the overall performance?\n- I am unsure why the proposed fairness definition is meaningful.\n- I want to see under what scenario will this model be useful and proposed fairness definition is justifiable.",
    "review_points_list": [
      "This paper is well-written and well-organized.",
      "The empirical section considers an adequate amount of datasets.",
      "The proposed algorithm can correct misidentified agent (who was originally mistaken to have low contribution).",
      "The technique/theoretical results are correct to me.",
      "I am worried about the convergence behavior.",
      "The authors should clearly discuss this limitation.",
      "What is the intuition behind this? Is there any theoretical justification?",
      "It is not clear to me how to reasonably sparsify the gradient.",
      "This vicious cycle will continue and situations will become worse and worse.",
      "Is this still fair?",
      "The experimental setup for results in Table 1 is not clear.",
      "Authors mentioned that 'we expect the agents with more classes to receive better models'. This is fundamentally an unfair argument for fairness, even though the goal is collaborative fairness.",
      "Under this scenario, what if a local device with a large amount of high-quality data is unwilling to collaborate with others and providing a fake gradient?",
      "Will this local device significantly affect other devices and the overall performance?",
      "I am unsure why the proposed fairness definition is meaningful.",
      "I want to see under what scenario will this model be useful and proposed fairness definition is justifiable."
    ]
  },
  {
    "paper_id": "1807.00392v1",
    "submission_id": "yRfsADObu18",
    "submission_title": "Gradient Driven Rewards to Guarantee Fairness in Collaborative Machine Learning",
    "review_id": "0tFgbUGV6o2",
    "input": {
      "title": "Gradient Driven Rewards to Guarantee Fairness in Collaborative Machine Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This work presents a novel approach for improving the reward allocation function in a multi-agent environment.\n- The authors propose an approximation of the CGS, which is computationally efficient.\n- The authors provide a theoretical analysis, but the results are not fully supported in the experimental results.\n- The paper is well-structured and the authors explain the method in detail.\n- However, there are some issues with the clarity of the paper.\n- For example, the section on fairness is unclear and could be clarified.\n- Additionally, some definitions and explanations are not clear.\n- Overall, the paper presents a new approach for improving reward allocation in a multi-agent environment, but the results are not fully supported by the experimental results.",
    "review_points_list": [
      "This work presents a novel approach for improving the reward allocation function in a multi-agent environment.",
      "The authors propose an approximation of the CGS, which is computationally efficient.",
      "The authors provide a theoretical analysis, but the results are not fully supported in the experimental results.",
      "The paper is well-structured and the authors explain the method in detail.",
      "However, there are some issues with the clarity of the paper.",
      "For example, the section on fairness is unclear and could be clarified.",
      "Additionally, some definitions and explanations are not clear.",
      "Overall, the paper presents a new approach for improving reward allocation in a multi-agent environment, but the results are not fully supported by the experimental results."
    ]
  },
  {
    "paper_id": "1807.00392v1",
    "submission_id": "yRfsADObu18",
    "submission_title": "Gradient Driven Rewards to Guarantee Fairness in Collaborative Machine Learning",
    "review_id": "qrDOMGZKQxC",
    "input": {
      "title": "Gradient Driven Rewards to Guarantee Fairness in Collaborative Machine Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- While collaborative learning is becoming more mainstream in applications, there has been limited attention in the academic literature on how to best facilitate the pooling of resources by self-interested agents.\n- The idea of using the Shapley value (which is standard in cooperative game theory) to determine rewards in the context of collaborative learning is very natural and interesting.\n- The approach of giving agents information whose \u201cquality\u201d is based on the Shapley value, rather than simply using the Shapley value to determine monetary transfers, is very interesting.\n- The paper is generally well-written.\n- One weakness is with the definition of Cosine Gradient Shapley Value. It is not clear that taking the inner product with the average gradient reported by all agents is always meaningful.\n- Even if the agents start at the same point at initialization, their trajectories might diverge significantly since they are given different gradients, and so the geometric proximity to the average gradient may not be an appropriate measure of quality.\n- Another weakness is that the authors do not provide theoretical insights into how the predictive performance for each agent changes with beta (the \u201caltruism degree\u201d) or how the rate of convergence changes with beta.\n- Regarding the estimator of Cosine Gradient Shapley Value in (3), this estimator does not seem to be unbiased, and the resulting bound in Theorem 1 requires an assumption on the inner products.\n- The empirical comparison against typical sampling-based approaches is fairly limited, and it would be helpful to discuss the advantages and disadvantages of the proposed estimator.\n- It would also be helpful to discuss motivating applications where agents give gradients at each step, rather than directly sharing their data or their learned model with the platform.\n- Update: Thanks to the authors for their detailed responses! I appreciate the authors' additional justifications of Cosine similarity (e.g. in relation to the cited work below and also in Appendix A.1), and have raised my score.",
    "review_points_list": [
      "While collaborative learning is becoming more mainstream in applications, there has been limited attention in the academic literature on how to best facilitate the pooling of resources by self-interested agents.",
      "The idea of using the Shapley value (which is standard in cooperative game theory) to determine rewards in the context of collaborative learning is very natural and interesting.",
      "The approach of giving agents information whose \u201cquality\u201d is based on the Shapley value, rather than simply using the Shapley value to determine monetary transfers, is very interesting.",
      "The paper is generally well-written.",
      "One weakness is with the definition of Cosine Gradient Shapley Value. It is not clear that taking the inner product with the average gradient reported by all agents is always meaningful.",
      "Even if the agents start at the same point at initialization, their trajectories might diverge significantly since they are given different gradients, and so the geometric proximity to the average gradient may not be an appropriate measure of quality.",
      "Another weakness is that the authors do not provide theoretical insights into how the predictive performance for each agent changes with beta (the \u201caltruism degree\u201d) or how the rate of convergence changes with beta.",
      "Regarding the estimator of Cosine Gradient Shapley Value in (3), this estimator does not seem to be unbiased, and the resulting bound in Theorem 1 requires an assumption on the inner products.",
      "The empirical comparison against typical sampling-based approaches is fairly limited, and it would be helpful to discuss the advantages and disadvantages of the proposed estimator.",
      "It would also be helpful to discuss motivating applications where agents give gradients at each step, rather than directly sharing their data or their learned model with the platform.",
      "Update: Thanks to the authors for their detailed responses! I appreciate the authors' additional justifications of Cosine similarity (e.g. in relation to the cited work below and also in Appendix A.1), and have raised my score."
    ]
  },
  {
    "paper_id": "1807.00392v1",
    "submission_id": "yRfsADObu18",
    "submission_title": "Gradient Driven Rewards to Guarantee Fairness in Collaborative Machine Learning",
    "review_id": "PKeZLuFCLY7",
    "input": {
      "title": "Gradient Driven Rewards to Guarantee Fairness in Collaborative Machine Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- An efficient approximation to the Cosine Gradient Shapley to address the computational issue of the Shapley value.\n- No validation dataset is required to evaluate participant's contribution.\n- Extensive experiments to demonstrate the effectiveness of the proposed solution in achieving fairness.\n- The high-level explanation on how fairness is achieved using sparsification of gradients can be clearer.\n- More comparison with existing methods such q-FFL should be added.",
    "review_points_list": [
      "An efficient approximation to the Cosine Gradient Shapley to address the computational issue of the Shapley value.",
      "No validation dataset is required to evaluate participant's contribution.",
      "Extensive experiments to demonstrate the effectiveness of the proposed solution in achieving fairness.",
      "The high-level explanation on how fairness is achieved using sparsification of gradients can be clearer.",
      "More comparison with existing methods such q-FFL should be added."
    ]
  },
  {
    "paper_id": "1904.05961v3",
    "submission_id": "we8d1FjibAc",
    "submission_title": "Robust and Fully-Dynamic Coreset for Continuous-and-Bounded Learning (With Outliers) Problems",
    "review_id": "5e6ZJX6NiFp",
    "input": {
      "title": "Robust and Fully-Dynamic Coreset for Continuous-and-Bounded Learning (With Outliers) Problems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper suggests a robust coreset construction framework for several problems, including logistic regression and $k$-means clustering, under the umbrella of continuous-and-bounded learning.\n- The method entails sensitivity sampling for 'inliers' while using $\tepsilon$-sample for 'outliers' to obtain a robust coreset.\n- The ideas are interesting in nature and the work is not trivial.\n- I enjoyed reading the paper and the results are sound yet there are some misclarifications.\n- Due to time constraints, I have managed to go over some of the proofs and they were sound other than the proof of Theorem 1 and Lemma 2; see my comment section below.\n- What is $Y$ at Line 168? It seems that $Y$ is the set $B$.\n- There is an additional 's' at Line 300.\n- It is very interesting that the sensitivity can be solved using quadratic fractional programming via a relaxation towards semi-definite programming. My question is, what is the total sensitivity in this case? what is the exponent in the $\realpoly(d)$ term at the time complexity?\n- At Lemma 2, the bounds are not tight since the coreset is a robust coreset. This means that some of the transitions need to involve an additional multiplicative term of O(1\u00b1\u03b5). This is due to the fact that you end up dividing the sum of weights of instances of C by the number of points in X. Through the literature of \u03b5-coresets, and robust coresets as well, this term is in the range of [ 1\u2212\u03b5, 1+\u03b5].\n- The proof of Theorem 1 is not clear as some of the transitions are not clear (see my first comment).\n- Some of the coresets that you have mentioned handled instances of the problems that the paper discusses, e.g., logistic regression. However, I believe that the related work can be further enhanced, e.g., 'Coresets for Near-Convex Functions' which proposes a unified framework for coreset construction for various loss functions including logistic regression, SVMs, and even robust \u2113p-regression. Using this paper as a black box to bound the sensitivity, how well your model will perform in terms of normalized loss error?\n- Please move some of the graphs to the main manuscript to further enhance your results in the paper.",
    "review_points_list": [
      "The paper suggests a robust coreset construction framework for several problems, including logistic regression and $k$-means clustering, under the umbrella of continuous-and-bounded learning.",
      "The method entails sensitivity sampling for 'inliers' while using $\tepsilon$-sample for 'outliers' to obtain a robust coreset.",
      "The ideas are interesting in nature and the work is not trivial.",
      "I enjoyed reading the paper and the results are sound yet there are some misclarifications.",
      "Due to time constraints, I have managed to go over some of the proofs and they were sound other than the proof of Theorem 1 and Lemma 2; see my comment section below.",
      "What is $Y$ at Line 168? It seems that $Y$ is the set $B$.",
      "There is an additional 's' at Line 300.",
      "It is very interesting that the sensitivity can be solved using quadratic fractional programming via a relaxation towards semi-definite programming. My question is, what is the total sensitivity in this case? what is the exponent in the $\realpoly(d)$ term at the time complexity?",
      "At Lemma 2, the bounds are not tight since the coreset is a robust coreset. This means that some of the transitions need to involve an additional multiplicative term of O(1\u00b1\u03b5). This is due to the fact that you end up dividing the sum of weights of instances of C by the number of points in X. Through the literature of \u03b5-coresets, and robust coresets as well, this term is in the range of [ 1\u2212\u03b5, 1+\u03b5].",
      "The proof of Theorem 1 is not clear as some of the transitions are not clear (see my first comment).",
      "Some of the coresets that you have mentioned handled instances of the problems that the paper discusses, e.g., logistic regression. However, I believe that the related work can be further enhanced, e.g., 'Coresets for Near-Convex Functions' which proposes a unified framework for coreset construction for various loss functions including logistic regression, SVMs, and even robust \u2113p-regression. Using this paper as a black box to bound the sensitivity, how well your model will perform in terms of normalized loss error?",
      "Please move some of the graphs to the main manuscript to further enhance your results in the paper."
    ]
  },
  {
    "paper_id": "1904.05961v3",
    "submission_id": "we8d1FjibAc",
    "submission_title": "Robust and Fully-Dynamic Coreset for Continuous-and-Bounded Learning (With Outliers) Problems",
    "review_id": "foN9XE2GAm",
    "input": {
      "title": "Robust and Fully-Dynamic Coreset for Continuous-and-Bounded Learning (With Outliers) Problems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I enjoyed reading the paper, which suggests a robust coreset construction framework for multiple problems such like logistic regression and k-means clustering.\n- The coreset uses sensitivity sampling for inliers, and $\\delta$-sample for outliers.\n- The ideas in this work are not trivial and the paper is well written,\n- However I have some comments\n- I suggest moving the graphs to the paper.\n- The graphs at supplementary material presents your efficiency against multiple candidates of coreset construction schemes.\n- I noticed some missing definitions, for example, in Theorem 1, line 168, what is Y?\n- I did not completely understand the proof because of missing definitions in this Theorem.\n- Shouldn't the upper bound in Lemma 2 include $5 \\epsilon$ instead of $3 \\epsilon$?\n- Line 177, what do you mean by 'not integral'? did you mean integer?",
    "review_points_list": [
      "I enjoyed reading the paper, which suggests a robust coreset construction framework for multiple problems such like logistic regression and k-means clustering.",
      "The coreset uses sensitivity sampling for inliers, and $\\delta$-sample for outliers.",
      "The ideas in this work are not trivial and the paper is well written,",
      "However I have some comments",
      "I suggest moving the graphs to the paper.",
      "The graphs at supplementary material presents your efficiency against multiple candidates of coreset construction schemes.",
      "I noticed some missing definitions, for example, in Theorem 1, line 168, what is Y?",
      "I did not completely understand the proof because of missing definitions in this Theorem.",
      "Shouldn't the upper bound in Lemma 2 include $5 \\epsilon$ instead of $3 \\epsilon$?",
      "Line 177, what do you mean by 'not integral'? did you mean integer?"
    ]
  },
  {
    "paper_id": "1904.05961v3",
    "submission_id": "we8d1FjibAc",
    "submission_title": "Robust and Fully-Dynamic Coreset for Continuous-and-Bounded Learning (With Outliers) Problems",
    "review_id": "dho3H_mt2el",
    "input": {
      "title": "Robust and Fully-Dynamic Coreset for Continuous-and-Bounded Learning (With Outliers) Problems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors tackle an interesting and relevant problem of constructing coresets in the context of outliers.\n- I appreciate their effort in trying to make their approach as widely applicable as possible to common optimization problems and scenarios in large-scale machine learning.\n- The technical results of the paper seem sound to the best of my knowledge.\n- Although the approach of partitioning the input set and sampling from each set separately is not new in importance sampling (cf., stratification [2]), I found its application to outlier-resistant coresets to be interesting and novel.\n- The paper is quite dense and the organization and exposition could use improvements.\n- Crucial details in certain parts of the paper (see comments regarding QP & SDP below) are not provided at all or deferred to the supplementary, but yet proofs of technical results (e.g., Lemma 2, Theorem 1, and Theorem 2) are provided inline -- taking up almost 2 pages total in the main paper.\n- To me, this seems to distract from the flow of the paper, and also leads to important omissions.\n- For example, the (only) empirical results of the work can only be found at the end of the supplementary material and additional details regarding the implementation of the method in practice are not provided (e.g., for a given sample size as in Sec. D of the supplementary, what $\\\r",
    "review_points_list": [
      "The authors tackle an interesting and relevant problem of constructing coresets in the context of outliers.",
      "I appreciate their effort in trying to make their approach as widely applicable as possible to common optimization problems and scenarios in large-scale machine learning.",
      "The technical results of the paper seem sound to the best of my knowledge.",
      "Although the approach of partitioning the input set and sampling from each set separately is not new in importance sampling (cf., stratification [2]), I found its application to outlier-resistant coresets to be interesting and novel.",
      "The paper is quite dense and the organization and exposition could use improvements.",
      "Crucial details in certain parts of the paper (see comments regarding QP & SDP below) are not provided at all or deferred to the supplementary, but yet proofs of technical results (e.g., Lemma 2, Theorem 1, and Theorem 2) are provided inline -- taking up almost 2 pages total in the main paper.",
      "To me, this seems to distract from the flow of the paper, and also leads to important omissions.",
      "For example, the (only) empirical results of the work can only be found at the end of the supplementary material and additional details regarding the implementation of the method in practice are not provided (e.g., for a given sample size as in Sec. D of the supplementary, what $\\\r"
    ]
  },
  {
    "paper_id": "1904.05961v3",
    "submission_id": "we8d1FjibAc",
    "submission_title": "Robust and Fully-Dynamic Coreset for Continuous-and-Bounded Learning (With Outliers) Problems",
    "review_id": "SE4HRj5zgFD",
    "input": {
      "title": "Robust and Fully-Dynamic Coreset for Continuous-and-Bounded Learning (With Outliers) Problems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The main novelty is the initiative of a unified framework for coresets for continuous-and-bounded learning with outliers.\n- The main result which reduces the outlier version to the non-outlier version is novel, and I do think this reduction seems to be strong enough to imply interesting new bounds for concrete instances of continuous-and-bounded learning problems.\n- Unfortunately, authors did not give any such examples, which makes me uncertain about the usefulness of this new unified theory.\n- In particular, the theorem requires the VC-dimension of the f-induced range space to be bounded \u2013 can you show an interesting example of continuous-and-bounded learning problem that has VC-dimension bounded?\n- It also makes it hard to tell whether this result can improve previous works without such examples.\n- An additional comment is that, your coreset is bi-criteria for the outlier problems \u2013 is the violation in the number of outliers necessary? Can you possibly justify this?\n- As another contribution, several coreset constructions for general continuous-and-bounded learning (without outliers) are given, and all of the proposed coresets depend on the doubling dimension of the parameter space.\n- But I\u2019m not sure if considering doubling dimension on the parameter space makes sense \u2013 indeed, doubling dimension is an intrinsic dimensionality measure, but it is usually applied on data set instead of parameter space.\n- In fact, parameter space is data-independent and usually depends on the problem itself, which does not seem to benefit from low intrinsic dimension.\n- Technically, many results are obtained by combining existing techniques in a straightforward way, and I don\u2019t see much novelty.\n- For instance, the dynamic algorithm follows almost immediately from previous works, and it doesn\u2019t add much to the paper; also, the two coresets for the non-outlier version of the problem are very much standard and follow from the previous framework with only minor modifications.\n- I think the paper is technically sound, and all major claims are reasonably supported by proofs.\n- However, a key missing part of the paper is some concrete applications of the unified theory \u2013 maybe some new bounds for specific learning problems?\n- Or experiments that validate the theory in a certain way?\n- This would make the theory more useful to the machine learning community.\n- The paper is overall very well written.\n- It does a good job to provide necessary information for (at least expert) readers to understand why each claim holds, without needing to read proofs.\n- Line 31 \u201cnoise\u201d -> \u201cnoisy\u201d.\n- Line 61 should be \u201ccontinuous-and-bounded\u201d.\n- In Definition 2, why use a different font for f? In general, please make sure you use the font consistently (which seems not the case in the paper).\n- In Definition 4, why do we need the assumption that \\mathcal{X} is a metric space? I don\u2019t think you need this.\n- Line 164, what do you mean by \u201c\\delta-approximate subset\u201d? I didn\u2019t find the definition.\n- Line 165, the use of O in \u201cO = ab\u201d seems not a good idea, since O is usually used in the big O notation.\n- Line 168, what is Y?\n- Theorem 2, line 223, what\u2019s the third parameter 2\\xi(l)? I think the notation only has two parameters?\n- Line 228, can you explain why f_z(\\theta, C) = f(\\theta, C_I + C_{II})? In particular, why don\u2019t we need C_{III} and C_{IV}?\n- In the statement of Theorem 3, the VC dimension should be a uniform upper bound for weighted range spaces over all weights.\n- In the statement of Theorem 4, line 321, you mentioned the hidden constant depends on \\inf_{\\theta} f(\\theta, X) \u2013 why this is bounded?",
    "review_points_list": [
      "The main novelty is the initiative of a unified framework for coresets for continuous-and-bounded learning with outliers.",
      "The main result which reduces the outlier version to the non-outlier version is novel, and I do think this reduction seems to be strong enough to imply interesting new bounds for concrete instances of continuous-and-bounded learning problems.",
      "Unfortunately, authors did not give any such examples, which makes me uncertain about the usefulness of this new unified theory.",
      "In particular, the theorem requires the VC-dimension of the f-induced range space to be bounded \u2013 can you show an interesting example of continuous-and-bounded learning problem that has VC-dimension bounded?",
      "It also makes it hard to tell whether this result can improve previous works without such examples.",
      "An additional comment is that, your coreset is bi-criteria for the outlier problems \u2013 is the violation in the number of outliers necessary? Can you possibly justify this?",
      "As another contribution, several coreset constructions for general continuous-and-bounded learning (without outliers) are given, and all of the proposed coresets depend on the doubling dimension of the parameter space.",
      "But I\u2019m not sure if considering doubling dimension on the parameter space makes sense \u2013 indeed, doubling dimension is an intrinsic dimensionality measure, but it is usually applied on data set instead of parameter space.",
      "In fact, parameter space is data-independent and usually depends on the problem itself, which does not seem to benefit from low intrinsic dimension.",
      "Technically, many results are obtained by combining existing techniques in a straightforward way, and I don\u2019t see much novelty.",
      "For instance, the dynamic algorithm follows almost immediately from previous works, and it doesn\u2019t add much to the paper; also, the two coresets for the non-outlier version of the problem are very much standard and follow from the previous framework with only minor modifications.",
      "I think the paper is technically sound, and all major claims are reasonably supported by proofs.",
      "However, a key missing part of the paper is some concrete applications of the unified theory \u2013 maybe some new bounds for specific learning problems?",
      "Or experiments that validate the theory in a certain way?",
      "This would make the theory more useful to the machine learning community.",
      "The paper is overall very well written.",
      "It does a good job to provide necessary information for (at least expert) readers to understand why each claim holds, without needing to read proofs.",
      "Line 31 \u201cnoise\u201d -> \u201cnoisy\u201d.",
      "Line 61 should be \u201ccontinuous-and-bounded\u201d.",
      "In Definition 2, why use a different font for f? In general, please make sure you use the font consistently (which seems not the case in the paper).",
      "In Definition 4, why do we need the assumption that \\mathcal{X} is a metric space? I don\u2019t think you need this.",
      "Line 164, what do you mean by \u201c\\delta-approximate subset\u201d? I didn\u2019t find the definition.",
      "Line 165, the use of O in \u201cO = ab\u201d seems not a good idea, since O is usually used in the big O notation.",
      "Line 168, what is Y?",
      "Theorem 2, line 223, what\u2019s the third parameter 2\\xi(l)? I think the notation only has two parameters?",
      "Line 228, can you explain why f_z(\\theta, C) = f(\\theta, C_I + C_{II})? In particular, why don\u2019t we need C_{III} and C_{IV}?",
      "In the statement of Theorem 3, the VC dimension should be a uniform upper bound for weighted range spaces over all weights.",
      "In the statement of Theorem 4, line 321, you mentioned the hidden constant depends on \\inf_{\\theta} f(\\theta, X) \u2013 why this is bounded?"
    ]
  },
  {
    "paper_id": "1904.05961v3",
    "submission_id": "we8d1FjibAc",
    "submission_title": "Robust and Fully-Dynamic Coreset for Continuous-and-Bounded Learning (With Outliers) Problems",
    "review_id": "7HzjHdNMxwy",
    "input": {
      "title": "Robust and Fully-Dynamic Coreset for Continuous-and-Bounded Learning (With Outliers) Problems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- a) Paper provides an extensive theoretical study analyzing the the robust coreset selection framework and proved a theorem stating that the proposed framework can successfully compute a (beta, epsilon) coreset.\n- Provided experimental results show that the proposed coreset selection framework achieves better speedup and accuracy compared to other coreset selection methods.\n- The theoretical assumption of boundedness is too restrictive for deep networks. Hence, the proposed framework may not work well in a deep learning scenario.\n- It would be nice to have some results using deep models even if the proposed method does not work so that others have an understanding of the limitations of the proposed approach.\n- In the experimental section (in the appendix), the authors mentioned speedups and accuracies achieved. It would be interesting to know how many actual outliers the proposed framework was able to select or filter during training.\n- The used coreset selection methods for experiments are simple. Hence, it would be interesting to know how the proposed coreset selection framework compares to other robust coreset selection frameworks like GLISTER, Coresets for Robust Training of Neural Networks against Noisy Labels, and Grad-Match in terms of speedups and accuracies.\n- It would also be interesting to find if the proposed approach can also be applied with the above-mentioned robust coreset selection methods.\n- The major limitation of this work is the lack of solid experiments. I would have expected more empirical results particularly given the nature of the problem not to have the experiments relegated to the Appendix.\n- I would encourage the authors to discuss how their approach compares to other subset selection and coreset approaches for robust learning. The authors have clarified a few of the issues pointed out.\n- However, a major criticism of this work is the lack of experiments. This, in my opinion, can be a limiting factor for the impact of this work, mainly because a lot of work in this area is empirical and an understanding of how an approach like this performs empirically is critical in understanding its place among the state-of-the-art.\n- However, I do think this paper contributes from a theoretical perspective, and I'll keep my score of weak acceptance.\n- I would strongly encourage the authors to add empirical evaluation in the main text if given a chance.",
    "review_points_list": [
      "a) Paper provides an extensive theoretical study analyzing the the robust coreset selection framework and proved a theorem stating that the proposed framework can successfully compute a (beta, epsilon) coreset.",
      "Provided experimental results show that the proposed coreset selection framework achieves better speedup and accuracy compared to other coreset selection methods.",
      "The theoretical assumption of boundedness is too restrictive for deep networks. Hence, the proposed framework may not work well in a deep learning scenario.",
      "It would be nice to have some results using deep models even if the proposed method does not work so that others have an understanding of the limitations of the proposed approach.",
      "In the experimental section (in the appendix), the authors mentioned speedups and accuracies achieved. It would be interesting to know how many actual outliers the proposed framework was able to select or filter during training.",
      "The used coreset selection methods for experiments are simple. Hence, it would be interesting to know how the proposed coreset selection framework compares to other robust coreset selection frameworks like GLISTER, Coresets for Robust Training of Neural Networks against Noisy Labels, and Grad-Match in terms of speedups and accuracies.",
      "It would also be interesting to find if the proposed approach can also be applied with the above-mentioned robust coreset selection methods.",
      "The major limitation of this work is the lack of solid experiments. I would have expected more empirical results particularly given the nature of the problem not to have the experiments relegated to the Appendix.",
      "I would encourage the authors to discuss how their approach compares to other subset selection and coreset approaches for robust learning. The authors have clarified a few of the issues pointed out.",
      "However, a major criticism of this work is the lack of experiments. This, in my opinion, can be a limiting factor for the impact of this work, mainly because a lot of work in this area is empirical and an understanding of how an approach like this performs empirically is critical in understanding its place among the state-of-the-art.",
      "However, I do think this paper contributes from a theoretical perspective, and I'll keep my score of weak acceptance.",
      "I would strongly encourage the authors to add empirical evaluation in the main text if given a chance."
    ]
  },
  {
    "paper_id": "2301.10988v1",
    "submission_id": "vecLnc6g6iQ",
    "submission_title": "Neural Rule-Execution Tracking Machine For Transformer-Based Text Generation",
    "review_id": "wGHyEBj08TX",
    "input": {
      "title": "Neural Rule-Execution Tracking Machine For Transformer-Based Text Generation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors' response was very thorough and addressed all my raised concerns, therefore I have increased my score.\n- The idea makes sense on a high level and having an efficient manner of incorporating constraints into the decoding process for text generation would be very beneficial for many tasks and applications.\n- Some important points about the method and the experiments are left unclear (see also questions below).\n- The writing could be improved (see also Typos & Additional Questions below).\n- Multiple runs and significance tests are missing. This makes it hard to judge the improvements (Table 2 & 3).\n- Line 156: What is q_ij^k here exactly? I thought q_ij was a state flag, such as \u201c2\u201d or \u201c0\u201d. But you tokenize it and encode it, so it sounds more like it is something like \u201cCopy(snow)\u201d? (If it is the latter, then what is the meaning of tokenizing and encoding something like \u201cLen(9)\u201d?)\n- 192: What exactly is storyline and what do you need it for?\n- The baseline takes the predicate logic constraints as input: How does T6 know what to do with these inputs? Was the model trained on this but without the NRETM module? Can you give an example of what the input looks likes? How do these inputs guide which sentences should be generated?\n- What is the overhead of your method compared to standard decoding approaches?\n- What happens if the decoding process cannot find a sequence that satisfies all constraint?\n- Document-level MT: How do you know at test time whether the system translates a particular sentence or not?\n- How many sentences are misaligned by Doc-mBART25? What are the s-BLEU and d-BLEU values on the subset that NRETM aligns correctly and Doc does not?\n- Why was NEUROLOGIC not used as a comparison baseline?\n- What is dynamic vs static strategy? In which experiment did you show that dynamic works better than static (from conclusion)?\n- Line 40: you could mention here that the examples will be translated into logic forms in the next section.\n- Paragraph starting at line 53: Why did you choose these datasets? How will they help evaluate the proposed approach?\n- Line 75: a and b should be bold faced?\n- 83: \u201cthat used\u201d -> \u201cthat are used\u201d\n- 83: \u201cdetails\u201d -> \u201cfor details\u201d\n- Paragraph at line 86: At this point, the state matrix is unclear. What are the initial values? How can the state matrix be used to understand if a constraint is satisfied or not?\n- 98: \u201ctake[s]\u201d & \u201cgenerate[s]\u201d\n- 108: \u201cbe all\u201d -> \u201call be\u201d\n- Paragraph at line 101: What is dynamic vs static strategy?\n- Paragraph at line 109: The state flag explanation would greatly benefit from an example.",
    "review_points_list": [
      "The authors' response was very thorough and addressed all my raised concerns, therefore I have increased my score.",
      "The idea makes sense on a high level and having an efficient manner of incorporating constraints into the decoding process for text generation would be very beneficial for many tasks and applications.",
      "Some important points about the method and the experiments are left unclear (see also questions below).",
      "The writing could be improved (see also Typos & Additional Questions below).",
      "Multiple runs and significance tests are missing. This makes it hard to judge the improvements (Table 2 & 3).",
      "Line 156: What is q_ij^k here exactly? I thought q_ij was a state flag, such as \u201c2\u201d or \u201c0\u201d. But you tokenize it and encode it, so it sounds more like it is something like \u201cCopy(snow)\u201d? (If it is the latter, then what is the meaning of tokenizing and encoding something like \u201cLen(9)\u201d?)",
      "192: What exactly is storyline and what do you need it for?",
      "The baseline takes the predicate logic constraints as input: How does T6 know what to do with these inputs? Was the model trained on this but without the NRETM module? Can you give an example of what the input looks likes? How do these inputs guide which sentences should be generated?",
      "What is the overhead of your method compared to standard decoding approaches?",
      "What happens if the decoding process cannot find a sequence that satisfies all constraint?",
      "Document-level MT: How do you know at test time whether the system translates a particular sentence or not?",
      "How many sentences are misaligned by Doc-mBART25? What are the s-BLEU and d-BLEU values on the subset that NRETM aligns correctly and Doc does not?",
      "Why was NEUROLOGIC not used as a comparison baseline?",
      "What is dynamic vs static strategy? In which experiment did you show that dynamic works better than static (from conclusion)?",
      "Line 40: you could mention here that the examples will be translated into logic forms in the next section.",
      "Paragraph starting at line 53: Why did you choose these datasets? How will they help evaluate the proposed approach?",
      "Line 75: a and b should be bold faced?",
      "83: \u201cthat used\u201d -> \u201cthat are used\u201d",
      "83: \u201cdetails\u201d -> \u201cfor details\u201d",
      "Paragraph at line 86: At this point, the state matrix is unclear. What are the initial values? How can the state matrix be used to understand if a constraint is satisfied or not?",
      "98: \u201ctake[s]\u201d & \u201cgenerate[s]\u201d",
      "108: \u201cbe all\u201d -> \u201call be\u201d",
      "Paragraph at line 101: What is dynamic vs static strategy?",
      "Paragraph at line 109: The state flag explanation would greatly benefit from an example."
    ]
  },
  {
    "paper_id": "2301.10988v1",
    "submission_id": "vecLnc6g6iQ",
    "submission_title": "Neural Rule-Execution Tracking Machine For Transformer-Based Text Generation",
    "review_id": "NeBGs1utWAk",
    "input": {
      "title": "Neural Rule-Execution Tracking Machine For Transformer-Based Text Generation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This work aims to find a way to impose the symbolic rules into powerful neural networks.\n- It proposes a unified and scalable approach, named NRETM, to perform fine-grained controllable text generation and incorporate multiple prior knowledge.\n- Strength: 1. This paper proposes a framework to unify the constrained generation and general text generation with prior knowledge incorporation.\n- Strength: 2. Experimental results on story generation, machine translation, and commonsense generation partially demonstrate the effectiveness of the proposed method.\n- Drawbacks: 1. The novelty of this work is not clear.\n- Drawbacks: 2. The experiments lack rigor.\n- The author should add some competitive baselines for comparison.\n- This paper mainly compares NRETM with pre-trained model T5.\n- T5 can not utilize prior knowledge efficiently.\n- Feeding the predicate logic constraints as inputs directly is not a suitable way to impose prior knowledge.\n- Eq. 1 P(y|x) is not defined.\n- Line 103, in 1 -> in Figure 1.\n- Line 116, consist -> consists.",
    "review_points_list": [
      "This work aims to find a way to impose the symbolic rules into powerful neural networks.",
      "It proposes a unified and scalable approach, named NRETM, to perform fine-grained controllable text generation and incorporate multiple prior knowledge.",
      "Strength: 1. This paper proposes a framework to unify the constrained generation and general text generation with prior knowledge incorporation.",
      "Strength: 2. Experimental results on story generation, machine translation, and commonsense generation partially demonstrate the effectiveness of the proposed method.",
      "Drawbacks: 1. The novelty of this work is not clear.",
      "Drawbacks: 2. The experiments lack rigor.",
      "The author should add some competitive baselines for comparison.",
      "This paper mainly compares NRETM with pre-trained model T5.",
      "T5 can not utilize prior knowledge efficiently.",
      "Feeding the predicate logic constraints as inputs directly is not a suitable way to impose prior knowledge.",
      "Eq. 1 P(y|x) is not defined.",
      "Line 103, in 1 -> in Figure 1.",
      "Line 116, consist -> consists."
    ]
  },
  {
    "paper_id": "2301.10988v1",
    "submission_id": "vecLnc6g6iQ",
    "submission_title": "Neural Rule-Execution Tracking Machine For Transformer-Based Text Generation",
    "review_id": "tBCGH9tFa_",
    "input": {
      "title": "Neural Rule-Execution Tracking Machine For Transformer-Based Text Generation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper tackles an interesting problem, and it obtains good results.\n- Another nice thing about the paper is the authors largely consider constraints that are *not* easy to implement with just a simple constrained beam search.\n- In particular, rather than constraints which disallow certain tokens or alignments, the authors consider constraints that require the presence or a particular number of certain words, which are much more challenging to guarantee with standard decoding algorithms.\n- The core contribution of the paper appears to be the proposal of an approach to dynamically and explicitly updating the decoder in response to whether or how much the text generated so far conforms with some pre-specified constraints.\n- Similar ideas have been proposed before (as the authors note), such as in the case of coverage attention (Tu et al., 2016).\n- The proposed approach would feel more compelling if the authors could argue that it is superior to other approaches to updating the decoder in response to how well constraints have been satisfied in the generated text so far.\n- However, I don't think there are any such comparisons.\n- It seems the main baselines the authors consider are either a baseline seq2seq model with the constraints encoded statically on the source side (Table 1) or a baseline seq2seq model with a constrained decoding algorithm (Table 2).\n- As such, it's hard to tell how crucial the various modeling/encoding choices the authors have made in implementing their approach are.\n- A natural baseline not considered, for instance, might involve dynamically updating the constraint tokens consumed by the encoder in the baseline in Table 1 instead of using the authors' proposed attention model.\n- I think the paper is largely clear, although I would encourage the authors to emphasize earlier on that their method involves fine-tuning the model rather than simply implementing constraints at decoding time;\n- I think the fact that fine-tuning is involved only really becomes clear on the bottom of page 5.\n- Are the script 'U's on like 116 different from the non-script upper case 'U's on line 109?\n- Update after response from authors: thanks for your response; I'm increasing my score in view of the new baseline results.",
    "review_points_list": [
      "This paper tackles an interesting problem, and it obtains good results.",
      "Another nice thing about the paper is the authors largely consider constraints that are *not* easy to implement with just a simple constrained beam search.",
      "In particular, rather than constraints which disallow certain tokens or alignments, the authors consider constraints that require the presence or a particular number of certain words, which are much more challenging to guarantee with standard decoding algorithms.",
      "The core contribution of the paper appears to be the proposal of an approach to dynamically and explicitly updating the decoder in response to whether or how much the text generated so far conforms with some pre-specified constraints.",
      "Similar ideas have been proposed before (as the authors note), such as in the case of coverage attention (Tu et al., 2016).",
      "The proposed approach would feel more compelling if the authors could argue that it is superior to other approaches to updating the decoder in response to how well constraints have been satisfied in the generated text so far.",
      "However, I don't think there are any such comparisons.",
      "It seems the main baselines the authors consider are either a baseline seq2seq model with the constraints encoded statically on the source side (Table 1) or a baseline seq2seq model with a constrained decoding algorithm (Table 2).",
      "As such, it's hard to tell how crucial the various modeling/encoding choices the authors have made in implementing their approach are.",
      "A natural baseline not considered, for instance, might involve dynamically updating the constraint tokens consumed by the encoder in the baseline in Table 1 instead of using the authors' proposed attention model.",
      "I think the paper is largely clear, although I would encourage the authors to emphasize earlier on that their method involves fine-tuning the model rather than simply implementing constraints at decoding time;",
      "I think the fact that fine-tuning is involved only really becomes clear on the bottom of page 5.",
      "Are the script 'U's on like 116 different from the non-script upper case 'U's on line 109?",
      "Update after response from authors: thanks for your response; I'm increasing my score in view of the new baseline results."
    ]
  },
  {
    "paper_id": "2301.10988v1",
    "submission_id": "vecLnc6g6iQ",
    "submission_title": "Neural Rule-Execution Tracking Machine For Transformer-Based Text Generation",
    "review_id": "bOdzLz9QncJ",
    "input": {
      "title": "Neural Rule-Execution Tracking Machine For Transformer-Based Text Generation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper focus on an interesting problem about constraint-based generation tasks.\n- The paper solves this problem by proposing a new Neural Rule-execution tracking machine that tries to incorporate rules into current transformer-based seq2seq generation models.\n- The paper utilizes the logic tracker as relative position information to guide the model in the generation\n- The experiment results over three different tasks seem to be promising.\n- The paper lists detailed experiment settings for three different tasks.\n- The paper also discusses the ability of the model in a zero-shot setting.\n- The paper includes code as a supplement and put more generation results as case studies for three different tasks.\n- Those examples show that the model captures those constraints through the proposed framework.\n- Section 2.4 is a little bit confusing.\n- Even though the paper provides Figure 2 as a running example of the NRETM model with three logic constraints, it still takes me some time to understand all the concepts introduced in this section.\n- It would be better to reorganize the content.\n- A logic tracker should be introduced before the state flag which can help readers to better understand the concepts.\n- The paper only compares their model to a limited baseline.\n- The paper needs to add some baseline mentioned in related work such as NEUROLOGIC DECODING (Liu et al., 2020).\n- The constraint satisfaction metric is not clearly defined.\n- The evaluation metrics for all/novel/seen constraints are also absent.\n- The evaluation metrics are also limited.\n- It would be better to include more automatic metrics to show a more comprehensive view of the generation quality.\n- such as Bertscore(Zhang et al., 2019), BLEU, etc.\n- The generalizability of the framework is unclear.\n- It seems that the model can only be applied with several pre-defined logic operators.",
    "review_points_list": [
      "The paper focus on an interesting problem about constraint-based generation tasks.",
      "The paper solves this problem by proposing a new Neural Rule-execution tracking machine that tries to incorporate rules into current transformer-based seq2seq generation models.",
      "The paper utilizes the logic tracker as relative position information to guide the model in the generation",
      "The experiment results over three different tasks seem to be promising.",
      "The paper lists detailed experiment settings for three different tasks.",
      "The paper also discusses the ability of the model in a zero-shot setting.",
      "The paper includes code as a supplement and put more generation results as case studies for three different tasks.",
      "Those examples show that the model captures those constraints through the proposed framework.",
      "Section 2.4 is a little bit confusing.",
      "Even though the paper provides Figure 2 as a running example of the NRETM model with three logic constraints, it still takes me some time to understand all the concepts introduced in this section.",
      "It would be better to reorganize the content.",
      "A logic tracker should be introduced before the state flag which can help readers to better understand the concepts.",
      "The paper only compares their model to a limited baseline.",
      "The paper needs to add some baseline mentioned in related work such as NEUROLOGIC DECODING (Liu et al., 2020).",
      "The constraint satisfaction metric is not clearly defined.",
      "The evaluation metrics for all/novel/seen constraints are also absent.",
      "The evaluation metrics are also limited.",
      "It would be better to include more automatic metrics to show a more comprehensive view of the generation quality.",
      "such as Bertscore(Zhang et al., 2019), BLEU, etc.",
      "The generalizability of the framework is unclear.",
      "It seems that the model can only be applied with several pre-defined logic operators."
    ]
  },
  {
    "paper_id": "2006.12311v1",
    "submission_id": "tUeeRzMXJZ",
    "submission_title": "Provably Efficient Causal Reinforcement Learning with Confounded Observational Data",
    "review_id": "rEuFOdTBJbi",
    "input": {
      "title": "Provably Efficient Causal Reinforcement Learning with Confounded Observational Data",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper has many positive aspects; it presents a well-motivated algorithm for an important problem, and provides regret bounds that shrink in terms of the amount of confounded logged data available.\n- In this sense, the paper seems to fill an important niche in the literature.\n- There is no empirical evaluation of their proposed algorithm, or even an empirical \u201cproof of concept\u201d on synthetic data.\n- This makes it extremely difficult to assess how the algorithm is likely to fair in practice.\n- The backdoor criterion in Assumption 3.1 seems to be extremely central to the theory, but it is not explained at all.\n- Ideally, there would be an explanation of when we expect this requirement to be satisfied versus not.\n- Furthermore, it would be very beneficial in motivating the entire paper to provide a compelling clear/concrete example of a problem with unmeasured confounding that fits within your framework and satisfies assumption 3.1.\n- Without such an example, it is difficult to assess how useful the theory is.\n- The confounding model presented in section 2 seems very weird and non-standard.\n- This is in contrast to standard kinds of confounding models, where e.g. confounders are independent at each time step, follow in a Markov chain, or follow the POMDP model, etc.\n- It would be great to have a compelling example of a problem with this kind of confounding structure.\n- The method is presented as being \u201cprovably efficient\u201d.\n- But what does this actually mean?\n- It doesn\u2019t seem to be actually justified as efficient in any concrete sense.\n- One possible sense of efficiency is in terms of semi-parametric estimation, but that doesn\u2019t seem to be applied anywhere here.\n- Another sense could be in terms of optimal regret, but this doesn\u2019t seem to be established;\n- \u2026nothing as far as I can tell rules out the possibility of an alternative algorithm that has faster regret decay as n \u2192 \u221e.\n- Given this, presenting the work as \u201cprovably efficient\u201d in the title is extremely misleading.\n- There seems to be a bunch of important recent literature on using confounded off-line RL data that is missing from the related work.\n- For example, Namkoong et al. (2020) \u201cOff-policy Policy Evaluation For Sequential Decisions Under Unobserved Confounding\u201d, and Bennett et al. (2021) \u201cOff-policy Evaluation in Infinite-horizon Reinforcement Learning with Latent Confounders\u201d.\n- Typo in line 4 \u201csemple\u201d -> \u201csample\u201d.\n- On line 41 you say that \u201cThe complicated traffic and poor road design subsequently affect both the action of the drivers and the outcome\u201d.\n- But do we expect these things to be unobserved?\n- This only makes sense as an example of confounding if they are things not observed in the state space, but which the agent took into account.\n- It would be good to elaborate here.\n- For fairness, since all presentation and discussion of DOVI+ was deferred to appendix, I am not taking it into account when assessing the paper.\n- The discussion of structural causal models at the start of section 2 is very confusingly presented.\n- Mostly doesn\u2019t seem to contribute much other than defining the \u201cdo\u201d notation.\n- It presents a bunch of notation that is then never used.\n- Also, it would be good to define what the \u201cdo calculus\u201d notation means more explicitly for people not already familiar with it.\n- The definition of Regret in equation 2.3 defines it as a random quantity.\n- Since the definition involves the initial state s_1^k for each k \u2208 [K], which seems somewhat odd.\n- Should there have been an expectation over the initial state?\n- You refer to Figure 4 on line 216, but there appears to be no Figure 4 in the paper.\n- In a bunch of different places, you talk about replacing P with \u03d5_h.\n- I don\u2019t understand what is meant to be the difference between these two functions.\n- This needs to be explained concretely.\n- In assumption 3.3, is \u03d5_h meant to be a fixed given feature map?\n- This is not explained.\n- Also, in assumption 3.3, you refer to the reward function parameters as \u03b8_h, but later in the paper this appears to instead be referred to as \u03c9_h.\n- Typo on lines 249-250 \u201cis know\u201d -> \u201cis known\u201d.\n- What is the interpretation of the \u03b2 tuning parameter in your algorithm?\n- This doesn\u2019t not appear to be clearly explained.\n- Also, what would be the expected impact of increasing versus decreasing \u03b2 on how the algorithm operates?",
    "review_points_list": [
      "The paper has many positive aspects; it presents a well-motivated algorithm for an important problem, and provides regret bounds that shrink in terms of the amount of confounded logged data available.",
      "In this sense, the paper seems to fill an important niche in the literature.",
      "There is no empirical evaluation of their proposed algorithm, or even an empirical \u201cproof of concept\u201d on synthetic data.",
      "This makes it extremely difficult to assess how the algorithm is likely to fair in practice.",
      "The backdoor criterion in Assumption 3.1 seems to be extremely central to the theory, but it is not explained at all.",
      "Ideally, there would be an explanation of when we expect this requirement to be satisfied versus not.",
      "Furthermore, it would be very beneficial in motivating the entire paper to provide a compelling clear/concrete example of a problem with unmeasured confounding that fits within your framework and satisfies assumption 3.1.",
      "Without such an example, it is difficult to assess how useful the theory is.",
      "The confounding model presented in section 2 seems very weird and non-standard.",
      "This is in contrast to standard kinds of confounding models, where e.g. confounders are independent at each time step, follow in a Markov chain, or follow the POMDP model, etc.",
      "It would be great to have a compelling example of a problem with this kind of confounding structure.",
      "The method is presented as being \u201cprovably efficient\u201d.",
      "But what does this actually mean?",
      "It doesn\u2019t seem to be actually justified as efficient in any concrete sense.",
      "One possible sense of efficiency is in terms of semi-parametric estimation, but that doesn\u2019t seem to be applied anywhere here.",
      "Another sense could be in terms of optimal regret, but this doesn\u2019t seem to be established;",
      "\u2026nothing as far as I can tell rules out the possibility of an alternative algorithm that has faster regret decay as n \u2192 \u221e.",
      "Given this, presenting the work as \u201cprovably efficient\u201d in the title is extremely misleading.",
      "There seems to be a bunch of important recent literature on using confounded off-line RL data that is missing from the related work.",
      "For example, Namkoong et al. (2020) \u201cOff-policy Policy Evaluation For Sequential Decisions Under Unobserved Confounding\u201d, and Bennett et al. (2021) \u201cOff-policy Evaluation in Infinite-horizon Reinforcement Learning with Latent Confounders\u201d.",
      "Typo in line 4 \u201csemple\u201d -> \u201csample\u201d.",
      "On line 41 you say that \u201cThe complicated traffic and poor road design subsequently affect both the action of the drivers and the outcome\u201d.",
      "But do we expect these things to be unobserved?",
      "This only makes sense as an example of confounding if they are things not observed in the state space, but which the agent took into account.",
      "It would be good to elaborate here.",
      "For fairness, since all presentation and discussion of DOVI+ was deferred to appendix, I am not taking it into account when assessing the paper.",
      "The discussion of structural causal models at the start of section 2 is very confusingly presented.",
      "Mostly doesn\u2019t seem to contribute much other than defining the \u201cdo\u201d notation.",
      "It presents a bunch of notation that is then never used.",
      "Also, it would be good to define what the \u201cdo calculus\u201d notation means more explicitly for people not already familiar with it.",
      "The definition of Regret in equation 2.3 defines it as a random quantity.",
      "Since the definition involves the initial state s_1^k for each k \u2208 [K], which seems somewhat odd.",
      "Should there have been an expectation over the initial state?",
      "You refer to Figure 4 on line 216, but there appears to be no Figure 4 in the paper.",
      "In a bunch of different places, you talk about replacing P with \u03d5_h.",
      "I don\u2019t understand what is meant to be the difference between these two functions.",
      "This needs to be explained concretely.",
      "In assumption 3.3, is \u03d5_h meant to be a fixed given feature map?",
      "This is not explained.",
      "Also, in assumption 3.3, you refer to the reward function parameters as \u03b8_h, but later in the paper this appears to instead be referred to as \u03c9_h.",
      "Typo on lines 249-250 \u201cis know\u201d -> \u201cis known\u201d.",
      "What is the interpretation of the \u03b2 tuning parameter in your algorithm?",
      "This doesn\u2019t not appear to be clearly explained.",
      "Also, what would be the expected impact of increasing versus decreasing \u03b2 on how the algorithm operates?"
    ]
  },
  {
    "paper_id": "2006.12311v1",
    "submission_id": "tUeeRzMXJZ",
    "submission_title": "Provably Efficient Causal Reinforcement Learning with Confounded Observational Data",
    "review_id": "X559JlrSoBZ",
    "input": {
      "title": "Provably Efficient Causal Reinforcement Learning with Confounded Observational Data",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well-written and clear.\n- There are no experiments.\n- While this is not particularly an issue for this kind of technical paper, a toy example illustrating the advantage of using offline observational data and the different regimes of the regret bound would have been beneficial.\n- The paper is well-motivated.\n- it is very often the case that observational data are available and it is indeed relevant to try to use this data to reduce the sample cost of existing deep reinforcement learning solutions, especially when simulators are not available as is the case for most real-life problems (engineering systems, health, ....).\n- Leveraging tools from causal inference is an interesting direction that is increasingly popular.\n- the theoretical result to be interesting for the community.\n- the definition of an intervention states that the value is assigned regardless of the other exogenous and endogenous variables. However in the online context, when using a policy, the authors uses the do operator (as an intervention) but the policy selects an action based on the state $s. This is confusing as the action is thus not assigned regardless of the state which is an endogenous variable.\n- Are the authors the first to state a Backdoor Adjusted Bellman Equation? this is not clear in the paper.\n- It is also not clear to me where the distinction between the observational and interventional data is in algorithm 1?\n- the abstract format is not correct.\n- line 4: semple -> sample\n- lines 56 and 57: please give references.",
    "review_points_list": [
      "The paper is well-written and clear.",
      "There are no experiments.",
      "While this is not particularly an issue for this kind of technical paper, a toy example illustrating the advantage of using offline observational data and the different regimes of the regret bound would have been beneficial.",
      "The paper is well-motivated.",
      "it is very often the case that observational data are available and it is indeed relevant to try to use this data to reduce the sample cost of existing deep reinforcement learning solutions, especially when simulators are not available as is the case for most real-life problems (engineering systems, health, ....).",
      "Leveraging tools from causal inference is an interesting direction that is increasingly popular.",
      "the theoretical result to be interesting for the community.",
      "the definition of an intervention states that the value is assigned regardless of the other exogenous and endogenous variables. However in the online context, when using a policy, the authors uses the do operator (as an intervention) but the policy selects an action based on the state $s. This is confusing as the action is thus not assigned regardless of the state which is an endogenous variable.",
      "Are the authors the first to state a Backdoor Adjusted Bellman Equation? this is not clear in the paper.",
      "It is also not clear to me where the distinction between the observational and interventional data is in algorithm 1?",
      "the abstract format is not correct.",
      "line 4: semple -> sample",
      "lines 56 and 57: please give references."
    ]
  },
  {
    "paper_id": "2006.12311v1",
    "submission_id": "tUeeRzMXJZ",
    "submission_title": "Provably Efficient Causal Reinforcement Learning with Confounded Observational Data",
    "review_id": "KiTaNyucEj6",
    "input": {
      "title": "Provably Efficient Causal Reinforcement Learning with Confounded Observational Data",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The customer service was excellent and very helpful.\n- The product quality exceeded my expectations.\n- The shipping was fast and the packaging was secure.\n- However, the pricing could be more competitive compared to similar products in the market.",
    "review_points_list": [
      "The customer service was excellent and very helpful.",
      "The product quality exceeded my expectations.",
      "The shipping was fast and the packaging was secure.",
      "However, the pricing could be more competitive compared to similar products in the market."
    ]
  },
  {
    "paper_id": "2106.12575v3",
    "submission_id": "uVPZCMVtsSG",
    "submission_title": "Weisfeiler and Lehman Go Cellular: CW Networks",
    "review_id": "1dT9V8eOT3a",
    "input": {
      "title": "Weisfeiler and Lehman Go Cellular: CW Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The author's review of the work is positive, stating that it has a solid theoretical analysis, sufficient and convincing experimental results, and detailed supplementary materials.\n- I like this work because of its solid theoretical analysis, sufficient and convincing experimental results, and detailed supplementary materials.\n- In Section 4, the authors connect the proposed method with existing works and highlight its advantages, which further clarifies the contribution of this work to the community.\n- The only minor suggestion is to correct a small error in Line 121, which currently reads 'Simplicial WL' but should read 'Simplicial WL (SWL)' for clarity.\n- The authors could consider defining a graph kernel based on the features and providing a kind of high-order WL kernel accordingly, as a potential baseline in the experiment.\n- The introduction of CWN in Section 4 is too brief and could be expanded to include a figure illustrating the molecular message-passing model.\n- Before showing Figure 1, it would be necessary to add a figure illustrating topological space X, its partitions, and cells, with sufficient symbols and notations, to make it easier to understand the concepts in definition 1.",
    "review_points_list": [
      "The author's review of the work is positive, stating that it has a solid theoretical analysis, sufficient and convincing experimental results, and detailed supplementary materials.",
      "I like this work because of its solid theoretical analysis, sufficient and convincing experimental results, and detailed supplementary materials.",
      "In Section 4, the authors connect the proposed method with existing works and highlight its advantages, which further clarifies the contribution of this work to the community.",
      "The only minor suggestion is to correct a small error in Line 121, which currently reads 'Simplicial WL' but should read 'Simplicial WL (SWL)' for clarity.",
      "The authors could consider defining a graph kernel based on the features and providing a kind of high-order WL kernel accordingly, as a potential baseline in the experiment.",
      "The introduction of CWN in Section 4 is too brief and could be expanded to include a figure illustrating the molecular message-passing model.",
      "Before showing Figure 1, it would be necessary to add a figure illustrating topological space X, its partitions, and cells, with sufficient symbols and notations, to make it easier to understand the concepts in definition 1."
    ]
  },
  {
    "paper_id": "2106.12575v3",
    "submission_id": "uVPZCMVtsSG",
    "submission_title": "Weisfeiler and Lehman Go Cellular: CW Networks",
    "review_id": "BKSOJ5Q83L4",
    "input": {
      "title": "Weisfeiler and Lehman Go Cellular: CW Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I want to thank the authors for their responses to my questions in the review and during the discussion period. Please add a discussion/clarification of Theorem 15 as discussed.\n- I maintain my score of the paper.\n- See the above for the summary of the paper and its contribution.\n- The strength of the paper: (1) Graph neural networks (especially message passing graph networks) have received great attention in recent years. Recently there has been much interest in message passing over higher order structures, mostly to increase the expressiveness power of graph networks. Using CW complexes as in this paper is more flexible (e.g, filling induced cycles by 2-cells) than using simplicial complexes. The use of CWL is both natural and useful in practical applications.\n- The authors present several theoretical results on CWL and CWN. The formulation of lifting map is interesting.\n- Good empirical studies are presented, with both synthetic datasets to show the expressiveness and real benchmark datasets to see performance improvements.\n- The weakness of the paper: (a) The development of CWL is a generalization of the simplicial version (SWL, ref[4]). Most of the theoretical results feel incremental compared to the work of ref[4]. (The notion of cellular lifting map is new but perhaps not surprising. I have read the supplement briefly as well, and understand that there are complications / technicality that need to be addressed due to the use of cells instead of simplices. The concept of cellular message passing also exists in ref[24].) If there are significant new ideas, it would be great if they can be articulated. Furthermore, just being more expressive than WL is not a very strong theoretical result, especially since CWL is using high-dimensional cells.\n- (b) (A minor one:) I like the discussions and theoretical results on expressive power in distinguishing non-isomorphic graphs. There are other ways to increase expressive power, for example, by using more powerful initial node features (say sth. that captures cycle information) or by using node coloring (e.g, the following reference): [Ref]: \"Coloring Graph Neural Networks for Node Disambiguation\", George Dasoulas, Ludovic Dos Santos, Kevin Scaman, Aladin Virmaux, IJCAI 2020. It could be good to include a comparison with the approach in the above Ref.\n- The overall evaluation: Overall, I think this is a solid paper that presented nice studies over a natural object with reasonably convincing experimental results (especially over molecular graphs). The originality is somewhat limited (e.g., when compared to work of Ref[4]). Nevertheless, it is well-written and I enjoyed reading it.\n- Other comments: -- Maybe I missed it in the submission and supplement: how is the ring size $k$ chosen in experiments (especially for real datasets)? Different values of $k$ seem to be used for different applications. Is there a consistent strategy to choose it? There is a range of hyperparameters listed in Table 8 in supplement. Why not having $k$ as another hyperparameter? Also, how does the number of hyperparameters compare to other standard approaches, say GIN?\n- In Definition 1, is \"regularity\" important for the CW network? Is it needed for any of the results later?",
    "review_points_list": [
      "I want to thank the authors for their responses to my questions in the review and during the discussion period. Please add a discussion/clarification of Theorem 15 as discussed.",
      "I maintain my score of the paper.",
      "See the above for the summary of the paper and its contribution.",
      "The strength of the paper: (1) Graph neural networks (especially message passing graph networks) have received great attention in recent years. Recently there has been much interest in message passing over higher order structures, mostly to increase the expressiveness power of graph networks. Using CW complexes as in this paper is more flexible (e.g, filling induced cycles by 2-cells) than using simplicial complexes. The use of CWL is both natural and useful in practical applications.",
      "The authors present several theoretical results on CWL and CWN. The formulation of lifting map is interesting.",
      "Good empirical studies are presented, with both synthetic datasets to show the expressiveness and real benchmark datasets to see performance improvements.",
      "The weakness of the paper: (a) The development of CWL is a generalization of the simplicial version (SWL, ref[4]). Most of the theoretical results feel incremental compared to the work of ref[4]. (The notion of cellular lifting map is new but perhaps not surprising. I have read the supplement briefly as well, and understand that there are complications / technicality that need to be addressed due to the use of cells instead of simplices. The concept of cellular message passing also exists in ref[24].) If there are significant new ideas, it would be great if they can be articulated. Furthermore, just being more expressive than WL is not a very strong theoretical result, especially since CWL is using high-dimensional cells.",
      "(b) (A minor one:) I like the discussions and theoretical results on expressive power in distinguishing non-isomorphic graphs. There are other ways to increase expressive power, for example, by using more powerful initial node features (say sth. that captures cycle information) or by using node coloring (e.g, the following reference): [Ref]: \"Coloring Graph Neural Networks for Node Disambiguation\", George Dasoulas, Ludovic Dos Santos, Kevin Scaman, Aladin Virmaux, IJCAI 2020. It could be good to include a comparison with the approach in the above Ref.",
      "The overall evaluation: Overall, I think this is a solid paper that presented nice studies over a natural object with reasonably convincing experimental results (especially over molecular graphs). The originality is somewhat limited (e.g., when compared to work of Ref[4]). Nevertheless, it is well-written and I enjoyed reading it.",
      "Other comments: -- Maybe I missed it in the submission and supplement: how is the ring size $k$ chosen in experiments (especially for real datasets)? Different values of $k$ seem to be used for different applications. Is there a consistent strategy to choose it? There is a range of hyperparameters listed in Table 8 in supplement. Why not having $k$ as another hyperparameter? Also, how does the number of hyperparameters compare to other standard approaches, say GIN?",
      "In Definition 1, is \"regularity\" important for the CW network? Is it needed for any of the results later?"
    ]
  },
  {
    "paper_id": "2106.12575v3",
    "submission_id": "uVPZCMVtsSG",
    "submission_title": "Weisfeiler and Lehman Go Cellular: CW Networks",
    "review_id": "MEOVmyIemz",
    "input": {
      "title": "Weisfeiler and Lehman Go Cellular: CW Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The idea of lifting graphs to higher order representation is interesting but not new and the authors should clarify it.\n- Since Cellular WL add a lot of information, Theorem 13 is not really surprising.\n- Indeed, the analysis made in Section 3 is rather misleading.\n- The interest of the various WL tests is to show the trade-off between the complexity of the algorithm and its expressive power.\n- 1-WL is less complex than 3-WL and so on but you gain in term of expressiveness.\n- See [34], or Waiss Azizian, Marc Lelarge. Expressive Power of Invariant and Equivariant Graph Neural Networks, ICLR 2021, for a general overview about GNN and WL tests.\n- In Section 3, the authors completely ignore the complexity part.\n- For example, if I understand correctly, the clique complex lifting will include the information about all cliques in the graph which might be very costly to compute, hence Corollary 14 is just telling that if you have access to this information you can do better than a very simple algorithm.\n- It is clearly true but not very interesting.\n- The authors mention the complexity of their GNN on page 6 and write that under some conditions the complexity is 'linear in the size of the input complex'.\n- But how big can this size of the input complex be in term of the size of the graph?\n- The authors show that CW Network layers are cell permutation invariant.\n- Does it imply that the GNN is graph permutation invariant?\n- It seems that the authors only look at graph embedding with their CWN.\n- Is it possible to obtain node embedding by modifying the READOUT function?\n- It would have been nice to compare CIN with other algorithms having access to the same information as CIN.\n- Since, the authors compute all the rings in the graph for their CIN, how is the performance of a standard GNN improved if we add the statistics of the rings in addition to the embedding computed by the GNN?\n- Such result would allow to demonstrate whether the improvement seen in the paper is due to the new architecture or to the new features added.\n- Similarly, you can probably increase the performance of the WL kernel by adding this new feature to get very good results.",
    "review_points_list": [
      "The idea of lifting graphs to higher order representation is interesting but not new and the authors should clarify it.",
      "Since Cellular WL add a lot of information, Theorem 13 is not really surprising.",
      "Indeed, the analysis made in Section 3 is rather misleading.",
      "The interest of the various WL tests is to show the trade-off between the complexity of the algorithm and its expressive power.",
      "1-WL is less complex than 3-WL and so on but you gain in term of expressiveness.",
      "See [34], or Waiss Azizian, Marc Lelarge. Expressive Power of Invariant and Equivariant Graph Neural Networks, ICLR 2021, for a general overview about GNN and WL tests.",
      "In Section 3, the authors completely ignore the complexity part.",
      "For example, if I understand correctly, the clique complex lifting will include the information about all cliques in the graph which might be very costly to compute, hence Corollary 14 is just telling that if you have access to this information you can do better than a very simple algorithm.",
      "It is clearly true but not very interesting.",
      "The authors mention the complexity of their GNN on page 6 and write that under some conditions the complexity is 'linear in the size of the input complex'.",
      "But how big can this size of the input complex be in term of the size of the graph?",
      "The authors show that CW Network layers are cell permutation invariant.",
      "Does it imply that the GNN is graph permutation invariant?",
      "It seems that the authors only look at graph embedding with their CWN.",
      "Is it possible to obtain node embedding by modifying the READOUT function?",
      "It would have been nice to compare CIN with other algorithms having access to the same information as CIN.",
      "Since, the authors compute all the rings in the graph for their CIN, how is the performance of a standard GNN improved if we add the statistics of the rings in addition to the embedding computed by the GNN?",
      "Such result would allow to demonstrate whether the improvement seen in the paper is due to the new architecture or to the new features added.",
      "Similarly, you can probably increase the performance of the WL kernel by adding this new feature to get very good results."
    ]
  },
  {
    "paper_id": "2106.12575v3",
    "submission_id": "uVPZCMVtsSG",
    "submission_title": "Weisfeiler and Lehman Go Cellular: CW Networks",
    "review_id": "fzT6BGmqIk3",
    "input": {
      "title": "Weisfeiler and Lehman Go Cellular: CW Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well written.\n- It makes a comprehensive theoretic analysis of the proposed model as well as a thorough empirical study.\n- The concept of using cell complexes seems to be a natural but novel extension of simplicial complexes and has some intuitive advantages on molecular datasets (with a lot of rings).\n- The experimental results are also quite good compared to other recent models.\n- I think it is already in good shape and ready for publication.\n- The authors actually already indicated the limitation of the method in the paper, i.e. the high computational complexity on more general large graphs, which would impede the applicability of the model.\n- Another minor problem may be the experiments of long-range interaction.\n- The synthetic data only contains chordless rings and it seems all nodes are in the same rings.\n- That may be not a general case, or we can say it just covers one case of long-range interactions.\n- To make the experiments more convincing, maybe in addition to the central rings there should also be some associated branches?\n- I have also another question for the authors: if we pre-process the graphs to decompose them into nodes, edges, rings, and use these elements as nodes to form one heterogenous graph, would a GNN on that graph be equal to the cellular message passing to some extent?",
    "review_points_list": [
      "The paper is well written.",
      "It makes a comprehensive theoretic analysis of the proposed model as well as a thorough empirical study.",
      "The concept of using cell complexes seems to be a natural but novel extension of simplicial complexes and has some intuitive advantages on molecular datasets (with a lot of rings).",
      "The experimental results are also quite good compared to other recent models.",
      "I think it is already in good shape and ready for publication.",
      "The authors actually already indicated the limitation of the method in the paper, i.e. the high computational complexity on more general large graphs, which would impede the applicability of the model.",
      "Another minor problem may be the experiments of long-range interaction.",
      "The synthetic data only contains chordless rings and it seems all nodes are in the same rings.",
      "That may be not a general case, or we can say it just covers one case of long-range interactions.",
      "To make the experiments more convincing, maybe in addition to the central rings there should also be some associated branches?",
      "I have also another question for the authors: if we pre-process the graphs to decompose them into nodes, edges, rings, and use these elements as nodes to form one heterogenous graph, would a GNN on that graph be equal to the cellular message passing to some extent?"
    ]
  },
  {
    "paper_id": "2103.16547v3",
    "submission_id": "zL1szwVKdwc",
    "submission_title": "The Elastic Lottery Ticket Hypothesis",
    "review_id": "MRxSltREdv",
    "input": {
      "title": "The Elastic Lottery Ticket Hypothesis",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The method to grow the depth and increase the width must be presented as they are critical dimensions for a large-scale model.\n- The SOTA dynamic method should include the latest methods such as DWN, DFP, STR, etc.\n- The paper mainly focuses on unstructured sparsity, which makes it harder to achieve speed gain.\n- It is suggested that the authors conduct experiments on channel/filter pruning or fine-grained structured sparsity.\n- There is a typo on line 358 with the word 'onlu'.\n- The framework proposed aims to reduce the IMP cost by transferring 'winner tickets' to other neural models.\n- No training time report is found in the experimental evaluation, which weakens the support for the claims made in the manuscript.",
    "review_points_list": [
      "The method to grow the depth and increase the width must be presented as they are critical dimensions for a large-scale model.",
      "The SOTA dynamic method should include the latest methods such as DWN, DFP, STR, etc.",
      "The paper mainly focuses on unstructured sparsity, which makes it harder to achieve speed gain.",
      "It is suggested that the authors conduct experiments on channel/filter pruning or fine-grained structured sparsity.",
      "There is a typo on line 358 with the word 'onlu'.",
      "The framework proposed aims to reduce the IMP cost by transferring 'winner tickets' to other neural models.",
      "No training time report is found in the experimental evaluation, which weakens the support for the claims made in the manuscript."
    ]
  },
  {
    "paper_id": "2103.16547v3",
    "submission_id": "zL1szwVKdwc",
    "submission_title": "The Elastic Lottery Ticket Hypothesis",
    "review_id": "z-xAF6o__OV",
    "input": {
      "title": "The Elastic Lottery Ticket Hypothesis",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper is drafted with a strong motivation resulting in an interesting research topic --- the transferability of a winning ticket.\n- The previous surprising findings in LTH require expensive computational costs to benefit real-world network training.\n- This paper tries to alleviate this disadvantage by transferring the obtained winning ticket to other network structures, showing a good potential for practical application and theoretical exploration.\n- The experiments are comprehensive.\n- In addition to the comparisons between networks in the same family based on several strong baselines, this work also provides other experimental analyses, such as the comparisons with dynamic sparse training and the analysis of linear mode connectivity.\n- Some experimental settings are unclear.\n- As mentioned in L257-L258, the sparsity ratio will be different.\n- It is better to provide detailed comparisons and how the \u201cbest possible extent\u201d (L259) was made to compensate for the difference.\n- Some potential missing baselines.\n- I am curious about the extreme situation of both \u201cstretching\u201d and \u201csqueezing.\u201d\n- How about only stretching the last unit to finish transferring from lower to deeper network, or even stretching randomly picked unit.\n- The value of \u201csqueezing\u201d network:\n- stretching network will benefit the winning ticket finding for a larger network based on a smaller one.\n- However, based on the results (e.g., ResNet56 to ResNet32 in Fig. 4), the structural changes in winning tickets will also cause a performance drop for the converse scenario.\n- It is better to elaborate on the potential benefits of this situation.",
    "review_points_list": [
      "This paper is drafted with a strong motivation resulting in an interesting research topic --- the transferability of a winning ticket.",
      "The previous surprising findings in LTH require expensive computational costs to benefit real-world network training.",
      "This paper tries to alleviate this disadvantage by transferring the obtained winning ticket to other network structures, showing a good potential for practical application and theoretical exploration.",
      "The experiments are comprehensive.",
      "In addition to the comparisons between networks in the same family based on several strong baselines, this work also provides other experimental analyses, such as the comparisons with dynamic sparse training and the analysis of linear mode connectivity.",
      "Some experimental settings are unclear.",
      "As mentioned in L257-L258, the sparsity ratio will be different.",
      "It is better to provide detailed comparisons and how the \u201cbest possible extent\u201d (L259) was made to compensate for the difference.",
      "Some potential missing baselines.",
      "I am curious about the extreme situation of both \u201cstretching\u201d and \u201csqueezing.\u201d",
      "How about only stretching the last unit to finish transferring from lower to deeper network, or even stretching randomly picked unit.",
      "The value of \u201csqueezing\u201d network:",
      "stretching network will benefit the winning ticket finding for a larger network based on a smaller one.",
      "However, based on the results (e.g., ResNet56 to ResNet32 in Fig. 4), the structural changes in winning tickets will also cause a performance drop for the converse scenario.",
      "It is better to elaborate on the potential benefits of this situation."
    ]
  },
  {
    "paper_id": "2103.16547v3",
    "submission_id": "zL1szwVKdwc",
    "submission_title": "The Elastic Lottery Ticket Hypothesis",
    "review_id": "NnJjHaOga6",
    "input": {
      "title": "The Elastic Lottery Ticket Hypothesis",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This work appears to be very original, as it is the first work I have seen for adapting one lottery ticket to multiple architectures.\n- To claim that the new network is a LT, we should see that 1) reinitialization under the LT mask, 2) LT weights with random mask, and 3) random weights with random mask all perform worse than the LT (while keeping the source blocks the same).\n- However, the 'Interpolation 1234 - Random' experiment in Figure 3 shows that it is not significantly different from 'Interpolation 1234', raising serious doubts about whether the approach generates 'lottery tickets' or just a way to stretch or shrink existing models.\n- No other experiments are conducted to establish that the new network is indeed a LT, which also raises questions.\n- It\u2019s unclear how much of the gain is due to simply having access to the LT on the original source model.\n- For pruning-at-initialization baselines, what if you copy the same weights as LTH for existing blocks, and only perform pruning for the new layers using pruning-at-initialization techniques?\n- This would be a more appropriate baseline to compare to.\n- The current experiments disadvantages other baselines by leveraging a prior LT model only for ETTs.\n- Are the baselines (unpruned, IMP) initialized in the same way as the elastic LTH? I.e. Weights are repeated for certain blocks?\n- Or is it done with random initializations?\n- If the latter, I would be curious to see what happens when you replicate blocks in the same way at initialization.\n- How much of the benefit of ELTH comes from replicating initial weights (if any)?\n- The claims that ETTs may transfer to general pruned solutions seems unfounded (also unclear what 'general pruned solutions' mean here, so I may be misreading).\n- To make the claim that LTs derived from different model architectures are connected, and that they stay in the same basin, the authors could look at linear mode connectivity between IMP solution on a target model and the ETT solutions.\n- The paper is generally well written.\n- My only comment is that the takeaway of section 4.4 confuses me.\n- I hope the authors can elaborate further on what the implication of their linear mode connectivity result is.\n- The paper raises a question that would be significant to the community.\n- However, the results so far do not make a compelling case for it.\n- Nonetheless, I would be convinced otherwise if my earlier concerns were sufficiently addressed.\n- The authors have provided additional experiments and clarifications that addressed my earlier concerns.\n- Although the performance difference between ELT and the appropriate baselines suggested in the review is small, it seems consistent, and would be interesting to the community given the general novelty of this work.\n- Assuming that these new results will be added to the paper accordingly, I will increase my score from 4 to 6.",
    "review_points_list": [
      "This work appears to be very original, as it is the first work I have seen for adapting one lottery ticket to multiple architectures.",
      "To claim that the new network is a LT, we should see that 1) reinitialization under the LT mask, 2) LT weights with random mask, and 3) random weights with random mask all perform worse than the LT (while keeping the source blocks the same).",
      "However, the 'Interpolation 1234 - Random' experiment in Figure 3 shows that it is not significantly different from 'Interpolation 1234', raising serious doubts about whether the approach generates 'lottery tickets' or just a way to stretch or shrink existing models.",
      "No other experiments are conducted to establish that the new network is indeed a LT, which also raises questions.",
      "It\u2019s unclear how much of the gain is due to simply having access to the LT on the original source model.",
      "For pruning-at-initialization baselines, what if you copy the same weights as LTH for existing blocks, and only perform pruning for the new layers using pruning-at-initialization techniques?",
      "This would be a more appropriate baseline to compare to.",
      "The current experiments disadvantages other baselines by leveraging a prior LT model only for ETTs.",
      "Are the baselines (unpruned, IMP) initialized in the same way as the elastic LTH? I.e. Weights are repeated for certain blocks?",
      "Or is it done with random initializations?",
      "If the latter, I would be curious to see what happens when you replicate blocks in the same way at initialization.",
      "How much of the benefit of ELTH comes from replicating initial weights (if any)?",
      "The claims that ETTs may transfer to general pruned solutions seems unfounded (also unclear what 'general pruned solutions' mean here, so I may be misreading).",
      "To make the claim that LTs derived from different model architectures are connected, and that they stay in the same basin, the authors could look at linear mode connectivity between IMP solution on a target model and the ETT solutions.",
      "The paper is generally well written.",
      "My only comment is that the takeaway of section 4.4 confuses me.",
      "I hope the authors can elaborate further on what the implication of their linear mode connectivity result is.",
      "The paper raises a question that would be significant to the community.",
      "However, the results so far do not make a compelling case for it.",
      "Nonetheless, I would be convinced otherwise if my earlier concerns were sufficiently addressed.",
      "The authors have provided additional experiments and clarifications that addressed my earlier concerns.",
      "Although the performance difference between ELT and the appropriate baselines suggested in the review is small, it seems consistent, and would be interesting to the community given the general novelty of this work.",
      "Assuming that these new results will be added to the paper accordingly, I will increase my score from 4 to 6."
    ]
  },
  {
    "paper_id": "1606.05962v1",
    "submission_id": "x8qirBbT9xp",
    "submission_title": "Causal Inference for Event Pairs in Multivariate Point Processes",
    "review_id": "2YeJLGk4E1B",
    "input": {
      "title": "Causal Inference for Event Pairs in Multivariate Point Processes",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.\n- The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.\n- The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset. The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).\n- Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.\n- The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.\n- The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.\n- This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.\n- The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.\n- log(k) is an upper bound on the improvement of query complexity for any sampler.\n- The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.\n- The paper is very clear and well organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.\n- The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.",
    "review_points_list": [
      "The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.",
      "The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.",
      "The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset. The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).",
      "Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.",
      "The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.",
      "The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.",
      "This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.",
      "The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.",
      "log(k) is an upper bound on the improvement of query complexity for any sampler.",
      "The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.",
      "The paper is very clear and well organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.",
      "The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm."
    ]
  },
  {
    "paper_id": "1606.05962v1",
    "submission_id": "x8qirBbT9xp",
    "submission_title": "Causal Inference for Event Pairs in Multivariate Point Processes",
    "review_id": "UrFsOS3bPG1",
    "input": {
      "title": "Causal Inference for Event Pairs in Multivariate Point Processes",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The work precisely define causal assumptions of the method: ignorability and overlap.\n- The method do not require causal sufficiency, unobserved confounders are allowed as long as the covariates form a proper adjustment set for their effect.\n- However it will ignore indirect effects mediated by these covariate variables.\n- What does it mean that $\\mathcal{K}$ is $y$'s future occurrences at $t$?\n- Later we see that $Y_i$ is actually equal the instantaneous expected number of occurrences OR the cumulative expected number of occurrences of the outcome.\n- At this point the entity $\\mathcal{K}$ is somewhat mysterious.\n- Line 131 (typo): y is the effect/outcome not a treatment\n- Line 180: Ignorability is misinterpreted here. Ignorability means that the counterfactual outcomes are independent from the actual outcome given the covariates.\n- It is actually telling that the current value of Z in the real world have no extra information to determine the counterfactual outcomes given the knowledge of the covariates.\n- It is closely related to the back-door criterion, see Pearl: Causality, 2009, Chapter 3; 11.\n- Line 198: What do you mean by 'the coarsest of such a function is the propensity score'?\n- Line 204: missing: given observing covariates $\\mathbf{x}_t^w$",
    "review_points_list": [
      "The work precisely define causal assumptions of the method: ignorability and overlap.",
      "The method do not require causal sufficiency, unobserved confounders are allowed as long as the covariates form a proper adjustment set for their effect.",
      "However it will ignore indirect effects mediated by these covariate variables.",
      "What does it mean that $\\mathcal{K}$ is $y$'s future occurrences at $t$?",
      "Later we see that $Y_i$ is actually equal the instantaneous expected number of occurrences OR the cumulative expected number of occurrences of the outcome.",
      "At this point the entity $\\mathcal{K}$ is somewhat mysterious.",
      "Line 131 (typo): y is the effect/outcome not a treatment",
      "Line 180: Ignorability is misinterpreted here. Ignorability means that the counterfactual outcomes are independent from the actual outcome given the covariates.",
      "It is actually telling that the current value of Z in the real world have no extra information to determine the counterfactual outcomes given the knowledge of the covariates.",
      "It is closely related to the back-door criterion, see Pearl: Causality, 2009, Chapter 3; 11.",
      "Line 198: What do you mean by 'the coarsest of such a function is the propensity score'?",
      "Line 204: missing: given observing covariates $\\mathbf{x}_t^w$"
    ]
  },
  {
    "paper_id": "1606.05962v1",
    "submission_id": "x8qirBbT9xp",
    "submission_title": "Causal Inference for Event Pairs in Multivariate Point Processes",
    "review_id": "k8lRBMdMIU-",
    "input": {
      "title": "Causal Inference for Event Pairs in Multivariate Point Processes",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think this is an interesting and important problem area\n- While the paper is on the lighter side in terms of theoretical contributions\n- My largest concerns are as follows\n- The authors could do more to tie the proposed approach to the larger literature\n- It's unclear to me how much is being sacrificed\n- Would be nice to have consistency / convergence results for the proposed estimator\n- It would be much more convincing if the authors ran experiments on any of the motivating domain examples\n- Some smaller points\n- The authors consistently conflate propensity scores with balancing weights\n- The citation to Zubizaretta (2015) on line 298 is incorrect\n- It's unclear how one would get confidence intervals from the proposed approach for the estimates\n- The authors offer a heuristic for choosing the window size for the estimate\n- Intuitively, it would seem that smaller window sizes should result in greater precision. Can the authors provide intuition for the observed behavior which appears either flat or bell shaped?\n- As-is it is difficult to reason over the true efficacy of the proposed approach on the synthetic domains.\n- It would seem to me that these are different estimands, however it is not clear when we would prefer this \"event happens at all\" estimand.\n- The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.",
    "review_points_list": [
      "I think this is an interesting and important problem area",
      "While the paper is on the lighter side in terms of theoretical contributions",
      "My largest concerns are as follows",
      "The authors could do more to tie the proposed approach to the larger literature",
      "It's unclear to me how much is being sacrificed",
      "Would be nice to have consistency / convergence results for the proposed estimator",
      "It would be much more convincing if the authors ran experiments on any of the motivating domain examples",
      "Some smaller points",
      "The authors consistently conflate propensity scores with balancing weights",
      "The citation to Zubizaretta (2015) on line 298 is incorrect",
      "It's unclear how one would get confidence intervals from the proposed approach for the estimates",
      "The authors offer a heuristic for choosing the window size for the estimate",
      "Intuitively, it would seem that smaller window sizes should result in greater precision. Can the authors provide intuition for the observed behavior which appears either flat or bell shaped?",
      "As-is it is difficult to reason over the true efficacy of the proposed approach on the synthetic domains.",
      "It would seem to me that these are different estimands, however it is not clear when we would prefer this \"event happens at all\" estimand.",
      "The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question."
    ]
  },
  {
    "paper_id": "1606.05962v1",
    "submission_id": "x8qirBbT9xp",
    "submission_title": "Causal Inference for Event Pairs in Multivariate Point Processes",
    "review_id": "fKrInhSwTgT",
    "input": {
      "title": "Causal Inference for Event Pairs in Multivariate Point Processes",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think this is an excellent paper.\n- It balances well the presentation of high-level concepts and motivations while providing rigor...\n- The framework of causal inference in multivariate point processes (MPPs) it develops could play a central role...\n- The paper combines well-established pieces in a new way by deriving the standard causal inference measure (ATE) -- and how to estimate it well -- for a class of models (MPPs)\n- The paper situates its contributions clearly in comparison to survival analysis, hazard models, and Granger causality.\n- The submission is very meticulously written and is technically sound as far as I have investigated.\n- Statements are well-cited, and experimental evidence supports the claims of effectiveness.\n- I don't have any complaints about the methodology or the completeness.\n- The authors do not include an explicit evaluation of strengths and weaknesses, but they have defined their scope well enough to allow those to be inferred.\n- My main suggestion is to use figures to illustrate the results rather than just listing them in tables.\n- Yes, I know it takes a lot more work, but the end result is so much easier for our feeble human brains to interpret.\n- If you think the specific numbers are important, then put them in the supplement, perhaps as a data file.\n- This alone brings my evaluation down one point.\n- I also suggest including proof sketches in the main body of the paper as a general rule of thumb.\n- I'm less concerned compared to unexpected/interesting results.\n- This paper is one of the clearest I have ever reviewed.\n- I have no suggestions.\n- I think other researchers are quite likely to build on this work in helping to establish a framework of causality for MPPs.\n- Since much of the observational data we collect is event-based, I believe causality with MPPs is quite important, and this paper could be a foundational contribution to the area.\n- These are just some things I noticed; they are not comprehensive.\n- It would be nice to have a citation here, if only for the newcomers.\n- Is the square brackets and pipes notation, '[...|...]', meant to be an expectation? That's what the text implies, but there's no 'E'\n- Please fix or clarify.\n- hawkes -> Hawkes\n- 2010 -> 2020",
    "review_points_list": [
      "I think this is an excellent paper.",
      "It balances well the presentation of high-level concepts and motivations while providing rigor...",
      "The framework of causal inference in multivariate point processes (MPPs) it develops could play a central role...",
      "The paper combines well-established pieces in a new way by deriving the standard causal inference measure (ATE) -- and how to estimate it well -- for a class of models (MPPs)",
      "The paper situates its contributions clearly in comparison to survival analysis, hazard models, and Granger causality.",
      "The submission is very meticulously written and is technically sound as far as I have investigated.",
      "Statements are well-cited, and experimental evidence supports the claims of effectiveness.",
      "I don't have any complaints about the methodology or the completeness.",
      "The authors do not include an explicit evaluation of strengths and weaknesses, but they have defined their scope well enough to allow those to be inferred.",
      "My main suggestion is to use figures to illustrate the results rather than just listing them in tables.",
      "Yes, I know it takes a lot more work, but the end result is so much easier for our feeble human brains to interpret.",
      "If you think the specific numbers are important, then put them in the supplement, perhaps as a data file.",
      "This alone brings my evaluation down one point.",
      "I also suggest including proof sketches in the main body of the paper as a general rule of thumb.",
      "I'm less concerned compared to unexpected/interesting results.",
      "This paper is one of the clearest I have ever reviewed.",
      "I have no suggestions.",
      "I think other researchers are quite likely to build on this work in helping to establish a framework of causality for MPPs.",
      "Since much of the observational data we collect is event-based, I believe causality with MPPs is quite important, and this paper could be a foundational contribution to the area.",
      "These are just some things I noticed; they are not comprehensive.",
      "It would be nice to have a citation here, if only for the newcomers.",
      "Is the square brackets and pipes notation, '[...|...]', meant to be an expectation? That's what the text implies, but there's no 'E'",
      "Please fix or clarify.",
      "hawkes -> Hawkes",
      "2010 -> 2020"
    ]
  },
  {
    "paper_id": "2108.13264v4",
    "submission_id": "uqv8-U4lKBe",
    "submission_title": "Deep Reinforcement Learning at the Edge of the Statistical Precipice",
    "review_id": "S7FsNCyONXS",
    "input": {
      "title": "Deep Reinforcement Learning at the Edge of the Statistical Precipice",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is an important contribution to the field of RL.\n- While similar failures of evaluation have been reported before, it seems (as demonstrated by the case studies in the paper) that these failures haven't been adequately addressed.\n- Further, the degree of detail and rigour taken in presenting the experimental results (and visualising those results) is a credit to the authors and means the work has an excellent clarity in its presentation.\n- The authors have proposed new methods for tackling these issues in deep reinforcement learning evaluation.\n- There has been previous work looking at the evaluation protocol of deep reinforcement learning, but this paper evaluates these problems more thoroughly, finds problems in previous recommendations of increasing the number of random seeds, and proposes new methods for tackling these issues in deep reinforcement learning evaluation.\n- The paper is very well-written, and explains its points clearly in all parts.\n- The visualisations are well explained and provide good intuition for the variety of statistical ideas presented in the text of the paper, in a way that is rigorous.\n- The paper's structure is well-organised the motivates the main messages of the paper well.\n- The technical quality of the experiments and visualisations is very high, and the techniques used and choices made are well-motivated.\n- The claims made are well supported by the experiments.\n- The results presented in the paper are of very high significance to the reinforcement learning community.\n- The demonstration of spurious or misleading reporting of previous results is very important and should inform the field as to which methods are actually improvements on previous methods, and in what way.\n- The improved approaches for reporting results, including representing the full distribution of results in multiple ways, should be taken up by current researchers in RL to improve the robustness of their results and determining whether real progress is being made.\n- It would be useful to have a (small) related work section on previous work and what it demonstrated, to clarify the contributions in this paper.\n- For example, the papers listed in L318 could be explained in more detail.\n- I think it would be more fair to say that the increase in the number of runs which would be required to address the statistical uncertainty issues is infeasible for computationally demanding deep RL benchmarks.\n- I think the '(1)' should go after '...' is also' for this list to read correctly.\n- Using the Rainbow implementation from dopamine isn't the full Rainbow algorithm (it misses out on three components - dueling DQN, double DQN and NoisyNets) - this should be made clear in the paper, as it changes the results on the Atari@200M benchmark.\n- For example, see the Rainbow results in table 2 of [Muesli: Combining Improvements in Policy Optimization](https://arxiv.org/abs/2104.06159), which has a much higher median than reported in your paper (and in the DreamerV2 paper, which also uses the dopamine implementation of Rainbow).\n- I have raised my confidence from 3 to 4, maintaining my score of 9.",
    "review_points_list": [
      "The paper is an important contribution to the field of RL.",
      "While similar failures of evaluation have been reported before, it seems (as demonstrated by the case studies in the paper) that these failures haven't been adequately addressed.",
      "Further, the degree of detail and rigour taken in presenting the experimental results (and visualising those results) is a credit to the authors and means the work has an excellent clarity in its presentation.",
      "The authors have proposed new methods for tackling these issues in deep reinforcement learning evaluation.",
      "There has been previous work looking at the evaluation protocol of deep reinforcement learning, but this paper evaluates these problems more thoroughly, finds problems in previous recommendations of increasing the number of random seeds, and proposes new methods for tackling these issues in deep reinforcement learning evaluation.",
      "The paper is very well-written, and explains its points clearly in all parts.",
      "The visualisations are well explained and provide good intuition for the variety of statistical ideas presented in the text of the paper, in a way that is rigorous.",
      "The paper's structure is well-organised the motivates the main messages of the paper well.",
      "The technical quality of the experiments and visualisations is very high, and the techniques used and choices made are well-motivated.",
      "The claims made are well supported by the experiments.",
      "The results presented in the paper are of very high significance to the reinforcement learning community.",
      "The demonstration of spurious or misleading reporting of previous results is very important and should inform the field as to which methods are actually improvements on previous methods, and in what way.",
      "The improved approaches for reporting results, including representing the full distribution of results in multiple ways, should be taken up by current researchers in RL to improve the robustness of their results and determining whether real progress is being made.",
      "It would be useful to have a (small) related work section on previous work and what it demonstrated, to clarify the contributions in this paper.",
      "For example, the papers listed in L318 could be explained in more detail.",
      "I think it would be more fair to say that the increase in the number of runs which would be required to address the statistical uncertainty issues is infeasible for computationally demanding deep RL benchmarks.",
      "I think the '(1)' should go after '...' is also' for this list to read correctly.",
      "Using the Rainbow implementation from dopamine isn't the full Rainbow algorithm (it misses out on three components - dueling DQN, double DQN and NoisyNets) - this should be made clear in the paper, as it changes the results on the Atari@200M benchmark.",
      "For example, see the Rainbow results in table 2 of [Muesli: Combining Improvements in Policy Optimization](https://arxiv.org/abs/2104.06159), which has a much higher median than reported in your paper (and in the DreamerV2 paper, which also uses the dopamine implementation of Rainbow).",
      "I have raised my confidence from 3 to 4, maintaining my score of 9."
    ]
  },
  {
    "paper_id": "2108.13264v4",
    "submission_id": "uqv8-U4lKBe",
    "submission_title": "Deep Reinforcement Learning at the Edge of the Statistical Precipice",
    "review_id": "2HrvadMdvy",
    "input": {
      "title": "Deep Reinforcement Learning at the Edge of the Statistical Precipice",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper raises an important problem for deep RL and presents a large empirical study along with some new proposals like reporting bootstrapped confidence intervals.\n- While the organization and theory in the paper could be improved, I think the contribution is good enough to warrant acceptance.\n- The findings of inconsistencies in the literature on this specific part of the pipeline seems like an important problem for the community to consider.\n- The large empirical evaluation provides solid evidence for the paper's claims.\n- This evaluation shows things like the ordering changing across different protocols, the high variability of prior metrics, and the reduced variability in the proposed metrics.\n- Relative to prior work on reproducibility and evaluation protocols, this paper provides a substantially larger evaluation across many seeds and many benchmark suites in different settings with both finite and continuous action spaces that considers many highly performing algorithms in each benchmark.\n- The paper's proposed solutions seem to help reduce the problems raised with prior work.\n- The main idea to report intervals or performance profiles instead of point estimates is a clearly better practice.\n- The authors provide useful tools for the RL community.\n- The authors plan to open source code in a colab notebook to compute all of the proposed confidence intervals, performance profiles, and metrics.\n- They also plan to release all of the data from the large-scale experiments.\n- The paper lacks a more formal argument for the proposed metrics.\n- Adding some theory about when and how the proposed metrics are more robust could help clarify the contribution.\n- Even some illustrative examples (perhaps in the appendix) could help to show what sorts of failure modes the new methods avoid.\n- Why does the paper not compute all of the proposed metrics for each task?\n- For example, there is no performance profile or IQM for the control suite, the probability of improvement seems to only be computed on procgen, and .\n- If all of these metrics are included in the paper, then these results should be reported in the appendix.\n- Alternatively, maybe things would be cleaner if one or two of the metrics were removed from the paper.\n- The clause 'we assert reporting interval estimates of aggregate performance' on line 15 does not make sense.\n- Perhaps the authors meant something like 'advocate for' instead of 'assert' here?\n- This is sort of a nitpick, but I don't think the title is very well-aligned with the content of the paper.\n- It would be useful to at least say something about 'evaluation' in the title so that the reader gets an idea of what the paper is about.\n- The proposed metrics often seems to order the metrics differently, eg. IQM vs. optimality gap in Figure 9.\n- Of course this is to be expected since they are measuring different things, but more of a discussion about how to deal with this inconsistency could be beneficial.",
    "review_points_list": [
      "The paper raises an important problem for deep RL and presents a large empirical study along with some new proposals like reporting bootstrapped confidence intervals.",
      "While the organization and theory in the paper could be improved, I think the contribution is good enough to warrant acceptance.",
      "The findings of inconsistencies in the literature on this specific part of the pipeline seems like an important problem for the community to consider.",
      "The large empirical evaluation provides solid evidence for the paper's claims.",
      "This evaluation shows things like the ordering changing across different protocols, the high variability of prior metrics, and the reduced variability in the proposed metrics.",
      "Relative to prior work on reproducibility and evaluation protocols, this paper provides a substantially larger evaluation across many seeds and many benchmark suites in different settings with both finite and continuous action spaces that considers many highly performing algorithms in each benchmark.",
      "The paper's proposed solutions seem to help reduce the problems raised with prior work.",
      "The main idea to report intervals or performance profiles instead of point estimates is a clearly better practice.",
      "The authors provide useful tools for the RL community.",
      "The authors plan to open source code in a colab notebook to compute all of the proposed confidence intervals, performance profiles, and metrics.",
      "They also plan to release all of the data from the large-scale experiments.",
      "The paper lacks a more formal argument for the proposed metrics.",
      "Adding some theory about when and how the proposed metrics are more robust could help clarify the contribution.",
      "Even some illustrative examples (perhaps in the appendix) could help to show what sorts of failure modes the new methods avoid.",
      "Why does the paper not compute all of the proposed metrics for each task?",
      "For example, there is no performance profile or IQM for the control suite, the probability of improvement seems to only be computed on procgen, and .",
      "If all of these metrics are included in the paper, then these results should be reported in the appendix.",
      "Alternatively, maybe things would be cleaner if one or two of the metrics were removed from the paper.",
      "The clause 'we assert reporting interval estimates of aggregate performance' on line 15 does not make sense.",
      "Perhaps the authors meant something like 'advocate for' instead of 'assert' here?",
      "This is sort of a nitpick, but I don't think the title is very well-aligned with the content of the paper.",
      "It would be useful to at least say something about 'evaluation' in the title so that the reader gets an idea of what the paper is about.",
      "The proposed metrics often seems to order the metrics differently, eg. IQM vs. optimality gap in Figure 9.",
      "Of course this is to be expected since they are measuring different things, but more of a discussion about how to deal with this inconsistency could be beneficial."
    ]
  },
  {
    "paper_id": "2108.13264v4",
    "submission_id": "uqv8-U4lKBe",
    "submission_title": "Deep Reinforcement Learning at the Edge of the Statistical Precipice",
    "review_id": "4xH37PivD3_",
    "input": {
      "title": "Deep Reinforcement Learning at the Edge of the Statistical Precipice",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper is another step in the growing area of research concerned with establishing a more rigorous evaluation of deep RL algorithms.\n- The paper's main strengths are the originality of the proposed protocols (particularly the performance profile), as well as an extensive performance analysis of a large set of deep RL methods.\n- The paper is of high-quality -- the experiments are illuminating because they are very relevant and well-done, and the writing is overall quite clear.\n- The paper could prove quite significant if its proposals are adopted.\n- One of the paper's weaknesses is that its conclusions are interspersed throughout the paper and appendix, which is more difficult to digest than a clearer 'executive summary' of proposed protocols and new findings.\n- While I think it's likely that most readers may agree with the spirit of more rigorous analysis, I think it's likely that many readers that do not closely read the paper may miss the important recommendations and findings.\n- The abstract mentions 'we present a more rigorous evaluation methodology', but the reality of the paper is that the methodological recommendations are scattered throughout, as opposed to consolidated into a single compact proposed methodology.\n- Relatedly, the abstract claims that the paper 'reveal[s] discrepancies in prior comparisons', but these are not really consolidated or summarized in one place.\n- These issues could be addressed by either making enumerated lists or tables of both (1) the proposed protocols / methodology (e.g. use CIs, use performance profiles, use IQM), and (2) the new findings that shed more light on previous findings.\n- Another weakness is the underdeveloped discussion of how this paper relates to prior work (L318 [11,15,16,32,37]).\n- For example, [15,16,32,37] also discuss CIs for deep RL.\n- The bars for CURL in Fig2. is very faint and hard to see -- the bars of the other methods are much easier to see.\n- L96 The collection of scores, $y_{1:K}$, is undefined in terms of $x$.\n- L165-169 The purpose of this experiment is not clearly explained at the beginning of the paragraph.\n- The paper should describe why this experiment is run;\n- Looking at [19], there are a few differences between the score distributions proposed herein and the originally proposed performance profiles.\n- These differences should be explicitly named and discussed.\n- Two important differences are (1) performance profiles were defined without any bootstrapping to estimated CIs (2) performance profiles are empirical CDFs, whereas score distributions are their complements (tail distributions).\n- The argument that median is not a good indicator because it is calculated using 'at most two tasks' (L256) is dubious.\n- The median is an aggregate metric that is calculated using 100% of the runs, not 1 or 2.\n- The 'IQM' acronym appears long before it is actually defined on L249.\n- L254 Is the following formal claim? 'IQM has considerably less bias than median'.\n- If so, then this claim requires evidence in the form of a derivation or citation, particularly because the audience for this paper is likely not intimately familiar with the IQM.\n- The ability to read the medians from the performance profiles would be better highlighted if the Fig 7 y=0.5 lines were thicker.\n- L297 'While publications make binary claims' -> 'While publications sometimes make binary claims'.\n- The former statement is too broad to be true.\n- L267 It's not clear how P(X_m > Y_m) is estimated.\n- More details are needed.\n- Appendix P20, it's not clear if 'Alternative alternative Metrics' is a typo or intentional.\n- L323 ... the problem is not solved by fixing random seeds, as has sometimes been proposed' -- consider adding citations here for epistemological completeness.",
    "review_points_list": [
      "This paper is another step in the growing area of research concerned with establishing a more rigorous evaluation of deep RL algorithms.",
      "The paper's main strengths are the originality of the proposed protocols (particularly the performance profile), as well as an extensive performance analysis of a large set of deep RL methods.",
      "The paper is of high-quality -- the experiments are illuminating because they are very relevant and well-done, and the writing is overall quite clear.",
      "The paper could prove quite significant if its proposals are adopted.",
      "One of the paper's weaknesses is that its conclusions are interspersed throughout the paper and appendix, which is more difficult to digest than a clearer 'executive summary' of proposed protocols and new findings.",
      "While I think it's likely that most readers may agree with the spirit of more rigorous analysis, I think it's likely that many readers that do not closely read the paper may miss the important recommendations and findings.",
      "The abstract mentions 'we present a more rigorous evaluation methodology', but the reality of the paper is that the methodological recommendations are scattered throughout, as opposed to consolidated into a single compact proposed methodology.",
      "Relatedly, the abstract claims that the paper 'reveal[s] discrepancies in prior comparisons', but these are not really consolidated or summarized in one place.",
      "These issues could be addressed by either making enumerated lists or tables of both (1) the proposed protocols / methodology (e.g. use CIs, use performance profiles, use IQM), and (2) the new findings that shed more light on previous findings.",
      "Another weakness is the underdeveloped discussion of how this paper relates to prior work (L318 [11,15,16,32,37]).",
      "For example, [15,16,32,37] also discuss CIs for deep RL.",
      "The bars for CURL in Fig2. is very faint and hard to see -- the bars of the other methods are much easier to see.",
      "L96 The collection of scores, $y_{1:K}$, is undefined in terms of $x$.",
      "L165-169 The purpose of this experiment is not clearly explained at the beginning of the paragraph.",
      "The paper should describe why this experiment is run;",
      "Looking at [19], there are a few differences between the score distributions proposed herein and the originally proposed performance profiles.",
      "These differences should be explicitly named and discussed.",
      "Two important differences are (1) performance profiles were defined without any bootstrapping to estimated CIs (2) performance profiles are empirical CDFs, whereas score distributions are their complements (tail distributions).",
      "The argument that median is not a good indicator because it is calculated using 'at most two tasks' (L256) is dubious.",
      "The median is an aggregate metric that is calculated using 100% of the runs, not 1 or 2.",
      "The 'IQM' acronym appears long before it is actually defined on L249.",
      "L254 Is the following formal claim? 'IQM has considerably less bias than median'.",
      "If so, then this claim requires evidence in the form of a derivation or citation, particularly because the audience for this paper is likely not intimately familiar with the IQM.",
      "The ability to read the medians from the performance profiles would be better highlighted if the Fig 7 y=0.5 lines were thicker.",
      "L297 'While publications make binary claims' -> 'While publications sometimes make binary claims'.",
      "The former statement is too broad to be true.",
      "L267 It's not clear how P(X_m > Y_m) is estimated.",
      "More details are needed.",
      "Appendix P20, it's not clear if 'Alternative alternative Metrics' is a typo or intentional.",
      "L323 ... the problem is not solved by fixing random seeds, as has sometimes been proposed' -- consider adding citations here for epistemological completeness."
    ]
  },
  {
    "paper_id": "2108.13264v4",
    "submission_id": "uqv8-U4lKBe",
    "submission_title": "Deep Reinforcement Learning at the Edge of the Statistical Precipice",
    "review_id": "aWYOVqljJNN",
    "input": {
      "title": "Deep Reinforcement Learning at the Edge of the Statistical Precipice",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper proposes using robust aggregate statistics (e.g. IQM) with interval estimates and performance distributions to compare RL tasks.\n- There are significant overlaps in interval estimates and performance distributions between different algorithms.\n- The comparison between algorithms raises questions about claiming a winner and the use of aggregate statistics.\n- The authors discuss the robustness of IQM compared to median in handling outliers.\n- The choice of statistics depends on the distribution of scores, with considerations like Gaussian distribution favoring mean over median.\n- The generalization of results to other task sets and algorithms is a concern.\n- Clarification on tasks for each plot and consideration of heteroskedasticity in tests are suggested.\n- Questions are raised about the variance of different statistics with varying parameters.\n- Details on calculation methods and requirements for specific values are requested.",
    "review_points_list": [
      "This paper proposes using robust aggregate statistics (e.g. IQM) with interval estimates and performance distributions to compare RL tasks.",
      "There are significant overlaps in interval estimates and performance distributions between different algorithms.",
      "The comparison between algorithms raises questions about claiming a winner and the use of aggregate statistics.",
      "The authors discuss the robustness of IQM compared to median in handling outliers.",
      "The choice of statistics depends on the distribution of scores, with considerations like Gaussian distribution favoring mean over median.",
      "The generalization of results to other task sets and algorithms is a concern.",
      "Clarification on tasks for each plot and consideration of heteroskedasticity in tests are suggested.",
      "Questions are raised about the variance of different statistics with varying parameters.",
      "Details on calculation methods and requirements for specific values are requested."
    ]
  },
  {
    "paper_id": "2109.02157v2",
    "submission_id": "zcrC_XDUFd",
    "submission_title": "Learning with Holographic Reduced Representations",
    "review_id": "ErowHln7VB1",
    "input": {
      "title": "Learning with Holographic Reduced Representations",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper introduces a projection operator that initializes vectors to have a complex magnitude of 1.\n- This has important practical implications for using these vectors in a holographic reduced representation, because it enables use of the inverse operator for decoding in a numerically stable way.\n- rather than the approximate inverse, which was traditionally used because of its greater numerical stability.\n- My subjective view of this paper is that it presents a useful method, and a pretty detailed comparison between architectures and parametrizations, but the application domain (multi-label classification) isn't a particularly interesting one.\n- HRRs were invented to do represent and reason about complex symbolic expressions.\n- It would have been more interesting to see an application to the kinds of domains where neurosymbolic approaches have been applied recently (e.g., scene understanding, knowledge graphs, natural language inference).\n- My other major comment is that it's not clear what problem is being solved here that wasn't already solved.\n- The authors concede that their approach is not intended to exceed performance of other algorithms on XML tasks, but rather to understand the pros and cons of using HRRs for this task.\n- I feel like this is a rather weak case for using HRRs (though I agree with the authors that the advantage of the HRR in their comparisons is compelling).\n- This connects back to my previous point, which is that a better case for HRRs might be made with a different task, one where symbolic reasoning is necessary.\n- abstract: 'differential component' -> 'differentiable component' (?)\n- abstract: 'differential solution' -> 'differentiable solution' (?)\n- abstract: 'a output' -> 'an output'\n- I don't understand the query example in the second paragraph of the introduction. Should this be the inverse operation applied to S and red? Why is there a convolution symbol in there?\n- P. 2: 'it\u2019s niche' -> 'its niche'\n- P. 2: 'takle' -> 'tackle'\n- P. 3: 'it's values' -> 'its values'\n- P. 4: It looks odd to have an equation number (4) in the middle of an equation.\n- P. 7: 'XXX lines of code' should be replaced with an integer.\n- P. 7: 'overal' -> 'overall'\n- P. 7: 'project step' -> 'projection step'\n- P. 7: 'largeness' -> 'size'\n- I was confused by Table 1. Why are different sets of models being applied to different data sets? I didn't see any explanation of these choices.",
    "review_points_list": [
      "This paper introduces a projection operator that initializes vectors to have a complex magnitude of 1.",
      "This has important practical implications for using these vectors in a holographic reduced representation, because it enables use of the inverse operator for decoding in a numerically stable way.",
      "rather than the approximate inverse, which was traditionally used because of its greater numerical stability.",
      "My subjective view of this paper is that it presents a useful method, and a pretty detailed comparison between architectures and parametrizations, but the application domain (multi-label classification) isn't a particularly interesting one.",
      "HRRs were invented to do represent and reason about complex symbolic expressions.",
      "It would have been more interesting to see an application to the kinds of domains where neurosymbolic approaches have been applied recently (e.g., scene understanding, knowledge graphs, natural language inference).",
      "My other major comment is that it's not clear what problem is being solved here that wasn't already solved.",
      "The authors concede that their approach is not intended to exceed performance of other algorithms on XML tasks, but rather to understand the pros and cons of using HRRs for this task.",
      "I feel like this is a rather weak case for using HRRs (though I agree with the authors that the advantage of the HRR in their comparisons is compelling).",
      "This connects back to my previous point, which is that a better case for HRRs might be made with a different task, one where symbolic reasoning is necessary.",
      "abstract: 'differential component' -> 'differentiable component' (?)",
      "abstract: 'differential solution' -> 'differentiable solution' (?)",
      "abstract: 'a output' -> 'an output'",
      "I don't understand the query example in the second paragraph of the introduction. Should this be the inverse operation applied to S and red? Why is there a convolution symbol in there?",
      "P. 2: 'it\u2019s niche' -> 'its niche'",
      "P. 2: 'takle' -> 'tackle'",
      "P. 3: 'it's values' -> 'its values'",
      "P. 4: It looks odd to have an equation number (4) in the middle of an equation.",
      "P. 7: 'XXX lines of code' should be replaced with an integer.",
      "P. 7: 'overal' -> 'overall'",
      "P. 7: 'project step' -> 'projection step'",
      "P. 7: 'largeness' -> 'size'",
      "I was confused by Table 1. Why are different sets of models being applied to different data sets? I didn't see any explanation of these choices."
    ]
  },
  {
    "paper_id": "2109.02157v2",
    "submission_id": "zcrC_XDUFd",
    "submission_title": "Learning with Holographic Reduced Representations",
    "review_id": "HY4-ItaKugS",
    "input": {
      "title": "Learning with Holographic Reduced Representations",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Strengths: Novelty of the proposed operation.\n- The authors introduce a projection scheme to the original HRR operation in Plate 1995 and a means of incorporating HRR into modern learnable architectures that appears to be novel...\n- Practical contribution: the authors convincingly demonstrate that the HRR operation allows a useful task (queryable lookup and retrieval of many labels in a low-dimensional vector) to be performed efficiently and relatively accurately with fewer vector parameters.\n- The empirical evaluations on the XML task use real-world datasets and demonstrate comparable (and in some cases SOTA-exceeding) performance over a fully-connected baseline for the lookup task, using several different neural architectures (FC; CNN; LSTM) as the base with the HRR layer as the final layer.\n- Significance and potential relevance.\n- Weaknesses: Paper framing and next steps using the HRR operation.\n- The authors stop short of (and in fact explicitly say) that their goals are not to demonstrate state-of-the-art XML performance.\n- This is fine, but I believe a useful revision of this paper could paint a clearer and more precise picture of why the HRR operation is being introduced -- and what its clearest advantages are (or could be) over other approaches.\n- The authors suggest that a major goal is to improve on HRRs.\n- It would seem that a better focus would be on how HRR itself improves over the existing symbolic and neural SOTA toolkit early on.\n- Empirical comparisons to existing \u2018competitor operators\u2019 were the FC-final layers the best comparison for the kinds of operations HRR might seek to replace?\n- What about other hashing and distillation approaches?\n- The authors mention that they replaced the hierarchical-attention based head in AttentionXML with an FC layer.\n- It seems like a pretty major change, especially since learnable attention seems like one of the closer comparisons to the kind of querying that HRR can perform.\n- Putting attention (or another common \u2018competitor\u2019 operation) through its paces with respect to HRR -- on a variety of metrics (computational efficiency, accuracy) would be useful.\n- The XML task seems to be a good fit for HRR.\n- But it would be even better if the authors could paint a picture of how or whether it could be used for other kinds of symbolic operations associated with Turing machines or modern programming languages -- for example, can HRR be used to preserve ordering and syntax, like a structured grammar?\n- These are key reasons why symbolic components are often added to neural architectures, beyond query capacity\n- The discussion of updating label vectors leaves open questions of how HRR would be practically incorporated into more complex learnable architectures -- when I think about attention-based architectures, for instance, one key aspect of their success is that they can play well with operations over implicit, learned vector representations.\n- Beyond XML, could the authors give a picture (or suggest how future work might tackle) HRR operations in other modern tasks?\n- Even better if these are tasks that intuitively require some learning and cannot be solved by a solely symbolic approach.\n- The paper is relatively clear in presenting the HRR operation and modifications made by the authors, though it is also notation dense (I\u2019m not an expert, but I had to look up the basic circular convolution and seek external references to suggest why this operation should have benefits over other attention-style operations.)\n- We might have benefitted (even in the supplement) from a worked example on a toy lookup task, as well as some figures showing how the operation works graphically (like those on the Wikipedia page about circular convolution!)\n- The discussion of the loss, however, is clear and useful relative to the more common cross-entropy loss.\n- The approach overall appears correct.\n- The authors extensively discuss prior work on HRRs.\n- It would be useful if they could also take a step back and at least review the closest prior work outside of HRRs that we should consider this work to be comparable to in order to frame the best comparisons early on.\n- Tiny nits: XXX lines of code.\n- HRR is sometimes misspelled as \u2018HHR\u2019 throughout. :)",
    "review_points_list": [
      "Strengths: Novelty of the proposed operation.",
      "The authors introduce a projection scheme to the original HRR operation in Plate 1995 and a means of incorporating HRR into modern learnable architectures that appears to be novel...",
      "Practical contribution: the authors convincingly demonstrate that the HRR operation allows a useful task (queryable lookup and retrieval of many labels in a low-dimensional vector) to be performed efficiently and relatively accurately with fewer vector parameters.",
      "The empirical evaluations on the XML task use real-world datasets and demonstrate comparable (and in some cases SOTA-exceeding) performance over a fully-connected baseline for the lookup task, using several different neural architectures (FC; CNN; LSTM) as the base with the HRR layer as the final layer.",
      "Significance and potential relevance.",
      "Weaknesses: Paper framing and next steps using the HRR operation.",
      "The authors stop short of (and in fact explicitly say) that their goals are not to demonstrate state-of-the-art XML performance.",
      "This is fine, but I believe a useful revision of this paper could paint a clearer and more precise picture of why the HRR operation is being introduced -- and what its clearest advantages are (or could be) over other approaches.",
      "The authors suggest that a major goal is to improve on HRRs.",
      "It would seem that a better focus would be on how HRR itself improves over the existing symbolic and neural SOTA toolkit early on.",
      "Empirical comparisons to existing \u2018competitor operators\u2019 were the FC-final layers the best comparison for the kinds of operations HRR might seek to replace?",
      "What about other hashing and distillation approaches?",
      "The authors mention that they replaced the hierarchical-attention based head in AttentionXML with an FC layer.",
      "It seems like a pretty major change, especially since learnable attention seems like one of the closer comparisons to the kind of querying that HRR can perform.",
      "Putting attention (or another common \u2018competitor\u2019 operation) through its paces with respect to HRR -- on a variety of metrics (computational efficiency, accuracy) would be useful.",
      "The XML task seems to be a good fit for HRR.",
      "But it would be even better if the authors could paint a picture of how or whether it could be used for other kinds of symbolic operations associated with Turing machines or modern programming languages -- for example, can HRR be used to preserve ordering and syntax, like a structured grammar?",
      "These are key reasons why symbolic components are often added to neural architectures, beyond query capacity",
      "The discussion of updating label vectors leaves open questions of how HRR would be practically incorporated into more complex learnable architectures -- when I think about attention-based architectures, for instance, one key aspect of their success is that they can play well with operations over implicit, learned vector representations.",
      "Beyond XML, could the authors give a picture (or suggest how future work might tackle) HRR operations in other modern tasks?",
      "Even better if these are tasks that intuitively require some learning and cannot be solved by a solely symbolic approach.",
      "The paper is relatively clear in presenting the HRR operation and modifications made by the authors, though it is also notation dense (I\u2019m not an expert, but I had to look up the basic circular convolution and seek external references to suggest why this operation should have benefits over other attention-style operations.)",
      "We might have benefitted (even in the supplement) from a worked example on a toy lookup task, as well as some figures showing how the operation works graphically (like those on the Wikipedia page about circular convolution!)",
      "The discussion of the loss, however, is clear and useful relative to the more common cross-entropy loss.",
      "The approach overall appears correct.",
      "The authors extensively discuss prior work on HRRs.",
      "It would be useful if they could also take a step back and at least review the closest prior work outside of HRRs that we should consider this work to be comparable to in order to frame the best comparisons early on.",
      "Tiny nits: XXX lines of code.",
      "HRR is sometimes misspelled as \u2018HHR\u2019 throughout. :)"
    ]
  },
  {
    "paper_id": "2109.02157v2",
    "submission_id": "zcrC_XDUFd",
    "submission_title": "Learning with Holographic Reduced Representations",
    "review_id": "X331kVXXlaP",
    "input": {
      "title": "Learning with Holographic Reduced Representations",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper presents a modification to the Holographic Reduced Representation that increases the precision of the unbinding operator while maintaining numerical stability and avoiding costly cleanup operations.\n- The paper also presents a novel loss that supports learning in large label spaces.\n- Together, these are applied to extreme classification using an approach that relies on two fixed, orthogonal, role vectors (label present / not present) and many label fillers.\n- This approach supports the novel loss that considers all of the labels without iterating over the large label space, by checking that absent labels are not bound to the label-present role.\n- For extreme classification tasks where few labels are present at any one time, this is significantly more efficient in terms of time and parameters than methods that explicitly model the entire label space.\n- Results are presented for a number of extreme classification benchmarks, and the new approach is compared to equivalent models that replace the HRR output layer with a standard logistic layer.\n- These results show that the loss is working well and being backpropagated through the (fixed) HRR.\n- There is a discussion of the effect of learning both the role and filler representations but this doesn't seem to have a big effect on the tasks studied.\n- Overall, I think this is a nice contribution with an interesting set of results.\n- The paper would be even stronger with more discussion of how these results could extend to tasks beyond the current classification settings, that may more explicitly require the binding and unbinding operations made available by the HRR.",
    "review_points_list": [
      "This paper presents a modification to the Holographic Reduced Representation that increases the precision of the unbinding operator while maintaining numerical stability and avoiding costly cleanup operations.",
      "The paper also presents a novel loss that supports learning in large label spaces.",
      "Together, these are applied to extreme classification using an approach that relies on two fixed, orthogonal, role vectors (label present / not present) and many label fillers.",
      "This approach supports the novel loss that considers all of the labels without iterating over the large label space, by checking that absent labels are not bound to the label-present role.",
      "For extreme classification tasks where few labels are present at any one time, this is significantly more efficient in terms of time and parameters than methods that explicitly model the entire label space.",
      "Results are presented for a number of extreme classification benchmarks, and the new approach is compared to equivalent models that replace the HRR output layer with a standard logistic layer.",
      "These results show that the loss is working well and being backpropagated through the (fixed) HRR.",
      "There is a discussion of the effect of learning both the role and filler representations but this doesn't seem to have a big effect on the tasks studied.",
      "Overall, I think this is a nice contribution with an interesting set of results.",
      "The paper would be even stronger with more discussion of how these results could extend to tasks beyond the current classification settings, that may more explicitly require the binding and unbinding operations made available by the HRR."
    ]
  },
  {
    "paper_id": "2112.00655v1",
    "submission_id": "yKoZfSVFtAx",
    "submission_title": "Efficient and Local Parallel Random Walks",
    "review_id": "q6GhxoDhKv8",
    "input": {
      "title": "Efficient and Local Parallel Random Walks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors seem to work on the distributed computer setting. However, for the application of local graph clustering, the target clusters are much smaller than the size of the graph.\n- For large graphs, the target clusters have constant size and they do not grow with the number of nodes in the graph.\n- Local graph clustering algorithms like ACL take a fraction of a second to terminate and their memory footprint is also constant.\n- For these reasons, I do not think that local graph clustering is the best application for the distributed setting.\n- Even the datasets that you have chosen can fit in RAM of my personal computer.\n- I think the authors should work on demonstrating an application where having multiple machines is necessary.\n- The introduction of the paper is very technical.\n- I could not understand what the authors are talking about until I read the proofs in the appendix.\n- I actually believe that reading the proofs was much easier than trying to figure out what is going on from the main paper.\n- I understand that it is important to mention all your contributions first, but the current text is dry.\n- I had to reach page 4 to figure out what stitching is.\n- For the application of local graph clustering, the authors have missed citing and discussing [1].\n- The authors work on shared-memory machines and they use the work-depth model.\n- The authors follow a different approach for parallelization.\n- In particular, the ACL method is a coordinate solver, thus instead of updating one coordinate at each iteration, the authors in [1] suggest to update as many coordinate as the number of threads, or if the the number of threads is larger than the eligible push nodes, then in [1] they update all eligible nodes.\n- The authors of the submitted paper need to compare their approach with [1] both in theory and in practice.\n- Regarding the conductance guaranteed for your modification of ACL. I think you should simply state the minor points where the proof changes instead of re-writing the whole proof.\n- Typo in line 34. 'From a' instead of  'From an'.\n- Typo in line 45. 'that' instead of 'than'.\n- Typo in line 244. 'we' instead of 'wee'.\n- Lines 520-521 in the appendix. This sentence seems incomplete.",
    "review_points_list": [
      "The authors seem to work on the distributed computer setting. However, for the application of local graph clustering, the target clusters are much smaller than the size of the graph.",
      "For large graphs, the target clusters have constant size and they do not grow with the number of nodes in the graph.",
      "Local graph clustering algorithms like ACL take a fraction of a second to terminate and their memory footprint is also constant.",
      "For these reasons, I do not think that local graph clustering is the best application for the distributed setting.",
      "Even the datasets that you have chosen can fit in RAM of my personal computer.",
      "I think the authors should work on demonstrating an application where having multiple machines is necessary.",
      "The introduction of the paper is very technical.",
      "I could not understand what the authors are talking about until I read the proofs in the appendix.",
      "I actually believe that reading the proofs was much easier than trying to figure out what is going on from the main paper.",
      "I understand that it is important to mention all your contributions first, but the current text is dry.",
      "I had to reach page 4 to figure out what stitching is.",
      "For the application of local graph clustering, the authors have missed citing and discussing [1].",
      "The authors work on shared-memory machines and they use the work-depth model.",
      "The authors follow a different approach for parallelization.",
      "In particular, the ACL method is a coordinate solver, thus instead of updating one coordinate at each iteration, the authors in [1] suggest to update as many coordinate as the number of threads, or if the the number of threads is larger than the eligible push nodes, then in [1] they update all eligible nodes.",
      "The authors of the submitted paper need to compare their approach with [1] both in theory and in practice.",
      "Regarding the conductance guaranteed for your modification of ACL. I think you should simply state the minor points where the proof changes instead of re-writing the whole proof.",
      "Typo in line 34. 'From a' instead of  'From an'.",
      "Typo in line 45. 'that' instead of 'than'.",
      "Typo in line 244. 'we' instead of 'wee'.",
      "Lines 520-521 in the appendix. This sentence seems incomplete."
    ]
  },
  {
    "paper_id": "2112.00655v1",
    "submission_id": "yKoZfSVFtAx",
    "submission_title": "Efficient and Local Parallel Random Walks",
    "review_id": "Q6ucsuAxBN0",
    "input": {
      "title": "Efficient and Local Parallel Random Walks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The presentation of the paper needs significant improvement.\n- There are numerous confusing statements, spelling problems, and typos, making it impossible for me to determine the paper's contributions.\n- The work lacks the intuition needed to describe the algorithms and proofs, making it nearly impossible for non-experts to comprehend.\n- What is the purpose of k in the Stitching algorithm?\n- What's the difference between odd and even k?\n- The concluding section is missing.\n- The preliminaries have been moved to the appendix.\n- The formal version of Theorem 1 is missing.\n- The proof of Theorem 1 has been omitted.\n- Some proofs aren't as rigorous as others.\n- Does Remark 1 require the existence of B*<n in order to derive the round complexity?\n- The error analysis appears to be missing in the proof of Theorem 6.\n- The Budgeting algorithm initializes B(v,k) as B_0\\*deg(v).\n- The stationary distribution pr_alpha=alpha\\*s*(I-(1-alpha)*W)^{-1} is difficult to obtain for the Personalized PageRank.\n- Some important sections and proofs have been left out.\n- There are a few key experiments that are lacking.\n- The paper only compares the proposed technique to one baseline (LMOS20) in Section 4.2.\n- Experiments for finding local sparse cuts and approximating Personalized PageRank should be provided.\n- In Remark 1, lambda should be replaced with n^eps in the total memory complexity.\n- The definition of \\Phi(C) is omitted in Theorem 3.\n- The definition of eps is omitted in Theorem 4.\n- The assumption 'each vertex v has its own machine that stores its neighborhood' is stated twice in lines 136 and 142.\n- can simulate -> we can simulate in Theorems 2 and 4.\n- Line 85, Page 2: dependen -> dependent.\n- Line 105, Page 3: then -> than.\n- Line 123, Page 3: As mentioned before our main idea -> As mentioned before, our main idea.\n- Lines 135, Page 3, and 142, Page 4: assume that -> we assume that.\n- Line 148, Page 4: After the initial round of edge generation W_k(v) consists of ... -> After the initial round of edge generation, W_k(v) consists of ...\n- Line 159 and line 178, Page 4: There are two headings both named as 'Budgeting'.\n- Line 180, Page 4: and to do we initialize -> and we initialize.\n- Line 182, Page 4: The key observation is that to do it we need to.\n- Line 189, Page 4: thee -> the.\n- Line 270, Page 8: machines each of modest memory ... -> machines. Each of them has modest memory.\n- Line 473, Page 13: of the supplementary material: the formal definition of TVD error is omitted.",
    "review_points_list": [
      "The presentation of the paper needs significant improvement.",
      "There are numerous confusing statements, spelling problems, and typos, making it impossible for me to determine the paper's contributions.",
      "The work lacks the intuition needed to describe the algorithms and proofs, making it nearly impossible for non-experts to comprehend.",
      "What is the purpose of k in the Stitching algorithm?",
      "What's the difference between odd and even k?",
      "The concluding section is missing.",
      "The preliminaries have been moved to the appendix.",
      "The formal version of Theorem 1 is missing.",
      "The proof of Theorem 1 has been omitted.",
      "Some proofs aren't as rigorous as others.",
      "Does Remark 1 require the existence of B*<n in order to derive the round complexity?",
      "The error analysis appears to be missing in the proof of Theorem 6.",
      "The Budgeting algorithm initializes B(v,k) as B_0\\*deg(v).",
      "The stationary distribution pr_alpha=alpha\\*s*(I-(1-alpha)*W)^{-1} is difficult to obtain for the Personalized PageRank.",
      "Some important sections and proofs have been left out.",
      "There are a few key experiments that are lacking.",
      "The paper only compares the proposed technique to one baseline (LMOS20) in Section 4.2.",
      "Experiments for finding local sparse cuts and approximating Personalized PageRank should be provided.",
      "In Remark 1, lambda should be replaced with n^eps in the total memory complexity.",
      "The definition of \\Phi(C) is omitted in Theorem 3.",
      "The definition of eps is omitted in Theorem 4.",
      "The assumption 'each vertex v has its own machine that stores its neighborhood' is stated twice in lines 136 and 142.",
      "can simulate -> we can simulate in Theorems 2 and 4.",
      "Line 85, Page 2: dependen -> dependent.",
      "Line 105, Page 3: then -> than.",
      "Line 123, Page 3: As mentioned before our main idea -> As mentioned before, our main idea.",
      "Lines 135, Page 3, and 142, Page 4: assume that -> we assume that.",
      "Line 148, Page 4: After the initial round of edge generation W_k(v) consists of ... -> After the initial round of edge generation, W_k(v) consists of ...",
      "Line 159 and line 178, Page 4: There are two headings both named as 'Budgeting'.",
      "Line 180, Page 4: and to do we initialize -> and we initialize.",
      "Line 182, Page 4: The key observation is that to do it we need to.",
      "Line 189, Page 4: thee -> the.",
      "Line 270, Page 8: machines each of modest memory ... -> machines. Each of them has modest memory.",
      "Line 473, Page 13: of the supplementary material: the formal definition of TVD error is omitted."
    ]
  },
  {
    "paper_id": "2112.00655v1",
    "submission_id": "yKoZfSVFtAx",
    "submission_title": "Efficient and Local Parallel Random Walks",
    "review_id": "Xq64ws0zP7B",
    "input": {
      "title": "Efficient and Local Parallel Random Walks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The solution follows the usual idea of stitching shorter random walks in order to create longer random walks.\n- In consecutive rounds, random walks of length 2^k are turned into random walks of length 2^{k+1}.\n- An obstacle that any such method has to overcome is that some of the length 2^k random walks may not have extensions.\n- [LMOS] overcame this obstacle by using the stationary distribution, so the rough number of extensions that are needed is known in advance at the cost of large total space requirement.\n- To avoid this, the paper runs several attempts at creating random walks and adjust based on them the distribution from which short random walks are generated.\n- Overall, this solution is not very difficult in hindsight but it is neat and its simplicity allows for implementing the algorithm.\n- The submission also explores applications of random walks to computing Personalized PageRank and clustering.\n- Furthermore, it shows experiments in which it positively compares the performance to [LMOS].\n- Apart from typos and small grammatical errors, the paper is well written and presents the main ideas very clearly.\n- The paper addresses a well-motivated question with real world applications in a practical model of computation.\n- It would be great to see this paper in NeurIPS.\n- I suggest that the authors spend some time proofreading the paper and fixing spelling and small grammatical errors.\n- l.25: has -> have\n- l.34: an high -> a high\n- l.41: a random walk' or 'random walks'\n- l.50: in details -> in detail\n- page 4: Two paragraphs are titled 'Budgeting'. Was this intended?\n- Page 3 and 4 have the same footnote.\n- wee -> we\n- Edit: I acknowledge reading the rebuttal from the authors.",
    "review_points_list": [
      "The solution follows the usual idea of stitching shorter random walks in order to create longer random walks.",
      "In consecutive rounds, random walks of length 2^k are turned into random walks of length 2^{k+1}.",
      "An obstacle that any such method has to overcome is that some of the length 2^k random walks may not have extensions.",
      "[LMOS] overcame this obstacle by using the stationary distribution, so the rough number of extensions that are needed is known in advance at the cost of large total space requirement.",
      "To avoid this, the paper runs several attempts at creating random walks and adjust based on them the distribution from which short random walks are generated.",
      "Overall, this solution is not very difficult in hindsight but it is neat and its simplicity allows for implementing the algorithm.",
      "The submission also explores applications of random walks to computing Personalized PageRank and clustering.",
      "Furthermore, it shows experiments in which it positively compares the performance to [LMOS].",
      "Apart from typos and small grammatical errors, the paper is well written and presents the main ideas very clearly.",
      "The paper addresses a well-motivated question with real world applications in a practical model of computation.",
      "It would be great to see this paper in NeurIPS.",
      "I suggest that the authors spend some time proofreading the paper and fixing spelling and small grammatical errors.",
      "l.25: has -> have",
      "l.34: an high -> a high",
      "l.41: a random walk' or 'random walks'",
      "l.50: in details -> in detail",
      "page 4: Two paragraphs are titled 'Budgeting'. Was this intended?",
      "Page 3 and 4 have the same footnote.",
      "wee -> we",
      "Edit: I acknowledge reading the rebuttal from the authors."
    ]
  },
  {
    "paper_id": "2106.02039v4",
    "submission_id": "wgeK563QgSw",
    "submission_title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem",
    "review_id": "yMVL3dxFZA",
    "input": {
      "title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The view that the usage of contemporary sequence modeling toolkit as a for sequential decision-making tasks is sufficiently novel.\n- It provides new prospective on how to make use of highly successful transformer archtecture in various contexts and get good results.\n- The related work adequately cited?\n- The submission is technically sound.\n- Claims are supported by the large number of experimental results.\n- The visualisations and qualitative examples are also assisting the reader.\n- The manuscript is clear, well organized and easy to follow.\n- These are interesting results that the community can learn from and build upon.\n- The authors admit that predictions with Transformers is slower and more resource intensive.\n- I think the reader would benefit from knowing how much slower TTO is compared to baselines.\n- Hence I ask the authors to add that information for their experiments (imitation learning, goal-conditioned RL, and offline RL).\n- I'd be curious to see if goal-reaching is possible in more challenging domains compared to 4 rooms.\n- Perhaps in procedurally generated mazes that change at every episode (e.g. MiniGrid).\n- I thanks the authors for their response and for running additional experiments using MiniGrid.\n- I've also read the reviews by my fellow reviewers and the authors rebuttal to them (including many additional experiments).\n- Therefore, I have increased my score by 1.",
    "review_points_list": [
      "The view that the usage of contemporary sequence modeling toolkit as a for sequential decision-making tasks is sufficiently novel.",
      "It provides new prospective on how to make use of highly successful transformer archtecture in various contexts and get good results.",
      "The related work adequately cited?",
      "The submission is technically sound.",
      "Claims are supported by the large number of experimental results.",
      "The visualisations and qualitative examples are also assisting the reader.",
      "The manuscript is clear, well organized and easy to follow.",
      "These are interesting results that the community can learn from and build upon.",
      "The authors admit that predictions with Transformers is slower and more resource intensive.",
      "I think the reader would benefit from knowing how much slower TTO is compared to baselines.",
      "Hence I ask the authors to add that information for their experiments (imitation learning, goal-conditioned RL, and offline RL).",
      "I'd be curious to see if goal-reaching is possible in more challenging domains compared to 4 rooms.",
      "Perhaps in procedurally generated mazes that change at every episode (e.g. MiniGrid).",
      "I thanks the authors for their response and for running additional experiments using MiniGrid.",
      "I've also read the reviews by my fellow reviewers and the authors rebuttal to them (including many additional experiments).",
      "Therefore, I have increased my score by 1."
    ]
  },
  {
    "paper_id": "2106.02039v4",
    "submission_id": "wgeK563QgSw",
    "submission_title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem",
    "review_id": "4bf_iBy0ZzN",
    "input": {
      "title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed approach is novel and well-motivated, given the successes of transformers in sequence modeling.\n- The experimental results indicate that TTO can be usefully applied to at least a few, somewhat peripheral (non-online) tasks that fall within the broad collection of work associated with RL. However, the paper is worded in a way that is easy to interpret too broadly, starting with the catchy title, which could make many readers think of online RL, since that is the core of the field. Some readers may not even realize that online RL is excluded by the final sentence of the abstract, since imitation learning and offline RL are common pretraining steps performed prior to online RL training, and since goal conditioning often appears in the online RL setting. Expectations could be better managed by making the title less all-inclusive. For instance, \u201c**Non-Online** Reinforcement Learning as One Big Sequence Modeling Problem\u201d.\n- Any reader who initially assumes that this work reduces online RL to sequence modeling, freeing them from the tyranny of estimating cumulative reward, will be disappointed by the fine print that follows.\n- Apart from needing greater clarity in its claims, the paper is generally clear and well-written. I see a few other areas for improvement.\n- This is an interesting new approach that may deliver benefits in certain types of RL problems, and may even lead to useful online techniques.\n- Given the shortcomings described above, I cannot support publication of the paper in its current form. But I believe the work makes important contributions which deserve a wide audience, so I hope the paper\u2019s claims can be clarified so as not to mislead over-anxious readers.",
    "review_points_list": [
      "The proposed approach is novel and well-motivated, given the successes of transformers in sequence modeling.",
      "The experimental results indicate that TTO can be usefully applied to at least a few, somewhat peripheral (non-online) tasks that fall within the broad collection of work associated with RL. However, the paper is worded in a way that is easy to interpret too broadly, starting with the catchy title, which could make many readers think of online RL, since that is the core of the field. Some readers may not even realize that online RL is excluded by the final sentence of the abstract, since imitation learning and offline RL are common pretraining steps performed prior to online RL training, and since goal conditioning often appears in the online RL setting. Expectations could be better managed by making the title less all-inclusive. For instance, \u201c**Non-Online** Reinforcement Learning as One Big Sequence Modeling Problem\u201d.",
      "Any reader who initially assumes that this work reduces online RL to sequence modeling, freeing them from the tyranny of estimating cumulative reward, will be disappointed by the fine print that follows.",
      "Apart from needing greater clarity in its claims, the paper is generally clear and well-written. I see a few other areas for improvement.",
      "This is an interesting new approach that may deliver benefits in certain types of RL problems, and may even lead to useful online techniques.",
      "Given the shortcomings described above, I cannot support publication of the paper in its current form. But I believe the work makes important contributions which deserve a wide audience, so I hope the paper\u2019s claims can be clarified so as not to mislead over-anxious readers."
    ]
  },
  {
    "paper_id": "2106.02039v4",
    "submission_id": "wgeK563QgSw",
    "submission_title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem",
    "review_id": "6oBJoUFOj-K",
    "input": {
      "title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I do not think that throwing away all the dynamic programming techniques and replacing them with Transformers will help us solve RL.\n- While I disagree with this idea, my decision is not based on the fact that I do not like this approach.\n- I feel like authors do not highlight the limitations of this simple sequence to sequence approach well enough.\n- Limitations mentioned in section 5 are not serious limitations! Would this approach work when there is stochasticity? Non-stationarity? More diverse tasks? This simple approach would suffer a lot in complex environments and this has to be made clear.\n- While it is ok for having these limitations, it is crucial for this paper to have an explicit limitations section so that it does not mislead the community.\n- Why did the authors decide to go with the proposed discretization approach? It would be nice to see the performance of some baseline representations to understand the significance of this representation.\n- Line 133 -> The maximum tokens in 512. What are the values of N and M? How many transitions can you keep in the history if your maximum token length is 512?\n- This is very useful information to know.\n- Again, Figure-1 experiments are very misleading. You are comparing Transformers models with PETS. PETS uses simple feedforward networks. I would like to see the comparison between Transformers and PlaNet (Hafner et al 2019).\n- Figure 3 - Are these the only two types of attention you have seen in the trained model? How much cherry-picking happened here? Please explain the selection process here.\n- It is not clear whether the performance trends that authors show here would be the same if they use proper recurrent models in their baselines as well.\n- Figure 2 and Figure 4 - Please specify the number of runs.\n- Figure 4 - What is the y axis?\n- [2] Reinforcement Learning Upside Down: Don't Predict Rewards -- Just Map Them to Actions. Schmidhuber 2019\n- [1] Learning Latent Dynamics for Planning from Pixels. Hafner et al 2019\n- I have several major concerns about this work.\n- While this is an interesting research direction,",
    "review_points_list": [
      "I do not think that throwing away all the dynamic programming techniques and replacing them with Transformers will help us solve RL.",
      "While I disagree with this idea, my decision is not based on the fact that I do not like this approach.",
      "I feel like authors do not highlight the limitations of this simple sequence to sequence approach well enough.",
      "Limitations mentioned in section 5 are not serious limitations! Would this approach work when there is stochasticity? Non-stationarity? More diverse tasks? This simple approach would suffer a lot in complex environments and this has to be made clear.",
      "While it is ok for having these limitations, it is crucial for this paper to have an explicit limitations section so that it does not mislead the community.",
      "Why did the authors decide to go with the proposed discretization approach? It would be nice to see the performance of some baseline representations to understand the significance of this representation.",
      "Line 133 -> The maximum tokens in 512. What are the values of N and M? How many transitions can you keep in the history if your maximum token length is 512?",
      "This is very useful information to know.",
      "Again, Figure-1 experiments are very misleading. You are comparing Transformers models with PETS. PETS uses simple feedforward networks. I would like to see the comparison between Transformers and PlaNet (Hafner et al 2019).",
      "Figure 3 - Are these the only two types of attention you have seen in the trained model? How much cherry-picking happened here? Please explain the selection process here.",
      "It is not clear whether the performance trends that authors show here would be the same if they use proper recurrent models in their baselines as well.",
      "Figure 2 and Figure 4 - Please specify the number of runs.",
      "Figure 4 - What is the y axis?",
      "[2] Reinforcement Learning Upside Down: Don't Predict Rewards -- Just Map Them to Actions. Schmidhuber 2019",
      "[1] Learning Latent Dynamics for Planning from Pixels. Hafner et al 2019",
      "I have several major concerns about this work.",
      "While this is an interesting research direction,"
    ]
  },
  {
    "paper_id": "2111.04276v1",
    "submission_id": "xN3XX6pKSD5",
    "submission_title": "Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D Shape Synthesis",
    "review_id": "9y9RJWE2bRn",
    "input": {
      "title": "Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D Shape Synthesis",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The method is novel and the results are impressive.\n- The main contribution, differentiable Marching Tetrahedras, as an alternative to Deep Marching Cubes, seems like it could be useful in other contexts as well.\n- The evaluation is thorough and convincing. I believe it exceeds the threshold for acceptance in its current form already, although I have some suggestions for minor changes.\n- The exact contributions are not clear to me. Which exact parts of Sec. 3.1 are novel? What are the changes made to [16]?\n- Switching to SDF, adding volume subdivision (and making it differentiable), and using Marching Tetrahedra for surface extraction (and making it differentiable) these should be clearly mentioned in the introduction.\n- The comment regarding prior work like Deep Marching Cubes in lines 147-151 is interesting. What is missing for full differentiability though are gradients into vertices outside the current tetrahedra...\n- The method is evaluated on only one dataset, which does contain fairly diverse animal shapes though.\n- The writing is fine but could use a final polishing touch.\n- What does the f(v_i) output of GCN in Eq. 2 mean? Does it overwrite the previous features f(v_i) from Eq. 1?\n- How often is the Surface Refinement with Volume Subdivision (Eq.s 1 and 2) applied per forward pass?\n- Does the GCN for Learnable Surface Subdivision also take in the features f(v_i) from the previous step? If so, how are those features transferred from the tetrahedral structure to the extracted mesh?\n- I assume the GCN uses Eq. 1-4 from the 'GCN Model' paragraph in [10]?\n- What effect does varying alpha have? Just very simply, e.g. higher alpha leads to smoother surfaces?\n- What exactly is the small noise in line 74 in the supplement added to?\n- How is the SDF function in Eq.s 4 and 5 in the supplement computed?\n- The sequence of surface refinement and subdivision steps that is mentioned in C.2 should be mentioned in the main paper already.\n- Line 116 and 118 have a typo 'et.al.'\n- Current training time is a bit over half a week on 4 V100s.\n- Is the implementation in any way optimized, e.g. are custom layers parallelized in CUDA?\n- What speedups seem reasonably achievable with relatively little work?\n- Which component is currently the major bottleneck?",
    "review_points_list": [
      "The method is novel and the results are impressive.",
      "The main contribution, differentiable Marching Tetrahedras, as an alternative to Deep Marching Cubes, seems like it could be useful in other contexts as well.",
      "The evaluation is thorough and convincing. I believe it exceeds the threshold for acceptance in its current form already, although I have some suggestions for minor changes.",
      "The exact contributions are not clear to me. Which exact parts of Sec. 3.1 are novel? What are the changes made to [16]?",
      "Switching to SDF, adding volume subdivision (and making it differentiable), and using Marching Tetrahedra for surface extraction (and making it differentiable) these should be clearly mentioned in the introduction.",
      "The comment regarding prior work like Deep Marching Cubes in lines 147-151 is interesting. What is missing for full differentiability though are gradients into vertices outside the current tetrahedra...",
      "The method is evaluated on only one dataset, which does contain fairly diverse animal shapes though.",
      "The writing is fine but could use a final polishing touch.",
      "What does the f(v_i) output of GCN in Eq. 2 mean? Does it overwrite the previous features f(v_i) from Eq. 1?",
      "How often is the Surface Refinement with Volume Subdivision (Eq.s 1 and 2) applied per forward pass?",
      "Does the GCN for Learnable Surface Subdivision also take in the features f(v_i) from the previous step? If so, how are those features transferred from the tetrahedral structure to the extracted mesh?",
      "I assume the GCN uses Eq. 1-4 from the 'GCN Model' paragraph in [10]?",
      "What effect does varying alpha have? Just very simply, e.g. higher alpha leads to smoother surfaces?",
      "What exactly is the small noise in line 74 in the supplement added to?",
      "How is the SDF function in Eq.s 4 and 5 in the supplement computed?",
      "The sequence of surface refinement and subdivision steps that is mentioned in C.2 should be mentioned in the main paper already.",
      "Line 116 and 118 have a typo 'et.al.'",
      "Current training time is a bit over half a week on 4 V100s.",
      "Is the implementation in any way optimized, e.g. are custom layers parallelized in CUDA?",
      "What speedups seem reasonably achievable with relatively little work?",
      "Which component is currently the major bottleneck?"
    ]
  },
  {
    "paper_id": "2111.04276v1",
    "submission_id": "xN3XX6pKSD5",
    "submission_title": "Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D Shape Synthesis",
    "review_id": "y2VAU-64mC",
    "input": {
      "title": "Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D Shape Synthesis",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper basically combines a couple of hand-crafted designs that are not clearly motivated.\n- The underlying principles from the machine learning and statistical aspects are rather unclear.\n- A benefit of the implicit representation is that it is known to capture shape details. This paper uses it as initialization.\n- The subdivision scheme produces smooth outputs that are not feature preserving under the loop subdivision scheme.\n- It would be good to compare the proposed approach with state-of-the-art neural implicit representations for shape synthesis. The comparisons to the following paper is necessary. Implicit Neural Representations with Periodic Activation Functions. NeurIPS 2020.\n- The notion of hybrid is different from many other works that combine predictions under different representations. In this case, the errors made under one representation can be rectified under other representations or different representations help learn better features under a multi-task learning framework. Such approaches are grounded by bias and variance of optimizing over-parameterized networks, where ensembles can help reduce the variance.\n- In contrast, the proposed approach is sequential, meaning that the topology mistakes of the implicit representation cannot be rectified in the mesh representation. On the other hand, the mesh representation cannot guarantee self-intersection free during subdivision, which is an advantage of the implicit representation.\n- The input is an initial grid, it is rather unclear what is the definition of an initial grid?\n- What is the suggested resolution in practice. How sensitive is the output if perturbing the initial grid?\n- For example, when a user specifies the initial grid, which consists of many cells in my opinion, it is likely to be imprecise and inexact compared to the coarse grid of the underlying ground-truth.\n- How robust is the approach if perturbing the input?\n- There are many inconsistencies between the main text and the supplemental material. For example, the main text states 'which controls the generated surface via weighting the smoothness of neighboring vertices'. The supplemental material states that this is done using a graph neural network. It is unclear what is actually implemented? If the graph neural network is a major contribution, then the details should be in the main text.\n- The paper takes the approach of first initializing a coarse grid using an implicit representation which is followed by learnable mesh subdivision. This approach is limited in the sense that a coarse implicit representation does not capture the right topology of the underlying model, which cannot be recovered using mesh subdivision.\n- The paper does not compare against state-of-the-art implicit based representations (performed at high resolutions). It is unclear if similar results cannot be achieved by these techniques.\n- The paper is rushed, there are many inconsistencies between the main text and the supplemental material. It is recommended to revise the paper and submit to future venues in vision and graphics.",
    "review_points_list": [
      "The paper basically combines a couple of hand-crafted designs that are not clearly motivated.",
      "The underlying principles from the machine learning and statistical aspects are rather unclear.",
      "A benefit of the implicit representation is that it is known to capture shape details. This paper uses it as initialization.",
      "The subdivision scheme produces smooth outputs that are not feature preserving under the loop subdivision scheme.",
      "It would be good to compare the proposed approach with state-of-the-art neural implicit representations for shape synthesis. The comparisons to the following paper is necessary. Implicit Neural Representations with Periodic Activation Functions. NeurIPS 2020.",
      "The notion of hybrid is different from many other works that combine predictions under different representations. In this case, the errors made under one representation can be rectified under other representations or different representations help learn better features under a multi-task learning framework. Such approaches are grounded by bias and variance of optimizing over-parameterized networks, where ensembles can help reduce the variance.",
      "In contrast, the proposed approach is sequential, meaning that the topology mistakes of the implicit representation cannot be rectified in the mesh representation. On the other hand, the mesh representation cannot guarantee self-intersection free during subdivision, which is an advantage of the implicit representation.",
      "The input is an initial grid, it is rather unclear what is the definition of an initial grid?",
      "What is the suggested resolution in practice. How sensitive is the output if perturbing the initial grid?",
      "For example, when a user specifies the initial grid, which consists of many cells in my opinion, it is likely to be imprecise and inexact compared to the coarse grid of the underlying ground-truth.",
      "How robust is the approach if perturbing the input?",
      "There are many inconsistencies between the main text and the supplemental material. For example, the main text states 'which controls the generated surface via weighting the smoothness of neighboring vertices'. The supplemental material states that this is done using a graph neural network. It is unclear what is actually implemented? If the graph neural network is a major contribution, then the details should be in the main text.",
      "The paper takes the approach of first initializing a coarse grid using an implicit representation which is followed by learnable mesh subdivision. This approach is limited in the sense that a coarse implicit representation does not capture the right topology of the underlying model, which cannot be recovered using mesh subdivision.",
      "The paper does not compare against state-of-the-art implicit based representations (performed at high resolutions). It is unclear if similar results cannot be achieved by these techniques.",
      "The paper is rushed, there are many inconsistencies between the main text and the supplemental material. It is recommended to revise the paper and submit to future venues in vision and graphics."
    ]
  },
  {
    "paper_id": "2111.04276v1",
    "submission_id": "xN3XX6pKSD5",
    "submission_title": "Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D Shape Synthesis",
    "review_id": "fBg_UEqyoN_",
    "input": {
      "title": "Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D Shape Synthesis",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This is a well-written paper that introduces a reasonable hybrid deep 3D shape representation.\n- Representing the SDF on a deformable tet grid is a clever way to efficiently enable a coarse to fine representation, and ultimately extracting a mesh allows the model to be trained on mesh data with less artifacts from sampling or discretization.\n- I also think that most of the experiments are quite comprehensive and show improvement over past work.\n- Although the proposed approach largely consists of combinations and perturbations of several existing methods, I do think that there is sufficient novelty.\n- In particular, using the tet grid to represent SDFs and optimizing gradient flow based on relevant regions are reasonable choices that seem to help the overall method.\n- There are a few missing citations that should be discussed and do somewhat limit the proposed method's novelty.\n- 'Neural Subdivision' [Liu et al., SIGGRAPH 2020] is relevant in the context of the learned mesh subdivision step.\n- 'Neural Unsigned Distance Fields for Implicit Function Learning' [Chibane et al., NeurIPS 2020] and 'SAL' [Atzmon et al., CVPR 2020] learn implicit fields using explicit geometry as input, somewhat undermining the claim that implicit methods require strict supervision in the form of occupancies or distances.\n- Also, 'Analytic Marching' [Lei et al., ICML 2020] is relevant in the context of differentiable mesh extraction.\n- I also have a question about Figure 6, which shows results on out-of-distribution voxels.\n- The results are impressive, but only eight inputs are shown.\n- How were these chosen?\n- Are they representative, or do other specific inputs reveal failure cases?\n- L44, 120: sign distance -> signed distance\n- L75,85,148,180: typology -> topology\n- L148: in practise -> in practice",
    "review_points_list": [
      "This is a well-written paper that introduces a reasonable hybrid deep 3D shape representation.",
      "Representing the SDF on a deformable tet grid is a clever way to efficiently enable a coarse to fine representation, and ultimately extracting a mesh allows the model to be trained on mesh data with less artifacts from sampling or discretization.",
      "I also think that most of the experiments are quite comprehensive and show improvement over past work.",
      "Although the proposed approach largely consists of combinations and perturbations of several existing methods, I do think that there is sufficient novelty.",
      "In particular, using the tet grid to represent SDFs and optimizing gradient flow based on relevant regions are reasonable choices that seem to help the overall method.",
      "There are a few missing citations that should be discussed and do somewhat limit the proposed method's novelty.",
      "'Neural Subdivision' [Liu et al., SIGGRAPH 2020] is relevant in the context of the learned mesh subdivision step.",
      "'Neural Unsigned Distance Fields for Implicit Function Learning' [Chibane et al., NeurIPS 2020] and 'SAL' [Atzmon et al., CVPR 2020] learn implicit fields using explicit geometry as input, somewhat undermining the claim that implicit methods require strict supervision in the form of occupancies or distances.",
      "Also, 'Analytic Marching' [Lei et al., ICML 2020] is relevant in the context of differentiable mesh extraction.",
      "I also have a question about Figure 6, which shows results on out-of-distribution voxels.",
      "The results are impressive, but only eight inputs are shown.",
      "How were these chosen?",
      "Are they representative, or do other specific inputs reveal failure cases?",
      "L44, 120: sign distance -> signed distance",
      "L75,85,148,180: typology -> topology",
      "L148: in practise -> in practice"
    ]
  },
  {
    "paper_id": "2111.04276v1",
    "submission_id": "xN3XX6pKSD5",
    "submission_title": "Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D Shape Synthesis",
    "review_id": "QMPwWWtYuG6",
    "input": {
      "title": "Deep Marching Tetrahedra: a Hybrid Representation for High-Resolution 3D Shape Synthesis",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper presents a method for generating high-resolution 3D shapes guided by coarse voxel-based input.\n- The key idea is to combine tetrahedral meshes which are adaptive and more efficient, with sign-distance field, along with a differentiable marching tetrahedra layer that bridges the gap between tetrahedra and surface meshes.\n- Overall, the method is plausible and shows decent performance.\n- I have the following concerns:\n- From a technical perspective, the method is built on DefTet [16], by introducing SDF and Marching Tetrahedra.\n- All these components are from existing publications, which somehow affects the novelty of the method.\n- Nevertheless, the approach to combine these leads to improved performance and is itself interesting.\n- Although the paper claims that the method can handle topological changes, I can't seem to find examples that clearly demonstrate this.\n- Moreover, a large part of the assessment is based on a dataset collected by authors, which makes comparisons more challenging.\n- Evaluation of guided synthesis on more public datasets would make it more convincing.",
    "review_points_list": [
      "The paper presents a method for generating high-resolution 3D shapes guided by coarse voxel-based input.",
      "The key idea is to combine tetrahedral meshes which are adaptive and more efficient, with sign-distance field, along with a differentiable marching tetrahedra layer that bridges the gap between tetrahedra and surface meshes.",
      "Overall, the method is plausible and shows decent performance.",
      "I have the following concerns:",
      "From a technical perspective, the method is built on DefTet [16], by introducing SDF and Marching Tetrahedra.",
      "All these components are from existing publications, which somehow affects the novelty of the method.",
      "Nevertheless, the approach to combine these leads to improved performance and is itself interesting.",
      "Although the paper claims that the method can handle topological changes, I can't seem to find examples that clearly demonstrate this.",
      "Moreover, a large part of the assessment is based on a dataset collected by authors, which makes comparisons more challenging.",
      "Evaluation of guided synthesis on more public datasets would make it more convincing."
    ]
  },
  {
    "paper_id": "2105.12909v3",
    "submission_id": "tX4OCWu3P7R",
    "submission_title": "Deconditional Downscaling with Gaussian Processes",
    "review_id": "dDcgl4foe2w",
    "input": {
      "title": "Deconditional Downscaling with Gaussian Processes",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper comes along with a theoretical analysis of the proposed approach and a careful experimental validation.\n- I found parts of it quiet confusing. However, this might also be attributed to my rather scarce background knowledge on conditional mean embeddings.\n- The title and abstract of the paper suggest that the main innovation of the paper is a new GP formulation that allows for different resolutions.\n- For large parts of the paper, this seems to not be very relevant.\n- The down-scaling only enters in Section 3.3 and in the experiments and is not even part of the main notation.\n- The major contribution of the paper seems to me is more the definition of the conditional mean process which allows for mediating variables in general.\n- Interestingly, one arrives at a GP formulation including analytical solutions for mean and covariance.\n- This was surprising to me because chaining two Gaussian processes together and marginalizing out the intermediate variable leads in general to non-Gaussian distributions.\n- The posterior mean recovers a solution that has been published previously using the deconditional mean embedding [19].\n- For ease of readibility, I would suggest to move the complete deconditional mean embedding discussion in Section 4 and not scattered between Section 1, Section 2.2 and Section 4. It is not strictly needed for understanding the conditional mean process and distracts from it.\n- I also wonder if the paper would not be better split into two separate contributions - one with the general theoretical framework and one with the specific down-scaling application in mind.\n- For me, the two parts seem to be a bit disconnected.\n- In the experimental section, I would suggest to add a second metric that takes the uncertainty estimates of the GP into account.\n- After all, this is one of the main benefits of the GP-based method.\n- It would also be interesting to compare the uncertainty estimates between the proposed solution and the GP in [19] for the special case that the granularity levels are the same on both datasets.",
    "review_points_list": [
      "The paper comes along with a theoretical analysis of the proposed approach and a careful experimental validation.",
      "I found parts of it quiet confusing. However, this might also be attributed to my rather scarce background knowledge on conditional mean embeddings.",
      "The title and abstract of the paper suggest that the main innovation of the paper is a new GP formulation that allows for different resolutions.",
      "For large parts of the paper, this seems to not be very relevant.",
      "The down-scaling only enters in Section 3.3 and in the experiments and is not even part of the main notation.",
      "The major contribution of the paper seems to me is more the definition of the conditional mean process which allows for mediating variables in general.",
      "Interestingly, one arrives at a GP formulation including analytical solutions for mean and covariance.",
      "This was surprising to me because chaining two Gaussian processes together and marginalizing out the intermediate variable leads in general to non-Gaussian distributions.",
      "The posterior mean recovers a solution that has been published previously using the deconditional mean embedding [19].",
      "For ease of readibility, I would suggest to move the complete deconditional mean embedding discussion in Section 4 and not scattered between Section 1, Section 2.2 and Section 4. It is not strictly needed for understanding the conditional mean process and distracts from it.",
      "I also wonder if the paper would not be better split into two separate contributions - one with the general theoretical framework and one with the specific down-scaling application in mind.",
      "For me, the two parts seem to be a bit disconnected.",
      "In the experimental section, I would suggest to add a second metric that takes the uncertainty estimates of the GP into account.",
      "After all, this is one of the main benefits of the GP-based method.",
      "It would also be interesting to compare the uncertainty estimates between the proposed solution and the GP in [19] for the special case that the granularity levels are the same on both datasets."
    ]
  },
  {
    "paper_id": "2105.12909v3",
    "submission_id": "tX4OCWu3P7R",
    "submission_title": "Deconditional Downscaling with Gaussian Processes",
    "review_id": "aJyU0b_gQBN",
    "input": {
      "title": "Deconditional Downscaling with Gaussian Processes",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The task of recovering spatial fields from aggregated data is interesting and important.\n- This paper is well-written and technically sound.\n- The use of Conditional and Deconditional Kernel Mean Embeddings to the downscaling problem is novel.\n- The experiments on atmospheric temperature data are encouraging.\n- My opinion tends to accept; but there are some concerns about technical issues.\n- It seems that the input of the proposed method is limited to data aggregated at grid cells.\n- the proposed method allows data aggregated over regions that have various shapes; is that right?\n- If that is the case, it would be helpful to clarify...\n- This idea may be similar to those of [e.g., 10, R1].\n- Actually, the spatially aggregated data (e.g., disease incidence [7]) are often associated with irregularly shaped regions such as districts.\n- As in [10, R1], can the proposed model handle the effects from the region's size and shape?\n- That could be critical for estimating prediction uncertainty.\n- I support you in that GP-based modeling is useful, but it would be better to mention the recently published downscaling methods based on DNN [e.g., R2] and clarify the advantages of the proposed approach.\n- In [6], learning from aggregated data is more generally formulated.\n- Can the authors consider the extension of the proposed method to other machine learning tasks such as classification and ordinal regression?\n- Could you please elaborate on the reason why the predictive performance of BAGG-GP and VBAGG is worse than vanilla GP?\n- R1 M. T. Smith, M. A. \u00c1lvarez, and N. D. Lawrence. Gaussian process regression for binned data. In arXiv e-prints, 2018.\n- Vandal, T.; Kodra, E.; Ganguly, S.; Michaelis, A.; Nemani, R.; and Ganguly, A. R. 2017. DeepSD: Generating high resolution climate change projections through single image super-resolution. In KDD, 1663\u20131672.",
    "review_points_list": [
      "The task of recovering spatial fields from aggregated data is interesting and important.",
      "This paper is well-written and technically sound.",
      "The use of Conditional and Deconditional Kernel Mean Embeddings to the downscaling problem is novel.",
      "The experiments on atmospheric temperature data are encouraging.",
      "My opinion tends to accept; but there are some concerns about technical issues.",
      "It seems that the input of the proposed method is limited to data aggregated at grid cells.",
      "the proposed method allows data aggregated over regions that have various shapes; is that right?",
      "If that is the case, it would be helpful to clarify...",
      "This idea may be similar to those of [e.g., 10, R1].",
      "Actually, the spatially aggregated data (e.g., disease incidence [7]) are often associated with irregularly shaped regions such as districts.",
      "As in [10, R1], can the proposed model handle the effects from the region's size and shape?",
      "That could be critical for estimating prediction uncertainty.",
      "I support you in that GP-based modeling is useful, but it would be better to mention the recently published downscaling methods based on DNN [e.g., R2] and clarify the advantages of the proposed approach.",
      "In [6], learning from aggregated data is more generally formulated.",
      "Can the authors consider the extension of the proposed method to other machine learning tasks such as classification and ordinal regression?",
      "Could you please elaborate on the reason why the predictive performance of BAGG-GP and VBAGG is worse than vanilla GP?",
      "R1 M. T. Smith, M. A. \u00c1lvarez, and N. D. Lawrence. Gaussian process regression for binned data. In arXiv e-prints, 2018.",
      "Vandal, T.; Kodra, E.; Ganguly, S.; Michaelis, A.; Nemani, R.; and Ganguly, A. R. 2017. DeepSD: Generating high resolution climate change projections through single image super-resolution. In KDD, 1663\u20131672."
    ]
  },
  {
    "paper_id": "2105.12909v3",
    "submission_id": "tX4OCWu3P7R",
    "submission_title": "Deconditional Downscaling with Gaussian Processes",
    "review_id": "FDrpvek88g",
    "input": {
      "title": "Deconditional Downscaling with Gaussian Processes",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The integral of a Gaussian process is another Gaussian process is a standard result (eg convolution of a GP is another GP), I feel I have seen variations of equation (3) in multiple previous works [1] [2].\n- I believe the following 'deconditioning' step is standard (as rightly acknowledged to be Gaussian conditioning) and equations (5), (6) are textbook results.\n- The sparse inducing point variational approach was applied in Hsu and Ramos\n- I believe the main practical novelty mainly lies in using the kernel $l_y$ as a means to model $\text{P}[X|Y]$ away from the training data thereby bridging the gap between the unmatched $y_i$ and $\tilde y_j$, I think this is really cool and the inclusion of VBAGG baseline (where $l_y$ is effectively 'switched off') demonstrates the efficacy.\n- However this seems rather unsurprising and rather incremental.\n- I have two major concerns, the overall writing and the novelty of the proposed conditional mean process.\n- I found the paper initially rather difficult to read, I felt the mathematical statements were very dense (mainly Section 2.2) with minimal explanation and required multiple passes to follow (I am largely familiar with the notation though not an expert).\n- I had to read the paper multiple times to first acquire an intuitive understanding of the problem definition, I felt there were multiple subtle ambiguities that threw me off course and minor clarifications would have made the paper much easier to read.\n- The first dataset is introduced as $(x, y)$. This would traditionally imply that $x$ is predicting $y$, i.e. modelling $\text{P}[Y|X]$, Figure 1 seems to imply this as well, however $y$ is an 'input' for the output $x^b$, it is used to Monte Carlo approximate $\text{P}[X|Y]$ instead.\n- Perhaps using $y$ as function outputs (like [3]) as in and $z$ (or anything else) as the 'middle man' variables.\n- $z = \text{E}[f(X)|Y] + \text{\u03b5}$ does not explicitly state what the expectation is over, though it slowly becomes clear that it is $X.\n- The word 'conditional' is used very frequently and I believe it is referring to the _marginal_ over $X$ using $\text{P}[X|Y]$ (which happens to be a conditional distribution although $Y$ could be any parameter).\n- Again upon first reading this led to a lot of ambiguity for me.\n- The 'de-marginalizing' or 'de-aggregation' to be much more intuitive than 'de-conditioning\n- Given the two datasets (x, y), (y, z) and the 'two stage regression' statements, I was partly expecting deep Gaussian Processes, again, this misinterpretation took a long time to un-misinterpret\n- A 'hands on' example application in the introduction with example $x$, $x$ and $z$ values would help a clear up much speculation from thee start avoiding many misinterpretations and blind alleys, upon first reading I didn't fully understand the problem setting until the experiments.\n- I have given a low confidence score to reflect my difficulty in reading the paper.\n- I believe the authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.\n- The paper is very clear and well organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.\n- The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.",
    "review_points_list": [
      "The integral of a Gaussian process is another Gaussian process is a standard result (eg convolution of a GP is another GP), I feel I have seen variations of equation (3) in multiple previous works [1] [2].",
      "I believe the following 'deconditioning' step is standard (as rightly acknowledged to be Gaussian conditioning) and equations (5), (6) are textbook results.",
      "The sparse inducing point variational approach was applied in Hsu and Ramos",
      "I believe the main practical novelty mainly lies in using the kernel $l_y$ as a means to model $\text{P}[X|Y]$ away from the training data thereby bridging the gap between the unmatched $y_i$ and $\tilde y_j$, I think this is really cool and the inclusion of VBAGG baseline (where $l_y$ is effectively 'switched off') demonstrates the efficacy.",
      "However this seems rather unsurprising and rather incremental.",
      "I have two major concerns, the overall writing and the novelty of the proposed conditional mean process.",
      "I found the paper initially rather difficult to read, I felt the mathematical statements were very dense (mainly Section 2.2) with minimal explanation and required multiple passes to follow (I am largely familiar with the notation though not an expert).",
      "I had to read the paper multiple times to first acquire an intuitive understanding of the problem definition, I felt there were multiple subtle ambiguities that threw me off course and minor clarifications would have made the paper much easier to read.",
      "The first dataset is introduced as $(x, y)$. This would traditionally imply that $x$ is predicting $y$, i.e. modelling $\text{P}[Y|X]$, Figure 1 seems to imply this as well, however $y$ is an 'input' for the output $x^b$, it is used to Monte Carlo approximate $\text{P}[X|Y]$ instead.",
      "Perhaps using $y$ as function outputs (like [3]) as in and $z$ (or anything else) as the 'middle man' variables.",
      "$z = \text{E}[f(X)|Y] + \text{\u03b5}$ does not explicitly state what the expectation is over, though it slowly becomes clear that it is $X.",
      "The word 'conditional' is used very frequently and I believe it is referring to the _marginal_ over $X$ using $\text{P}[X|Y]$ (which happens to be a conditional distribution although $Y$ could be any parameter).",
      "Again upon first reading this led to a lot of ambiguity for me.",
      "The 'de-marginalizing' or 'de-aggregation' to be much more intuitive than 'de-conditioning",
      "Given the two datasets (x, y), (y, z) and the 'two stage regression' statements, I was partly expecting deep Gaussian Processes, again, this misinterpretation took a long time to un-misinterpret",
      "A 'hands on' example application in the introduction with example $x$, $x$ and $z$ values would help a clear up much speculation from thee start avoiding many misinterpretations and blind alleys, upon first reading I didn't fully understand the problem setting until the experiments.",
      "I have given a low confidence score to reflect my difficulty in reading the paper.",
      "I believe the authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.",
      "The paper is very clear and well organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.",
      "The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm."
    ]
  },
  {
    "paper_id": "2105.12909v3",
    "submission_id": "tX4OCWu3P7R",
    "submission_title": "Deconditional Downscaling with Gaussian Processes",
    "review_id": "xM1Ew_0GK_4",
    "input": {
      "title": "Deconditional Downscaling with Gaussian Processes",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The estimator previously appears in Hsu and Ramos.\n- Prop 3.2 and Prop 3.3 appear to be new characterizations of the Bayesian approach.\n- Prop 4.1 demonstrates that the estimator is the solution to a 2-stage (frequentist) regression.\n- Theorem 4.2 relates the problem considered in this paper to the nonparametric instrumental variable problem in order to match symbols with an existing theorem.\n- The theoretical results are complete and thorough.\n- Why is H_l finite dimensional?\n- This seems to be unnecessary when appealing to the quoted theorem.\n- There seems to be a small clash between the theory and empirics.\n- In theory, k is characteristic and ell is finite.\n- In empirics, k and ell are sums of Gaussian and Matern kernels, so they are infinite dimensional and not characteristic.\n- It took me a long time to understand the problem set up: what is observed, what is the goal, and what will be estimated.\n- Figure 1 helps, and should be larger.\n- Please improve the introduction to this learning problem.\n- Theorem D.4 should be in the main text since otherwise its assumptions are hidden.\n- It is difficult for me to assess the significance of this paper in the spatial observation resolution literature.\n- Within the RKHS literature, the theoretical contributions are modest: the estimator and main theorem are essentially from previous papers, but the Bayesian characterization and connection to nonparametric instrumental variable regression are new and insightful.\n- I think these should be emphasized more.\n- If there is strong significance for practitioners, I will raise the score.",
    "review_points_list": [
      "The estimator previously appears in Hsu and Ramos.",
      "Prop 3.2 and Prop 3.3 appear to be new characterizations of the Bayesian approach.",
      "Prop 4.1 demonstrates that the estimator is the solution to a 2-stage (frequentist) regression.",
      "Theorem 4.2 relates the problem considered in this paper to the nonparametric instrumental variable problem in order to match symbols with an existing theorem.",
      "The theoretical results are complete and thorough.",
      "Why is H_l finite dimensional?",
      "This seems to be unnecessary when appealing to the quoted theorem.",
      "There seems to be a small clash between the theory and empirics.",
      "In theory, k is characteristic and ell is finite.",
      "In empirics, k and ell are sums of Gaussian and Matern kernels, so they are infinite dimensional and not characteristic.",
      "It took me a long time to understand the problem set up: what is observed, what is the goal, and what will be estimated.",
      "Figure 1 helps, and should be larger.",
      "Please improve the introduction to this learning problem.",
      "Theorem D.4 should be in the main text since otherwise its assumptions are hidden.",
      "It is difficult for me to assess the significance of this paper in the spatial observation resolution literature.",
      "Within the RKHS literature, the theoretical contributions are modest: the estimator and main theorem are essentially from previous papers, but the Bayesian characterization and connection to nonparametric instrumental variable regression are new and insightful.",
      "I think these should be emphasized more.",
      "If there is strong significance for practitioners, I will raise the score."
    ]
  },
  {
    "paper_id": "2011.12719v4",
    "submission_id": "trNDfee72NQ",
    "submission_title": "RLlib Flow: Distributed Reinforcement Learning is a Dataflow Problem",
    "review_id": "OUmKqOwc2K",
    "input": {
      "title": "RLlib Flow: Distributed Reinforcement Learning is a Dataflow Problem",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- A commendable work on reinforcement learning that addresses some important issues\n- The work investigates the limitations of the present RL libraries such as ACME, RLib, and Coach\n- The work proposes a completely different view on the RL problem and advocates looking at it in a data flow context\n- It introduces the concept of data flow operators and shows by example how this framework can be used to implement RL-based solutions or experiment with the existing ones\n- Despite the good work, there are some flaws in the way article is presented\n- The framework should have a sound theoretical discussion instead of a discussion about which library to chose for the implementation and which to reject\n- There are always two main choices to make when implementing a distributed framework\n- Either to use message passing mechanism\n- Or use a shared memory model\n- From a theoretical point this discussion is important, because it enables us to think above the individual libraries and frameworks\n- It is well known that the shared memory systems perform better in certain situations as compared to message-passing systems\n- In other cases, the situation is the opposite\n- For the sake of completeness, it is essential to have that discussion, whether to implement a data flow-based RL framework using shared memory or message passing\n- A key benefit of message passing systems is that they are scalable and robust, and can work in many different scenarios and machine capabilities\n- A shared memory-based system may perform better with greater compute capabilities of machines, but may totally fail in a situation where there are numerous small devices\n- In the light of the above, I think the paper presents a good idea but lacks the theoretical rigor that was needed to draw some long-lasting conclusions",
    "review_points_list": [
      "A commendable work on reinforcement learning that addresses some important issues",
      "The work investigates the limitations of the present RL libraries such as ACME, RLib, and Coach",
      "The work proposes a completely different view on the RL problem and advocates looking at it in a data flow context",
      "It introduces the concept of data flow operators and shows by example how this framework can be used to implement RL-based solutions or experiment with the existing ones",
      "Despite the good work, there are some flaws in the way article is presented",
      "The framework should have a sound theoretical discussion instead of a discussion about which library to chose for the implementation and which to reject",
      "There are always two main choices to make when implementing a distributed framework",
      "Either to use message passing mechanism",
      "Or use a shared memory model",
      "From a theoretical point this discussion is important, because it enables us to think above the individual libraries and frameworks",
      "It is well known that the shared memory systems perform better in certain situations as compared to message-passing systems",
      "In other cases, the situation is the opposite",
      "For the sake of completeness, it is essential to have that discussion, whether to implement a data flow-based RL framework using shared memory or message passing",
      "A key benefit of message passing systems is that they are scalable and robust, and can work in many different scenarios and machine capabilities",
      "A shared memory-based system may perform better with greater compute capabilities of machines, but may totally fail in a situation where there are numerous small devices",
      "In the light of the above, I think the paper presents a good idea but lacks the theoretical rigor that was needed to draw some long-lasting conclusions"
    ]
  },
  {
    "paper_id": "2011.12719v4",
    "submission_id": "trNDfee72NQ",
    "submission_title": "RLlib Flow: Distributed Reinforcement Learning is a Dataflow Problem",
    "review_id": "yteqfei1X5",
    "input": {
      "title": "RLlib Flow: Distributed Reinforcement Learning is a Dataflow Problem",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The idea is interesting for simplifying the implementation of distributed RL algorithms.\n- It organizes the common distributed actor processing patterns into higher level abstractions.\n- Although this abstraction simplifies the implementations of existing algorithms, I wonder whether it will have lower flexibility for experimentation and new algorithms.\n- For example: dynamically changing dataflow based on the rollout performance.\n- These abstractions can improve readability of the high-level dataflow, but it seems also hide some of the details of the underlying operations.\n- For example, in Figure 10 b), \u201cppo_plan\u201d basically hides all the details of how the operations of the PPO algorithm, and how the weights are updated.\n- How do users gain more understanding of the actual operations (like Figure 10a)?\n- These high-level abstractions ease the implementation of distributed RL.\n- However, it increases the overhead when running the algorithm (for example in a single machine).\n- Is it possible to quantify the overhead of these abstractions?\n- For figure 12, how is the theoretical best performance calculated using Amdahl\u2019s law?\n- AnonFlow\u2019s performance is very similar to RLlib.\n- Since AnonFlow provides a high-level abstraction, does it also allow more lower-level optimizations for improving the performance of RL tasks?",
    "review_points_list": [
      "The idea is interesting for simplifying the implementation of distributed RL algorithms.",
      "It organizes the common distributed actor processing patterns into higher level abstractions.",
      "Although this abstraction simplifies the implementations of existing algorithms, I wonder whether it will have lower flexibility for experimentation and new algorithms.",
      "For example: dynamically changing dataflow based on the rollout performance.",
      "These abstractions can improve readability of the high-level dataflow, but it seems also hide some of the details of the underlying operations.",
      "For example, in Figure 10 b), \u201cppo_plan\u201d basically hides all the details of how the operations of the PPO algorithm, and how the weights are updated.",
      "How do users gain more understanding of the actual operations (like Figure 10a)?",
      "These high-level abstractions ease the implementation of distributed RL.",
      "However, it increases the overhead when running the algorithm (for example in a single machine).",
      "Is it possible to quantify the overhead of these abstractions?",
      "For figure 12, how is the theoretical best performance calculated using Amdahl\u2019s law?",
      "AnonFlow\u2019s performance is very similar to RLlib.",
      "Since AnonFlow provides a high-level abstraction, does it also allow more lower-level optimizations for improving the performance of RL tasks?"
    ]
  },
  {
    "paper_id": "2011.12719v4",
    "submission_id": "trNDfee72NQ",
    "submission_title": "RLlib Flow: Distributed Reinforcement Learning is a Dataflow Problem",
    "review_id": "LpeNOPQWBOv",
    "input": {
      "title": "RLlib Flow: Distributed Reinforcement Learning is a Dataflow Problem",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- In this paper, the authors combine ideas from dataflow programming with actors and argue that this provides a more flexible programming environment for RL researchers.\n- The methods described in the work, dataflow and actors, are not novel but the combination of these components targeting the development of RL algorithms is interesting.\n- The distinction between the proposed and previous systems, as outlined in Table 1, makes it clear AnonFlow is meant to provide a more generic data distribution scheme alongside a higher-level interface.\n- Support for the proposed abstractions is provided in the form of examples, in Figures 9 and 10, that use lines of code and readability as the metrics of interest.\n- A reduction w.r.t LOC is expected given the authors positioning of AnonFlow as a high-level interface, relative to RLlib.\n- No performance degradation resulted from the proposed transformations as demonstrated in Figure 11.\n- The paper is well-written and clearly organized to support the author's RL dataflow/RL argument.\n- Comparisons with competing dataflow and RL libraries are provided to draw attention to the distinctive advantages of AnonFlow.\n- Overall, although there is a novelty in the expression of the RL algorithms, I think it would be difficult to gauge the significance of the work.\n- It's unclear if the RL community would adopt and/or see value in the insights of the dataflow/actor implementation.\n- I lean toward acceptance because IMHO the current offering of RL frameworks appears to be quite rigid and 'new' algorithms typically require a substantial investment in time and effort.\n- From that perspective, this work provides at least one sample of an alternative formulation worth considering to alleviate some concerns.",
    "review_points_list": [
      "In this paper, the authors combine ideas from dataflow programming with actors and argue that this provides a more flexible programming environment for RL researchers.",
      "The methods described in the work, dataflow and actors, are not novel but the combination of these components targeting the development of RL algorithms is interesting.",
      "The distinction between the proposed and previous systems, as outlined in Table 1, makes it clear AnonFlow is meant to provide a more generic data distribution scheme alongside a higher-level interface.",
      "Support for the proposed abstractions is provided in the form of examples, in Figures 9 and 10, that use lines of code and readability as the metrics of interest.",
      "A reduction w.r.t LOC is expected given the authors positioning of AnonFlow as a high-level interface, relative to RLlib.",
      "No performance degradation resulted from the proposed transformations as demonstrated in Figure 11.",
      "The paper is well-written and clearly organized to support the author's RL dataflow/RL argument.",
      "Comparisons with competing dataflow and RL libraries are provided to draw attention to the distinctive advantages of AnonFlow.",
      "Overall, although there is a novelty in the expression of the RL algorithms, I think it would be difficult to gauge the significance of the work.",
      "It's unclear if the RL community would adopt and/or see value in the insights of the dataflow/actor implementation.",
      "I lean toward acceptance because IMHO the current offering of RL frameworks appears to be quite rigid and 'new' algorithms typically require a substantial investment in time and effort.",
      "From that perspective, this work provides at least one sample of an alternative formulation worth considering to alleviate some concerns."
    ]
  },
  {
    "paper_id": "2011.12719v4",
    "submission_id": "trNDfee72NQ",
    "submission_title": "RLlib Flow: Distributed Reinforcement Learning is a Dataflow Problem",
    "review_id": "FDLMUnQm9Nn",
    "input": {
      "title": "RLlib Flow: Distributed Reinforcement Learning is a Dataflow Problem",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper proposes AnonFlow, an actor-dataflow programming model for reinforcement learning. Algorithms in RLib have been ported to AnonFlow and the lines of code for distributed execution are reduced.\n- It is a novel point of view to treat the distributed reinforcement learning as a dataflow problem.\n- This paper claims that it is common for RL researchers to eschew existing infrastructures. However, no empirical evidence is provided in the experiment to show that RL researchers prefer to use the proposed AnonFlow, rather than existing infrastructures or writing their own approaches.\n- It is insufficient that only evaluating the performance of AnonFlow on several RL algorithms. This paper claims that RL researchers may wish to customize a particular algorithm into various RL tasks (e.g., single-agent, multi-agent, meta-learning) and configuration options (e.g., degree of parallelism, batch size). The author fails to evaluate the performance of AnonFlow on various RL tasks and configuration options.\n- The improvement of experimental results is marginal. It can be observed from Figure 11(a) that the sample throughput of AnonFlow on CartPole is less than that of RLib when the number of workers is small. In addition, Figure 11(b) shows that the training throughput of AnonFlow on Atari is almost the same as that of RLib.\n- It is a novel point of view to treat the distributed reinforcement learning as a dataflow problem.\n- This paper proposes AnonFlow, an actor-dataflow programming model for reinforcement learning. Algorithms in RLib have been ported to AnonFlow and the lines of code for distributed execution are reduced.\n- This paper claims that it is common for RL researchers to eschew existing infrastructures. However, no empirical evidence is provided in the experiment to show that RL researchers prefer to use the proposed AnonFlow, rather than existing infrastructures or writing their own approaches.\n- It is insufficient that only evaluating the performance of AnonFlow on several RL algorithms. This paper claims that RL researchers may wish to customize a particular algorithm into various RL tasks (e.g., single-agent, multi-agent, meta-learning) and configuration options (e.g., degree of parallelism, batch size). The author fails to evaluate the performance of AnonFlow on various RL tasks and configuration options.\n- The improvement of experimental results is marginal.\n- It can be observed from Figure 11(a) that the sample throughput of AnonFlow on CartPole is less than that of RLib when the number of workers is small.\n- In addition, Figure 11(b) shows that the training throughput of AnonFlow on Atari is almost the same as that of RLib.",
    "review_points_list": [
      "The paper proposes AnonFlow, an actor-dataflow programming model for reinforcement learning. Algorithms in RLib have been ported to AnonFlow and the lines of code for distributed execution are reduced.",
      "It is a novel point of view to treat the distributed reinforcement learning as a dataflow problem.",
      "This paper claims that it is common for RL researchers to eschew existing infrastructures. However, no empirical evidence is provided in the experiment to show that RL researchers prefer to use the proposed AnonFlow, rather than existing infrastructures or writing their own approaches.",
      "It is insufficient that only evaluating the performance of AnonFlow on several RL algorithms. This paper claims that RL researchers may wish to customize a particular algorithm into various RL tasks (e.g., single-agent, multi-agent, meta-learning) and configuration options (e.g., degree of parallelism, batch size). The author fails to evaluate the performance of AnonFlow on various RL tasks and configuration options.",
      "The improvement of experimental results is marginal. It can be observed from Figure 11(a) that the sample throughput of AnonFlow on CartPole is less than that of RLib when the number of workers is small. In addition, Figure 11(b) shows that the training throughput of AnonFlow on Atari is almost the same as that of RLib.",
      "It is a novel point of view to treat the distributed reinforcement learning as a dataflow problem.",
      "This paper proposes AnonFlow, an actor-dataflow programming model for reinforcement learning. Algorithms in RLib have been ported to AnonFlow and the lines of code for distributed execution are reduced.",
      "This paper claims that it is common for RL researchers to eschew existing infrastructures. However, no empirical evidence is provided in the experiment to show that RL researchers prefer to use the proposed AnonFlow, rather than existing infrastructures or writing their own approaches.",
      "It is insufficient that only evaluating the performance of AnonFlow on several RL algorithms. This paper claims that RL researchers may wish to customize a particular algorithm into various RL tasks (e.g., single-agent, multi-agent, meta-learning) and configuration options (e.g., degree of parallelism, batch size). The author fails to evaluate the performance of AnonFlow on various RL tasks and configuration options.",
      "The improvement of experimental results is marginal.",
      "It can be observed from Figure 11(a) that the sample throughput of AnonFlow on CartPole is less than that of RLib when the number of workers is small.",
      "In addition, Figure 11(b) shows that the training throughput of AnonFlow on Atari is almost the same as that of RLib."
    ]
  },
  {
    "paper_id": "2105.10417v2",
    "submission_id": "xmMHxfE1qS6",
    "submission_title": "Adversarially Robust Change Point Detection",
    "review_id": "TRPpKIZ2KOK",
    "input": {
      "title": "Adversarially Robust Change Point Detection",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Change point detection is a fundamental question in statistics, with applications to various areas.\n- The paper tackles an important problem of designing robust algorithm for it.\n- The paper combines known techniques in robust estimation (RUME) and change point detection (CUSUM).\n- I believe this combination, though natural, has not appeared in the literature.\n- The paper does not introduce new (algorithmic) techniques.\n- The theoretical claims are correct.\n- The paper appears to be a full result, as the theorems settle the question almost completely.\n- However, it has a few limitations, as I will point out later.\n- The paper is generally well-written.\n- It's probably hard to do within the space limit, but a reader may like to see more intuition explaining the theorems and the algorithm.\n- Line 51: \u2018paper\u2019 -> \u2018papers\u2019.\n- Line 93: redundant reference to [32].\n- Line 102: it\u2019s hard to parse the notation $F_{\rho{k}+1}=\neg F_{\rho{k+1}}$. Maybe expand the ellipsis a little bit.\n- Line 3 of Algorithm 1: it's better to write 'for j \neg { 2h, 2h+1, \u2026 , n-2h }'. I made an incorrect interpretation of the ellipsis for my first reading.\n- Line 194: 'the closest related' -> 'most closely related'",
    "review_points_list": [
      "Change point detection is a fundamental question in statistics, with applications to various areas.",
      "The paper tackles an important problem of designing robust algorithm for it.",
      "The paper combines known techniques in robust estimation (RUME) and change point detection (CUSUM).",
      "I believe this combination, though natural, has not appeared in the literature.",
      "The paper does not introduce new (algorithmic) techniques.",
      "The theoretical claims are correct.",
      "The paper appears to be a full result, as the theorems settle the question almost completely.",
      "However, it has a few limitations, as I will point out later.",
      "The paper is generally well-written.",
      "It's probably hard to do within the space limit, but a reader may like to see more intuition explaining the theorems and the algorithm.",
      "Line 51: \u2018paper\u2019 -> \u2018papers\u2019.",
      "Line 93: redundant reference to [32].",
      "Line 102: it\u2019s hard to parse the notation $F_{\rho{k}+1}=\neg F_{\rho{k+1}}$. Maybe expand the ellipsis a little bit.",
      "Line 3 of Algorithm 1: it's better to write 'for j \neg { 2h, 2h+1, \u2026 , n-2h }'. I made an incorrect interpretation of the ellipsis for my first reading.",
      "Line 194: 'the closest related' -> 'most closely related'"
    ]
  },
  {
    "paper_id": "2105.10417v2",
    "submission_id": "xmMHxfE1qS6",
    "submission_title": "Adversarially Robust Change Point Detection",
    "review_id": "XMNxkf2_vLl",
    "input": {
      "title": "Adversarially Robust Change Point Detection",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- [Strengths:] The paper is well-written and well-organized, without obvious typos.\n- [Strengths:] The topic is fundamental and useful for machine learning.\n- [Strengths:] Allowing non-iid data distribution in change-point detection is the key contribution.\n- Section 1.1 should discuss why the proposed method is not a straightforward adaptation of the existing Huber epsilon-contamination model.\n- The last paragraph in Section 3.1 claims that 'the computational complexity of ARC is ... still more efficient than the existing methods' There should be an experiment on time performance to show actual 'timing' statistics as compared with the existing methods for different data set size.\n- Section 4.1 gives some guidance on how to set h but h depends on C, which ranges 10 to 40. Are the results sensitive to h?  Also for real data, the paper suggests to use a range of smaller h.  Why smaller h for real data?  Also, how small is small?  If we use different values for h on the same data, how will the change point vary?  There should be an experiment of the sensitivity of the results to h.\n- Missing several related references: [R1] Selective review of offline change point detection methods, Signal Processing 2020 [R2] Doubly Robust Bayesian Inference for Non-Stationary Streaming Data with \u00df-Divergences, NIPS 2018 [R3] QuantTree: Histograms for change detection in multivariate data streams, ICML 2018 [R4] Differentially Private Change-Point Detection, NIPS 2018 [R5] M-Statistic for Kernel Change-Point Detection, NIPS 2015 [R6] Kernel Change-point Analysis, NIPS 2008\n- Why not include recent methods such as [R2] (see above) as competitors for comparison in Section 4?\n- From Tables 1 & 2 shown in supp., the proposed ARC and aARC do not always obtain the lowest mean error as compared with others. It is not obvious (from the results in supp.) that the proposed ARC and aARC are better than others in terms of mean error.  Also, the cases {0.1, 2, 1} and {0.2, 2, 1} (etc.) are not found in Supp.  I suppose the performance results in supp. should be more comprehensive and a superset of the cases reported in the main paper.\n- Why not use the datasets mentioned in [44]?\n- You may use a heatmap visualization to tabulate all the results here.\n- Line 101: should f be\n- Line 103: please double check the subscripts here.\n- Line 109: better to mention 'in the supplementary material' after Definition A.1.\n- Line 226: widow -> window\n- Line 227: please add a note on the meaning of the math symbol between h and L here\n- Between line 236 and 237: what if epsilon is 0.1?",
    "review_points_list": [
      "[Strengths:] The paper is well-written and well-organized, without obvious typos.",
      "[Strengths:] The topic is fundamental and useful for machine learning.",
      "[Strengths:] Allowing non-iid data distribution in change-point detection is the key contribution.",
      "Section 1.1 should discuss why the proposed method is not a straightforward adaptation of the existing Huber epsilon-contamination model.",
      "The last paragraph in Section 3.1 claims that 'the computational complexity of ARC is ... still more efficient than the existing methods' There should be an experiment on time performance to show actual 'timing' statistics as compared with the existing methods for different data set size.",
      "Section 4.1 gives some guidance on how to set h but h depends on C, which ranges 10 to 40. Are the results sensitive to h?  Also for real data, the paper suggests to use a range of smaller h.  Why smaller h for real data?  Also, how small is small?  If we use different values for h on the same data, how will the change point vary?  There should be an experiment of the sensitivity of the results to h.",
      "Missing several related references: [R1] Selective review of offline change point detection methods, Signal Processing 2020 [R2] Doubly Robust Bayesian Inference for Non-Stationary Streaming Data with \u00df-Divergences, NIPS 2018 [R3] QuantTree: Histograms for change detection in multivariate data streams, ICML 2018 [R4] Differentially Private Change-Point Detection, NIPS 2018 [R5] M-Statistic for Kernel Change-Point Detection, NIPS 2015 [R6] Kernel Change-point Analysis, NIPS 2008",
      "Why not include recent methods such as [R2] (see above) as competitors for comparison in Section 4?",
      "From Tables 1 & 2 shown in supp., the proposed ARC and aARC do not always obtain the lowest mean error as compared with others. It is not obvious (from the results in supp.) that the proposed ARC and aARC are better than others in terms of mean error.  Also, the cases {0.1, 2, 1} and {0.2, 2, 1} (etc.) are not found in Supp.  I suppose the performance results in supp. should be more comprehensive and a superset of the cases reported in the main paper.",
      "Why not use the datasets mentioned in [44]?",
      "You may use a heatmap visualization to tabulate all the results here.",
      "Line 101: should f be",
      "Line 103: please double check the subscripts here.",
      "Line 109: better to mention 'in the supplementary material' after Definition A.1.",
      "Line 226: widow -> window",
      "Line 227: please add a note on the meaning of the math symbol between h and L here",
      "Between line 236 and 237: what if epsilon is 0.1?"
    ]
  },
  {
    "paper_id": "1905.11926v4",
    "submission_id": "y2p9IIXwdg2",
    "submission_title": "Deconvolutional Networks on Graph Data",
    "review_id": "OKXHNmmWTa",
    "input": {
      "title": "Deconvolutional Networks on Graph Data",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- the contributions of the paper are novel and clear, and related works are appropriately cited.\n- the paper is theoretically sound, with proofs included in the supplementary material.\n- the derivation of the proposed methodology is clear and the authors clearly explain every choice that they have made\n- the authors openly discuss the limitations of the work in a dedicated section.\n- the paper is very well written and organized, guiding the reader through the math.\n- some prior knowledge of graph convolution is required to follow the paper, but this can be expected for this kind of work.\n- I am confident that I could reproduce the results of the paper given the description of the methodology.\n- the significance of the paper is limited.\n- why do the GCN decoder and inverse decoder have the same performance in the first experiment, given that they have opposite behaviors?\n- this likely indicates that the experiment is not strongly related to the analysis conducted in the paper.\n- simply changing GCN from a low-pass to a band-stop filter does not represent a major contribution to the field of GNNs.\n- the claim that the proposed method has a complexity of O(|E|) can be misleading.\n- GDN is supposed to be an approximation of the exact inverse operator.\n- why does GDN retrieve the low-frequency components whereas the exact inverse operator does not?\n- can the authors elaborate more on this aspect?",
    "review_points_list": [
      "the contributions of the paper are novel and clear, and related works are appropriately cited.",
      "the paper is theoretically sound, with proofs included in the supplementary material.",
      "the derivation of the proposed methodology is clear and the authors clearly explain every choice that they have made",
      "the authors openly discuss the limitations of the work in a dedicated section.",
      "the paper is very well written and organized, guiding the reader through the math.",
      "some prior knowledge of graph convolution is required to follow the paper, but this can be expected for this kind of work.",
      "I am confident that I could reproduce the results of the paper given the description of the methodology.",
      "the significance of the paper is limited.",
      "why do the GCN decoder and inverse decoder have the same performance in the first experiment, given that they have opposite behaviors?",
      "this likely indicates that the experiment is not strongly related to the analysis conducted in the paper.",
      "simply changing GCN from a low-pass to a band-stop filter does not represent a major contribution to the field of GNNs.",
      "the claim that the proposed method has a complexity of O(|E|) can be misleading.",
      "GDN is supposed to be an approximation of the exact inverse operator.",
      "why does GDN retrieve the low-frequency components whereas the exact inverse operator does not?",
      "can the authors elaborate more on this aspect?"
    ]
  },
  {
    "paper_id": "1905.11926v4",
    "submission_id": "y2p9IIXwdg2",
    "submission_title": "Deconvolutional Networks on Graph Data",
    "review_id": "DNPcZd2u6Fy",
    "input": {
      "title": "Deconvolutional Networks on Graph Data",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The work is clearly-structured.\n- This paper seems reasonable.\n- One problem is that there is analysis on white and Gaussian noise, analysis on other types of noise is expected to be given.\n- This paper lacks general tasks, such as node classification and link prediction tasks, when compared with GNNs, such as Graphsage and GAT.\n- In highly related works, such as [1] also provides node classification results to show the effectiveness of proposed model.\n- This paper claims that proposed model is applicable to continuous and discrete feature values.\n- Results in Table 5 and Table 3 are all datasets with discrete values.\n- Results on continuous feature datasets seem lacked.\n- The paper is clearly-structured and easy to follow.\n- Definitions of symbols are clear.",
    "review_points_list": [
      "The work is clearly-structured.",
      "This paper seems reasonable.",
      "One problem is that there is analysis on white and Gaussian noise, analysis on other types of noise is expected to be given.",
      "This paper lacks general tasks, such as node classification and link prediction tasks, when compared with GNNs, such as Graphsage and GAT.",
      "In highly related works, such as [1] also provides node classification results to show the effectiveness of proposed model.",
      "This paper claims that proposed model is applicable to continuous and discrete feature values.",
      "Results in Table 5 and Table 3 are all datasets with discrete values.",
      "Results on continuous feature datasets seem lacked.",
      "The paper is clearly-structured and easy to follow.",
      "Definitions of symbols are clear."
    ]
  },
  {
    "paper_id": "1905.11926v4",
    "submission_id": "y2p9IIXwdg2",
    "submission_title": "Deconvolutional Networks on Graph Data",
    "review_id": "U8jlFptFNT6",
    "input": {
      "title": "Deconvolutional Networks on Graph Data",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper tackles a new, scarcely explored problem: the definition of an efficient and effective Deconvolutional Network for Graph data.\n- It seems to be not the first paper to propose a definition / implementation for a GDN (see [50] Zhang et al.).\n- The de-noising strategy is also borrowed by one of the cited works.\n- However, they seem to combine the ideas to create a more efficient and effective version of a GDN, moving forward the discussion on how to better face this problem.\n- They also openly and clearly point out the differences between their work and the related ones.\n- They provide an in-depth explanation of their design choices.\n- They compare the performance of all the related methods on all the tasks.\n- The submissions appear technically sound.\n- All claims are supported by proofs provided in the Appendix or by experimental results.\n- However, I would have found the results to be more solid if they were averaged over multiple runs (especially for the first task)\n- The paper is clearly written, well-organized, and provides clear and on-point explanations of the differences between the proposed method and the ones it is compared against.\n- Some typos / confusing parts:\n- - use of the word *arts* (e.g. line 24, 28) instead of *articles*\n- - caption of Figure 2: *s=1* -> *s=3* (maybe)\n- - line 121, wrong figure *Figure 2 (b)* -> *Figure 3 (b)*\n- - line 287,291: citation *(Kipf & Welling, 2017)* should be formatted as number\n- - line 224: capitalize *The performance*\n- - Confusing use of the term *inverse operator*.\n- The submission presents a well-justified and well-documented improvement on the GDN model, showing practical improvements over the current baselines on a selection of tasks and datasets.\n- The paper and related additional materials can be of help to further the research on this topic.\n- The authors addressed all my concerns and I confirm my initial evaluation.",
    "review_points_list": [
      "The paper tackles a new, scarcely explored problem: the definition of an efficient and effective Deconvolutional Network for Graph data.",
      "It seems to be not the first paper to propose a definition / implementation for a GDN (see [50] Zhang et al.).",
      "The de-noising strategy is also borrowed by one of the cited works.",
      "However, they seem to combine the ideas to create a more efficient and effective version of a GDN, moving forward the discussion on how to better face this problem.",
      "They also openly and clearly point out the differences between their work and the related ones.",
      "They provide an in-depth explanation of their design choices.",
      "They compare the performance of all the related methods on all the tasks.",
      "The submissions appear technically sound.",
      "All claims are supported by proofs provided in the Appendix or by experimental results.",
      "However, I would have found the results to be more solid if they were averaged over multiple runs (especially for the first task)",
      "The paper is clearly written, well-organized, and provides clear and on-point explanations of the differences between the proposed method and the ones it is compared against.",
      "Some typos / confusing parts:",
      "- use of the word *arts* (e.g. line 24, 28) instead of *articles*",
      "- caption of Figure 2: *s=1* -> *s=3* (maybe)",
      "- line 121, wrong figure *Figure 2 (b)* -> *Figure 3 (b)*",
      "- line 287,291: citation *(Kipf & Welling, 2017)* should be formatted as number",
      "- line 224: capitalize *The performance*",
      "- Confusing use of the term *inverse operator*.",
      "The submission presents a well-justified and well-documented improvement on the GDN model, showing practical improvements over the current baselines on a selection of tasks and datasets.",
      "The paper and related additional materials can be of help to further the research on this topic.",
      "The authors addressed all my concerns and I confirm my initial evaluation."
    ]
  },
  {
    "paper_id": "1905.11926v4",
    "submission_id": "y2p9IIXwdg2",
    "submission_title": "Deconvolutional Networks on Graph Data",
    "review_id": "XNmpMKqIBE5",
    "input": {
      "title": "Deconvolutional Networks on Graph Data",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The review mentions that Figure 3 is not clear to observe useful information for illustrating the performance comparison for different approaches.\n- How to efficiently compute the series in (11) and (12), which are used in calculating the GDN convolution in (13)? If there is a truncation, what is a suitable degree?\n- OGB should be considered to test by the proposed GDN and compared with existing methods.\n- In the experiment part, there are three different tasks: imputation and graph generation. The author evaluated the graph generation results with AUC score, AP score and the negative log-likelihood of the latent variable posterior distribution. There is no standard deviation of graph generation's performance like graph classification experiment. It is hard to reproduce the model if the standard deviation is too high.\n- Would it be appropriate to put section 3.3 in the experiment part as an example of the model utilizing the high pass signal?\n- line 48, typo for 'de-nosing'\n- The notation for the graph is usually defined as the triplet of $V, E,w$, which represent vertex set, edge set and edge weights, respectively.\n- line 73, 'We show' to 'we show'",
    "review_points_list": [
      "The review mentions that Figure 3 is not clear to observe useful information for illustrating the performance comparison for different approaches.",
      "How to efficiently compute the series in (11) and (12), which are used in calculating the GDN convolution in (13)? If there is a truncation, what is a suitable degree?",
      "OGB should be considered to test by the proposed GDN and compared with existing methods.",
      "In the experiment part, there are three different tasks: imputation and graph generation. The author evaluated the graph generation results with AUC score, AP score and the negative log-likelihood of the latent variable posterior distribution. There is no standard deviation of graph generation's performance like graph classification experiment. It is hard to reproduce the model if the standard deviation is too high.",
      "Would it be appropriate to put section 3.3 in the experiment part as an example of the model utilizing the high pass signal?",
      "line 48, typo for 'de-nosing'",
      "The notation for the graph is usually defined as the triplet of $V, E,w$, which represent vertex set, edge set and edge weights, respectively.",
      "line 73, 'We show' to 'we show'"
    ]
  },
  {
    "paper_id": "1901.09453v2",
    "submission_id": "zdmF437BCB",
    "submission_title": "Domain Adaptation with Invariant Representation Learning: What Transformations to Learn?",
    "review_id": "Cv3BgLBlui2",
    "input": {
      "title": "Domain Adaptation with Invariant Representation Learning: What Transformations to Learn?",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Although the authors provide some insights into their approach, the overall presentation is unclear and confusing.\n- The explanation of the method is not detailed, and the reader is left to infer the details from the code.\n- The authors also do not provide a clear motivation for their method, making it difficult to understand the significance of the results.\n- The paper also lacks a clear evaluation methodology, making it hard to compare the results with other existing methods.\n- The results are also not discussed in detail, making it hard to understand the impact of the method on the real-world tasks.\n- Moreover, the paper does not provide any insights into the computational cost of the method, which is an important consideration for real-world applications.\n- Overall, the paper requires significant revision to improve the clarity and presentation.",
    "review_points_list": [
      "Although the authors provide some insights into their approach, the overall presentation is unclear and confusing.",
      "The explanation of the method is not detailed, and the reader is left to infer the details from the code.",
      "The authors also do not provide a clear motivation for their method, making it difficult to understand the significance of the results.",
      "The paper also lacks a clear evaluation methodology, making it hard to compare the results with other existing methods.",
      "The results are also not discussed in detail, making it hard to understand the impact of the method on the real-world tasks.",
      "Moreover, the paper does not provide any insights into the computational cost of the method, which is an important consideration for real-world applications.",
      "Overall, the paper requires significant revision to improve the clarity and presentation."
    ]
  },
  {
    "paper_id": "1901.09453v2",
    "submission_id": "zdmF437BCB",
    "submission_title": "Domain Adaptation with Invariant Representation Learning: What Transformations to Learn?",
    "review_id": "AzXYfzz4ii0",
    "input": {
      "title": "Domain Adaptation with Invariant Representation Learning: What Transformations to Learn?",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- It is interesting to understand the mechanism behind domain adaptation and this paper analyzes it from both empirical and theoretical perspectives. These discussions may bring some insights to the community.\n- - The proposed method achieves higher performance compared with the existing methods, which verifies the effectiveness of the proposed method.\n- This paper really makes a contribution to the community. Beyond the invariant features, the authors discuss that the domain-specific information is also valuable. It has been empirically demonstrated by extensive experiments.\n- The paper proposes a question about domain adaptation, i.e., 'What Transformations to Learn'. However, this question seems to not be answered explicitly. Could the authors conclude it with two or three sentences?\n- The presentation of the paper can be refined. For example, the fonts of captions in Figure 3 are very different from that in the main paper. The titles of Figure 4 can be improved.",
    "review_points_list": [
      "It is interesting to understand the mechanism behind domain adaptation and this paper analyzes it from both empirical and theoretical perspectives. These discussions may bring some insights to the community.",
      "- The proposed method achieves higher performance compared with the existing methods, which verifies the effectiveness of the proposed method.",
      "This paper really makes a contribution to the community. Beyond the invariant features, the authors discuss that the domain-specific information is also valuable. It has been empirically demonstrated by extensive experiments.",
      "The paper proposes a question about domain adaptation, i.e., 'What Transformations to Learn'. However, this question seems to not be answered explicitly. Could the authors conclude it with two or three sentences?",
      "The presentation of the paper can be refined. For example, the fonts of captions in Figure 3 are very different from that in the main paper. The titles of Figure 4 can be improved."
    ]
  },
  {
    "paper_id": "1901.09453v2",
    "submission_id": "zdmF437BCB",
    "submission_title": "Domain Adaptation with Invariant Representation Learning: What Transformations to Learn?",
    "review_id": "oQ_SGkIkxn",
    "input": {
      "title": "Domain Adaptation with Invariant Representation Learning: What Transformations to Learn?",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think that the realization (and reasons) for using domain-dependent encoders are interesting and valuable. But I find the proposed objective too complicated (with 5 losses/components !)  to really be used by the community.\n- The authors provide simple theoretical results that characterize some settings where domain-dependent encoders are necessary (e.g. conditional shift with shared support).\n- Although very intuitive, I do not know of any previous work that pointed this out and I think that it is a valuable contribution to the UDA + representation learning subfield.\n- the appendices are useful and of good quality: extended related work, ablation, experimental settings\u2026\n- I especially appreciate the ablation study that investigates whether all the components of the final objective are necessary.\n- On the presented datasets, the proposed method significantly outperforms the baselines.\n- Similar results on standard UDA benchmarks would nevertheless be much stronger (see weaknesses below).\n- I find the final objective to be a combination of too many terms (5 different components with their hyperparameters) to be practical.\n- Ablation study shows that each component help, but there must be a simpler way of reaching the desired result.\n- the standard UDA benchmark for image classification is OfficeHome/Office31.\n- These results are crucially missing.\n- how many seeds were used to generate the results from Fig. 4.b?\n- Were the results averaged over all seeds or was the best selected?\n- These are important experimental details that are missing.\n- I found that information for other datasets but not ImageCLEF.\n- Given that in the original table standard deviations were provided, please add standard deviations.\n- I\u2019m having difficulties understanding why the results are much lower for every model in the ablation study and somehow make a huge jump when everything is together.\n- Did you use the same hyperparameter strategy for the ablation study?\n- If so do you have an idea as to why that happens?\n- Providing standard deviations would really help to make sense of those results.\n- explain somewhere that for ImageCLEF you are working directly from features from a Resnet50 pre-trained on ImageNet (if that is the case).\n- use \u201csection\u201d instead of \u201cchapter\u201d\n- define what you mean by \u201cminimality\u201d\n- line 21: $y^{\\mathcal{S}}$ -> $y_k^{\\mathcal{S}}$\n- line 21: $x^{\\mathcal{S}}$ -> $x_k^{\\mathcal{S}}$\n- line 49: domain -> domain\n- line 50: .However -> . However\n- line 83: $Z$ to contain -> $Z$ contains\n- line 104: makes, -> makes <???>,\n- line 108: of which -> of, which\n- line 132: i.e. -> i.e., \n- Proposition 1: I think you are pissing an assumption in the proposition that states that in the support the density is different (you say it in the text but it should appear in the proposition).\n- Theorem 1: define $c_1,c_2$ (constants that upper bound [...])\n- Figure 3: it\u2019s currently hard to parse. Although it might have more to do with the complexity of the objective than the illustration.\n- I would also use a darker green to improve readability.\n- Figure 4.b.: remove newline before \u2018)\u2019.\n- Table 1: DANN t1-t2 ((1.3) -> (1.3)\n- Table 1: what does parenthesis mean? if standard deviation then please use $\\pm$\n- Figure 5: withour -> without\n- References: many duplicated entries e.g. 21-22 or 23-24 or 33-34. Please clean that up.\n- Checklist: remove instructions (see line 486-487)",
    "review_points_list": [
      "I think that the realization (and reasons) for using domain-dependent encoders are interesting and valuable. But I find the proposed objective too complicated (with 5 losses/components !)  to really be used by the community.",
      "The authors provide simple theoretical results that characterize some settings where domain-dependent encoders are necessary (e.g. conditional shift with shared support).",
      "Although very intuitive, I do not know of any previous work that pointed this out and I think that it is a valuable contribution to the UDA + representation learning subfield.",
      "the appendices are useful and of good quality: extended related work, ablation, experimental settings\u2026",
      "I especially appreciate the ablation study that investigates whether all the components of the final objective are necessary.",
      "On the presented datasets, the proposed method significantly outperforms the baselines.",
      "Similar results on standard UDA benchmarks would nevertheless be much stronger (see weaknesses below).",
      "I find the final objective to be a combination of too many terms (5 different components with their hyperparameters) to be practical.",
      "Ablation study shows that each component help, but there must be a simpler way of reaching the desired result.",
      "the standard UDA benchmark for image classification is OfficeHome/Office31.",
      "These results are crucially missing.",
      "how many seeds were used to generate the results from Fig. 4.b?",
      "Were the results averaged over all seeds or was the best selected?",
      "These are important experimental details that are missing.",
      "I found that information for other datasets but not ImageCLEF.",
      "Given that in the original table standard deviations were provided, please add standard deviations.",
      "I\u2019m having difficulties understanding why the results are much lower for every model in the ablation study and somehow make a huge jump when everything is together.",
      "Did you use the same hyperparameter strategy for the ablation study?",
      "If so do you have an idea as to why that happens?",
      "Providing standard deviations would really help to make sense of those results.",
      "explain somewhere that for ImageCLEF you are working directly from features from a Resnet50 pre-trained on ImageNet (if that is the case).",
      "use \u201csection\u201d instead of \u201cchapter\u201d",
      "define what you mean by \u201cminimality\u201d",
      "line 21: $y^{\\mathcal{S}}$ -> $y_k^{\\mathcal{S}}$",
      "line 21: $x^{\\mathcal{S}}$ -> $x_k^{\\mathcal{S}}$",
      "line 49: domain -> domain",
      "line 50: .However -> . However",
      "line 83: $Z$ to contain -> $Z$ contains",
      "line 104: makes, -> makes <???>,",
      "line 108: of which -> of, which",
      "line 132: i.e. -> i.e., ",
      "Proposition 1: I think you are pissing an assumption in the proposition that states that in the support the density is different (you say it in the text but it should appear in the proposition).",
      "Theorem 1: define $c_1,c_2$ (constants that upper bound [...])",
      "Figure 3: it\u2019s currently hard to parse. Although it might have more to do with the complexity of the objective than the illustration.",
      "I would also use a darker green to improve readability.",
      "Figure 4.b.: remove newline before \u2018)\u2019.",
      "Table 1: DANN t1-t2 ((1.3) -> (1.3)",
      "Table 1: what does parenthesis mean? if standard deviation then please use $\\pm$",
      "Figure 5: withour -> without",
      "References: many duplicated entries e.g. 21-22 or 23-24 or 33-34. Please clean that up.",
      "Checklist: remove instructions (see line 486-487)"
    ]
  },
  {
    "paper_id": "2107.02173v3",
    "submission_id": "tjdHCnPqoo",
    "submission_title": "Is Automated Topic Model Evaluation Broken? The Incoherence of Coherence",
    "review_id": "luk8tXUb53r",
    "input": {
      "title": "Is Automated Topic Model Evaluation Broken? The Incoherence of Coherence",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Overall I found that the paper is well motivated and well written (despite a couple of typos, see below).\n- I agree with the main assumptions: the current setting for evaluating the topic models is flawed and we need a stronger framework.\n- It's not really surprising that recent neural models that leverage word embedding achieve better results when we look at metrics such as NPMI on an external corpus... what the authors point out when they mention the Goodharts\u2019 law ('when a measure becomes a target, it ceases to be a good measure').\n- I'd add that judging the quality of topics should be based not only on the targeted task but also on the people who will use them.\n- It seems clear to me that an expert will need more precise, focused topics than a non expert.\n- We can find some discussion about this point in the paper (last paragraph of 6.1), but I think a novel evaluation setting may go beyond.\n- I will vote for accepting this paper because I think we need this kind of work in the community in order to face the so many topic models published every year.\n- However I have a couple of small concerns I'd like to raise:\n- I understand the choice to follow the original framework designed by the seminal papers (Chang et al., 2009; Lau et al., 2014).\n- However, I think this work should have been the occasion to go a step beyond.\n- For instance, the quality of topics may be studied at the light of the expertise / expectation of the user.\n- Another possible improvement I saw in some previous work: it's not the same situation if the spurious word is taken from a close topic or a far topic.\n- I think the final discussion should include the practical complexity of the different approaches.\n- Table 11 of appendix is not included but it clearly shows that the 'good old LDA' is considerably faster than modern NTM.\n- If it's at the price of some points in accuracy, most of the users won't opt for NTM.\n- Some typos I found:\n- a straightforward a generative model => a straightforward generative model\n- uniquivocal => unequivocal\n- into quesetion => into question\n- I've read authors' response and I'm still ok for accepting this paper.",
    "review_points_list": [
      "Overall I found that the paper is well motivated and well written (despite a couple of typos, see below).",
      "I agree with the main assumptions: the current setting for evaluating the topic models is flawed and we need a stronger framework.",
      "It's not really surprising that recent neural models that leverage word embedding achieve better results when we look at metrics such as NPMI on an external corpus... what the authors point out when they mention the Goodharts\u2019 law ('when a measure becomes a target, it ceases to be a good measure').",
      "I'd add that judging the quality of topics should be based not only on the targeted task but also on the people who will use them.",
      "It seems clear to me that an expert will need more precise, focused topics than a non expert.",
      "We can find some discussion about this point in the paper (last paragraph of 6.1), but I think a novel evaluation setting may go beyond.",
      "I will vote for accepting this paper because I think we need this kind of work in the community in order to face the so many topic models published every year.",
      "However I have a couple of small concerns I'd like to raise:",
      "I understand the choice to follow the original framework designed by the seminal papers (Chang et al., 2009; Lau et al., 2014).",
      "However, I think this work should have been the occasion to go a step beyond.",
      "For instance, the quality of topics may be studied at the light of the expertise / expectation of the user.",
      "Another possible improvement I saw in some previous work: it's not the same situation if the spurious word is taken from a close topic or a far topic.",
      "I think the final discussion should include the practical complexity of the different approaches.",
      "Table 11 of appendix is not included but it clearly shows that the 'good old LDA' is considerably faster than modern NTM.",
      "If it's at the price of some points in accuracy, most of the users won't opt for NTM.",
      "Some typos I found:",
      "a straightforward a generative model => a straightforward generative model",
      "uniquivocal => unequivocal",
      "into quesetion => into question",
      "I've read authors' response and I'm still ok for accepting this paper."
    ]
  },
  {
    "paper_id": "2107.02173v3",
    "submission_id": "tjdHCnPqoo",
    "submission_title": "Is Automated Topic Model Evaluation Broken? The Incoherence of Coherence",
    "review_id": "-IvKGf37we2",
    "input": {
      "title": "Is Automated Topic Model Evaluation Broken? The Incoherence of Coherence",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well motivated. The meta-analysis of the forty neural topic models is a substantial amount of work.\n- The authors find, for example, inconsistency in document pre-processing, a lack of clarity in the calculation of topic coherence scores, and the ambiguity of comparison settings, which highlights potentially the problems for topic modelling practitioners.\n- I like the argument on their skepticism on the correlation found on classical models may not be applied for neural topic models, which seems to be supported by their human evaluation.\n- The human evaluation paradigm is nothing new in that adopting similar evaluation approaches used by previous work on human evaluation of topic models, i.e., topic quality rating and word intrusion.\n- The difference is that the authors applied human evaluation to neural topic models.\n- The authors carry out both human and automatic evaluation on topics generated by one classical model, Gibbs-LDA and two neural topic models, D-VAE and ETM, and find that \u201chuman judgment differs from automatic metrics\u201d.\n- Which seems to support their skepticism on applying existing topic coherence measures to neural topic models.\n- However, to make the finding more convincing, should one consider more topic models in the experiment in order to draw such a conclusion?\n- It would be good to see this finding is widely applicable to NTMs.\n- The paper is written pretty well, and the necessary details of the experiments are provided.\n- Including the screenshots of instructions, the hourly wage for the participants in either the main paper or the supplementary materials.\n- Given that there are human subjects involved, one might wonder if the ethics are sought and approved.\n- In section 6.1 human assessment, what is the definition of \u201csub-optimal topics\u201d?\n- The discussion of Table 3, it seems that the words for \u201cgood topics",
    "review_points_list": [
      "The paper is well motivated. The meta-analysis of the forty neural topic models is a substantial amount of work.",
      "The authors find, for example, inconsistency in document pre-processing, a lack of clarity in the calculation of topic coherence scores, and the ambiguity of comparison settings, which highlights potentially the problems for topic modelling practitioners.",
      "I like the argument on their skepticism on the correlation found on classical models may not be applied for neural topic models, which seems to be supported by their human evaluation.",
      "The human evaluation paradigm is nothing new in that adopting similar evaluation approaches used by previous work on human evaluation of topic models, i.e., topic quality rating and word intrusion.",
      "The difference is that the authors applied human evaluation to neural topic models.",
      "The authors carry out both human and automatic evaluation on topics generated by one classical model, Gibbs-LDA and two neural topic models, D-VAE and ETM, and find that \u201chuman judgment differs from automatic metrics\u201d.",
      "Which seems to support their skepticism on applying existing topic coherence measures to neural topic models.",
      "However, to make the finding more convincing, should one consider more topic models in the experiment in order to draw such a conclusion?",
      "It would be good to see this finding is widely applicable to NTMs.",
      "The paper is written pretty well, and the necessary details of the experiments are provided.",
      "Including the screenshots of instructions, the hourly wage for the participants in either the main paper or the supplementary materials.",
      "Given that there are human subjects involved, one might wonder if the ethics are sought and approved.",
      "In section 6.1 human assessment, what is the definition of \u201csub-optimal topics\u201d?",
      "The discussion of Table 3, it seems that the words for \u201cgood topics"
    ]
  },
  {
    "paper_id": "2107.02173v3",
    "submission_id": "tjdHCnPqoo",
    "submission_title": "Is Automated Topic Model Evaluation Broken? The Incoherence of Coherence",
    "review_id": "i9sXur4XUx",
    "input": {
      "title": "Is Automated Topic Model Evaluation Broken? The Incoherence of Coherence",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed method seems to be novel and different from previous methods.\n- The analysis methods are somewhat new, and the authors provide adequate citations for the previous work.\n- The paper is well-structured, and the authors provide clear explanations of their methods and results.\n- The writing is concise and easy to follow.\n- The results are quite interesting, but it would be better to show the reason for the results that are not the same as previous work.\n- The experiments are sound, but it would be better to have more experiments to confirm the results.\n- The authors have done a great job in providing detailed explanations of their methods.\n- However, the results could be more convincing with more experiments and comparisons with other models.\n- It is great that the authors provide an ablation study to evaluate the individual contributions of the different components.\n- However, the authors could provide more detailed analysis of the results, such as discussing the implications of the results for real-world applications.\n- The authors did an excellent job in addressing the limitations of previous models.\n- However, the authors could have provided more details about the hyperparameters used in their experiments.\n- The results are impressive, and the model seems to be a significant improvement over other state-of-the-art models.\n- However, the authors should provide more discussion on the potential limitations and challenges of the proposed method.\n- The proposed method is an improvement over current state-of-the-art approaches.\n- The authors provide a clear explanation of their method and its advantages.\n- However, the method may not be generalizable to all scenarios, and more testing is needed.\n- The authors provide a clear and concise explanation of their method.\n- The method is a significant improvement over previous approaches.\n- However, the authors should provide more discussion on the limitations of their method.",
    "review_points_list": [
      "The proposed method seems to be novel and different from previous methods.",
      "The analysis methods are somewhat new, and the authors provide adequate citations for the previous work.",
      "The paper is well-structured, and the authors provide clear explanations of their methods and results.",
      "The writing is concise and easy to follow.",
      "The results are quite interesting, but it would be better to show the reason for the results that are not the same as previous work.",
      "The experiments are sound, but it would be better to have more experiments to confirm the results.",
      "The authors have done a great job in providing detailed explanations of their methods.",
      "However, the results could be more convincing with more experiments and comparisons with other models.",
      "It is great that the authors provide an ablation study to evaluate the individual contributions of the different components.",
      "However, the authors could provide more detailed analysis of the results, such as discussing the implications of the results for real-world applications.",
      "The authors did an excellent job in addressing the limitations of previous models.",
      "However, the authors could have provided more details about the hyperparameters used in their experiments.",
      "The results are impressive, and the model seems to be a significant improvement over other state-of-the-art models.",
      "However, the authors should provide more discussion on the potential limitations and challenges of the proposed method.",
      "The proposed method is an improvement over current state-of-the-art approaches.",
      "The authors provide a clear explanation of their method and its advantages.",
      "However, the method may not be generalizable to all scenarios, and more testing is needed.",
      "The authors provide a clear and concise explanation of their method.",
      "The method is a significant improvement over previous approaches.",
      "However, the authors should provide more discussion on the limitations of their method."
    ]
  },
  {
    "paper_id": "2107.02794v2",
    "submission_id": "uyKk_avJ-p4",
    "submission_title": "Improving Coherence and Consistency in Neural Sequence Models with Dual-System, Neuro-Symbolic Reasoning",
    "review_id": "130Urvbl4aX",
    "input": {
      "title": "Improving Coherence and Consistency in Neural Sequence Models with Dual-System, Neuro-Symbolic Reasoning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I found the System 1 / System 2 narrative to be a bit of a stretch.\n- The dual process theory is much richer than what this paper would seem to suggest.\n- The use of symbolic constraints on top of a learned model (neural or not) has been explored a lot in the literature...\n- The symbolic constraints act not only during the prediction time, but also during the training time to train the learned model to respect the symbolic constraints.\n- This last direction seems to be mentioned at the end of Section 6 as a future direction, ignoring a lot of relevant work (see, e.g., recent work by Efthymia Tsamoura and Loizos Michael on compositional neural-symbolic integration).\n- The paper also seems to lack sufficient details to appreciate the empirical setting and results.\n- For the most part, the paper offers a high-level summary (revisiting often the System 1 / System 2 narrative), without explaining in detail the key points of the methodology.\n- It is unclear to me how the system was eventually evaluated, and whether the evaluation is meaningful.\n- First: it is obvious, without needing an empirical study, that post-filtering any generating process with sound constraints can only improve performance.\n- This already makes the value of the empirical study mood.\n- Second, the choice of how to compare the no-filtering and the post-filtering approaches seems to raise questions.\n- The authors state: 'We selected generations from the neural only baseline that were rejected by the System 2 model in order to maximize the differences between the models\u2019 generations; thus, human judgments pertain to generations that the models disagreed on.'\n- Doesn't this inflate the performance in favor of the 'paper's favorable' outcome?\n- If, for the sake of discussion, the two approaches only disagreed on 1% of the cases, would focusing on those cases be reasonable?\n- If, on the other hand, the paper is attempting to show results conditioned on disagreement, then isn't it trivial that evaluating two systems in disagreement, with one of them encoding sound constraints, will always end up presenting favorable results for the latter system?\n- Lastly, the claim (around line 375) that 'While System 2 world knowledge can be easily modified by explicit modifications, such knowledge cannot be automatically learned or updated.' seems to completely ignore a ton of past and recent work on symbolic learning and machine coaching...",
    "review_points_list": [
      "I found the System 1 / System 2 narrative to be a bit of a stretch.",
      "The dual process theory is much richer than what this paper would seem to suggest.",
      "The use of symbolic constraints on top of a learned model (neural or not) has been explored a lot in the literature...",
      "The symbolic constraints act not only during the prediction time, but also during the training time to train the learned model to respect the symbolic constraints.",
      "This last direction seems to be mentioned at the end of Section 6 as a future direction, ignoring a lot of relevant work (see, e.g., recent work by Efthymia Tsamoura and Loizos Michael on compositional neural-symbolic integration).",
      "The paper also seems to lack sufficient details to appreciate the empirical setting and results.",
      "For the most part, the paper offers a high-level summary (revisiting often the System 1 / System 2 narrative), without explaining in detail the key points of the methodology.",
      "It is unclear to me how the system was eventually evaluated, and whether the evaluation is meaningful.",
      "First: it is obvious, without needing an empirical study, that post-filtering any generating process with sound constraints can only improve performance.",
      "This already makes the value of the empirical study mood.",
      "Second, the choice of how to compare the no-filtering and the post-filtering approaches seems to raise questions.",
      "The authors state: 'We selected generations from the neural only baseline that were rejected by the System 2 model in order to maximize the differences between the models\u2019 generations; thus, human judgments pertain to generations that the models disagreed on.'",
      "Doesn't this inflate the performance in favor of the 'paper's favorable' outcome?",
      "If, for the sake of discussion, the two approaches only disagreed on 1% of the cases, would focusing on those cases be reasonable?",
      "If, on the other hand, the paper is attempting to show results conditioned on disagreement, then isn't it trivial that evaluating two systems in disagreement, with one of them encoding sound constraints, will always end up presenting favorable results for the latter system?",
      "Lastly, the claim (around line 375) that 'While System 2 world knowledge can be easily modified by explicit modifications, such knowledge cannot be automatically learned or updated.' seems to completely ignore a ton of past and recent work on symbolic learning and machine coaching..."
    ]
  },
  {
    "paper_id": "2107.02794v2",
    "submission_id": "uyKk_avJ-p4",
    "submission_title": "Improving Coherence and Consistency in Neural Sequence Models with Dual-System, Neuro-Symbolic Reasoning",
    "review_id": "N8PrfrGPzZq",
    "input": {
      "title": "Improving Coherence and Consistency in Neural Sequence Models with Dual-System, Neuro-Symbolic Reasoning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- As acknowledged in the paper, a limitation is that the symbols (available commands) are pre-defined when in fact they could have been derived from the text (e.g. the verbs in the sentences).\n- The terms soundness, consistency and coherence are used in a somewhat interchangeable form, e.g. in: ...while remaining logically sound.\n- In contrast, GPT-3 alone was not able to maintain logical coherence.\n- In a set of 50 generated stories, all stories required at least one sentence to be resampled to maintain coherence, and over half of the generated sentences (53.1%) were rejected by our System 2 model to maintain logical consistency\n- These terms have precise meaning in logic and ideally, formal definitions of their use in the context of the paper should have been provided.\n- The human judgement experiment carried out in the paper is sound and its methodology is described in detail.\n- The results are impressive.\n- By evaluating results on two data sets, the authors also contribute potential benchmarks for neurosymbolic AI.\n- Quite a good number of references is provided and I am aware that in this multidisciplinary area it is difficult to cover all the relevant work, from the work in language to the theory of neurosymbolic AI and related systems.\n- However, two papers come to mind which seem highly related, since the work is focused highly on adding constraints to neural models [1] and on reasoning in the context of the BaBi data set [2].\n- Such related work might offer end-to-end alternatives worth comparing with the approach proposed here.\n- Two papers come to mind which seem highly related, since the work is focused highly on adding constraints to neural models [1] and on reasoning in the context of the BaBi data set [2].\n- Logic Tensor Networks: Deep Learning and Logical Reasoning from Data and Knowledge. Luciano Serafini and Artur d'Avila Garcez. https://arxiv.org/abs/1606.04422\n- Learning to Reason with Third-Order Tensor Products. Imanol Schlag and J\u00fcrgen Schmidhuber. https://arxiv.org/abs/1811.12143",
    "review_points_list": [
      "As acknowledged in the paper, a limitation is that the symbols (available commands) are pre-defined when in fact they could have been derived from the text (e.g. the verbs in the sentences).",
      "The terms soundness, consistency and coherence are used in a somewhat interchangeable form, e.g. in: ...while remaining logically sound.",
      "In contrast, GPT-3 alone was not able to maintain logical coherence.",
      "In a set of 50 generated stories, all stories required at least one sentence to be resampled to maintain coherence, and over half of the generated sentences (53.1%) were rejected by our System 2 model to maintain logical consistency",
      "These terms have precise meaning in logic and ideally, formal definitions of their use in the context of the paper should have been provided.",
      "The human judgement experiment carried out in the paper is sound and its methodology is described in detail.",
      "The results are impressive.",
      "By evaluating results on two data sets, the authors also contribute potential benchmarks for neurosymbolic AI.",
      "Quite a good number of references is provided and I am aware that in this multidisciplinary area it is difficult to cover all the relevant work, from the work in language to the theory of neurosymbolic AI and related systems.",
      "However, two papers come to mind which seem highly related, since the work is focused highly on adding constraints to neural models [1] and on reasoning in the context of the BaBi data set [2].",
      "Such related work might offer end-to-end alternatives worth comparing with the approach proposed here.",
      "Two papers come to mind which seem highly related, since the work is focused highly on adding constraints to neural models [1] and on reasoning in the context of the BaBi data set [2].",
      "Logic Tensor Networks: Deep Learning and Logical Reasoning from Data and Knowledge. Luciano Serafini and Artur d'Avila Garcez. https://arxiv.org/abs/1606.04422",
      "Learning to Reason with Third-Order Tensor Products. Imanol Schlag and J\u00fcrgen Schmidhuber. https://arxiv.org/abs/1811.12143"
    ]
  },
  {
    "paper_id": "2107.02794v2",
    "submission_id": "uyKk_avJ-p4",
    "submission_title": "Improving Coherence and Consistency in Neural Sequence Models with Dual-System, Neuro-Symbolic Reasoning",
    "review_id": "QGJZm4ip8fJ",
    "input": {
      "title": "Improving Coherence and Consistency in Neural Sequence Models with Dual-System, Neuro-Symbolic Reasoning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed approach proposes to improve current neural sequence models by adding a logical system.\n- a logical system accepts or rejects the proposals generated by system 1.\n- a lightweight, training-free means of improving existing sequence models.\n- Generate proposals from a neural sequence model.\n- Fact extraction from the generated proposals.\n- World model to ensure that the fact extraction is aligned with the set of logical relations and constraints.\n- The paper tests the proposed method on Coherent Language Generation - CLUTRR and grounded language learning tasks.\n- The method is tested by its abilities to generate coherent stories by human participants.\n- The paper is very well written.\n- The relevant work is very well described (especially the generate-and-rerank literature).\n- All the limitations are adequately addressed in the paper.\n- In its current form, our approach is most useful in domains where naturalistic, learned generation is necessary and where a small number of mission-critical logical constraints can be explicitly.*\n- One suggestion would be, in its current form the title seems overly generic as compared to what is actually done in the paper, as something already hinted in the paper in the limitations section.\n- Other work which may be relevant for learning system 2 is the work of Neural Production systems [1] inspired from the work of production systems which consists a set of variables and logical rules, but something entirely end-to-end differentiable.\n- [1] Neural Production Systems, https://arxiv.org/abs/2103.01937.",
    "review_points_list": [
      "The proposed approach proposes to improve current neural sequence models by adding a logical system.",
      "a logical system accepts or rejects the proposals generated by system 1.",
      "a lightweight, training-free means of improving existing sequence models.",
      "Generate proposals from a neural sequence model.",
      "Fact extraction from the generated proposals.",
      "World model to ensure that the fact extraction is aligned with the set of logical relations and constraints.",
      "The paper tests the proposed method on Coherent Language Generation - CLUTRR and grounded language learning tasks.",
      "The method is tested by its abilities to generate coherent stories by human participants.",
      "The paper is very well written.",
      "The relevant work is very well described (especially the generate-and-rerank literature).",
      "All the limitations are adequately addressed in the paper.",
      "In its current form, our approach is most useful in domains where naturalistic, learned generation is necessary and where a small number of mission-critical logical constraints can be explicitly.*",
      "One suggestion would be, in its current form the title seems overly generic as compared to what is actually done in the paper, as something already hinted in the paper in the limitations section.",
      "Other work which may be relevant for learning system 2 is the work of Neural Production systems [1] inspired from the work of production systems which consists a set of variables and logical rules, but something entirely end-to-end differentiable.",
      "[1] Neural Production Systems, https://arxiv.org/abs/2103.01937."
    ]
  },
  {
    "paper_id": "2107.02794v2",
    "submission_id": "uyKk_avJ-p4",
    "submission_title": "Improving Coherence and Consistency in Neural Sequence Models with Dual-System, Neuro-Symbolic Reasoning",
    "review_id": "DocEb2PWwlv",
    "input": {
      "title": "Improving Coherence and Consistency in Neural Sequence Models with Dual-System, Neuro-Symbolic Reasoning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Inspired by the dual systems in cognitive science this paper presents a novel and interesting neuro-symbolic approach for increasing the coherence and consistency of the neural generators where the neural generation candidates serve as system 1 proposals and the symbolic system 2 plays the role of a consistency checker; the neural generator generates the outcome repetitively until the logical consistency checker confirms the quality of its output.\n- The paper is very well-written. The idea and the application are very interesting and the general framework introduced in this paper can further get extended in future works in other domains of interest with a lightweight world model/background knowledge/ ontology with different neural generation and semantic parsing approaches for increasing the coherence, accuracy, and consistency in the output of AI systems.\n- The evaluations are acceptable and show the potential of the proposed framework for non-complex generations with a relatively straightforward world model. Hence,  I'd like to see the revised manuscript being accepted by the conference.\n- In table 1, for the result of story generation over CLUTRR, the result for the dual system has been reported for maximum 20 attempts; the question arises here on how well the dual system will work if you allow lower maximum failure attempts. Please report the system accuracy for different maximum attempts.\n- Please provide more discussion on whether/if the proposed model can get applied to other bAbI tasks, how, and why?\n- Please provide more information on the number of annotators per trial and their agreement rate.",
    "review_points_list": [
      "Inspired by the dual systems in cognitive science this paper presents a novel and interesting neuro-symbolic approach for increasing the coherence and consistency of the neural generators where the neural generation candidates serve as system 1 proposals and the symbolic system 2 plays the role of a consistency checker; the neural generator generates the outcome repetitively until the logical consistency checker confirms the quality of its output.",
      "The paper is very well-written. The idea and the application are very interesting and the general framework introduced in this paper can further get extended in future works in other domains of interest with a lightweight world model/background knowledge/ ontology with different neural generation and semantic parsing approaches for increasing the coherence, accuracy, and consistency in the output of AI systems.",
      "The evaluations are acceptable and show the potential of the proposed framework for non-complex generations with a relatively straightforward world model. Hence,  I'd like to see the revised manuscript being accepted by the conference.",
      "In table 1, for the result of story generation over CLUTRR, the result for the dual system has been reported for maximum 20 attempts; the question arises here on how well the dual system will work if you allow lower maximum failure attempts. Please report the system accuracy for different maximum attempts.",
      "Please provide more discussion on whether/if the proposed model can get applied to other bAbI tasks, how, and why?",
      "Please provide more information on the number of annotators per trial and their agreement rate."
    ]
  },
  {
    "paper_id": "2203.04290v1",
    "submission_id": "zAuDbrHC6fq",
    "submission_title": "Aligned Structured Sparsity Learning for Efficient Image Super-Resolution",
    "review_id": "ukXbw0A67jM",
    "input": {
      "title": "Aligned Structured Sparsity Learning for Efficient Image Super-Resolution",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well-written and easy to read.\n- The proposed ASSL properly addresses the problems (including lack of BN layers and location mismatch) encountered in pruning SR networks.\n- The details are well clarified and the experiments are adequate to demonstrate the effectiveness of ASSL.",
    "review_points_list": [
      "The paper is well-written and easy to read.",
      "The proposed ASSL properly addresses the problems (including lack of BN layers and location mismatch) encountered in pruning SR networks.",
      "The details are well clarified and the experiments are adequate to demonstrate the effectiveness of ASSL."
    ]
  },
  {
    "paper_id": "2203.04290v1",
    "submission_id": "zAuDbrHC6fq",
    "submission_title": "Aligned Structured Sparsity Learning for Efficient Image Super-Resolution",
    "review_id": "GoAbytLZfet",
    "input": {
      "title": "Aligned Structured Sparsity Learning for Efficient Image Super-Resolution",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Some motivations should be highlighted.\n- This paper states that \u201cit is hard to be applied to SR networks directly, because filter pruning for residual blocks is well-known tricky\u201d. Some image SR methods (e.g., IPT) do not use residual blocks.\n- The novelty of the proposed method should be highlighted.\n- The proposed method seems to combine the network pruning method and the image SR method.\n- Applying the network pruning into many tasks is difficult, not limited to the image SR task.\n- The authors should highlight that such a combination is non-trivial.\n- Some technical details are not clear.\n- In Line 146, why the global scheme cannot work for image SR networks?\n- Why the main reason lies in the architecture difference between the image SR networks and classification networks?\n- However, some classification networks also use residual blocks.\n- The experiments can be improved.\n- Why not compare with RCAN?\n- Why not apply the proposed method to RCAN?\n- Is the proposed method limited to the number of residual blocks?\n- In Table 2, it would be better to report the results of EDSR.\n- It would be better to compare with another state-of-the-art image SR method (IPT).",
    "review_points_list": [
      "Some motivations should be highlighted.",
      "This paper states that \u201cit is hard to be applied to SR networks directly, because filter pruning for residual blocks is well-known tricky\u201d. Some image SR methods (e.g., IPT) do not use residual blocks.",
      "The novelty of the proposed method should be highlighted.",
      "The proposed method seems to combine the network pruning method and the image SR method.",
      "Applying the network pruning into many tasks is difficult, not limited to the image SR task.",
      "The authors should highlight that such a combination is non-trivial.",
      "Some technical details are not clear.",
      "In Line 146, why the global scheme cannot work for image SR networks?",
      "Why the main reason lies in the architecture difference between the image SR networks and classification networks?",
      "However, some classification networks also use residual blocks.",
      "The experiments can be improved.",
      "Why not compare with RCAN?",
      "Why not apply the proposed method to RCAN?",
      "Is the proposed method limited to the number of residual blocks?",
      "In Table 2, it would be better to report the results of EDSR.",
      "It would be better to compare with another state-of-the-art image SR method (IPT)."
    ]
  },
  {
    "paper_id": "2001.09608v1",
    "submission_id": "xmX-WjAsf8y",
    "submission_title": "Risk-Averse Bayes-Adaptive Reinforcement Learning",
    "review_id": "KDq9aReKUpc",
    "input": {
      "title": "Risk-Averse Bayes-Adaptive Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper proposes a CVaR formulation of Bayes-adaptive MDP.\n- The theoretical novelty mainly comes from translating the problem to a minimization over measures (Prop 1) and then to a stochastic game (Prop 2).\n- This is novel and by itself has value to the community.\n- The proposed algorithm is a MCTS algorithm that searches/plans over actions, chance nodes, and adversary nodes.\n- Multi-player versions of MCTS are not new.\n- The authors use progressive widening to handle the large action space of the adversary (continuous).\n- This is also already existent in the literature as cited by the authors.\n- It could be that the combination of both techniques is new (I am unsure about this) albeit somewhat trivial.\n- The authors use Bayesian optimization for alleviating the problem of finding good proposals for the progressive widening.\n- Again, I believe this addition is somewhat trivial, but I understand that this is what makes the algorithm achieve high performance.\n- So overall, here I see a combination of well-known techniques used in harmony to solve the problem at hand.\n- The proofs in the appendix are very well explained and easy to follow.\n- I think the proofs are of quality and technically sound.\n- The experimental results are conducted in toy domains.\n- I understand that the Bayes-adaptive MDP problem is hard, so I guess this is fine given the theoretical contributions.\n- I found the results a bit difficult to follow and interpret.\n- However, given enough time I think one can parse and interpret the results.\n- The results suggest that the proposed algorithm is on par or better in terms of performance and time compared to the other variations.\n- This conclusion is only obtained from a couple of environments though.\n- Most of the paper is very well written.\n- A bit more effort could have been devoted to the result section.\n- All details provided seem sufficient to reproduce the results.\n- I think the problem of risk-sensitivity in Bayes adaptive MDPs is very relevant for deploying general-purpose AI applications.\n- Management of risk is important for deployment, and adaptive agents is crucial for achieving flexible AI tools that can solve many problems.\n- As such, the domain of study seems to be significant.\n- Additionally, the theory might inspire researchers to take the problem in a different way.\n- The algorithm seems complex to implement (Bayesian optimization + MCTS + extended state spaces etc.) so it might not have huge adoption.",
    "review_points_list": [
      "The paper proposes a CVaR formulation of Bayes-adaptive MDP.",
      "The theoretical novelty mainly comes from translating the problem to a minimization over measures (Prop 1) and then to a stochastic game (Prop 2).",
      "This is novel and by itself has value to the community.",
      "The proposed algorithm is a MCTS algorithm that searches/plans over actions, chance nodes, and adversary nodes.",
      "Multi-player versions of MCTS are not new.",
      "The authors use progressive widening to handle the large action space of the adversary (continuous).",
      "This is also already existent in the literature as cited by the authors.",
      "It could be that the combination of both techniques is new (I am unsure about this) albeit somewhat trivial.",
      "The authors use Bayesian optimization for alleviating the problem of finding good proposals for the progressive widening.",
      "Again, I believe this addition is somewhat trivial, but I understand that this is what makes the algorithm achieve high performance.",
      "So overall, here I see a combination of well-known techniques used in harmony to solve the problem at hand.",
      "The proofs in the appendix are very well explained and easy to follow.",
      "I think the proofs are of quality and technically sound.",
      "The experimental results are conducted in toy domains.",
      "I understand that the Bayes-adaptive MDP problem is hard, so I guess this is fine given the theoretical contributions.",
      "I found the results a bit difficult to follow and interpret.",
      "However, given enough time I think one can parse and interpret the results.",
      "The results suggest that the proposed algorithm is on par or better in terms of performance and time compared to the other variations.",
      "This conclusion is only obtained from a couple of environments though.",
      "Most of the paper is very well written.",
      "A bit more effort could have been devoted to the result section.",
      "All details provided seem sufficient to reproduce the results.",
      "I think the problem of risk-sensitivity in Bayes adaptive MDPs is very relevant for deploying general-purpose AI applications.",
      "Management of risk is important for deployment, and adaptive agents is crucial for achieving flexible AI tools that can solve many problems.",
      "As such, the domain of study seems to be significant.",
      "Additionally, the theory might inspire researchers to take the problem in a different way.",
      "The algorithm seems complex to implement (Bayesian optimization + MCTS + extended state spaces etc.) so it might not have huge adoption."
    ]
  },
  {
    "paper_id": "2001.09608v1",
    "submission_id": "xmX-WjAsf8y",
    "submission_title": "Risk-Averse Bayes-Adaptive Reinforcement Learning",
    "review_id": "qPDuoM1OU2b",
    "input": {
      "title": "Risk-Averse Bayes-Adaptive Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper deals with an important but under-explored problem in RL, risk-sensitive decision-making under uncertainty.\n- Different complex frameworks are combined in this paper (CVaR, BAMDPs, etc.), yet I found the writing to be clear and the paper was pleasant to read.\n- One novel contribution (as far as I can tell) is to consider the CVaR optimization in the Bayes-Adaptive setting, and the stochastic game formulation of the problem.\n- The formal problem is exposed with enough precision but, to improve the presentation, I think some didactic example(s) would be useful to provide intuition about the optimal solution in such a setting, and generally make the paper more accessible.\n- The other contribution is the planning algorithm and the experimental work to demonstrate its efficacy.\n- The use of Bayesian optimization to control the adversary in the search seems reasonable here, and the BAMCP integration makes sense.\n- The experimental domains are simple but probably quite challenging to solve in this BAMDP+risk setting (at least the car nav domain).\n- I was satisfied with the chosen baselines, they give a good coverage for what other methods would do, and the experimental results make sense here.\n- This is a good sanity check that the algorithm is indeed able to optimize the proposed problem formulation, even if the current solution might not be readily scalable to much bigger domains.\n- The delta perturbation on the prior seems to disappear when introducing the stochastic game formulation (sec 4.2).\n- I'm understanding that it's because zeta is now perturbing directly the BAMDP transition which includes the prior, and this is explained by line 225-229, but perhaps this is worth expanding a bit and mentioning before in 4.2.\n- L121, I think the min should be a max in the definition of V(s,y).\n- This probably comes from the Chow et al. paper which uses costs instead of rewards in your case?\n- I could be wrong but I think there might be a variant of RA-BAMCP with root sampling that could work.\n- Couldn't you do a different perturbation for the sampling at the root from the adversary and then do regular MDP transition perturbations as in Prop 1?\n- Haven't completely thought this through, and I understand this might be left for future work.",
    "review_points_list": [
      "The paper deals with an important but under-explored problem in RL, risk-sensitive decision-making under uncertainty.",
      "Different complex frameworks are combined in this paper (CVaR, BAMDPs, etc.), yet I found the writing to be clear and the paper was pleasant to read.",
      "One novel contribution (as far as I can tell) is to consider the CVaR optimization in the Bayes-Adaptive setting, and the stochastic game formulation of the problem.",
      "The formal problem is exposed with enough precision but, to improve the presentation, I think some didactic example(s) would be useful to provide intuition about the optimal solution in such a setting, and generally make the paper more accessible.",
      "The other contribution is the planning algorithm and the experimental work to demonstrate its efficacy.",
      "The use of Bayesian optimization to control the adversary in the search seems reasonable here, and the BAMCP integration makes sense.",
      "The experimental domains are simple but probably quite challenging to solve in this BAMDP+risk setting (at least the car nav domain).",
      "I was satisfied with the chosen baselines, they give a good coverage for what other methods would do, and the experimental results make sense here.",
      "This is a good sanity check that the algorithm is indeed able to optimize the proposed problem formulation, even if the current solution might not be readily scalable to much bigger domains.",
      "The delta perturbation on the prior seems to disappear when introducing the stochastic game formulation (sec 4.2).",
      "I'm understanding that it's because zeta is now perturbing directly the BAMDP transition which includes the prior, and this is explained by line 225-229, but perhaps this is worth expanding a bit and mentioning before in 4.2.",
      "L121, I think the min should be a max in the definition of V(s,y).",
      "This probably comes from the Chow et al. paper which uses costs instead of rewards in your case?",
      "I could be wrong but I think there might be a variant of RA-BAMCP with root sampling that could work.",
      "Couldn't you do a different perturbation for the sampling at the root from the adversary and then do regular MDP transition perturbations as in Prop 1?",
      "Haven't completely thought this through, and I understand this might be left for future work."
    ]
  },
  {
    "paper_id": "2001.09608v1",
    "submission_id": "xmX-WjAsf8y",
    "submission_title": "Risk-Averse Bayes-Adaptive Reinforcement Learning",
    "review_id": "2Af0DVMYxO",
    "input": {
      "title": "Risk-Averse Bayes-Adaptive Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is clearly written and addresses its main topic succinctly and thoroughly.\n- The derivations and proofs appear correct after checking them.\n- The motivation is clearly stated and the algorithm is well developed from there.\n- The authors choose a static risk setting but do not discuss why.\n- It would be good to elaborate on this design choice, especially since it seems to make the adversarial game more difficult.\n- One big drawback of the method that is also discussed by the authors is the poor scalability of their findings.\n- Combining a full Bayesian approach to RL and CVaR optimization on its own are hard problems with known scaling issues.\n- A longer discussion of potential approximations would have improved the applicability of the paper.\n- It would have been interesting to see how the found solutions of the MCTS approach scale with growing computational budget.\n- The authors stress several times that their method is able to take into account both parametric and intrinsic uncertainty, yet the experiments do not separate this.\n- It would be very instructive to add two sets of experiments, one where it is vital to be robust towards parametric and one where intrinsic uncertainty is challenging.\n- While a baseline for this was used, it is unclear whether the difference in performance is due to the difference in methodology or implementation.\n- Many recent paper (i.e. GANs, robust MDP formulations) show that two player optimization is a very difficult topic.\n- Are similar concerns valid here?\n- I would encourage the authors to investigate the stability of the equilibria found with their algorithm either in the practical algorithm or the theoretical derivation.\n- The paper presents a good derivation of the main contribution, the Bayes adaptive CVaR optimization.\n- While there are several concerns and suggested improvements to the paper, I think that overall the presented submission should be accepted, since some of the additional questions might be out of scope for this paper and even without them, the paper is interesting, novel and clear.\n- The minor comments were very well written.",
    "review_points_list": [
      "The paper is clearly written and addresses its main topic succinctly and thoroughly.",
      "The derivations and proofs appear correct after checking them.",
      "The motivation is clearly stated and the algorithm is well developed from there.",
      "The authors choose a static risk setting but do not discuss why.",
      "It would be good to elaborate on this design choice, especially since it seems to make the adversarial game more difficult.",
      "One big drawback of the method that is also discussed by the authors is the poor scalability of their findings.",
      "Combining a full Bayesian approach to RL and CVaR optimization on its own are hard problems with known scaling issues.",
      "A longer discussion of potential approximations would have improved the applicability of the paper.",
      "It would have been interesting to see how the found solutions of the MCTS approach scale with growing computational budget.",
      "The authors stress several times that their method is able to take into account both parametric and intrinsic uncertainty, yet the experiments do not separate this.",
      "It would be very instructive to add two sets of experiments, one where it is vital to be robust towards parametric and one where intrinsic uncertainty is challenging.",
      "While a baseline for this was used, it is unclear whether the difference in performance is due to the difference in methodology or implementation.",
      "Many recent paper (i.e. GANs, robust MDP formulations) show that two player optimization is a very difficult topic.",
      "Are similar concerns valid here?",
      "I would encourage the authors to investigate the stability of the equilibria found with their algorithm either in the practical algorithm or the theoretical derivation.",
      "The paper presents a good derivation of the main contribution, the Bayes adaptive CVaR optimization.",
      "While there are several concerns and suggested improvements to the paper, I think that overall the presented submission should be accepted, since some of the additional questions might be out of scope for this paper and even without them, the paper is interesting, novel and clear.",
      "The minor comments were very well written."
    ]
  },
  {
    "paper_id": "1904.12083v3",
    "submission_id": "uRwcGRwQK1L",
    "submission_title": "Exponential Separation between Two Learning Models and Adversarial Robustness",
    "review_id": "rFUY9L32cTB",
    "input": {
      "title": "Exponential Separation between Two Learning Models and Adversarial Robustness",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I have not checked in detail the various proofs, but for the largest part the paper is clearly written.\n- The exponential improvement on the query complexity is not very surprising given that the counter-examples are coming from the symmetric difference between the hypothesis and the target.\n- The authors discuss adversarial training based on adversarial instances that are drawn from the manifold of the data, and draw a parallel between that model and the model of learning by using equivalence queries.\n- The point is that the improved complexity bound in the PAC-EQ model that is discussed in the paper can help explain the faster rate of learning that can be observed in adversarial training based on on-manifold adversarial instances.\n- It is this last idea that the authors discuss in more detail in the latter part of the paper, where the adversary may now generate adversarial examples as if these were returned by an equivalence query oracle and naturally they exploit the result from the main part of the paper.\n- The exponential improvement result that the authors find between the query complexity of PAC learning and of the PAC-EQ model that they introduce is not very surprising, given that the examples are coming from the symmetric difference between the hypothesis and the target.\n- Furthermore, the authors appear to be introducing a new attack model (based on equivalence queries) and it appears that the justification is in line 300, where they say that 'introducing new attack models might be necessary for realizing adversarial robustness in the real world.'\n- While it appears that a good discussion has been made earlier in Section 5, nevertheless, I do not quite understand the adversary of the paper and how feasible it can be in a real-world setting.\n- There are also some minor typos here and there.\n- Thank you for the response. Having read the reviews of others, and based on the discussion offline, I have concluded that we are all a bit concerned with the latter part of the paper on adversarial robustness.\n- For this reason, my evaluation on this paper has not changed.",
    "review_points_list": [
      "I have not checked in detail the various proofs, but for the largest part the paper is clearly written.",
      "The exponential improvement on the query complexity is not very surprising given that the counter-examples are coming from the symmetric difference between the hypothesis and the target.",
      "The authors discuss adversarial training based on adversarial instances that are drawn from the manifold of the data, and draw a parallel between that model and the model of learning by using equivalence queries.",
      "The point is that the improved complexity bound in the PAC-EQ model that is discussed in the paper can help explain the faster rate of learning that can be observed in adversarial training based on on-manifold adversarial instances.",
      "It is this last idea that the authors discuss in more detail in the latter part of the paper, where the adversary may now generate adversarial examples as if these were returned by an equivalence query oracle and naturally they exploit the result from the main part of the paper.",
      "The exponential improvement result that the authors find between the query complexity of PAC learning and of the PAC-EQ model that they introduce is not very surprising, given that the examples are coming from the symmetric difference between the hypothesis and the target.",
      "Furthermore, the authors appear to be introducing a new attack model (based on equivalence queries) and it appears that the justification is in line 300, where they say that 'introducing new attack models might be necessary for realizing adversarial robustness in the real world.'",
      "While it appears that a good discussion has been made earlier in Section 5, nevertheless, I do not quite understand the adversary of the paper and how feasible it can be in a real-world setting.",
      "There are also some minor typos here and there.",
      "Thank you for the response. Having read the reviews of others, and based on the discussion offline, I have concluded that we are all a bit concerned with the latter part of the paper on adversarial robustness.",
      "For this reason, my evaluation on this paper has not changed."
    ]
  },
  {
    "paper_id": "1904.12083v3",
    "submission_id": "uRwcGRwQK1L",
    "submission_title": "Exponential Separation between Two Learning Models and Adversarial Robustness",
    "review_id": "zw7kgq4IOPP",
    "input": {
      "title": "Exponential Separation between Two Learning Models and Adversarial Robustness",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The randomized EQ-model is well studied in the regime of finite hypothesis classes (where it is known that perfectly identifying any $h \\in H$ requires $\\log(|H|)$ queries), but to my knowledge this is the first work giving PAC-style guarantees for general hypothesis classes.\n- The model is mathematically natural in this regime, and the obtained exponential speedup (in query complexity) is quite interesting.\n- In fact, since active learning with a sample oracle fails in many natural scenarios, this result is the first I know of giving an exponential speedup for all PAC learnable classes (albeit in a much stronger interactive model).\n- The proof technique is a novel twist on majority boosting, and can sort of be thought of as a (much trickier) version of known connections between perfect selective classification (or RPU learning) and standard active learning.\n- My only complaint on the theory side is that there is no discussion of lower bounds for the model.\n- The query complexity is also obviously off (exponent of 9), but this is discussed by the authors and not really a major concern, as the main point is to show a polylog bound.\n- This result alone is likely of broad interest to the learning community.\n- I find the rest of the paper, mostly the proposed connections with adversarial robustness, to be hand-wavy and very confusing.\n- The authors make a number of assumptions without much justification, e.g. that the distribution of adversarial attack is random.\n- The claimed connection to robustness against adversaries with restricted learning power is interesting, but not formalized at all.\n- Formally, the authors focus more on adversarial training, but don\u2019t discuss how this leads to adversarial robustness, or even really define the adversary/attack at all in the sense discussed at the beginning of the section (where an adversary attempts to find $x\u2019$ that is misclassified and \u201csemantically indistinguishable\u201d from the input $x$).\n- Overall the writing is too informal, and the exposition doesn\u2019t clearly match up to the definitions and formal statements.\n- I thank the authors for their response but my opinion remains unchanged.",
    "review_points_list": [
      "The randomized EQ-model is well studied in the regime of finite hypothesis classes (where it is known that perfectly identifying any $h \\in H$ requires $\\log(|H|)$ queries), but to my knowledge this is the first work giving PAC-style guarantees for general hypothesis classes.",
      "The model is mathematically natural in this regime, and the obtained exponential speedup (in query complexity) is quite interesting.",
      "In fact, since active learning with a sample oracle fails in many natural scenarios, this result is the first I know of giving an exponential speedup for all PAC learnable classes (albeit in a much stronger interactive model).",
      "The proof technique is a novel twist on majority boosting, and can sort of be thought of as a (much trickier) version of known connections between perfect selective classification (or RPU learning) and standard active learning.",
      "My only complaint on the theory side is that there is no discussion of lower bounds for the model.",
      "The query complexity is also obviously off (exponent of 9), but this is discussed by the authors and not really a major concern, as the main point is to show a polylog bound.",
      "This result alone is likely of broad interest to the learning community.",
      "I find the rest of the paper, mostly the proposed connections with adversarial robustness, to be hand-wavy and very confusing.",
      "The authors make a number of assumptions without much justification, e.g. that the distribution of adversarial attack is random.",
      "The claimed connection to robustness against adversaries with restricted learning power is interesting, but not formalized at all.",
      "Formally, the authors focus more on adversarial training, but don\u2019t discuss how this leads to adversarial robustness, or even really define the adversary/attack at all in the sense discussed at the beginning of the section (where an adversary attempts to find $x\u2019$ that is misclassified and \u201csemantically indistinguishable\u201d from the input $x$).",
      "Overall the writing is too informal, and the exposition doesn\u2019t clearly match up to the definitions and formal statements.",
      "I thank the authors for their response but my opinion remains unchanged."
    ]
  },
  {
    "paper_id": "1904.12083v3",
    "submission_id": "uRwcGRwQK1L",
    "submission_title": "Exponential Separation between Two Learning Models and Adversarial Robustness",
    "review_id": "beKCraBIHuj",
    "input": {
      "title": "Exponential Separation between Two Learning Models and Adversarial Robustness",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I believe that the main result (Theorem 3.1) is novel.\n- In Section 3.3, this presentation of the main result is also interesting: taking any black-box PAC learner and converting it to a learner in the EQ-model but with improved dependence on (1/epsilon).\n- I suggest making this a bit more formal, e.g. as a Corollary.\n- I do not see how Section 5 fits with the rest of the paper.\n- Specifically, I do not see how the problem of adversarial robustness is formally defined.\n- What is the goal here?\n- Even the discussion (lines 282-299) about the attacks, and needing to introduce new attack models, it is not clear why that is necessary without even defining the goal.\n- Is the goal to generalize against any adversary that is restricted to some perturbation set, or to a fixed specific adversary that we can interact with during training time?\n- Even with the model of attack (definition 2) in Section 5.1, there are no guarantees given in the paper, except for Corollary 1, which is not very meaningful in terms of robustness guarantees.\n- Because all it says is that we can view the adversary as an equivalence query oracle.\n- This has already been presented in Section 3, so I am not sure if its adding anything new.\n- In Section 5.1, the authors should discuss the related work of Montasser, Hanneke, Srebro (2021).\n- That work introduces similar learning models where the learner interacts with an adversary (similar to Definition 3), with the addition that an end goal is specified which is either obtaining: robustness guarantees against *any* adversary that is constrained to some perturbation set, or robustness guarantees against a *fixed* adversary that the learner can interact with at training time.\n- This is currently lacking in this work, and I encourage the authors to think further about their end-goal in the adversarial learning setup.\n- Some minor comments.\n- lines 282 and 283: the statement is not clear.\n- Is it not possible computationally or statistically?\n- lines 371 and 372 are not accurate.\n- There is no robustness guarantee presented in Section 5.\n- I thank the authors for their response.\n- After consideration, I decided to keep my score the same.\n- The connection to adversarial robustness is a bit under-developed in my opinion.\n- One of my main concerns is that the result presented in Corollary 1 (Section 5) lacks any robust learning guarantees.\n- Specifically, at best, the learned predictor will have low standard generalization error (but it won't necessarily be robust to adversarial perturbations).\n- I encourage the authors to think further about the robust learning guarantees they are considering.",
    "review_points_list": [
      "I believe that the main result (Theorem 3.1) is novel.",
      "In Section 3.3, this presentation of the main result is also interesting: taking any black-box PAC learner and converting it to a learner in the EQ-model but with improved dependence on (1/epsilon).",
      "I suggest making this a bit more formal, e.g. as a Corollary.",
      "I do not see how Section 5 fits with the rest of the paper.",
      "Specifically, I do not see how the problem of adversarial robustness is formally defined.",
      "What is the goal here?",
      "Even the discussion (lines 282-299) about the attacks, and needing to introduce new attack models, it is not clear why that is necessary without even defining the goal.",
      "Is the goal to generalize against any adversary that is restricted to some perturbation set, or to a fixed specific adversary that we can interact with during training time?",
      "Even with the model of attack (definition 2) in Section 5.1, there are no guarantees given in the paper, except for Corollary 1, which is not very meaningful in terms of robustness guarantees.",
      "Because all it says is that we can view the adversary as an equivalence query oracle.",
      "This has already been presented in Section 3, so I am not sure if its adding anything new.",
      "In Section 5.1, the authors should discuss the related work of Montasser, Hanneke, Srebro (2021).",
      "That work introduces similar learning models where the learner interacts with an adversary (similar to Definition 3), with the addition that an end goal is specified which is either obtaining: robustness guarantees against *any* adversary that is constrained to some perturbation set, or robustness guarantees against a *fixed* adversary that the learner can interact with at training time.",
      "This is currently lacking in this work, and I encourage the authors to think further about their end-goal in the adversarial learning setup.",
      "Some minor comments.",
      "lines 282 and 283: the statement is not clear.",
      "Is it not possible computationally or statistically?",
      "lines 371 and 372 are not accurate.",
      "There is no robustness guarantee presented in Section 5.",
      "I thank the authors for their response.",
      "After consideration, I decided to keep my score the same.",
      "The connection to adversarial robustness is a bit under-developed in my opinion.",
      "One of my main concerns is that the result presented in Corollary 1 (Section 5) lacks any robust learning guarantees.",
      "Specifically, at best, the learned predictor will have low standard generalization error (but it won't necessarily be robust to adversarial perturbations).",
      "I encourage the authors to think further about the robust learning guarantees they are considering."
    ]
  },
  {
    "paper_id": "2301.11542v1",
    "submission_id": "wQZWg82TWx",
    "submission_title": "A Mathematical Framework for Quantifying Transferability in Multi-source Transfer Learning",
    "review_id": "G0r5IrL0CiB",
    "input": {
      "title": "A Mathematical Framework for Quantifying Transferability in Multi-source Transfer Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper proposes a notion to quantify transferability and derive the analytic form, which depends on sample size, chi-sq distance between the source and target tasks, and the complexity of the model.\n- A new algorithm is then proposed based on this notion for transfer learning.",
    "review_points_list": [
      "This paper proposes a notion to quantify transferability and derive the analytic form, which depends on sample size, chi-sq distance between the source and target tasks, and the complexity of the model.",
      "A new algorithm is then proposed based on this notion for transfer learning."
    ]
  },
  {
    "paper_id": "2301.11542v1",
    "submission_id": "wQZWg82TWx",
    "submission_title": "A Mathematical Framework for Quantifying Transferability in Multi-source Transfer Learning",
    "review_id": "21-W1c5ZFrI",
    "input": {
      "title": "A Mathematical Framework for Quantifying Transferability in Multi-source Transfer Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The idea of studying task transferability under the assumption that the target task\u2019s model is a convex combination of the source tasks\u2019 models is new to me.\n- The linearity assumption allows for a very simple and nice solution: the optimal coefficients can be computed in closed-form (in finite domain cases).\n- The simplicity of the solution allows for the great applicability of the methods.\n- I find the paper does not provide enough information to convince the reader that this is a good transferability measure?\n- While I am convinced that the technical theorems are correct, I am unsure why this would be a good framework to measure transferability across tasks.\n- More concretely, equations 2, 3, and definition 1 expound the basic structure of the framework, yet no explanation is given to motivate these choices.\n- One could provide citations to convince readers that this is common practice or argue that certain assumptions are weak and generally hold in practice.\n- The paper does not mention any properties enjoyed by the proposed transferability notion (Eq. 4).\n- The experiments are designed to demonstrate the performance of Algorithm 1 and not the validity of the proposed notion of transferability (Eq. 4).\n- The most glaring evidence is that, although the optimal coefficients \u03b1^* is introduced as the transferability measure in the previous section, \u03b1^* were never mentioned or discussed in the experiments, and the paper solely focuses on the test accuracy of the model.\n- The introduction of the transferability \u03b1^* seems unnecessary.\n- I feel that the focus of the paper is a new algorithm for transfer learning (Algorithm 1), and not a mathematical framework for measuring transferability across tasks.\n- I would appreciate the contribution here if the author can demonstrate that the proposed notion of transferability is useful.\n- One could construct a synthetic experiment in which one of the source tasks is more intimately related to the target task than the others, and demonstrate that the coefficient of that task is large.\n- The main paper is clear and well-written.\n- I can follow and understand the ideas most of the time.\n- Notations are consistent and correct.",
    "review_points_list": [
      "The idea of studying task transferability under the assumption that the target task\u2019s model is a convex combination of the source tasks\u2019 models is new to me.",
      "The linearity assumption allows for a very simple and nice solution: the optimal coefficients can be computed in closed-form (in finite domain cases).",
      "The simplicity of the solution allows for the great applicability of the methods.",
      "I find the paper does not provide enough information to convince the reader that this is a good transferability measure?",
      "While I am convinced that the technical theorems are correct, I am unsure why this would be a good framework to measure transferability across tasks.",
      "More concretely, equations 2, 3, and definition 1 expound the basic structure of the framework, yet no explanation is given to motivate these choices.",
      "One could provide citations to convince readers that this is common practice or argue that certain assumptions are weak and generally hold in practice.",
      "The paper does not mention any properties enjoyed by the proposed transferability notion (Eq. 4).",
      "The experiments are designed to demonstrate the performance of Algorithm 1 and not the validity of the proposed notion of transferability (Eq. 4).",
      "The most glaring evidence is that, although the optimal coefficients \u03b1^* is introduced as the transferability measure in the previous section, \u03b1^* were never mentioned or discussed in the experiments, and the paper solely focuses on the test accuracy of the model.",
      "The introduction of the transferability \u03b1^* seems unnecessary.",
      "I feel that the focus of the paper is a new algorithm for transfer learning (Algorithm 1), and not a mathematical framework for measuring transferability across tasks.",
      "I would appreciate the contribution here if the author can demonstrate that the proposed notion of transferability is useful.",
      "One could construct a synthetic experiment in which one of the source tasks is more intimately related to the target task than the others, and demonstrate that the coefficient of that task is large.",
      "The main paper is clear and well-written.",
      "I can follow and understand the ideas most of the time.",
      "Notations are consistent and correct."
    ]
  },
  {
    "paper_id": "2301.11542v1",
    "submission_id": "wQZWg82TWx",
    "submission_title": "A Mathematical Framework for Quantifying Transferability in Multi-source Transfer Learning",
    "review_id": "5X6bthScND2",
    "input": {
      "title": "A Mathematical Framework for Quantifying Transferability in Multi-source Transfer Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think the paper aims to address an important machine learning problem in the field of transfer learning.\n- The paper is clearly written, and the authors make an effort to factor in various important aspects of transfer learning in their solutions including sample complexity and task similarity.\n- However, the proposed solution is relatively straightforward without rigorous, principled justifications.\n- Experimental results are limited on three datasets.\n- The originality of the paper lies in the proposal of a new objective function for transfer learning that accounts for both task similarity and sample complexity.\n- I find such a contribution somewhat limited.\n- While the proposed objective function and algorithm intuitively makes sense, the proposal is not validated in a rigorous, principled manner, ideally with certain theoretical justification.\n- I find the claim that the objective provides \u2018fundamental insights\u2019 somewhat unsubstantiated.\n- Furthermore, the iterative algorithm makes sense because each sub-step is concerned with solving a different subproblem.\n- It is unclear to me whether a simple first-order method to solve the parameters jointly will suffice, making the proposed algorithm unnecessary.\n- Experimental results are also somewhat limited both in terms of datasets and in terms of competing methods.\n- It is unclear to me why the datasets and methods compared are representative enough to be compared against.\n- I think the presentation in this paper is clear.\n- Mathematical notations are well setted-up.\n- I can follow the major argument of the paper easily.\n- Based on my concern in originality and quality, I find the paper is of limited significance.\n- Thank you for the detailed response.\n- My questions are partially answered by the authors, and I would like to keep my original rating.",
    "review_points_list": [
      "I think the paper aims to address an important machine learning problem in the field of transfer learning.",
      "The paper is clearly written, and the authors make an effort to factor in various important aspects of transfer learning in their solutions including sample complexity and task similarity.",
      "However, the proposed solution is relatively straightforward without rigorous, principled justifications.",
      "Experimental results are limited on three datasets.",
      "The originality of the paper lies in the proposal of a new objective function for transfer learning that accounts for both task similarity and sample complexity.",
      "I find such a contribution somewhat limited.",
      "While the proposed objective function and algorithm intuitively makes sense, the proposal is not validated in a rigorous, principled manner, ideally with certain theoretical justification.",
      "I find the claim that the objective provides \u2018fundamental insights\u2019 somewhat unsubstantiated.",
      "Furthermore, the iterative algorithm makes sense because each sub-step is concerned with solving a different subproblem.",
      "It is unclear to me whether a simple first-order method to solve the parameters jointly will suffice, making the proposed algorithm unnecessary.",
      "Experimental results are also somewhat limited both in terms of datasets and in terms of competing methods.",
      "It is unclear to me why the datasets and methods compared are representative enough to be compared against.",
      "I think the presentation in this paper is clear.",
      "Mathematical notations are well setted-up.",
      "I can follow the major argument of the paper easily.",
      "Based on my concern in originality and quality, I find the paper is of limited significance.",
      "Thank you for the detailed response.",
      "My questions are partially answered by the authors, and I would like to keep my original rating."
    ]
  },
  {
    "paper_id": "2301.11542v1",
    "submission_id": "wQZWg82TWx",
    "submission_title": "A Mathematical Framework for Quantifying Transferability in Multi-source Transfer Learning",
    "review_id": "hW9G5KXZBv",
    "input": {
      "title": "A Mathematical Framework for Quantifying Transferability in Multi-source Transfer Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The assumption that the input space $X$ is discrete is quite strong.\n- I was wondering is this assumption crucial for the analysis?\n- The authors mention that the definition of $V^0$ in Eq. (7) only works when $|X|$ is finite, otherwise $V^0$ would become infinity.\n- I know that later in Section 3 the authors discuss such an extension, however, it seems to me that the results in Theorem 4 no longer shares the characterization that $V_i$ measures the size of the problem?\n- Could the authors comment on this?\n- I like the interpretation of the result in Eq. (5) as a decomposition of bias and variance.\n- This is quite interesting.\n- Why the authors describe $|X||Y| - 1$ as the model complexity? I would think model complexity often refers to VC dimension, covering number, etc.\n- It seems to me this explanation is a little bit forced.\n- Shouldn't the $|X||Y| - 1$ solely depend on the problem specification itself?\n- The authors briefly mention that the optimal solution of $\beta$ in the multi-source setting could be attained by solving a nonnegative quadratic programming problem.\n- It would better if the authors could also derive the closed form solutions (if possible) in this case, as what has been done in Theorem 2.\n- Line 25: the citation of the GAN paper on describing it as transferring techniques is not accurate.\n- Line 145 - 146: 'the previous analyzing framework' -> 'the previous analysis framework'.",
    "review_points_list": [
      "The assumption that the input space $X$ is discrete is quite strong.",
      "I was wondering is this assumption crucial for the analysis?",
      "The authors mention that the definition of $V^0$ in Eq. (7) only works when $|X|$ is finite, otherwise $V^0$ would become infinity.",
      "I know that later in Section 3 the authors discuss such an extension, however, it seems to me that the results in Theorem 4 no longer shares the characterization that $V_i$ measures the size of the problem?",
      "Could the authors comment on this?",
      "I like the interpretation of the result in Eq. (5) as a decomposition of bias and variance.",
      "This is quite interesting.",
      "Why the authors describe $|X||Y| - 1$ as the model complexity? I would think model complexity often refers to VC dimension, covering number, etc.",
      "It seems to me this explanation is a little bit forced.",
      "Shouldn't the $|X||Y| - 1$ solely depend on the problem specification itself?",
      "The authors briefly mention that the optimal solution of $\beta$ in the multi-source setting could be attained by solving a nonnegative quadratic programming problem.",
      "It would better if the authors could also derive the closed form solutions (if possible) in this case, as what has been done in Theorem 2.",
      "Line 25: the citation of the GAN paper on describing it as transferring techniques is not accurate.",
      "Line 145 - 146: 'the previous analyzing framework' -> 'the previous analysis framework'."
    ]
  },
  {
    "paper_id": "2109.15154v1",
    "submission_id": "wfJCeMS-jH",
    "submission_title": "Causal Identification with Matrix Equations",
    "review_id": "kk7m0Tc-hYE",
    "input": {
      "title": "Causal Identification with Matrix Equations",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The submission makes a relevant and significant contribution to the field of causal inference.\n- Moving from identification results based on the full observable joint distribution (as in the do-calculus) to sets of observational and interventional distributions is of practical value.\n- My understanding is that this extends the existing identification algorithms using observational and interventional data to settings where the sets of observational variables are disjoint, as in the Kuroki and Pearl proxy variable setting.\n- While my impression of the work is generally very positive, I think some changes could be made to make the content easier to contextualize in the literature.\n- I would suggest adding a table that describes how ID-ME relates to recent identification algorithms.\n- I respectfully disagree with previous reviewers who encouraged the authors to emphasize the main theoretical results in the main body at the expense of exposition and examples.\n- It would be helpful to clarify how graph structure relates to the resulting matrices a bit more intuitively.\n- ID-ME is proven to be sound, but not complete.\n- It would be helpful to understand these limitations in a bit more detail.\n- Are there example graphs/queries the authors could point to where ID-ME does not provide complete identification results?\n- Alternatively, do the authors expect that ID-ME is complete but that a proof of completeness is left to future work?",
    "review_points_list": [
      "The submission makes a relevant and significant contribution to the field of causal inference.",
      "Moving from identification results based on the full observable joint distribution (as in the do-calculus) to sets of observational and interventional distributions is of practical value.",
      "My understanding is that this extends the existing identification algorithms using observational and interventional data to settings where the sets of observational variables are disjoint, as in the Kuroki and Pearl proxy variable setting.",
      "While my impression of the work is generally very positive, I think some changes could be made to make the content easier to contextualize in the literature.",
      "I would suggest adding a table that describes how ID-ME relates to recent identification algorithms.",
      "I respectfully disagree with previous reviewers who encouraged the authors to emphasize the main theoretical results in the main body at the expense of exposition and examples.",
      "It would be helpful to clarify how graph structure relates to the resulting matrices a bit more intuitively.",
      "ID-ME is proven to be sound, but not complete.",
      "It would be helpful to understand these limitations in a bit more detail.",
      "Are there example graphs/queries the authors could point to where ID-ME does not provide complete identification results?",
      "Alternatively, do the authors expect that ID-ME is complete but that a proof of completeness is left to future work?"
    ]
  },
  {
    "paper_id": "2109.15154v1",
    "submission_id": "wfJCeMS-jH",
    "submission_title": "Causal Identification with Matrix Equations",
    "review_id": "6805-NyIoqy",
    "input": {
      "title": "Causal Identification with Matrix Equations",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is quite well written and motivated.\n- The overall storyline of the paper is clear, however I had the impression that the balance of the amount of material the authors would like to treat was suboptimal.\n- For example, the authors revisit different proxy based approaches, which take a lot of space.\n- I would move either the single-proxy or the double-proxy setting to the appendix, which gives additional space for, for example, a running example of the identification algorithm, which would have been helpful.\n- Although the authors explain their main algorithm in Section 6, it is very difficult to understand the motivation of the steps they are taking without having any intuition on what is happening.\n- This also would give more space for explaining C-factorization better and the example in that section.\n- In particular, it was not clear to me how this example relates to C-factorization and what the actual point is that the authors are trying to make.\n- The notation used, such as lower and upper case, back and forward slashes, accents and double accents and the different combination of those make this paper very hard to read, especially if their meaning change if applied in different combinations\n- or if there are typos present\n- For example, what does (x_{ij} \\/ y_{ij}) / ( X_j \\/ X_i \\/ Y_i ) mean?\n- Because of this notational overload I was unable to understand the results in all their detail and I was not be able verify any of the proofs of the paper.\n- The approach and results of this paper seem interesting and valuable.\n- However, given the current state of the paper I would give it a marginally below accept, due to the imbalanced amount of material covered and the notational overload of the paper.\n- I think that improving the notation and trading of some material for clarity would be a good idea to improve the overall readability and impact of the paper.\n- Minor comments:\n- - Lemma 3: Why the graph in the lemma?\n- - Footnote 1: Put this in the main text: writing a distribution in matrix notation is very confusing if one does not know that the variables are discrete.\n- - line 81-82: What are W, Z and the union here?\n- - line 91: State that it is acyclic somewhere? Or, not?\n- - line 299: Here, $X^+_k$ and $Y^+_i$ have an ambiguous definition.\n- Does this relate to the C-factor $Y^+$ definition?",
    "review_points_list": [
      "The paper is quite well written and motivated.",
      "The overall storyline of the paper is clear, however I had the impression that the balance of the amount of material the authors would like to treat was suboptimal.",
      "For example, the authors revisit different proxy based approaches, which take a lot of space.",
      "I would move either the single-proxy or the double-proxy setting to the appendix, which gives additional space for, for example, a running example of the identification algorithm, which would have been helpful.",
      "Although the authors explain their main algorithm in Section 6, it is very difficult to understand the motivation of the steps they are taking without having any intuition on what is happening.",
      "This also would give more space for explaining C-factorization better and the example in that section.",
      "In particular, it was not clear to me how this example relates to C-factorization and what the actual point is that the authors are trying to make.",
      "The notation used, such as lower and upper case, back and forward slashes, accents and double accents and the different combination of those make this paper very hard to read, especially if their meaning change if applied in different combinations",
      "or if there are typos present",
      "For example, what does (x_{ij} \\/ y_{ij}) / ( X_j \\/ X_i \\/ Y_i ) mean?",
      "Because of this notational overload I was unable to understand the results in all their detail and I was not be able verify any of the proofs of the paper.",
      "The approach and results of this paper seem interesting and valuable.",
      "However, given the current state of the paper I would give it a marginally below accept, due to the imbalanced amount of material covered and the notational overload of the paper.",
      "I think that improving the notation and trading of some material for clarity would be a good idea to improve the overall readability and impact of the paper.",
      "Minor comments:",
      "- Lemma 3: Why the graph in the lemma?",
      "- Footnote 1: Put this in the main text: writing a distribution in matrix notation is very confusing if one does not know that the variables are discrete.",
      "- line 81-82: What are W, Z and the union here?",
      "- line 91: State that it is acyclic somewhere? Or, not?",
      "- line 299: Here, $X^+_k$ and $Y^+_i$ have an ambiguous definition.",
      "Does this relate to the C-factor $Y^+$ definition?"
    ]
  },
  {
    "paper_id": "2109.15154v1",
    "submission_id": "wfJCeMS-jH",
    "submission_title": "Causal Identification with Matrix Equations",
    "review_id": "eEEISxaYhmG",
    "input": {
      "title": "Causal Identification with Matrix Equations",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is a very strong contribution to the literature.\n- This paper presents no experimental evidence\n- My largest concern is that some of the entailed statistical inference procedures may be exceedingly difficult to estimate in practice.\n- While I wouldn't recommend rejection based on this, perhaps the authors could make mention of it.\n- In Miao, et al. there is a requirement on the rank of the proxy variables, are no such assumptions necessary here?\n- It would be helpful if the authors placed necessary assumptions in a more well delineated fashion.\n- As it stands, they are strewn throughout and often made opaque.",
    "review_points_list": [
      "The paper is a very strong contribution to the literature.",
      "This paper presents no experimental evidence",
      "My largest concern is that some of the entailed statistical inference procedures may be exceedingly difficult to estimate in practice.",
      "While I wouldn't recommend rejection based on this, perhaps the authors could make mention of it.",
      "In Miao, et al. there is a requirement on the rank of the proxy variables, are no such assumptions necessary here?",
      "It would be helpful if the authors placed necessary assumptions in a more well delineated fashion.",
      "As it stands, they are strewn throughout and often made opaque."
    ]
  },
  {
    "paper_id": "1703.05641v2",
    "submission_id": "uIMwuJHfuLM",
    "submission_title": "Distributed Learning with Strategic Users: A Repeated Game Approach",
    "review_id": "M-2j-nDmJ2L",
    "input": {
      "title": "Distributed Learning with Strategic Users: A Repeated Game Approach",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Federated learning is a relevant problem in machine learning and I believe this work positively contributes to the existing literature.\n- The work adds both novel theoretical contributions and experimental results. Moreover, it is clearly written.\n- Hence, my acceptance score.\n- However, I have a few comments for the authors:\n- - It would be nice to have related works discussed in the main paper, clearly highlighting the differences in terms of set-ups and assumptions considered.\n- I believe the problem of federated learning can be tackled from a lot of different perspectives and it would be nice to have this clear from the first sections.\n- A lot of technical definitions and details could be moved to the Appendix instead (e.g., Equation 20).\n- - In the experiments, only a static strategy vector is considered for the users. However, it would be natural to consider users who adapt their strategy online.\n- Is there a particular reason why this was not considered?\n- This would test whether the FC algorithm actually steers the agents to collaborate in the long run.",
    "review_points_list": [
      "Federated learning is a relevant problem in machine learning and I believe this work positively contributes to the existing literature.",
      "The work adds both novel theoretical contributions and experimental results. Moreover, it is clearly written.",
      "Hence, my acceptance score.",
      "However, I have a few comments for the authors:",
      "- It would be nice to have related works discussed in the main paper, clearly highlighting the differences in terms of set-ups and assumptions considered.",
      "I believe the problem of federated learning can be tackled from a lot of different perspectives and it would be nice to have this clear from the first sections.",
      "A lot of technical definitions and details could be moved to the Appendix instead (e.g., Equation 20).",
      "- In the experiments, only a static strategy vector is considered for the users. However, it would be natural to consider users who adapt their strategy online.",
      "Is there a particular reason why this was not considered?",
      "This would test whether the FC algorithm actually steers the agents to collaborate in the long run."
    ]
  },
  {
    "paper_id": "1703.05641v2",
    "submission_id": "uIMwuJHfuLM",
    "submission_title": "Distributed Learning with Strategic Users: A Repeated Game Approach",
    "review_id": "N9VSRVToRfG",
    "input": {
      "title": "Distributed Learning with Strategic Users: A Repeated Game Approach",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper formulates the interaction between the fusion center (FC) and users in distributed learning (or federated learning) from the perspective of game theory.\n- The FC adopt zero-determinant (ZD) strategy, associated with which there are some practical issues addressed by the authors.\n- Theoretical analysis on the convergence of the proposed algorithm is presented.\n- The formulation and the results are interesting; however, there are some concerns from the reviewer:\n- What\u2019s the motivation of the users submitting random noninformative signal to the FC instead of just submitting nothing when they decide not to cooperate. Submitting random noninformative signal does not benefit the users but harms the FC.\n- Please explain the state transition matrix \\\\Omega in eq. (3), why it is constructed as it is and why the states are supposed to evolve according to it.\n- Just below eq. (3), the authors use \\\\bar{\\\\Omega} to denote the transition matrix, what is the difference between \\\\Omega and \\\\bar{\\\\Omega}, or it is just a typo?\n- The authors are expected to clearly state the goal of users in playing the game, namely, in each iteration, the users maximize what, the expected long-term reward, or the reward of this iteration.\n- Based on the objective of the users, the author shall show that the users' best response is q* = [1, 1, 1, 1]^T given that the FC adopts ZD strategy.\n- In the Experiments section, the figure referred is Fig 2 rather than Fig 4.\n- SGSU is SGD-SU, typo?\n- Does Pavlov mean the win-stay-lose-switch? If it does, please just use one of these two phrases throughout the paper.\n- From Figure 2(a) and (b), it is shown that the optimality gap is the smallest when the users take tit-for-tat strategy. Does this mean the FC prefers tit-for-tat instead of full-cooperation in order to obtain a favorable solution to optimization problem (1)?\n- This is not consistent with the game, where the FC prefers full-cooperation?\n- Since the problem is formulated as a repeated game, the experiments shall show whether the strategy of the users converges exactly to q* starting from any initial state and action.\n- The reviewer believes (24) admits a closed-form solution, and the computational complexity of (24) is the same as that of (6). Please check this.",
    "review_points_list": [
      "The paper formulates the interaction between the fusion center (FC) and users in distributed learning (or federated learning) from the perspective of game theory.",
      "The FC adopt zero-determinant (ZD) strategy, associated with which there are some practical issues addressed by the authors.",
      "Theoretical analysis on the convergence of the proposed algorithm is presented.",
      "The formulation and the results are interesting; however, there are some concerns from the reviewer:",
      "What\u2019s the motivation of the users submitting random noninformative signal to the FC instead of just submitting nothing when they decide not to cooperate. Submitting random noninformative signal does not benefit the users but harms the FC.",
      "Please explain the state transition matrix \\\\Omega in eq. (3), why it is constructed as it is and why the states are supposed to evolve according to it.",
      "Just below eq. (3), the authors use \\\\bar{\\\\Omega} to denote the transition matrix, what is the difference between \\\\Omega and \\\\bar{\\\\Omega}, or it is just a typo?",
      "The authors are expected to clearly state the goal of users in playing the game, namely, in each iteration, the users maximize what, the expected long-term reward, or the reward of this iteration.",
      "Based on the objective of the users, the author shall show that the users' best response is q* = [1, 1, 1, 1]^T given that the FC adopts ZD strategy.",
      "In the Experiments section, the figure referred is Fig 2 rather than Fig 4.",
      "SGSU is SGD-SU, typo?",
      "Does Pavlov mean the win-stay-lose-switch? If it does, please just use one of these two phrases throughout the paper.",
      "From Figure 2(a) and (b), it is shown that the optimality gap is the smallest when the users take tit-for-tat strategy. Does this mean the FC prefers tit-for-tat instead of full-cooperation in order to obtain a favorable solution to optimization problem (1)?",
      "This is not consistent with the game, where the FC prefers full-cooperation?",
      "Since the problem is formulated as a repeated game, the experiments shall show whether the strategy of the users converges exactly to q* starting from any initial state and action.",
      "The reviewer believes (24) admits a closed-form solution, and the computational complexity of (24) is the same as that of (6). Please check this."
    ]
  },
  {
    "paper_id": "1703.05641v2",
    "submission_id": "uIMwuJHfuLM",
    "submission_title": "Distributed Learning with Strategic Users: A Repeated Game Approach",
    "review_id": "Bel7NM-cSKL",
    "input": {
      "title": "Distributed Learning with Strategic Users: A Repeated Game Approach",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I am mostly concerned about the setup (line 64-line 74).\n- It is unclear to me how the authors quantifies the privacy cost and why it is related to the information gain R via a factor V_U between 0 and 1.\n- It seems to me that the information gain R was not used in Algorithm 1. Would the authors explain how R is used? Moreover, the information gain R should vary every time. Is it the case in the paper's setup?\n- Why is the cost of the FC rV_FC related to V_FC via a factor V_FC between 0 and 1? Would the authors explain the intuition behind this?\n- line 72-73: the authors did not specify how each entry in a payoff vector is ordered.\n- It would be beneficial to discuss when Phi_t/Psi_t>=p1/p2, Phi_t/Psi_t>=p3/p4 are satisfied and if they are always satisfied (line 151).\n- I like it that Theorem 2 gives a bound on zeta_t. But there are still some unclear things.\n- how large is sum_{i=1}^{t-1} alpha_i^2 compared to eta^2? The authors should establish that the bound (22a) would not be vacuous.\n- Recall in line 61 that the norm of the gradient is <= ell. This bound is vacuous if the upper bound is just close to ell. The authors may want to compute the expected value of zeta_t and then check if the bound is vacuous.\n- What is Delta_{i,t}?\n- The current form looks pretty complicated. The authors may want to do some asymptotic analysis and present the asymptotic order of each term so that the presentation of the results can also be simplified.",
    "review_points_list": [
      "I am mostly concerned about the setup (line 64-line 74).",
      "It is unclear to me how the authors quantifies the privacy cost and why it is related to the information gain R via a factor V_U between 0 and 1.",
      "It seems to me that the information gain R was not used in Algorithm 1. Would the authors explain how R is used? Moreover, the information gain R should vary every time. Is it the case in the paper's setup?",
      "Why is the cost of the FC rV_FC related to V_FC via a factor V_FC between 0 and 1? Would the authors explain the intuition behind this?",
      "line 72-73: the authors did not specify how each entry in a payoff vector is ordered.",
      "It would be beneficial to discuss when Phi_t/Psi_t>=p1/p2, Phi_t/Psi_t>=p3/p4 are satisfied and if they are always satisfied (line 151).",
      "I like it that Theorem 2 gives a bound on zeta_t. But there are still some unclear things.",
      "how large is sum_{i=1}^{t-1} alpha_i^2 compared to eta^2? The authors should establish that the bound (22a) would not be vacuous.",
      "Recall in line 61 that the norm of the gradient is <= ell. This bound is vacuous if the upper bound is just close to ell. The authors may want to compute the expected value of zeta_t and then check if the bound is vacuous.",
      "What is Delta_{i,t}?",
      "The current form looks pretty complicated. The authors may want to do some asymptotic analysis and present the asymptotic order of each term so that the presentation of the results can also be simplified."
    ]
  },
  {
    "paper_id": "2202.12265v1",
    "submission_id": "yLEcG62ANX",
    "submission_title": "Directed Graph Contrastive Learning",
    "review_id": "tFQOsGbqL7t",
    "input": {
      "title": "Directed Graph Contrastive Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Pros: Clean idea and easy.\n- Neat problem definition and step-by-step description of the intuition and model presentation.\n- The key innovation is constructing all pairs of construct views is superior than a single view with pre-defined parameter.\n- The multi-task curriculum learning formula is well motivated.\n- It is a descent model design reducing the complex intractable expectation problem to a simple multi-task learning problem.\n- Good experimental results and solid result analysis.\n- Good experiments description and open-sourced data and code.\n- Readers should be able to reproduce the results.\n- Cons: Novelty and significance is kind of limited.\n- First of all, I appreciate the idea and the work presented in the paper, but the contribution for the large machine learning community can be incremental.\n- Digraph Laplacian has been proposed in [1]  and reduce multi-view contrastive learning as a multi-task problem has been explored as well.\n- A combination of the two is kind of natural and straight-forward.\n- It is not clear how does the approach work for edge level problem, e.g, link prediction.\n- The paper presents results on node classification only.\n- It would be more promising if performance on link prediction results are provided.",
    "review_points_list": [
      "Pros: Clean idea and easy.",
      "Neat problem definition and step-by-step description of the intuition and model presentation.",
      "The key innovation is constructing all pairs of construct views is superior than a single view with pre-defined parameter.",
      "The multi-task curriculum learning formula is well motivated.",
      "It is a descent model design reducing the complex intractable expectation problem to a simple multi-task learning problem.",
      "Good experimental results and solid result analysis.",
      "Good experiments description and open-sourced data and code.",
      "Readers should be able to reproduce the results.",
      "Cons: Novelty and significance is kind of limited.",
      "First of all, I appreciate the idea and the work presented in the paper, but the contribution for the large machine learning community can be incremental.",
      "Digraph Laplacian has been proposed in [1]  and reduce multi-view contrastive learning as a multi-task problem has been explored as well.",
      "A combination of the two is kind of natural and straight-forward.",
      "It is not clear how does the approach work for edge level problem, e.g, link prediction.",
      "The paper presents results on node classification only.",
      "It would be more promising if performance on link prediction results are provided."
    ]
  },
  {
    "paper_id": "2202.12265v1",
    "submission_id": "yLEcG62ANX",
    "submission_title": "Directed Graph Contrastive Learning",
    "review_id": "OsbgO8l0SO",
    "input": {
      "title": "Directed Graph Contrastive Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- First, Laplacian perturbation can also be achieved by adjusting the teleport probability alpha, which in the random walk strategy means probability return to the beginning node from current position.\n- However, it means that we manually add an edge from current node to the starting node when alpha doesn\u2019t equal to 0 so that we have a chance to return back.\n- And in this perspective, Laplacian perturbation also equals to change the digraph structure.\n- Second, since Laplacian perturbation also changes the digraph structure like other perturbation strategies do, the reviewer does not agree with the opinion that DiGCL provides more contrastive views than other existing models.\n- Theoretically, by using different perturbation strategy and scale, one can get different views as many as one wants.\n- So DiGCL doesn\u2019t provides more views than other models although it does offer many contrastive views.\n- Third, pacing function takes effect by automatically adjusting the difficulty scores along with training proceeding,\n- while pacing function relies heavily on the pre-defined parameters such as starting and ending difficulty scores, step size and even the type of pacing functions.\n- So, it is hard to agree with the opinion that DiGCL doesn\u2019t rely on the pre-defined parameters.\n- In my opinion, DiGCL depends heavily on the pre-defined parameters like other models do.\n- Finally, I did not find much relationship between DiGCL with directed graphs.\n- That is, it is not specifically designed for directed networks.\n- There are some typos such as the link to Table 2, page 6th\n- and some prove mistakes such as equation 5.",
    "review_points_list": [
      "First, Laplacian perturbation can also be achieved by adjusting the teleport probability alpha, which in the random walk strategy means probability return to the beginning node from current position.",
      "However, it means that we manually add an edge from current node to the starting node when alpha doesn\u2019t equal to 0 so that we have a chance to return back.",
      "And in this perspective, Laplacian perturbation also equals to change the digraph structure.",
      "Second, since Laplacian perturbation also changes the digraph structure like other perturbation strategies do, the reviewer does not agree with the opinion that DiGCL provides more contrastive views than other existing models.",
      "Theoretically, by using different perturbation strategy and scale, one can get different views as many as one wants.",
      "So DiGCL doesn\u2019t provides more views than other models although it does offer many contrastive views.",
      "Third, pacing function takes effect by automatically adjusting the difficulty scores along with training proceeding,",
      "while pacing function relies heavily on the pre-defined parameters such as starting and ending difficulty scores, step size and even the type of pacing functions.",
      "So, it is hard to agree with the opinion that DiGCL doesn\u2019t rely on the pre-defined parameters.",
      "In my opinion, DiGCL depends heavily on the pre-defined parameters like other models do.",
      "Finally, I did not find much relationship between DiGCL with directed graphs.",
      "That is, it is not specifically designed for directed networks.",
      "There are some typos such as the link to Table 2, page 6th",
      "and some prove mistakes such as equation 5."
    ]
  },
  {
    "paper_id": "2202.12265v1",
    "submission_id": "yLEcG62ANX",
    "submission_title": "Directed Graph Contrastive Learning",
    "review_id": "11jF54uTQd",
    "input": {
      "title": "Directed Graph Contrastive Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The work is well presented and easy to follow.\n- Many theoretical analyses guarantee correctness.\n- Experiments are thorough.\n- Basically, the novel part is to introduce Laplacian perturbation to generate augmentation for contrastive learning with a theoretical guarantee.\n- However, from Table 1 ablation results, it is clear Laplacian perturbation parts actually are not comparable to many baseline approaches.\n- The major performance gain comes from curriculum learning which however is not a very novel technique.\n- The authors blend many techniques in the work. This makes the contribution not very clear.\n- I would suggest the authors isolate the contributions.",
    "review_points_list": [
      "The work is well presented and easy to follow.",
      "Many theoretical analyses guarantee correctness.",
      "Experiments are thorough.",
      "Basically, the novel part is to introduce Laplacian perturbation to generate augmentation for contrastive learning with a theoretical guarantee.",
      "However, from Table 1 ablation results, it is clear Laplacian perturbation parts actually are not comparable to many baseline approaches.",
      "The major performance gain comes from curriculum learning which however is not a very novel technique.",
      "The authors blend many techniques in the work. This makes the contribution not very clear.",
      "I would suggest the authors isolate the contributions."
    ]
  },
  {
    "paper_id": "1712.05134v2",
    "submission_id": "yr7nrY18Xu",
    "submission_title": "Learning and Generalization in RNNs",
    "review_id": "R0yyvheU8c",
    "input": {
      "title": "Learning and Generalization in RNNs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors extend the result shown in https://arxiv.org/pdf/1811.04918.pdf to recurrent neural networks.\n- A wide enough RNN can learn any function from sequence input space (i.e. R^(d*L), where d is the input dimension and L is the sequence length) to output space, so long as it can be parametrized by a neural network with one hidden layer and smooth activation.\n- RNNs are limited to a constant function between input space and hidden layer, hidden layer at one time-point and the next, and the hidden layer to output.\n- The authors show SGD is in fact able to learn any function from the concept class described above.\n- The proof is obviously very long, but the authors provide a straightforward 'sketch' of the proof, which makes it clear what are the key innovations and ideas that went into it.\n- The authors make note of their contributions beyond other works such as https://arxiv.org/pdf/1902.01028.pdf and https://papers.nips.cc/paper/2019/file/62dad6e273d32235ae02b7d321578ee8-Paper.pdf, which follow a similar formalism.\n- Overall, this work is a critical step in the theoretical analysis of sequential neural networks and I recommend acceptance.",
    "review_points_list": [
      "The authors extend the result shown in https://arxiv.org/pdf/1811.04918.pdf to recurrent neural networks.",
      "A wide enough RNN can learn any function from sequence input space (i.e. R^(d*L), where d is the input dimension and L is the sequence length) to output space, so long as it can be parametrized by a neural network with one hidden layer and smooth activation.",
      "RNNs are limited to a constant function between input space and hidden layer, hidden layer at one time-point and the next, and the hidden layer to output.",
      "The authors show SGD is in fact able to learn any function from the concept class described above.",
      "The proof is obviously very long, but the authors provide a straightforward 'sketch' of the proof, which makes it clear what are the key innovations and ideas that went into it.",
      "The authors make note of their contributions beyond other works such as https://arxiv.org/pdf/1902.01028.pdf and https://papers.nips.cc/paper/2019/file/62dad6e273d32235ae02b7d321578ee8-Paper.pdf, which follow a similar formalism.",
      "Overall, this work is a critical step in the theoretical analysis of sequential neural networks and I recommend acceptance."
    ]
  },
  {
    "paper_id": "1712.05134v2",
    "submission_id": "yr7nrY18Xu",
    "submission_title": "Learning and Generalization in RNNs",
    "review_id": "Yy1aA-lQOlk",
    "input": {
      "title": "Learning and Generalization in RNNs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- In the spirit of many recent papers, the generalization error bound considered here is not a monotonically increasing function of the number of hidden nodes.\n- Instead, as in reference [37], the generalization bound is actually a monotonically decreasing function of the number of hidden nodes, for any fixed dataset size.\n- An interesting and surprising result in this derivation is that the number of hidden nodes is required to be very large: at least polynomial in the sequence length, function class complexity, and output dimension.\n- This result is fundamental to the proof method, because the proof method encodes the entire input sequence into the state vector.\n- I'm actually not sure if this is a strength or a weakness of the paper: it obviously limits the applicability of this result in practical settings, but the purpose of that limitation (the state vector needs to encode the input) is quite interesting, and might cause practitioners to think about the designs of their architectures.\n- The convergence proof depends on similarity between the pseudo-network and the learned network.\n- The pseudo-network and learned network differ if many of the ReLUs have switched on or off during training.\n- Although each step of SGD might switch very few ReLUs, the optimum weights (the end of SGD) might have a completely different set of ReLU activations than the initial set, and in that case, the pseudo-network will be an arbitrarily poor approximation of the true network.\n- In that case, I believe, the convergence proof fails.\n- The requirement that the length is fixed at L is proposed in the text as being 'w.l.o.g.'\n- It is more accurate to say, as the conclusion says, that because of this requirement, the results in this article are only proven for test sequences that are shorter than the longest training sequence.\n- parameterization is sometimes spelled parameterization, sometimes paramterization, sometimes paramtrization\n- OK, we know what you mean, but this seems sloppy.\n- There are other places where spelling or grammar are sloppy.",
    "review_points_list": [
      "In the spirit of many recent papers, the generalization error bound considered here is not a monotonically increasing function of the number of hidden nodes.",
      "Instead, as in reference [37], the generalization bound is actually a monotonically decreasing function of the number of hidden nodes, for any fixed dataset size.",
      "An interesting and surprising result in this derivation is that the number of hidden nodes is required to be very large: at least polynomial in the sequence length, function class complexity, and output dimension.",
      "This result is fundamental to the proof method, because the proof method encodes the entire input sequence into the state vector.",
      "I'm actually not sure if this is a strength or a weakness of the paper: it obviously limits the applicability of this result in practical settings, but the purpose of that limitation (the state vector needs to encode the input) is quite interesting, and might cause practitioners to think about the designs of their architectures.",
      "The convergence proof depends on similarity between the pseudo-network and the learned network.",
      "The pseudo-network and learned network differ if many of the ReLUs have switched on or off during training.",
      "Although each step of SGD might switch very few ReLUs, the optimum weights (the end of SGD) might have a completely different set of ReLU activations than the initial set, and in that case, the pseudo-network will be an arbitrarily poor approximation of the true network.",
      "In that case, I believe, the convergence proof fails.",
      "The requirement that the length is fixed at L is proposed in the text as being 'w.l.o.g.'",
      "It is more accurate to say, as the conclusion says, that because of this requirement, the results in this article are only proven for test sequences that are shorter than the longest training sequence.",
      "parameterization is sometimes spelled parameterization, sometimes paramterization, sometimes paramtrization",
      "OK, we know what you mean, but this seems sloppy.",
      "There are other places where spelling or grammar are sloppy."
    ]
  },
  {
    "paper_id": "1712.05134v2",
    "submission_id": "yr7nrY18Xu",
    "submission_title": "Learning and Generalization in RNNs",
    "review_id": "FwPbB6Sf1pi",
    "input": {
      "title": "Learning and Generalization in RNNs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The work is a natural extension of previous work, the main difference between this work and prior work [1] is the the analysis under a more general concept class and instead of fixing A and B at initialization only B is fixed in this work. The contribution seems marginal as the majority of technical tools were introduced in prior work.\n- The submission seems technically sound and well supported although verifying correctness of all claims will require hundreds of hours to do rigorously and is beyond the capacity of a standard review.\n- I would appreciate a discussion on the practical bounds achieved, i.e. are the bounds meaningful in practice or do they require huge widths that practically make this result no different than those obtained via NTK?\n- The paper is clear and well written. The authors do a good job in interpreting their technical claims.\n- The implications of theorem 3.1 are not clear enough, an example would be very informative, for example in lemma D.4 the bound contains \u03c1^7 where in theorem 3.1 \u03c1 is defined to be \u03c1=100Ld_out, for sequence length 10 and output dimension 1, the value is huge: \u03c1^7=10^21.\n- It seems a bit misleading to present this as analysis in the finite case.\n- I think this paper's significance is incremental as it is mostly technical changes to prior work and the technical tools that constitute a significant contribution were mostly established in [1].\n- The introduction provides background and then shifts to be related work in line 52.\n- Line 97 - why is C_s of sin z O(1) ?\n- Lemma 4.2 - if you set W*=0, doesn't this imply you find a feed-forward NN and not an RNN?\n- Re-randomization 295-305 - what are the assumptions implied by this process? Is it equivalent to having random weights?",
    "review_points_list": [
      "The work is a natural extension of previous work, the main difference between this work and prior work [1] is the the analysis under a more general concept class and instead of fixing A and B at initialization only B is fixed in this work. The contribution seems marginal as the majority of technical tools were introduced in prior work.",
      "The submission seems technically sound and well supported although verifying correctness of all claims will require hundreds of hours to do rigorously and is beyond the capacity of a standard review.",
      "I would appreciate a discussion on the practical bounds achieved, i.e. are the bounds meaningful in practice or do they require huge widths that practically make this result no different than those obtained via NTK?",
      "The paper is clear and well written. The authors do a good job in interpreting their technical claims.",
      "The implications of theorem 3.1 are not clear enough, an example would be very informative, for example in lemma D.4 the bound contains \u03c1^7 where in theorem 3.1 \u03c1 is defined to be \u03c1=100Ld_out, for sequence length 10 and output dimension 1, the value is huge: \u03c1^7=10^21.",
      "It seems a bit misleading to present this as analysis in the finite case.",
      "I think this paper's significance is incremental as it is mostly technical changes to prior work and the technical tools that constitute a significant contribution were mostly established in [1].",
      "The introduction provides background and then shifts to be related work in line 52.",
      "Line 97 - why is C_s of sin z O(1) ?",
      "Lemma 4.2 - if you set W*=0, doesn't this imply you find a feed-forward NN and not an RNN?",
      "Re-randomization 295-305 - what are the assumptions implied by this process? Is it equivalent to having random weights?"
    ]
  },
  {
    "paper_id": "1911.06757v1",
    "submission_id": "w1FvEPcwTnI",
    "submission_title": "Graphical Models in Heavy-Tailed Markets",
    "review_id": "fpupL80il_v",
    "input": {
      "title": "Graphical Models in Heavy-Tailed Markets",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I understand that the lack of constraints on the degree of the nodes may lead to graphs with isolated nodes however, I am not sure whether in real world applications one will always have the number d available. The information on the graph whether it is sparse or dense may be known but the exact number d may not be known. Any other soft constraints to consider here when d is not known?\n- Both theorem 3 and theorem 4 discusses the convergence of the respective algorithms for large $\rho$. But, can author(s) shed some light about any connection with the number of iterations required to achieve the convergence?\n- I am not sure whether in the K-connected components case the number k would be always known. One may has to do an estimation of K at the first stage. Am I missing something?",
    "review_points_list": [
      "I understand that the lack of constraints on the degree of the nodes may lead to graphs with isolated nodes however, I am not sure whether in real world applications one will always have the number d available. The information on the graph whether it is sparse or dense may be known but the exact number d may not be known. Any other soft constraints to consider here when d is not known?",
      "Both theorem 3 and theorem 4 discusses the convergence of the respective algorithms for large $\rho$. But, can author(s) shed some light about any connection with the number of iterations required to achieve the convergence?",
      "I am not sure whether in the K-connected components case the number k would be always known. One may has to do an estimation of K at the first stage. Am I missing something?"
    ]
  },
  {
    "paper_id": "1911.06757v1",
    "submission_id": "w1FvEPcwTnI",
    "submission_title": "Graphical Models in Heavy-Tailed Markets",
    "review_id": "gcEJYtXO8w6",
    "input": {
      "title": "Graphical Models in Heavy-Tailed Markets",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed estimator is not entirely new in the literature, given that t-distribution has been used in graphical models before (see [1]).\n- Also, it is a direct result of well-known maximum-likelihood principle, so deriving such estimator should not be difficult.\n- For the ADMM-type learning algorithm, I acknowledge that there are numbers of technical details to be figured out in order to have the exact algorithm, but at the high level this seems to be a standard application of ADMM recipe.\n- So it seems to me that the novelty of this paper is somewhat limited.\n- In terms of technical quality, though the ADMM algorithm seems straightforward, it is nice to see that the paper proves its convergence to stationary points, which requires some efforts and skills.\n- Regarding the algorithm, one thing that is not clear to me is the reason why the trace regularization term is needed in Eq. (16).\n- Conceptually if we drop the regularization term, the new formulation is still equivalent to problem (16) (in the sense that they would end up with the same set of minimizers if globally optimality could be achieved), as the constraints rank(Theta) = p - k and Theta = Lw are imposed.\n- I understand that due to the nonconvexity, ADMM algorithm could end up with different solutions for the two formulations (with or without the regularization term), but it is not obvious to me that the regularized one could work better or there is a need to introduce it.\n- This regularization seems to add some novelty to this paper, so I hope that either theoretical or empirical comparison could be provided to support it (e.g., faster convergence or better quality of solutions), otherwise the additional computational cost seems not well-justified.\n- For the practical perspective, I like the extensive evaluation of the proposed algorithm on different datasets, showing its usefulness and advantage, but it would be better to extend the comparison beyond the algorithms that just work for Gaussian distributions.\n- Below are a few questions I have for the experiments.\n- 1. For S&P500 stocks, is there a particular reason for choosing the three GICS sectors (Communication Services, Utilities and Real Estate), as opposed to other sectors?\n- 2. Have you considered using some type of residual returns from econometrics literature instead of log returns?\n- If you use GICS sectors as the ground truth for clustering, residual returns may be preferred, as sometimes the co-movement of stock returns is mainly driven by some econometrics factors, which may connect stocks across different sectors.\n- Overall the presentation of the paper is clear.\n- The description of the problem setup and the derivation of the algorithm are easy to follow.\n- The figures shown in the experiments give an nice qualitatively demonstration of the superiority of the algorithm.\n- The proposed algorithm seems to be readily applicable to a few real-world problems, as demonstrated in the experiment section.\n- So it should be a good addition to this area for handling heavy-tailed distributions.",
    "review_points_list": [
      "The proposed estimator is not entirely new in the literature, given that t-distribution has been used in graphical models before (see [1]).",
      "Also, it is a direct result of well-known maximum-likelihood principle, so deriving such estimator should not be difficult.",
      "For the ADMM-type learning algorithm, I acknowledge that there are numbers of technical details to be figured out in order to have the exact algorithm, but at the high level this seems to be a standard application of ADMM recipe.",
      "So it seems to me that the novelty of this paper is somewhat limited.",
      "In terms of technical quality, though the ADMM algorithm seems straightforward, it is nice to see that the paper proves its convergence to stationary points, which requires some efforts and skills.",
      "Regarding the algorithm, one thing that is not clear to me is the reason why the trace regularization term is needed in Eq. (16).",
      "Conceptually if we drop the regularization term, the new formulation is still equivalent to problem (16) (in the sense that they would end up with the same set of minimizers if globally optimality could be achieved), as the constraints rank(Theta) = p - k and Theta = Lw are imposed.",
      "I understand that due to the nonconvexity, ADMM algorithm could end up with different solutions for the two formulations (with or without the regularization term), but it is not obvious to me that the regularized one could work better or there is a need to introduce it.",
      "This regularization seems to add some novelty to this paper, so I hope that either theoretical or empirical comparison could be provided to support it (e.g., faster convergence or better quality of solutions), otherwise the additional computational cost seems not well-justified.",
      "For the practical perspective, I like the extensive evaluation of the proposed algorithm on different datasets, showing its usefulness and advantage, but it would be better to extend the comparison beyond the algorithms that just work for Gaussian distributions.",
      "Below are a few questions I have for the experiments.",
      "1. For S&P500 stocks, is there a particular reason for choosing the three GICS sectors (Communication Services, Utilities and Real Estate), as opposed to other sectors?",
      "2. Have you considered using some type of residual returns from econometrics literature instead of log returns?",
      "If you use GICS sectors as the ground truth for clustering, residual returns may be preferred, as sometimes the co-movement of stock returns is mainly driven by some econometrics factors, which may connect stocks across different sectors.",
      "Overall the presentation of the paper is clear.",
      "The description of the problem setup and the derivation of the algorithm are easy to follow.",
      "The figures shown in the experiments give an nice qualitatively demonstration of the superiority of the algorithm.",
      "The proposed algorithm seems to be readily applicable to a few real-world problems, as demonstrated in the experiment section.",
      "So it should be a good addition to this area for handling heavy-tailed distributions."
    ]
  },
  {
    "paper_id": "1911.06757v1",
    "submission_id": "w1FvEPcwTnI",
    "submission_title": "Graphical Models in Heavy-Tailed Markets",
    "review_id": "K5-yqx6NC1n",
    "input": {
      "title": "Graphical Models in Heavy-Tailed Markets",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper addresses an important problem of designing graph learning algorithms under heavy-tailed data distributions which is relevant in the financial domain but challenging due to its non-convex nature.\n- The convergence of proposed algorithms is analytically proven\n- Simulations suggest better performance compared to existing algorithms.\n- The paper is written well and easy to understand\n- The mathematical details are clear",
    "review_points_list": [
      "The paper addresses an important problem of designing graph learning algorithms under heavy-tailed data distributions which is relevant in the financial domain but challenging due to its non-convex nature.",
      "The convergence of proposed algorithms is analytically proven",
      "Simulations suggest better performance compared to existing algorithms.",
      "The paper is written well and easy to understand",
      "The mathematical details are clear"
    ]
  },
  {
    "paper_id": "2211.09619v5",
    "submission_id": "x6tV8QhHjs1",
    "submission_title": "Online Learning and Control of Complex Dynamical Systems from Sensory Input",
    "review_id": "enbKA43lq6",
    "input": {
      "title": "Online Learning and Control of Complex Dynamical Systems from Sensory Input",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed pipeline seems reasonable.\n- The method is evaluated on three classical control problems only.\n- In my opinion, a NeurIPS paper needs more competitive examples.\n- It is a bit too much to call cart-pole/(double) pendulum \u201ccomplex dynamical systems\u201d in the title/abstract/introduction.\n- Please consider toning down the writing in title/abstract/introduction.\n- The discussion on Eqn. (3) and (5) would be clearer if some context about the dimension of n and m could be given.\n- As far as I understand, Eqn. (3) and (5) are two quite different optimization problems that should be used in different scenarios:\n- If AZ_1 = Z_2 is an under-determined system (e.g., n >> m), then Eqn. (5) is preferred.\n- On the other hand, if AZ_1 = Z_2 is an overdetermined system (n << m), one should stick to Eqn. (3) because the equality condition AZ_1 = Z_2 in Eqn. (5) may not be feasible at all.\n- Which case is this paper faced with?\n- From what I understand, all three examples (cart-pole, pendulum, and double pendulum) deal with 2D dynamics only.\n- I would like to see a 3D example (e.g., quadrotor, ant, cheetah, or humanoid robots) in simulation, and more importantly, I am curious to see if the pipeline from video frames to embedded space still works for a 3D task.\n- I would guess this would create some additional challenges due to the ambiguities in understanding 3D scenes from 2D images.",
    "review_points_list": [
      "The proposed pipeline seems reasonable.",
      "The method is evaluated on three classical control problems only.",
      "In my opinion, a NeurIPS paper needs more competitive examples.",
      "It is a bit too much to call cart-pole/(double) pendulum \u201ccomplex dynamical systems\u201d in the title/abstract/introduction.",
      "Please consider toning down the writing in title/abstract/introduction.",
      "The discussion on Eqn. (3) and (5) would be clearer if some context about the dimension of n and m could be given.",
      "As far as I understand, Eqn. (3) and (5) are two quite different optimization problems that should be used in different scenarios:",
      "If AZ_1 = Z_2 is an under-determined system (e.g., n >> m), then Eqn. (5) is preferred.",
      "On the other hand, if AZ_1 = Z_2 is an overdetermined system (n << m), one should stick to Eqn. (3) because the equality condition AZ_1 = Z_2 in Eqn. (5) may not be feasible at all.",
      "Which case is this paper faced with?",
      "From what I understand, all three examples (cart-pole, pendulum, and double pendulum) deal with 2D dynamics only.",
      "I would like to see a 3D example (e.g., quadrotor, ant, cheetah, or humanoid robots) in simulation, and more importantly, I am curious to see if the pipeline from video frames to embedded space still works for a 3D task.",
      "I would guess this would create some additional challenges due to the ambiguities in understanding 3D scenes from 2D images."
    ]
  },
  {
    "paper_id": "2211.09619v5",
    "submission_id": "x6tV8QhHjs1",
    "submission_title": "Online Learning and Control of Complex Dynamical Systems from Sensory Input",
    "review_id": "94fVaVojtj",
    "input": {
      "title": "Online Learning and Control of Complex Dynamical Systems from Sensory Input",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think that this paper is interested and could be accepted for NeurIPS, however there are some improvements that could be done.\n- Discussion of algorithmic limitations. Experiments could be extended to higher DOF control systems to address this issue.\n- Failures/problems with auto-encoder should be mentioned, how/when do these effect the introduced approach?\n- In 3.4 how would the approach work if one were learning and controlling at the same time?\n- How would some of the hyperparameters influence the results if not specified well? e.g. h, \\rho,\n- How would the approach work if B(x) also depended on x, with x the image or if B(z), if z is the latent variable?\n- In control theory, the control affine dynamics x_{t+1} = A(x) x_{t} + B(x) u_{t} is very popular.\n- How does minimizing (12) work together with the least squares estimation for A, B?\n- Maybe including algorithm (with the full loop) could clarify this.\n- Koopman operator theory seems almost tangential to the introduced approach.\n- How does this theory influence/guide the introduced approximate approach?\n- When could the approximations be problematic, does the theory offer any insights?\n- Comparisons: are there other control/model learning papers (also those that don't use autoencoders?) that work on images? Could these be included in the comparisons?\n- The title is too general, please change to restrict to the specific method that is introduced (adaptively learning latent linear models from images).\n- There are a few mistakes, some hindering the readability, please go over the manuscript carefully.\n- Captions are not adequate, the figures need to be self-explanatory. Check also line 251 for missing figure.\n- After reading the rebuttal and re-reading the paper, I still think that the paper can be accepted.\n- The authors have replied well to most points raised also.\n- However I cannot raise my score more because one of my main concerns, that of the Koopman operator theory not guiding the introduced methodology, was not answered sufficiently.\n- For future work (regardless whether the paper is accepted or not), I would advise the authors to look at when or if Koopman operator theory could guide the design of approximate frameworks.\n- When could features be sufficient for a control task?\n- Can we know if by constraining the features and the dynamics model within some parametric form + dimensionality, we are not sacrificing much (i.e. staying 'close' to the operator P in some metric?)",
    "review_points_list": [
      "I think that this paper is interested and could be accepted for NeurIPS, however there are some improvements that could be done.",
      "Discussion of algorithmic limitations. Experiments could be extended to higher DOF control systems to address this issue.",
      "Failures/problems with auto-encoder should be mentioned, how/when do these effect the introduced approach?",
      "In 3.4 how would the approach work if one were learning and controlling at the same time?",
      "How would some of the hyperparameters influence the results if not specified well? e.g. h, \\rho,",
      "How would the approach work if B(x) also depended on x, with x the image or if B(z), if z is the latent variable?",
      "In control theory, the control affine dynamics x_{t+1} = A(x) x_{t} + B(x) u_{t} is very popular.",
      "How does minimizing (12) work together with the least squares estimation for A, B?",
      "Maybe including algorithm (with the full loop) could clarify this.",
      "Koopman operator theory seems almost tangential to the introduced approach.",
      "How does this theory influence/guide the introduced approximate approach?",
      "When could the approximations be problematic, does the theory offer any insights?",
      "Comparisons: are there other control/model learning papers (also those that don't use autoencoders?) that work on images? Could these be included in the comparisons?",
      "The title is too general, please change to restrict to the specific method that is introduced (adaptively learning latent linear models from images).",
      "There are a few mistakes, some hindering the readability, please go over the manuscript carefully.",
      "Captions are not adequate, the figures need to be self-explanatory. Check also line 251 for missing figure.",
      "After reading the rebuttal and re-reading the paper, I still think that the paper can be accepted.",
      "The authors have replied well to most points raised also.",
      "However I cannot raise my score more because one of my main concerns, that of the Koopman operator theory not guiding the introduced methodology, was not answered sufficiently.",
      "For future work (regardless whether the paper is accepted or not), I would advise the authors to look at when or if Koopman operator theory could guide the design of approximate frameworks.",
      "When could features be sufficient for a control task?",
      "Can we know if by constraining the features and the dynamics model within some parametric form + dimensionality, we are not sacrificing much (i.e. staying 'close' to the operator P in some metric?)"
    ]
  },
  {
    "paper_id": "2211.09619v5",
    "submission_id": "x6tV8QhHjs1",
    "submission_title": "Online Learning and Control of Complex Dynamical Systems from Sensory Input",
    "review_id": "lKiMJ7bu_YO",
    "input": {
      "title": "Online Learning and Control of Complex Dynamical Systems from Sensory Input",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The importance of online nonlinear control problem is clear and should be studied.\n- However, for this work, the reviewer has several major concerns.\n- The overall approach is very similar to embed to control [https://arxiv.org/pdf/1506.07365.pdf].\n- Embed to control primarily considers locally linear model over latent space, but it also mentions that it can be easily applied to globally linear cases.\n- It tackles the problem of controlling agents from raw image inputs and studies the empirical results thoroughly.\n- Therefore, except for the fact that the current work explicitly says it is doing online updates, the reviewer hardly sees any difference from the line of work mentioned above.  (see [https://arxiv.org/pdf/1910.08264.pdf] as well)\n- For online update aspects; the difficulty of online learning for control problems basically stems from the difficulty of exploration.\n- Without exploration, for example, [https://arxiv.org/pdf/1703.04680.pdf] this work studies convergence of EDMD under certain conditions, and it is straightforward to use this idea to study the trade-off between the amount of data and approximation accuracy, which can then be used for robust control for example.\n- Also, [https://arxiv.org/pdf/1906.05194.pdf] this work already studies active learning of Koopman operator for optimal control problem under certain conditions, which is basically about the online learning.\n- If the current work considers so carefully about the online learning problem either experimentally or theoretically that it gives us more insights than the line of work mentioned above, those should be clearly stated (the reviewer thinks it is not clarified in the current form)\n- The author(s) claim that this work is for controlling complex dynamical systems; however, as long as the underlying dynamics is pendulum, it would be hard to justify this claim.\n- Also, it is not always possible to write a nonlinear controlled system by  z_t+1 = Az_t + Bu+t even if the space of z is carefully selected.  (B should be dependent on x in general)\n- The advantage of this linear model is the ease of computing optimal control using Riccati equation; however, if this transformation cannot be applied to general nonlinear systems, it is hard to say that this formulation can be applied to complex dynamical systems.\n- Then, what are the advantages of this approach over existing model-based RL (which includes online algorithm as well)?\n- Here are some minor comments\n- line 251; what is \"??\" here?\n- there are some minor typos, please check them again.",
    "review_points_list": [
      "The importance of online nonlinear control problem is clear and should be studied.",
      "However, for this work, the reviewer has several major concerns.",
      "The overall approach is very similar to embed to control [https://arxiv.org/pdf/1506.07365.pdf].",
      "Embed to control primarily considers locally linear model over latent space, but it also mentions that it can be easily applied to globally linear cases.",
      "It tackles the problem of controlling agents from raw image inputs and studies the empirical results thoroughly.",
      "Therefore, except for the fact that the current work explicitly says it is doing online updates, the reviewer hardly sees any difference from the line of work mentioned above.  (see [https://arxiv.org/pdf/1910.08264.pdf] as well)",
      "For online update aspects; the difficulty of online learning for control problems basically stems from the difficulty of exploration.",
      "Without exploration, for example, [https://arxiv.org/pdf/1703.04680.pdf] this work studies convergence of EDMD under certain conditions, and it is straightforward to use this idea to study the trade-off between the amount of data and approximation accuracy, which can then be used for robust control for example.",
      "Also, [https://arxiv.org/pdf/1906.05194.pdf] this work already studies active learning of Koopman operator for optimal control problem under certain conditions, which is basically about the online learning.",
      "If the current work considers so carefully about the online learning problem either experimentally or theoretically that it gives us more insights than the line of work mentioned above, those should be clearly stated (the reviewer thinks it is not clarified in the current form)",
      "The author(s) claim that this work is for controlling complex dynamical systems; however, as long as the underlying dynamics is pendulum, it would be hard to justify this claim.",
      "Also, it is not always possible to write a nonlinear controlled system by  z_t+1 = Az_t + Bu+t even if the space of z is carefully selected.  (B should be dependent on x in general)",
      "The advantage of this linear model is the ease of computing optimal control using Riccati equation; however, if this transformation cannot be applied to general nonlinear systems, it is hard to say that this formulation can be applied to complex dynamical systems.",
      "Then, what are the advantages of this approach over existing model-based RL (which includes online algorithm as well)?",
      "Here are some minor comments",
      "line 251; what is \"??\" here?",
      "there are some minor typos, please check them again."
    ]
  },
  {
    "paper_id": "2504.03740v1",
    "submission_id": "uY-XMIbyXec",
    "submission_title": "Shift-Robust GNNs: Overcoming the Limitations of Localized Graph Training data",
    "review_id": "ZEaYz7Kkhc6",
    "input": {
      "title": "Shift-Robust GNNs: Overcoming the Limitations of Localized Graph Training data",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The problem of addressing distributional shifts between training and test is important in machine learning but it is less addressed in the geometric (graph) machine learning.\n- The paper has clear merit that tackles such problems with the simple approach SR-GNN and well-designed experiments.\n- Experimental results show that the proposed SR-GNN clearly handles the problem of distribution shift in semi-supervised node classification tasks with imbalanced data.\n- The only concern I have is about the fairness of evaluation.\n- SR-GNN seems to use additional input $Z_{IID}$, which are the representations of unlabeled data sampled from the unifying set of training and test dataset.\n- However, other baselines only consider input from the biased distribution.\n- Is it a fair evaluation?\n- I think authors should include additional baselines that also consider features from unbiased samples to highlight the advantage of SR-GNN in the domain adaptation setting.\n- 1. typo - line 62 (that that -> that)\n- It will be better to include axis labels in Figure 1.\n- In addition, it seems ambiguous to see relations between F1 and CMD only with Figure 1.\n- Would you consider adding any metric such as the Pearson correlation coefficient?\n- Ganin et al., 'Domain-Adversarial Training of Neural Networks', JMLR 2016.",
    "review_points_list": [
      "The problem of addressing distributional shifts between training and test is important in machine learning but it is less addressed in the geometric (graph) machine learning.",
      "The paper has clear merit that tackles such problems with the simple approach SR-GNN and well-designed experiments.",
      "Experimental results show that the proposed SR-GNN clearly handles the problem of distribution shift in semi-supervised node classification tasks with imbalanced data.",
      "The only concern I have is about the fairness of evaluation.",
      "SR-GNN seems to use additional input $Z_{IID}$, which are the representations of unlabeled data sampled from the unifying set of training and test dataset.",
      "However, other baselines only consider input from the biased distribution.",
      "Is it a fair evaluation?",
      "I think authors should include additional baselines that also consider features from unbiased samples to highlight the advantage of SR-GNN in the domain adaptation setting.",
      "1. typo - line 62 (that that -> that)",
      "It will be better to include axis labels in Figure 1.",
      "In addition, it seems ambiguous to see relations between F1 and CMD only with Figure 1.",
      "Would you consider adding any metric such as the Pearson correlation coefficient?",
      "Ganin et al., 'Domain-Adversarial Training of Neural Networks', JMLR 2016."
    ]
  },
  {
    "paper_id": "2504.03740v1",
    "submission_id": "uY-XMIbyXec",
    "submission_title": "Shift-Robust GNNs: Overcoming the Limitations of Localized Graph Training data",
    "review_id": "4Qo2I5AX-vm",
    "input": {
      "title": "Shift-Robust GNNs: Overcoming the Limitations of Localized Graph Training data",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The introduction section is well-written and provides good background information.\n- The methodology needs more detailed explanations for better understanding.\n- The results section lacks clear visualizations to support the findings mentioned.\n- It would be beneficial to include a comparison with other existing studies in the discussion.\n- Overall, the conclusion does a good job summarizing the key points discussed throughout the paper.",
    "review_points_list": [
      "The introduction section is well-written and provides good background information.",
      "The methodology needs more detailed explanations for better understanding.",
      "The results section lacks clear visualizations to support the findings mentioned.",
      "It would be beneficial to include a comparison with other existing studies in the discussion.",
      "Overall, the conclusion does a good job summarizing the key points discussed throughout the paper."
    ]
  },
  {
    "paper_id": "2504.03740v1",
    "submission_id": "uY-XMIbyXec",
    "submission_title": "Shift-Robust GNNs: Overcoming the Limitations of Localized Graph Training data",
    "review_id": "85lTfIAAueQ",
    "input": {
      "title": "Shift-Robust GNNs: Overcoming the Limitations of Localized Graph Training data",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper first considers the distributional shift for standard GNN models where training nodes are very biased. Since the problem is new, the proposed algorithm also has novelty.\n- This paper is the first work that considers biased training nodes in GNN training. The proposed SR-GNN framework is intuitive, and the performance of SR-GNN is evaluated with three real graph data.\n- However, the experimental setting has some limitations.\n- First of all, the biased setting is artificial. To motivate this paper's bias problem, the authors should provide some real examples where the labeled nodes really have the biased property.\n- The main component of the proposed framework is not fully justified. Eq. (10) is the objective function of the proposed framework. In the objective function, weight $\\beta_i$ and distance $d$ are crucial for the performance. Although there are many possible candidates for computing $\\beta_i$ and $d$, this paper did not compare with other methods for finding $\\beta_i$ and $d.\n- As the authors also mentioned, it would be much nice to consider some more particular kinds of distribution shifts.\n- This paper is easy to read.\n- This paper is the first work considering training bias in GNNs. I think many follow-up works are likely to refer to this work.",
    "review_points_list": [
      "This paper first considers the distributional shift for standard GNN models where training nodes are very biased. Since the problem is new, the proposed algorithm also has novelty.",
      "This paper is the first work that considers biased training nodes in GNN training. The proposed SR-GNN framework is intuitive, and the performance of SR-GNN is evaluated with three real graph data.",
      "However, the experimental setting has some limitations.",
      "First of all, the biased setting is artificial. To motivate this paper's bias problem, the authors should provide some real examples where the labeled nodes really have the biased property.",
      "The main component of the proposed framework is not fully justified. Eq. (10) is the objective function of the proposed framework. In the objective function, weight $\\beta_i$ and distance $d$ are crucial for the performance. Although there are many possible candidates for computing $\\beta_i$ and $d$, this paper did not compare with other methods for finding $\\beta_i$ and $d.",
      "As the authors also mentioned, it would be much nice to consider some more particular kinds of distribution shifts.",
      "This paper is easy to read.",
      "This paper is the first work considering training bias in GNNs. I think many follow-up works are likely to refer to this work."
    ]
  },
  {
    "paper_id": "2504.03740v1",
    "submission_id": "uY-XMIbyXec",
    "submission_title": "Shift-Robust GNNs: Overcoming the Limitations of Localized Graph Training data",
    "review_id": "8uix2U7beo2",
    "input": {
      "title": "Shift-Robust GNNs: Overcoming the Limitations of Localized Graph Training data",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- GNNs, as many ML approaches, suffer from overfitting to the distribution of the training data. This typically arises in graph-based approaches when the nodes used for labeling in SSL are not IID.\n- A discussion on the connectedness of the graph would be useful.\n- Depending on the dataset size, the graph might not be fully connected if the two classes are very far apart in the representation space $Z$. Would that be a problem? If yes, how to avoid it?\n- There are many different types of distributional shift, but the one considered here seems to be tightly related to the covariate shift where only the distribution of the covariates (here one can think of the representation $Z$ instead of the input $X$) varies while the conditional stays the same.\n- I don\u2019t think there is any reference in the paper on this. Could the authors extend on this similarity, or if not, the differences? Would the authors have a reference for the representation shift as defined on L132-133? Could this approach be used for other types of distributional shifts?\n- The locality aspect is not very clear to me. Would this be equivalent to sampling in the presence of unbalanced classes? What is the difference between the two? The locality aspect makes me think in spatial terms rather than imbalance.\n- L21: varying exactly \u2013 not straightforward, maybe \u201cdecide\u201d\n- L23: difference\n- L26: most works\n- L27: which \u201cthis\u201d?\n- Both distribution shift and distributional shift are used\n- L66: propose a\n- L87: why unlabeled in brackets?\n- L98: to\n- L102: F not defined\n- $M$ is used both for the training data size and the labeled data size. In SSL, I understand the training dataset to be larger than the labeled dataset so the two should be different. Maybe I am missing smth?\n- L140: $K$ -> $k$\n- L148: $z_M$\n- Fig. 1: ideally add labels for the axis. For the Cora dataset it\u2019s difficult to see that the performance degrades as a function of CMD, it looks fairly uniformly distributed to me.\n- CMD: why not combine all moments under the sum, why keep the first moment separate, it would be more intuitive to use $c_1$ instead of expectation.\n- L170: what do the \u2018 represent?\n- L179: distinct different\n- L183: should it be $A^K$ instead of k?\n- Eq 8 and 10: is there a $\rmsum$ missing?\n- Eq 9: missing $\beta_i$ in the second term? Should the min be over all $\beta$, not just $\beta_i$?\n- L198: sum is over i not $\rmalpha_i$?\n- L203: what is $l_i$? should it be $y_i$?\n- L223: repeatable -> reproducible?\n- L234-238: How is the number of nodes needed per label known in advance (=enough number of nodes per label)?\n- Could you describe a bit the APPNP model and ideally define all the acronyms before using (DGI, GAT, etc)?\n- L271: how is $h_i$ used here?\n- Define Micro-F1 and Macro-F1\n- Check spelling: lineared, ppr -> PPR\n- Notations: check for A, E, F, \\Theta \u2013 sometimes bold, sometimes normal\n- the paper addresses an important aspect of generalization/extrapolation and suggests a solution to address the bias in SSL using GNNs. The work looks fairly original to me even though I am not an expert in the field.\n- the paper is of good quality with a clear explanation of the theory and clean and thorough experiments.\n- the paper is mostly clearly written with a few exceptions as in my comments above\n- Biases and extrapolation are important challenges and solutions to address them as in the current paper are relevant",
    "review_points_list": [
      "GNNs, as many ML approaches, suffer from overfitting to the distribution of the training data. This typically arises in graph-based approaches when the nodes used for labeling in SSL are not IID.",
      "A discussion on the connectedness of the graph would be useful.",
      "Depending on the dataset size, the graph might not be fully connected if the two classes are very far apart in the representation space $Z$. Would that be a problem? If yes, how to avoid it?",
      "There are many different types of distributional shift, but the one considered here seems to be tightly related to the covariate shift where only the distribution of the covariates (here one can think of the representation $Z$ instead of the input $X$) varies while the conditional stays the same.",
      "I don\u2019t think there is any reference in the paper on this. Could the authors extend on this similarity, or if not, the differences? Would the authors have a reference for the representation shift as defined on L132-133? Could this approach be used for other types of distributional shifts?",
      "The locality aspect is not very clear to me. Would this be equivalent to sampling in the presence of unbalanced classes? What is the difference between the two? The locality aspect makes me think in spatial terms rather than imbalance.",
      "L21: varying exactly \u2013 not straightforward, maybe \u201cdecide\u201d",
      "L23: difference",
      "L26: most works",
      "L27: which \u201cthis\u201d?",
      "Both distribution shift and distributional shift are used",
      "L66: propose a",
      "L87: why unlabeled in brackets?",
      "L98: to",
      "L102: F not defined",
      "$M$ is used both for the training data size and the labeled data size. In SSL, I understand the training dataset to be larger than the labeled dataset so the two should be different. Maybe I am missing smth?",
      "L140: $K$ -> $k$",
      "L148: $z_M$",
      "Fig. 1: ideally add labels for the axis. For the Cora dataset it\u2019s difficult to see that the performance degrades as a function of CMD, it looks fairly uniformly distributed to me.",
      "CMD: why not combine all moments under the sum, why keep the first moment separate, it would be more intuitive to use $c_1$ instead of expectation.",
      "L170: what do the \u2018 represent?",
      "L179: distinct different",
      "L183: should it be $A^K$ instead of k?",
      "Eq 8 and 10: is there a $\rmsum$ missing?",
      "Eq 9: missing $\beta_i$ in the second term? Should the min be over all $\beta$, not just $\beta_i$?",
      "L198: sum is over i not $\rmalpha_i$?",
      "L203: what is $l_i$? should it be $y_i$?",
      "L223: repeatable -> reproducible?",
      "L234-238: How is the number of nodes needed per label known in advance (=enough number of nodes per label)?",
      "Could you describe a bit the APPNP model and ideally define all the acronyms before using (DGI, GAT, etc)?",
      "L271: how is $h_i$ used here?",
      "Define Micro-F1 and Macro-F1",
      "Check spelling: lineared, ppr -> PPR",
      "Notations: check for A, E, F, \\Theta \u2013 sometimes bold, sometimes normal",
      "the paper addresses an important aspect of generalization/extrapolation and suggests a solution to address the bias in SSL using GNNs. The work looks fairly original to me even though I am not an expert in the field.",
      "the paper is of good quality with a clear explanation of the theory and clean and thorough experiments.",
      "the paper is mostly clearly written with a few exceptions as in my comments above",
      "Biases and extrapolation are important challenges and solutions to address them as in the current paper are relevant"
    ]
  },
  {
    "paper_id": "2101.09446v2",
    "submission_id": "xV6ZDMwRspN",
    "submission_title": "Unlabeled Principal Component Analysis",
    "review_id": "h0Dn2V1_-lv",
    "input": {
      "title": "Unlabeled Principal Component Analysis",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I recommend acceptance for the paper.\n- In my opinion it is clearly above the bar in all respects.\n- The problem is convincingly useful, challenging and not really studied so far.\n- The authors put a lot of effort providing not just the raw technical results but also very helpful pedagogical discussion that makes this mathy paper more easily accessible to the ML folk.\n- Motivation: This line of work and this problem in particular is relatively new and not necessarily widely recognized as important.\n- So it was important for the authors to provide convincing motivation.\n- I was happy to see that the introduction provides a solid, clear motivation for the problem with plenty of references.\n- Technically the paper is solid.\n- The authors use unusually heavy algebra to prove their main result, but Section 2 provides a concise, but pedagogical explanation of the algebraic results necessary in the paper.\n- The evaluation is relatively extensive and more than sufficiently thorough.\n- I appreciated the effort that the authors put in evaluating different base methods for the two 'stages' for their UPCA workflow.\n- With the exception of the proposal of Algorithm 2 (an alternative method for unlabelled sensing) the methodology in the paper is completely drawn from the robust PCA and unlabelled sensing literature.\n- I mention this point for completeness, but I think that it is a minor point that does not detract from the paper's value.\n- The strong points mentioned above outweigh this point.\n- Algorithm 2 seems to perform great on the re-identification problem of Section 4.4.\n- On the other hand, it doesn't seem particularly useful in the face experiments of 4.3 (AIEM appears to be both faster and more accurate that Algorithm 2 in the experiment of Figure 4).\n- Can the authors comment a bit on what might be the best conditions to use Algorithm 2 vs AIEM?\n- There is discussion in the main body of the paper on what it means for a solution to be generic in algebraic terms.\n- Can the authors provide some discussion on a few reasonable necessary or sufficient conditions for data matrices to be generic in applications?",
    "review_points_list": [
      "I recommend acceptance for the paper.",
      "In my opinion it is clearly above the bar in all respects.",
      "The problem is convincingly useful, challenging and not really studied so far.",
      "The authors put a lot of effort providing not just the raw technical results but also very helpful pedagogical discussion that makes this mathy paper more easily accessible to the ML folk.",
      "Motivation: This line of work and this problem in particular is relatively new and not necessarily widely recognized as important.",
      "So it was important for the authors to provide convincing motivation.",
      "I was happy to see that the introduction provides a solid, clear motivation for the problem with plenty of references.",
      "Technically the paper is solid.",
      "The authors use unusually heavy algebra to prove their main result, but Section 2 provides a concise, but pedagogical explanation of the algebraic results necessary in the paper.",
      "The evaluation is relatively extensive and more than sufficiently thorough.",
      "I appreciated the effort that the authors put in evaluating different base methods for the two 'stages' for their UPCA workflow.",
      "With the exception of the proposal of Algorithm 2 (an alternative method for unlabelled sensing) the methodology in the paper is completely drawn from the robust PCA and unlabelled sensing literature.",
      "I mention this point for completeness, but I think that it is a minor point that does not detract from the paper's value.",
      "The strong points mentioned above outweigh this point.",
      "Algorithm 2 seems to perform great on the re-identification problem of Section 4.4.",
      "On the other hand, it doesn't seem particularly useful in the face experiments of 4.3 (AIEM appears to be both faster and more accurate that Algorithm 2 in the experiment of Figure 4).",
      "Can the authors comment a bit on what might be the best conditions to use Algorithm 2 vs AIEM?",
      "There is discussion in the main body of the paper on what it means for a solution to be generic in algebraic terms.",
      "Can the authors provide some discussion on a few reasonable necessary or sufficient conditions for data matrices to be generic in applications?"
    ]
  },
  {
    "paper_id": "2101.09446v2",
    "submission_id": "xV6ZDMwRspN",
    "submission_title": "Unlabeled Principal Component Analysis",
    "review_id": "v9HKO2zsBUQ",
    "input": {
      "title": "Unlabeled Principal Component Analysis",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This is an excellent paper in terms of theoretical contribution.\n- In my knowledge, this is the first paper which uses algebraic geometry to have a polynomial solution of robust PCA where the noise if permutation of column entries.\n- Strength:\n- (a) Theorem 3 is very interesting as it shows that the corrupted data matrix admits a partition into a inlier and outlier based on the ground truth column space.\n- This is the main finding that helps to give the two stage proposed algorithm\n- (b) The polynomial two stage algorithm is natural as in the first stage the authors tried to find an estimation of column space.\n- Given an estimation of the column space, using Theorem 3 the authors used a sensing method as second stage to get the partition between inliers and outliers.\n- My main criticism is readability of the paper, please see the comments below\n- (a) The paper is very dense in places and even with a fair knowledge about algebraic geometry the reader may find it difficult to read\n- (i) the authors should separate definition/discussion about Zariski topology in separate paragraph, line 115 - 132 can be  restructured\n- (ii) Theorem 3 should be introduced before and theorem 1 and 2 may be discussed in detail in supp. material\n- (iii) The discussion regarding polynomial root finding starting from line 150 is dense and can be restructured.\n- (iv) The authors did not spend enough lines explaining the polynomial algorithm, for example complexity analysis of Algorithm 2 needs to be there.\n- (b) The experimental results should be cut down as the main contribution is Theorem 3 and the polynomial algorithm.\n- I am willing to strong accept after this restructuring for better readability.",
    "review_points_list": [
      "This is an excellent paper in terms of theoretical contribution.",
      "In my knowledge, this is the first paper which uses algebraic geometry to have a polynomial solution of robust PCA where the noise if permutation of column entries.",
      "Strength:",
      "(a) Theorem 3 is very interesting as it shows that the corrupted data matrix admits a partition into a inlier and outlier based on the ground truth column space.",
      "This is the main finding that helps to give the two stage proposed algorithm",
      "(b) The polynomial two stage algorithm is natural as in the first stage the authors tried to find an estimation of column space.",
      "Given an estimation of the column space, using Theorem 3 the authors used a sensing method as second stage to get the partition between inliers and outliers.",
      "My main criticism is readability of the paper, please see the comments below",
      "(a) The paper is very dense in places and even with a fair knowledge about algebraic geometry the reader may find it difficult to read",
      "(i) the authors should separate definition/discussion about Zariski topology in separate paragraph, line 115 - 132 can be  restructured",
      "(ii) Theorem 3 should be introduced before and theorem 1 and 2 may be discussed in detail in supp. material",
      "(iii) The discussion regarding polynomial root finding starting from line 150 is dense and can be restructured.",
      "(iv) The authors did not spend enough lines explaining the polynomial algorithm, for example complexity analysis of Algorithm 2 needs to be there.",
      "(b) The experimental results should be cut down as the main contribution is Theorem 3 and the polynomial algorithm.",
      "I am willing to strong accept after this restructuring for better readability."
    ]
  },
  {
    "paper_id": "2105.08714v1",
    "submission_id": "x8gM-4nFq9b",
    "submission_title": "Fighting Gradients with Gradients: Dynamic Defenses against Adversarial Attacks",
    "review_id": "oB0W57Yr9KK",
    "input": {
      "title": "Fighting Gradients with Gradients: Dynamic Defenses against Adversarial Attacks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The idea is novel and very interesting.\n- The paper is easy to follow.\n- Experimental results show strong robustness against existing attacks including AutoAttack.\n- The paper considers adaptive attacks.\n- There is a big concern about vulnerability against a kind of data poisoning attacks at test time.\n- The proposed method sequentially updates model parameters, and it is concerning that this type of defense methods could be vulnerable against a kind of data poisoning attacks at test time.\n- Before attacks, between attack steps, and a part of each batch, attackers can feed malicious inputs (e.g., random noises) to make model parameters meaningless.\n- The attackers can also craft inputs to broke model parameters.\n- Is the proposed defense robust against these attacks?\n- It is important to present discussions and experiments for this type of attacks to show the robustness of the proposed method in white-box settings.\n- I would be happy to raise my score in case these points are properly addressed.\n- The word 'step' is sometimes confusing.\n- There are two kinds of steps in the paper: attack steps and dent steps.\n- For example, Figure 1 shows three attack steps for static/dynamic defenses, while 'Step' in Table 3 is dent steps.\n- However, it seems no sufficient explanation about dent steps in the paper.\n- The drawback of dent+ is not clear.\n- In line 148, the authors wrote 'Dent adapts on batches rather than samples. Batch-wise adaptation stabilizes optimization', but Table 1 shows that sample-wise Dent+ achieves better performance.\n- I feel the statement lacks consistency.\n- Readers may think that dent is not necessary as dent+ is better than dent.\n- The difference in the optimizer for Dent and Dent+ is a bit weird.\n- Why do the authors adopt AdaMod with large learning rate for Dent+, and how do you decide the optimizer?",
    "review_points_list": [
      "The idea is novel and very interesting.",
      "The paper is easy to follow.",
      "Experimental results show strong robustness against existing attacks including AutoAttack.",
      "The paper considers adaptive attacks.",
      "There is a big concern about vulnerability against a kind of data poisoning attacks at test time.",
      "The proposed method sequentially updates model parameters, and it is concerning that this type of defense methods could be vulnerable against a kind of data poisoning attacks at test time.",
      "Before attacks, between attack steps, and a part of each batch, attackers can feed malicious inputs (e.g., random noises) to make model parameters meaningless.",
      "The attackers can also craft inputs to broke model parameters.",
      "Is the proposed defense robust against these attacks?",
      "It is important to present discussions and experiments for this type of attacks to show the robustness of the proposed method in white-box settings.",
      "I would be happy to raise my score in case these points are properly addressed.",
      "The word 'step' is sometimes confusing.",
      "There are two kinds of steps in the paper: attack steps and dent steps.",
      "For example, Figure 1 shows three attack steps for static/dynamic defenses, while 'Step' in Table 3 is dent steps.",
      "However, it seems no sufficient explanation about dent steps in the paper.",
      "The drawback of dent+ is not clear.",
      "In line 148, the authors wrote 'Dent adapts on batches rather than samples. Batch-wise adaptation stabilizes optimization', but Table 1 shows that sample-wise Dent+ achieves better performance.",
      "I feel the statement lacks consistency.",
      "Readers may think that dent is not necessary as dent+ is better than dent.",
      "The difference in the optimizer for Dent and Dent+ is a bit weird.",
      "Why do the authors adopt AdaMod with large learning rate for Dent+, and how do you decide the optimizer?"
    ]
  },
  {
    "paper_id": "2105.08714v1",
    "submission_id": "x8gM-4nFq9b",
    "submission_title": "Fighting Gradients with Gradients: Dynamic Defenses against Adversarial Attacks",
    "review_id": "1G6KoBWgmu_",
    "input": {
      "title": "Fighting Gradients with Gradients: Dynamic Defenses against Adversarial Attacks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper is clearly organized and easy to follow.\n- The proposed method (dent) is interesting and reasonable.\n- Extensive experimental results on multiple datasets are provided and the effectiveness of the proposed method is confirmed.\n- The performance of the proposed method (dent) is not stable as the static defense (e.g., adversarial training).\n- When the batch size of the test data becomes smaller, the defense effect will be weakened.\n- Since the adaptation is based on the test data, dent may not be able to handle the test scenarios (e.g., using small test batch size or hard dataset like ImageNet) which are not friendly to the estimation for the sample-wise parameters.\n- Could the authors give more discussion or analysis and make some improvements to the method?\n- The relationship between this method and domain adaptation is not very clear.\n- Could the authors give more explanation about it and how dent improves robust accuracy while maintaining natural accuracy?\n- Lack of further analysis or discussion on the performance using different datasets.\n- More experimental results or discussion about dent's performance on the large dataset (i.e., ImageNet) are encouraged.\n- It seems that the correct reference is missing in line 224.",
    "review_points_list": [
      "This paper is clearly organized and easy to follow.",
      "The proposed method (dent) is interesting and reasonable.",
      "Extensive experimental results on multiple datasets are provided and the effectiveness of the proposed method is confirmed.",
      "The performance of the proposed method (dent) is not stable as the static defense (e.g., adversarial training).",
      "When the batch size of the test data becomes smaller, the defense effect will be weakened.",
      "Since the adaptation is based on the test data, dent may not be able to handle the test scenarios (e.g., using small test batch size or hard dataset like ImageNet) which are not friendly to the estimation for the sample-wise parameters.",
      "Could the authors give more discussion or analysis and make some improvements to the method?",
      "The relationship between this method and domain adaptation is not very clear.",
      "Could the authors give more explanation about it and how dent improves robust accuracy while maintaining natural accuracy?",
      "Lack of further analysis or discussion on the performance using different datasets.",
      "More experimental results or discussion about dent's performance on the large dataset (i.e., ImageNet) are encouraged.",
      "It seems that the correct reference is missing in line 224."
    ]
  },
  {
    "paper_id": "2105.08714v1",
    "submission_id": "x8gM-4nFq9b",
    "submission_title": "Fighting Gradients with Gradients: Dynamic Defenses against Adversarial Attacks",
    "review_id": "LN6IJ2K-wG",
    "input": {
      "title": "Fighting Gradients with Gradients: Dynamic Defenses against Adversarial Attacks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper presents a comprehensive overview of the current state of active learning research.\n- The authors have done an excellent job in summarizing the key ideas and concepts in the field.\n- A clear and concise explanation of the Cluster-Margin algorithm is provided, which is the main contribution of this paper.\n- The authors also explain the theoretical guarantees for the Cluster-MarginV algorithm, which is a more general version of the Cluster-Margin algorithm.\n- The comparison with other algorithms in terms of efficiency is only done based on experiments and does not provide any theoretical insights.",
    "review_points_list": [
      "The paper presents a comprehensive overview of the current state of active learning research.",
      "The authors have done an excellent job in summarizing the key ideas and concepts in the field.",
      "A clear and concise explanation of the Cluster-Margin algorithm is provided, which is the main contribution of this paper.",
      "The authors also explain the theoretical guarantees for the Cluster-MarginV algorithm, which is a more general version of the Cluster-Margin algorithm.",
      "The comparison with other algorithms in terms of efficiency is only done based on experiments and does not provide any theoretical insights."
    ]
  },
  {
    "paper_id": "2105.08714v1",
    "submission_id": "x8gM-4nFq9b",
    "submission_title": "Fighting Gradients with Gradients: Dynamic Defenses against Adversarial Attacks",
    "review_id": "MKzTgQaZuuA",
    "input": {
      "title": "Fighting Gradients with Gradients: Dynamic Defenses against Adversarial Attacks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Major Issues: 1) First of all, modifying the input [1,2] and dynamically modifying the model [3] for defensive purpose has been explored in previous works.\n- The authors should cite these works and be more careful and precise with the claim of:\n- > Line 53 We demonstrate the **first** defense to optimize the model and input during testing for improved robustness.\n- The key design of this work is the proposal of minimizing the Shannon entropy, which confuses me a lot.\n- How come can optimizing the current prediction help find the correct prediction?\n- For an adversarial example that is wrongly classified, wouldn't optimizing the wrong prediction worsen the prediction?\n- To be more clear, from my experience, for an example with label A, if adversarial attacks can modify the example to make the model predict B, and the dent method optimizes the entropy for the adversarial example, it is likely to be in favor of B rather than A.\n- After briefly reading the provided code of cifar10a.py, I think I find a possible reason.\n- What is the accuracy of the attack in the line 28 and does the attack really succeed?\n- This means what is the accuracy if adversarial examples are generated with dynamic model but predict by a static model?\n- If the adversarial example generated on the dynamic model can not fool the static model, then this is an evidence that the attack in the code is not properly implemented.\n- What will happen if we generate adversarial examples on a static model then predict these adversarial examples on dynamic one?\n- I suspect that, in this setting, the dent method will be broken.\n- BTW, to show the effectiveness, [1] also tested on both static and dynamic/randomized model.\n- The authors should follow the same routine.\n- Also notice that, the author claims:\n- > Line154 : Our defense does not rely on shattered gradients\n- This claim is questionable.\n- It seems to me that the dynamic process is not differentiable and may hamper a proper gradient computation.\n- The author should adopt the BPDA in [4] to show it does not suffer from the obfuscated gradient.\n- Also, the author claims that their method is deterministic and thus does not suffer from stochastic gradient problem (Line155).\n- This is somewhat confusing.\n- If the method is **deterministic**, then this method should not be claimed as **dynamic**.\n- Please explain.\n- The evaluations in this work is questionable on several aspects.\n- For robust models, the author omit two of the most important works: TRADES[5] and Adversarial Training[6].\n- Although the models tested in this paper are occasionally built up on these two methods, the author still should provide evaluations on these two important baselines for better comparison.\n- Also, on Table 2, why only provide the detailed results on only two methods?\n- Clearly the authors have the information for other models since they show it on Table1.\n- The presented two methods Wong and Ding are either not the most representative nor have the best performance.\n- As claimed by the author, the methods require batch predictions.\n- What causes this deficit?\n- To me, the modification of the model should not rely on batch information so much since it is stable after training.\n- On Table 8, the author says:\n- > With static batch statistics (\u00d7), small batch sizes are better.\n- > With dynamic \u221abatch statistics (), small batch sizes are worse.\n- What causes this phenomena?\n- For Line 29~32, I understand that adversarial robustness is related to domain adaptation.\n- But how does this fact relate to the method in this work?\n- For Line 36, what does 'adaptive attacks that are aware of its updates' refer to?\n- For Line 135~137, please be more clear?\n- Have dent solve the batch-wise deficiency?\n- For Line 158, what does 'stale gradient' mean?\n- I recommend the author to write an algorithm to show their method more clear.\n- For Line 224, Table what?",
    "review_points_list": [
      "Major Issues: 1) First of all, modifying the input [1,2] and dynamically modifying the model [3] for defensive purpose has been explored in previous works.",
      "The authors should cite these works and be more careful and precise with the claim of:",
      "> Line 53 We demonstrate the **first** defense to optimize the model and input during testing for improved robustness.",
      "The key design of this work is the proposal of minimizing the Shannon entropy, which confuses me a lot.",
      "How come can optimizing the current prediction help find the correct prediction?",
      "For an adversarial example that is wrongly classified, wouldn't optimizing the wrong prediction worsen the prediction?",
      "To be more clear, from my experience, for an example with label A, if adversarial attacks can modify the example to make the model predict B, and the dent method optimizes the entropy for the adversarial example, it is likely to be in favor of B rather than A.",
      "After briefly reading the provided code of cifar10a.py, I think I find a possible reason.",
      "What is the accuracy of the attack in the line 28 and does the attack really succeed?",
      "This means what is the accuracy if adversarial examples are generated with dynamic model but predict by a static model?",
      "If the adversarial example generated on the dynamic model can not fool the static model, then this is an evidence that the attack in the code is not properly implemented.",
      "What will happen if we generate adversarial examples on a static model then predict these adversarial examples on dynamic one?",
      "I suspect that, in this setting, the dent method will be broken.",
      "BTW, to show the effectiveness, [1] also tested on both static and dynamic/randomized model.",
      "The authors should follow the same routine.",
      "Also notice that, the author claims:",
      "> Line154 : Our defense does not rely on shattered gradients",
      "This claim is questionable.",
      "It seems to me that the dynamic process is not differentiable and may hamper a proper gradient computation.",
      "The author should adopt the BPDA in [4] to show it does not suffer from the obfuscated gradient.",
      "Also, the author claims that their method is deterministic and thus does not suffer from stochastic gradient problem (Line155).",
      "This is somewhat confusing.",
      "If the method is **deterministic**, then this method should not be claimed as **dynamic**.",
      "Please explain.",
      "The evaluations in this work is questionable on several aspects.",
      "For robust models, the author omit two of the most important works: TRADES[5] and Adversarial Training[6].",
      "Although the models tested in this paper are occasionally built up on these two methods, the author still should provide evaluations on these two important baselines for better comparison.",
      "Also, on Table 2, why only provide the detailed results on only two methods?",
      "Clearly the authors have the information for other models since they show it on Table1.",
      "The presented two methods Wong and Ding are either not the most representative nor have the best performance.",
      "As claimed by the author, the methods require batch predictions.",
      "What causes this deficit?",
      "To me, the modification of the model should not rely on batch information so much since it is stable after training.",
      "On Table 8, the author says:",
      "> With static batch statistics (\u00d7), small batch sizes are better.",
      "> With dynamic \u221abatch statistics (), small batch sizes are worse.",
      "What causes this phenomena?",
      "For Line 29~32, I understand that adversarial robustness is related to domain adaptation.",
      "But how does this fact relate to the method in this work?",
      "For Line 36, what does 'adaptive attacks that are aware of its updates' refer to?",
      "For Line 135~137, please be more clear?",
      "Have dent solve the batch-wise deficiency?",
      "For Line 158, what does 'stale gradient' mean?",
      "I recommend the author to write an algorithm to show their method more clear.",
      "For Line 224, Table what?"
    ]
  },
  {
    "paper_id": "2105.08714v1",
    "submission_id": "x8gM-4nFq9b",
    "submission_title": "Fighting Gradients with Gradients: Dynamic Defenses against Adversarial Attacks",
    "review_id": "KaROrCzLPJK",
    "input": {
      "title": "Fighting Gradients with Gradients: Dynamic Defenses against Adversarial Attacks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The new perspective on defense at inference time indeed deserves some explorations. This perspective is interesting.\n- comprehensive experiments on CIFAR-10/100 and ImageNet are reported; the experimental results look good.\n- Auto-attack is meant for evaluating a single & static model, which may not be applicable to evaluating dynamic defense. Therefore, authors may consider the adaptive attacks for the robustness evaluations.\n- Inference-time defense may hurdle the speed of the model prediction.\n- The authors implicitly assume adversarial data comes from a different distribution from that of natural data. Could authors elaborate more about it?\n- The authors did not resolve my concerns. Please find my reasons as follows.\n- Auto-attack is meant for evaluating a single & static model, which may not be applicable to evaluating dynamic defense. Therefore, using AA attacks for evaluating the dynamic defense is a factual error.\n- Although there are some discussions of adaptive attacks on dent, those adaptive attacks strategy still cannot convince me enough.",
    "review_points_list": [
      "The new perspective on defense at inference time indeed deserves some explorations. This perspective is interesting.",
      "comprehensive experiments on CIFAR-10/100 and ImageNet are reported; the experimental results look good.",
      "Auto-attack is meant for evaluating a single & static model, which may not be applicable to evaluating dynamic defense. Therefore, authors may consider the adaptive attacks for the robustness evaluations.",
      "Inference-time defense may hurdle the speed of the model prediction.",
      "The authors implicitly assume adversarial data comes from a different distribution from that of natural data. Could authors elaborate more about it?",
      "The authors did not resolve my concerns. Please find my reasons as follows.",
      "Auto-attack is meant for evaluating a single & static model, which may not be applicable to evaluating dynamic defense. Therefore, using AA attacks for evaluating the dynamic defense is a factual error.",
      "Although there are some discussions of adaptive attacks on dent, those adaptive attacks strategy still cannot convince me enough."
    ]
  },
  {
    "paper_id": "2406.12925v2",
    "submission_id": "zweDnxxWRe",
    "submission_title": "Multi-task Learning of Order-Consistent Causal Graphs",
    "review_id": "cncp70Fm6wi",
    "input": {
      "title": "Multi-task Learning of Order-Consistent Causal Graphs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- A quantitative theoretic analysis of sample complexity regarding causal order and union support recovery, which is interesting and novel.\n- An efficient algorithm to estimate the graph.\n- Paper is generally very well-written.\n- Perhaps the most major issue to me is the setting of the problem.\n- Authors consider linear-Gaussian models where all the noise variances are identical, in particular, are set to be 1 among all datasets.\n- The consideration for this choice is from identifiability.\n- However, it is believed (at least I believe) that the condition of identical noise variances is quite restricted in practice, and it is not testable from observations.\n- Consequently, the proposed theory and algorithm may have little use in practice.\n- Authors are encouraged to also consider non-identifiable case.\n- In this case, it might be beneficial to reduce some indeterminacies of the edges in Markov equivalence class, since you have some different but related DAGs?\n- While it is claimed the analysis could easily extend to a more general case where the noise variances are different across datasets, it is not clear how they would affect the structure recovery result.\n- In particular, if a dataset has a small very noise variance while another has a large one, then is the result affected?\n- What if the DAGs do not share the same causal order but can have a very few violations? Can the proposed algorithm return any guaranteed results?\n- The paper is well-written in other parts, but this section seem to omit some import details:\n- 1) running time is not reported.\n- 2) since you have multiple DAGs, it is not clear what DAGs are counted in calculating the metrics (FDR, SHD); are they the average? or simply the result regarding the causal order?\n- 3) standard deviations are not provided.\n- Import baselines are missing:\n- for linear Gaussian models with equal noise variances, a well known method is to check the marginal variances of the variables; the largest one would be the source node; for other variables, apply linear regression with the previous variable and obtain residuals; again check the marginal variances of these residuals and follow the same steps; one would then obtain a causal order.\n- How does this procedure compare with the proposed method, when, e.g., in the second experiment that a single dataset can have a number of samples?\n- It would be also beneficial to consider some more settings: different graph structures and densities; different sample numbers across datasets.\n- I appreciate authors' response which clearly extends the practical use of this work.\n- I have decided to increase my score to 6 (tentatively), and I am also waiting for other reviewers' opinions on the practical usage to see if it is possible to further increase the evaluation.\n- Two followed questions: 1. Even without identifiability of the unique graph, how about thinking about the MEC? i.e., how close the estimated graph could be to the MEC?\n- 2. Please check the followed comment on the mentioned baseline. Sorry for any inconvience.",
    "review_points_list": [
      "A quantitative theoretic analysis of sample complexity regarding causal order and union support recovery, which is interesting and novel.",
      "An efficient algorithm to estimate the graph.",
      "Paper is generally very well-written.",
      "Perhaps the most major issue to me is the setting of the problem.",
      "Authors consider linear-Gaussian models where all the noise variances are identical, in particular, are set to be 1 among all datasets.",
      "The consideration for this choice is from identifiability.",
      "However, it is believed (at least I believe) that the condition of identical noise variances is quite restricted in practice, and it is not testable from observations.",
      "Consequently, the proposed theory and algorithm may have little use in practice.",
      "Authors are encouraged to also consider non-identifiable case.",
      "In this case, it might be beneficial to reduce some indeterminacies of the edges in Markov equivalence class, since you have some different but related DAGs?",
      "While it is claimed the analysis could easily extend to a more general case where the noise variances are different across datasets, it is not clear how they would affect the structure recovery result.",
      "In particular, if a dataset has a small very noise variance while another has a large one, then is the result affected?",
      "What if the DAGs do not share the same causal order but can have a very few violations? Can the proposed algorithm return any guaranteed results?",
      "The paper is well-written in other parts, but this section seem to omit some import details:",
      "1) running time is not reported.",
      "2) since you have multiple DAGs, it is not clear what DAGs are counted in calculating the metrics (FDR, SHD); are they the average? or simply the result regarding the causal order?",
      "3) standard deviations are not provided.",
      "Import baselines are missing:",
      "for linear Gaussian models with equal noise variances, a well known method is to check the marginal variances of the variables; the largest one would be the source node; for other variables, apply linear regression with the previous variable and obtain residuals; again check the marginal variances of these residuals and follow the same steps; one would then obtain a causal order.",
      "How does this procedure compare with the proposed method, when, e.g., in the second experiment that a single dataset can have a number of samples?",
      "It would be also beneficial to consider some more settings: different graph structures and densities; different sample numbers across datasets.",
      "I appreciate authors' response which clearly extends the practical use of this work.",
      "I have decided to increase my score to 6 (tentatively), and I am also waiting for other reviewers' opinions on the practical usage to see if it is possible to further increase the evaluation.",
      "Two followed questions: 1. Even without identifiability of the unique graph, how about thinking about the MEC? i.e., how close the estimated graph could be to the MEC?",
      "2. Please check the followed comment on the mentioned baseline. Sorry for any inconvience."
    ]
  },
  {
    "paper_id": "2406.12925v2",
    "submission_id": "zweDnxxWRe",
    "submission_title": "Multi-task Learning of Order-Consistent Causal Graphs",
    "review_id": "PUtNUTbMZW4",
    "input": {
      "title": "Multi-task Learning of Order-Consistent Causal Graphs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Are the tasks or methods new? - Yes. Authors study the problem of multitask learning of causal ordering which has been previously unexplored to the best of my knowledge.\n- Is it clear how this work differs from previous contributions? - Yes. The setting itself is different from existing ones.\n- Is related work adequately cited? - Yes. I think the work can benefit from referencing additional works.\n- Is the submission technically sound? - Yes. Proofs seem sound although I have not checked in full detail.\n- Are claims well supported (e.g., by theoretical analysis or experimental results)? - Yes. Proofs are provided in the appendix. Empirical validation is provided for synthetic and real-world data.\n- Are the methods used appropriate? - Yes. The theoretical analyses use tools from optimization, linear algebra, and concentration inequalities.\n- Is this a complete piece of work or work in progress? - Complete work.\n- Are the authors careful and honest about evaluating both the strengths and weaknesses of their work? - Discussions on the limitations of the presented approach can be beneficial.\n- Is the submission clearly written? - Yes.\n- Is it well organized? - Yes. I was able to follow the main contributions without issues.\n- Does it adequately inform the reader? - Yes. Experimental details are provided in the appendix. The work is reproducible.\n- Are the results important? - Yes. I think the topic is of interest to the graphical models community.\n- Are others (researchers or practitioners) likely to use the ideas or build on them? - Probably yes.\n- Does the submission address a difficult task in a better way than previous work? - The work can be considered as a first set of results for multitask DAG learning.\n- Does it advance the state of the art in a demonstrable way? - Yes.\n- I believe the work might benefit from a discussion section on the limitations of the results. For instance, Condition 3.3 (Bounded spectrum) might be an assumption that will not work for the high-dimensional case.\n- The statement of Theorem 3.2. has been updated in the appendix, where authors claim that the appendix version is better than the one in the main paper.\n- I think the paper can benefit from referencing works that also have a 'direct' or 'joint' goal instead of separate estimations.\n- Typos: * L51: p was not introduced. * L245: Appendix F not G.",
    "review_points_list": [
      "Are the tasks or methods new? - Yes. Authors study the problem of multitask learning of causal ordering which has been previously unexplored to the best of my knowledge.",
      "Is it clear how this work differs from previous contributions? - Yes. The setting itself is different from existing ones.",
      "Is related work adequately cited? - Yes. I think the work can benefit from referencing additional works.",
      "Is the submission technically sound? - Yes. Proofs seem sound although I have not checked in full detail.",
      "Are claims well supported (e.g., by theoretical analysis or experimental results)? - Yes. Proofs are provided in the appendix. Empirical validation is provided for synthetic and real-world data.",
      "Are the methods used appropriate? - Yes. The theoretical analyses use tools from optimization, linear algebra, and concentration inequalities.",
      "Is this a complete piece of work or work in progress? - Complete work.",
      "Are the authors careful and honest about evaluating both the strengths and weaknesses of their work? - Discussions on the limitations of the presented approach can be beneficial.",
      "Is the submission clearly written? - Yes.",
      "Is it well organized? - Yes. I was able to follow the main contributions without issues.",
      "Does it adequately inform the reader? - Yes. Experimental details are provided in the appendix. The work is reproducible.",
      "Are the results important? - Yes. I think the topic is of interest to the graphical models community.",
      "Are others (researchers or practitioners) likely to use the ideas or build on them? - Probably yes.",
      "Does the submission address a difficult task in a better way than previous work? - The work can be considered as a first set of results for multitask DAG learning.",
      "Does it advance the state of the art in a demonstrable way? - Yes.",
      "I believe the work might benefit from a discussion section on the limitations of the results. For instance, Condition 3.3 (Bounded spectrum) might be an assumption that will not work for the high-dimensional case.",
      "The statement of Theorem 3.2. has been updated in the appendix, where authors claim that the appendix version is better than the one in the main paper.",
      "I think the paper can benefit from referencing works that also have a 'direct' or 'joint' goal instead of separate estimations.",
      "Typos: * L51: p was not introduced. * L245: Appendix F not G."
    ]
  },
  {
    "paper_id": "1712.09948v1",
    "submission_id": "ye-NP0VZtLC",
    "submission_title": "Minimizing Polarization and Disagreement in Social Networks via Link Recommendation",
    "review_id": "eDuWYX3V3qr",
    "input": {
      "title": "Minimizing Polarization and Disagreement in Social Networks via Link Recommendation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- In this work the authors focus on recommending k links in order to minimize polarization and disagreement in social networks.\n- Intuitively, in a recommender system links may connect nodes with similar opinions and thus have low disagreement but incur higher polarization, or nodes with totally different opinions and thus have low polarization but incur higher disagreement.\n- The objective takes into account both terms, and aims to balance between the two.\n- Specifically, the authors rely on the framework of Musco et al. that assumes the Friedkin-Johnsen model of opinion dynamics and defines disagreement as the sum of the squared differences of opinions over all edges, whereas the polarization as the second moment of the opinions centered around 0.\n- Both terms can be nicely expressed using the Laplacian.\n- The authors consider the problem of   minimizing the sum of those terms over all possible recommendations/additions of k edges.\n- The objective is monotone, a statement proved directly from applying the Sherman-Morisson formula.\n- Clearly, there is a straight-forward naive algorithm that checks all possible subsets of cardinality k among the set of possible recommendations Ec.\n- This is infeasible in practice, and thus the authors study the performance of greedy.\n- The authors prove that the resulting optimization problem is neither submodular nor supermodular, so the greedy algorithm is not guaranteed to provide an 1-1/e approximation ratio or an exact solution.\n- They use the results of [5] to characterize the parameters of how \u201cfar\u201d is the objective from being submodular, and provide some insights on how the greedy algorithm behaves; it depends on the graph G, and the graph formed by the possible recommendations that in principal can be the complement of G.\n- The authors also leverage the ideas of Spielman-Srivastava from their work on spectral sparsifiers  that use random projections for fast effective resistance computations in order to speed up the greedy algorithm.\n- Finally they implement their algorithm in Julia (code available in supplement), and test it on a variety of datasets.\n- Some questions to the authors:\n- 1. Unfortunately the approximation guarantees are not easy to interpret. Perhaps you can use some classes of graphs with known spectral guarantees to derive some interesting corollaries (e.g., expander graphs, stochastic blockmodel).\n- 2. Unfortunately none of the datasets contains some true opinion dynamics. Therefore it would have been more interesting to see more distributions other than the uniform.\n- 3. Did you consider the case of directed graphs? The framework of Musco et al. does not seem to be directly applicable there.\n- Post-rebuttal: I thank to the authors for their detailed response. I have upgraded my score.",
    "review_points_list": [
      "In this work the authors focus on recommending k links in order to minimize polarization and disagreement in social networks.",
      "Intuitively, in a recommender system links may connect nodes with similar opinions and thus have low disagreement but incur higher polarization, or nodes with totally different opinions and thus have low polarization but incur higher disagreement.",
      "The objective takes into account both terms, and aims to balance between the two.",
      "Specifically, the authors rely on the framework of Musco et al. that assumes the Friedkin-Johnsen model of opinion dynamics and defines disagreement as the sum of the squared differences of opinions over all edges, whereas the polarization as the second moment of the opinions centered around 0.",
      "Both terms can be nicely expressed using the Laplacian.",
      "The authors consider the problem of   minimizing the sum of those terms over all possible recommendations/additions of k edges.",
      "The objective is monotone, a statement proved directly from applying the Sherman-Morisson formula.",
      "Clearly, there is a straight-forward naive algorithm that checks all possible subsets of cardinality k among the set of possible recommendations Ec.",
      "This is infeasible in practice, and thus the authors study the performance of greedy.",
      "The authors prove that the resulting optimization problem is neither submodular nor supermodular, so the greedy algorithm is not guaranteed to provide an 1-1/e approximation ratio or an exact solution.",
      "They use the results of [5] to characterize the parameters of how \u201cfar\u201d is the objective from being submodular, and provide some insights on how the greedy algorithm behaves; it depends on the graph G, and the graph formed by the possible recommendations that in principal can be the complement of G.",
      "The authors also leverage the ideas of Spielman-Srivastava from their work on spectral sparsifiers  that use random projections for fast effective resistance computations in order to speed up the greedy algorithm.",
      "Finally they implement their algorithm in Julia (code available in supplement), and test it on a variety of datasets.",
      "Some questions to the authors:",
      "1. Unfortunately the approximation guarantees are not easy to interpret. Perhaps you can use some classes of graphs with known spectral guarantees to derive some interesting corollaries (e.g., expander graphs, stochastic blockmodel).",
      "2. Unfortunately none of the datasets contains some true opinion dynamics. Therefore it would have been more interesting to see more distributions other than the uniform.",
      "3. Did you consider the case of directed graphs? The framework of Musco et al. does not seem to be directly applicable there.",
      "Post-rebuttal: I thank to the authors for their detailed response. I have upgraded my score."
    ]
  },
  {
    "paper_id": "1712.09948v1",
    "submission_id": "ye-NP0VZtLC",
    "submission_title": "Minimizing Polarization and Disagreement in Social Networks via Link Recommendation",
    "review_id": "lbKxj0dctz",
    "input": {
      "title": "Minimizing Polarization and Disagreement in Social Networks via Link Recommendation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Novel+interesting opinion dynamics problem\n- Clean analysis of algorithms\n- Empirical results are very good\n- Writing is good for the most part\n- Writing in Section 6 could be clearer\n- Could use better experimental baselines\n- The problem itself seems novel and interesting - similar to [36], but completely different type of analysis\n- The greedy algorithms flow quite naturally from the observation in Lemma 4.1, that P+D index goes down as you add more edges\n- On a side note, this observation was not immediately obvious to me, e.g. if you have a barbell-like graph, with two dense clusters that are not that connected to each other, and you add edges between nodes in the same cluster - I would guess polarization goes up and disagreement goes down, but unclear what happens to P+D\n- The empirical results are also very impressive, showing that your fast algorithm can run on graphs with millions of nodes/edges\n- I only have minor complaints; see below.\n- Section 6: I find the X, X-bar, X-tilde notation (line 252) to be quite confusing\n- Seems easier to just write these formulas out directly without introducing X\u2019s\n- In general this excess of notation makes Section 6 hard to read\n- It should be made explicit that Algorithm 2 does not have any guarantees (eg constant factor approx) unlike Algorithm 1\n- The writing is a bit too slick, making it seem like Algorithm 2 has some global guarantees (eg by mentioning \",\" in the runtime) when it does not\n- I find the baselines in the experiments a bit lacking since none of them use the innate opinions S\n- It would be good to add more baselines that use s\n- Question: Do any results extend to convex combinations of polarization + disagreement?\n- E.g. [36] notes that convex combinations P + rho*D of polarization and disagreement are generally not convex (except for when rho=1)\n- I wonder if that affects Lemma 4.1 at all\n- Line 221: I understand space is limited but it would be interesting to see the approximation guarantee for the naive greedy algorithm written out, since you say in line 223 that it is not satisfactory\n- Line 8 of SpGreedy: I find the interchanging of (I+L)^{-1} and \"\u03a9\" to be confusing notation since they are the same thing\n- In general this is confusing notation throughout the paper\n- Line 233: would be good to define what SDDM means\n- Table 1: What is the k (number of edges added) here? Should be included somewhere, eg in table caption\n- **Nits/typos**:\n- line 41: to greedy -> to a greedy\n- line 161: \u201cin the sequel\u201d unsure what this means\n- line 172: Similar idea -> A similar idea\n- Supplement 1: Should say proof of 4.1, not 3.1\n- Problem 1: I assume E and E_C are disjoint?\n- Line 191: \u201cby the following\u201d -> \u201cin the following\u201d\n- Line 8 of supplement: capitalize \u201cwhen\u201d\n- Line 26 of supplement: L_{W + T} should be L_{W \\/ T}\n- Line 27 of supplement: how did you get the last inequality?",
    "review_points_list": [
      "Novel+interesting opinion dynamics problem",
      "Clean analysis of algorithms",
      "Empirical results are very good",
      "Writing is good for the most part",
      "Writing in Section 6 could be clearer",
      "Could use better experimental baselines",
      "The problem itself seems novel and interesting - similar to [36], but completely different type of analysis",
      "The greedy algorithms flow quite naturally from the observation in Lemma 4.1, that P+D index goes down as you add more edges",
      "On a side note, this observation was not immediately obvious to me, e.g. if you have a barbell-like graph, with two dense clusters that are not that connected to each other, and you add edges between nodes in the same cluster - I would guess polarization goes up and disagreement goes down, but unclear what happens to P+D",
      "The empirical results are also very impressive, showing that your fast algorithm can run on graphs with millions of nodes/edges",
      "I only have minor complaints; see below.",
      "Section 6: I find the X, X-bar, X-tilde notation (line 252) to be quite confusing",
      "Seems easier to just write these formulas out directly without introducing X\u2019s",
      "In general this excess of notation makes Section 6 hard to read",
      "It should be made explicit that Algorithm 2 does not have any guarantees (eg constant factor approx) unlike Algorithm 1",
      "The writing is a bit too slick, making it seem like Algorithm 2 has some global guarantees (eg by mentioning \",\" in the runtime) when it does not",
      "I find the baselines in the experiments a bit lacking since none of them use the innate opinions S",
      "It would be good to add more baselines that use s",
      "Question: Do any results extend to convex combinations of polarization + disagreement?",
      "E.g. [36] notes that convex combinations P + rho*D of polarization and disagreement are generally not convex (except for when rho=1)",
      "I wonder if that affects Lemma 4.1 at all",
      "Line 221: I understand space is limited but it would be interesting to see the approximation guarantee for the naive greedy algorithm written out, since you say in line 223 that it is not satisfactory",
      "Line 8 of SpGreedy: I find the interchanging of (I+L)^{-1} and \"\u03a9\" to be confusing notation since they are the same thing",
      "In general this is confusing notation throughout the paper",
      "Line 233: would be good to define what SDDM means",
      "Table 1: What is the k (number of edges added) here? Should be included somewhere, eg in table caption",
      "**Nits/typos**:",
      "line 41: to greedy -> to a greedy",
      "line 161: \u201cin the sequel\u201d unsure what this means",
      "line 172: Similar idea -> A similar idea",
      "Supplement 1: Should say proof of 4.1, not 3.1",
      "Problem 1: I assume E and E_C are disjoint?",
      "Line 191: \u201cby the following\u201d -> \u201cin the following\u201d",
      "Line 8 of supplement: capitalize \u201cwhen\u201d",
      "Line 26 of supplement: L_{W + T} should be L_{W \\/ T}",
      "Line 27 of supplement: how did you get the last inequality?"
    ]
  },
  {
    "paper_id": "1712.09948v1",
    "submission_id": "ye-NP0VZtLC",
    "submission_title": "Minimizing Polarization and Disagreement in Social Networks via Link Recommendation",
    "review_id": "bTPge3Zrhl",
    "input": {
      "title": "Minimizing Polarization and Disagreement in Social Networks via Link Recommendation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Overall, the paper has a clear and well-structured presentation, which is commendable.\n- The paper presents a novel algorithm, the clustering-marginalization algorithm, which seems to have some interesting properties.\n- However, the evaluation is not comprehensive, as some important aspects like scalability and robustness are not addressed.\n- One of the major concerns I have is the lack of theoretical guarantees for the proposed algorithm.\n- The authors provide some empirical evidence of its performance, but they do not provide any theoretical proof of its correctness or any bounds on its performance.\n- The paper also lacks a clear explanation of what makes this algorithm novel compared to existing methods.\n- It seems to me that this algorithm is just a variation of the core-set algorithm, and the authors could have done a better job in explaining the differences between the two.\n- In addition, I was surprised to see that the authors did not consider any of the other methods that have been proposed for this problem.\n- It seems to me that a more thorough comparison with existing methods would be valuable.\n- Finally, I think the authors could have done a better job of presenting their results in a more detailed and concise manner.",
    "review_points_list": [
      "Overall, the paper has a clear and well-structured presentation, which is commendable.",
      "The paper presents a novel algorithm, the clustering-marginalization algorithm, which seems to have some interesting properties.",
      "However, the evaluation is not comprehensive, as some important aspects like scalability and robustness are not addressed.",
      "One of the major concerns I have is the lack of theoretical guarantees for the proposed algorithm.",
      "The authors provide some empirical evidence of its performance, but they do not provide any theoretical proof of its correctness or any bounds on its performance.",
      "The paper also lacks a clear explanation of what makes this algorithm novel compared to existing methods.",
      "It seems to me that this algorithm is just a variation of the core-set algorithm, and the authors could have done a better job in explaining the differences between the two.",
      "In addition, I was surprised to see that the authors did not consider any of the other methods that have been proposed for this problem.",
      "It seems to me that a more thorough comparison with existing methods would be valuable.",
      "Finally, I think the authors could have done a better job of presenting their results in a more detailed and concise manner."
    ]
  },
  {
    "paper_id": "1712.09948v1",
    "submission_id": "ye-NP0VZtLC",
    "submission_title": "Minimizing Polarization and Disagreement in Social Networks via Link Recommendation",
    "review_id": "6V8T7u9Lie",
    "input": {
      "title": "Minimizing Polarization and Disagreement in Social Networks via Link Recommendation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I find the result showing that polarization+disagreement is close enough to being submodular to give guarantees for approximation interesting!\n- I am a bit disappointed that all these details were pushed to supplemental material, including all proofs as well as even including the definition of curvature and submodularity ratio.\n- The faster approximate version is important to make the method practical.\n- I am not sure if NeurIPS is the right venue for this work, but it is definitely very interesting\n- The work is well-motivated and the authors have done a thorough job in evaluating their method.\n- I found the presentation a bit unclear and the writing could be improved.\n- I am disappointed that there is no comparison with other methods that are more relevant to the problem at hand.\n- I do not think that the results fully support the claims made in the abstract.\n- I think that the method can be further developed to achieve even better results.\n- I am concerned about the computational efficiency of the method, as it seems to be quite expensive.\n- I think that the authors should have explored more thoroughly the implications of the results for the problem being studied.\n- I am not convinced that the results demonstrate the claimed level of improvement in performance.\n- I think that the paper could be improved with more detail on the implementation and evaluation of the algorithm.\n- This is a very interesting paper! The main idea is well-motivated and the results are impressive.\n- I do find some parts of the paper a bit unclear. For example, the authors could have done a better job explaining the intuition behind the algorithm.\n- I am excited about the potential of this method and its applications.\n- I do have some concerns about the limitations of the method.\n- I think the authors did a good job in comparing their method to other existing approaches.\n- I would like to see more experimental results to verify the claims made in the paper.\n- The main contribution of the paper is not entirely clear to me.\n- I find the experimental results to be quite convincing.\n- I am concerned about the lack of theoretical guarantees for the method.\n- I think the authors did a good job in evaluating the method.\n- I would like to see more detail on the implementation of the algorithm.\n- I do not think the paper is well-motivated enough.\n- I would like to see more experiments to verify the claims made in the paper.\n- The main idea of the paper is interesting.\n- The authors did a good job explaining the background and related work.\n- The experimental results are impressive and demonstrate the effectiveness of the method.\n- I am concerned about the lack of theoretical guarantees for the method.\n- I think the authors could have done a better job in comparing their method to other existing approaches.\n- I would like to see more experimental results to verify the claims made in the paper.\n- The authors provide a clear and concise overview of their method.\n- I find the explanation of the method a bit unclear.\n- The results are impressive, but I would like to see more experimental results to verify the claims made in the paper.\n- I am concerned about the potential for overfitting due to the large size of the training set.\n- The authors could provide more detail on the hyperparameters used in the experiments.\n- I think the method has potential, but more work is needed to improve the robustness of the results.\n- The paper provides an interesting contribution to the field.\n- I find the writing a bit unclear at times.\n- The authors did a good job in evaluating their method, but I would like to see more experimental results to verify the claims made in the paper.\n- I am concerned about the potential for overfitting due to the large size of the training set.\n- The authors could provide more detail on the hyperparameters used in the experiments.\n- I think the method has potential, but more work is needed.\n- This is an interesting paper with a unique contribution.\n- I find some parts of the paper a bit unclear.\n- The experimental results are impressive, but I would like to see more detail on the implementation of the algorithm.\n- I am concerned about the lack of theoretical guarantees for the method.\n- I think the authors did a good job in comparing their method to other existing approaches.\n- I would like to see more experimental results to verify the claims made in the paper.\n- The authors' idea is novel and could be important.\n- I find the explanation of the method a bit unclear.\n- The results are impressive, but I would like to see more experimental results to verify the claims made in the paper.\n- I am concerned about the potential for overfitting due to the large size of the training set.\n- The authors should provide more detail on the hyperparameters used in the experiments.\n- I think the method has potential, but more work is needed.\n- The authors' idea is interesting and could be important.\n- I find the explanation of the method a bit unclear.\n- The results are impressive, but I would like to see more experimental results to verify the claims made in the paper.\n- I am concerned about the potential for overfitting due to the large size of the training set.\n- The authors should provide more detail on the hyperparameters used in the experiments.\n- I think the method has potential, but more work is needed.",
    "review_points_list": [
      "I find the result showing that polarization+disagreement is close enough to being submodular to give guarantees for approximation interesting!",
      "I am a bit disappointed that all these details were pushed to supplemental material, including all proofs as well as even including the definition of curvature and submodularity ratio.",
      "The faster approximate version is important to make the method practical.",
      "I am not sure if NeurIPS is the right venue for this work, but it is definitely very interesting",
      "The work is well-motivated and the authors have done a thorough job in evaluating their method.",
      "I found the presentation a bit unclear and the writing could be improved.",
      "I am disappointed that there is no comparison with other methods that are more relevant to the problem at hand.",
      "I do not think that the results fully support the claims made in the abstract.",
      "I think that the method can be further developed to achieve even better results.",
      "I am concerned about the computational efficiency of the method, as it seems to be quite expensive.",
      "I think that the authors should have explored more thoroughly the implications of the results for the problem being studied.",
      "I am not convinced that the results demonstrate the claimed level of improvement in performance.",
      "I think that the paper could be improved with more detail on the implementation and evaluation of the algorithm.",
      "This is a very interesting paper! The main idea is well-motivated and the results are impressive.",
      "I do find some parts of the paper a bit unclear. For example, the authors could have done a better job explaining the intuition behind the algorithm.",
      "I am excited about the potential of this method and its applications.",
      "I do have some concerns about the limitations of the method.",
      "I think the authors did a good job in comparing their method to other existing approaches.",
      "I would like to see more experimental results to verify the claims made in the paper.",
      "The main contribution of the paper is not entirely clear to me.",
      "I find the experimental results to be quite convincing.",
      "I am concerned about the lack of theoretical guarantees for the method.",
      "I think the authors did a good job in evaluating the method.",
      "I would like to see more detail on the implementation of the algorithm.",
      "I do not think the paper is well-motivated enough.",
      "I would like to see more experiments to verify the claims made in the paper.",
      "The main idea of the paper is interesting.",
      "The authors did a good job explaining the background and related work.",
      "The experimental results are impressive and demonstrate the effectiveness of the method.",
      "I am concerned about the lack of theoretical guarantees for the method.",
      "I think the authors could have done a better job in comparing their method to other existing approaches.",
      "I would like to see more experimental results to verify the claims made in the paper.",
      "The authors provide a clear and concise overview of their method.",
      "I find the explanation of the method a bit unclear.",
      "The results are impressive, but I would like to see more experimental results to verify the claims made in the paper.",
      "I am concerned about the potential for overfitting due to the large size of the training set.",
      "The authors could provide more detail on the hyperparameters used in the experiments.",
      "I think the method has potential, but more work is needed to improve the robustness of the results.",
      "The paper provides an interesting contribution to the field.",
      "I find the writing a bit unclear at times.",
      "The authors did a good job in evaluating their method, but I would like to see more experimental results to verify the claims made in the paper.",
      "I am concerned about the potential for overfitting due to the large size of the training set.",
      "The authors could provide more detail on the hyperparameters used in the experiments.",
      "I think the method has potential, but more work is needed.",
      "This is an interesting paper with a unique contribution.",
      "I find some parts of the paper a bit unclear.",
      "The experimental results are impressive, but I would like to see more detail on the implementation of the algorithm.",
      "I am concerned about the lack of theoretical guarantees for the method.",
      "I think the authors did a good job in comparing their method to other existing approaches.",
      "I would like to see more experimental results to verify the claims made in the paper.",
      "The authors' idea is novel and could be important.",
      "I find the explanation of the method a bit unclear.",
      "The results are impressive, but I would like to see more experimental results to verify the claims made in the paper.",
      "I am concerned about the potential for overfitting due to the large size of the training set.",
      "The authors should provide more detail on the hyperparameters used in the experiments.",
      "I think the method has potential, but more work is needed.",
      "The authors' idea is interesting and could be important.",
      "I find the explanation of the method a bit unclear.",
      "The results are impressive, but I would like to see more experimental results to verify the claims made in the paper.",
      "I am concerned about the potential for overfitting due to the large size of the training set.",
      "The authors should provide more detail on the hyperparameters used in the experiments.",
      "I think the method has potential, but more work is needed."
    ]
  },
  {
    "paper_id": "2107.04867v1",
    "submission_id": "vLVEZr_66Ik",
    "submission_title": "Learning 3D Dense Correspondence via Canonical Point Autoencoder",
    "review_id": "o7LOf2v5tom",
    "input": {
      "title": "Learning 3D Dense Correspondence via Canonical Point Autoencoder",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- (+) the ability to ignore parts of $\bb{S}^2$ embedding space with asymmetric Chamfer regulariser is novel and useful;\n- (+) most methods in this area train on ShapeNet with aligned cameras;\n- (\u2212) experiments on rotation invariance are somewhat limited though;\n- (\u2212) all experiments are performed on the synthetic ShapeNet dataset;\n- (\u2212) the performance is measured on sparse keypoints, which are usually defined in distinctive points;\n- (+) asymmetric Chamfer distance loss to the unit sphere is a new idea which appears to be crucial for being able to learn the spherical embedding;\n- (\u2212) on the other hand, I don\u2019t see why the first term in ACD, which makes the points to lie on the unit sphere, is needed;\n- The weight $\bb{\u03b1}$ will then balance half of the CD vs MSE.\n- Also, can the second term be replaced by entropy to avoid sampling/discretisation artefacts?\n- (+) asymmetric Chamfer distance loss to the unit sphere is a new idea which appears to be crucial for being able to learn the spherical embedding;\n- (\u2212) the performance is measured on sparse keypoints, which are usually defined in distinctive points;\n- (\u2212) in eq. (2), why are the CD and EMD terms needed?\n- (\u2212) line 253: do I understand correctly that tanh is used in the end of the MLP that generates points?\n- Equality sign (=) all other components have been used in point cloud autoencoders (including cross-reconstruction loss and PointNet encoder).\n- (\u2212) The paper provides loss formulations (1\u20133) but does not say how they are combined, e.g. with what weights;\n- (\u2212) is $\bb{\u03b1}$ *gradually* decreased during training (line 151) or in one step (line 255)?\n- (\u2212) I don\u2019t understand the theoretical argument in Section 3.2.\n- Also, in eq. (5), I don\u2019t understand the idea of using Euclidean distance in the world space to determine the confidence?\n- Notes to the authors (no effect on rating):\n- I would not call such method self-supervised;\n- line 48: the sentence is not in grammatical agreement;\n- line 89: the algorithm is feasible to calculate \u2190 is able to calculate;\n- line 146 refers to the pink box in Fig. 1; I don\u2019t see it;\n- line 159: MES loss;\n- line 161: 1e1 \u2190 10;\n- line 165: a Chamfer loss \u2190 Chamfer loss;\n- line 310: equivalent to enforce \u2190 equivalent to enforcing.\n- UPD. Thank you for engaging in a discussion and diligently evaluating new baselines.\n- My main concerns are now resolved, to an extent.\n- For rotation invariance the method indeed beats the weak baseline (non-rotation invariant method by design).\n- Please follow-up on the promises to re-position the paper, i.e. claim only invariance within small angles and acknowledge that the problem is far from being solved even for small angles.\n- The new experiments on the ShapeNet crops and nearest-neighbour baseline are steps in the right direction;\n- I encourage you to find ways to evaluate quantitatively.\n- The clarity will hopefully be sorted out with the help of our comments.",
    "review_points_list": [
      "(+) the ability to ignore parts of $\bb{S}^2$ embedding space with asymmetric Chamfer regulariser is novel and useful;",
      "(+) most methods in this area train on ShapeNet with aligned cameras;",
      "(\u2212) experiments on rotation invariance are somewhat limited though;",
      "(\u2212) all experiments are performed on the synthetic ShapeNet dataset;",
      "(\u2212) the performance is measured on sparse keypoints, which are usually defined in distinctive points;",
      "(+) asymmetric Chamfer distance loss to the unit sphere is a new idea which appears to be crucial for being able to learn the spherical embedding;",
      "(\u2212) on the other hand, I don\u2019t see why the first term in ACD, which makes the points to lie on the unit sphere, is needed;",
      "The weight $\bb{\u03b1}$ will then balance half of the CD vs MSE.",
      "Also, can the second term be replaced by entropy to avoid sampling/discretisation artefacts?",
      "(+) asymmetric Chamfer distance loss to the unit sphere is a new idea which appears to be crucial for being able to learn the spherical embedding;",
      "(\u2212) the performance is measured on sparse keypoints, which are usually defined in distinctive points;",
      "(\u2212) in eq. (2), why are the CD and EMD terms needed?",
      "(\u2212) line 253: do I understand correctly that tanh is used in the end of the MLP that generates points?",
      "Equality sign (=) all other components have been used in point cloud autoencoders (including cross-reconstruction loss and PointNet encoder).",
      "(\u2212) The paper provides loss formulations (1\u20133) but does not say how they are combined, e.g. with what weights;",
      "(\u2212) is $\bb{\u03b1}$ *gradually* decreased during training (line 151) or in one step (line 255)?",
      "(\u2212) I don\u2019t understand the theoretical argument in Section 3.2.",
      "Also, in eq. (5), I don\u2019t understand the idea of using Euclidean distance in the world space to determine the confidence?",
      "Notes to the authors (no effect on rating):",
      "I would not call such method self-supervised;",
      "line 48: the sentence is not in grammatical agreement;",
      "line 89: the algorithm is feasible to calculate \u2190 is able to calculate;",
      "line 146 refers to the pink box in Fig. 1; I don\u2019t see it;",
      "line 159: MES loss;",
      "line 161: 1e1 \u2190 10;",
      "line 165: a Chamfer loss \u2190 Chamfer loss;",
      "line 310: equivalent to enforce \u2190 equivalent to enforcing.",
      "UPD. Thank you for engaging in a discussion and diligently evaluating new baselines.",
      "My main concerns are now resolved, to an extent.",
      "For rotation invariance the method indeed beats the weak baseline (non-rotation invariant method by design).",
      "Please follow-up on the promises to re-position the paper, i.e. claim only invariance within small angles and acknowledge that the problem is far from being solved even for small angles.",
      "The new experiments on the ShapeNet crops and nearest-neighbour baseline are steps in the right direction;",
      "I encourage you to find ways to evaluate quantitatively.",
      "The clarity will hopefully be sorted out with the help of our comments."
    ]
  },
  {
    "paper_id": "2107.04867v1",
    "submission_id": "vLVEZr_66Ik",
    "submission_title": "Learning 3D Dense Correspondence via Canonical Point Autoencoder",
    "review_id": "U3YBnm38iwZ",
    "input": {
      "title": "Learning 3D Dense Correspondence via Canonical Point Autoencoder",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- In general the idea of learning a point cloud autoencoder with the bottleneck defined as the projection onto a 3D sphere seems to be effective, as demonstrated by the authors in the experiments.\n- The authors did a pretty good job in explaining their methods, and the experiments are thorough.\n- The intuition of why the proposed 3D sphere canonical space can handle non genus 0 shapes is provided very late in the paper, not until page 4 when 'relax the bidirectional constraint of the Chamfer loss' is mentioned.\n- The authors should give a clearer explanation about this in their intro, otherwise, a spherical canonical mapping is not enough detail to convince the readers that the proposed method is going to work for non genus 0 shapes.\n- On page 3 Ln 99, 'non-linear mappings' alone is too ambiguous and not enough to explain why the method is able to lift 'such restriction'.\n- In the intro, the author claimed the method works '.. even. when instances in the training dataset are not aligned, \u2026, does not need to predict an additional rotation matrix ...'\n- I fail to see why the proposed method is 'rotational invariant', and how the method is able to solve the ambiguity between shape variation and rotation.\n- The way it computes confidence of correspondences are clearly not rotational invariant, as it directly evaluates the euclidean distance between two points in the 3D world coordinates.\n- If the source & target point cloud differs by a significant amount of rotation, such confidence score would not make any sense.\n- I find the 'reconstruction of ordered point clouds' section on page 5 difficult to understand.\n- I would suggest the author to make a more formal mathematical proposition.\n- Moreover, the authors seem to try to prove something w.r.t. affine transformation, but why does that applies to MLP which is non-linear?",
    "review_points_list": [
      "In general the idea of learning a point cloud autoencoder with the bottleneck defined as the projection onto a 3D sphere seems to be effective, as demonstrated by the authors in the experiments.",
      "The authors did a pretty good job in explaining their methods, and the experiments are thorough.",
      "The intuition of why the proposed 3D sphere canonical space can handle non genus 0 shapes is provided very late in the paper, not until page 4 when 'relax the bidirectional constraint of the Chamfer loss' is mentioned.",
      "The authors should give a clearer explanation about this in their intro, otherwise, a spherical canonical mapping is not enough detail to convince the readers that the proposed method is going to work for non genus 0 shapes.",
      "On page 3 Ln 99, 'non-linear mappings' alone is too ambiguous and not enough to explain why the method is able to lift 'such restriction'.",
      "In the intro, the author claimed the method works '.. even. when instances in the training dataset are not aligned, \u2026, does not need to predict an additional rotation matrix ...'",
      "I fail to see why the proposed method is 'rotational invariant', and how the method is able to solve the ambiguity between shape variation and rotation.",
      "The way it computes confidence of correspondences are clearly not rotational invariant, as it directly evaluates the euclidean distance between two points in the 3D world coordinates.",
      "If the source & target point cloud differs by a significant amount of rotation, such confidence score would not make any sense.",
      "I find the 'reconstruction of ordered point clouds' section on page 5 difficult to understand.",
      "I would suggest the author to make a more formal mathematical proposition.",
      "Moreover, the authors seem to try to prove something w.r.t. affine transformation, but why does that applies to MLP which is non-linear?"
    ]
  },
  {
    "paper_id": "2107.04867v1",
    "submission_id": "vLVEZr_66Ik",
    "submission_title": "Learning 3D Dense Correspondence via Canonical Point Autoencoder",
    "review_id": "3GXkuCYkVSu",
    "input": {
      "title": "Learning 3D Dense Correspondence via Canonical Point Autoencoder",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well written. The problem setting is well-motivated, and the paper addresses an important research problem.\n- The model achieves state-of-the-art performance.\n- The purpose of each component of the model is well discussed.\n- The ablation study is insightful.\n- The biggest concern I have with the proposed approach is with the combination of loss components.\n- What if the chosen random samples are part-missing etc. samples?\n- Reducing \u03b1 in L_{ACD} allows each shape to have its own UV coordinates to some extent.\n- L_{ACD} can easily force the model to find different UV coordinates for similar instances also (not only part missing instances).\n- The model might be too sensitive and dataset dependent for the ideal gradual decreasing of \u03b1.\n- Even similar instances might have different UV coordinates.\n- The authors argue that somehow they can find an ideal point where the end-goal is satisfied.\n- The model contains too many moving parts and hence is not a robust approach.",
    "review_points_list": [
      "The paper is well written. The problem setting is well-motivated, and the paper addresses an important research problem.",
      "The model achieves state-of-the-art performance.",
      "The purpose of each component of the model is well discussed.",
      "The ablation study is insightful.",
      "The biggest concern I have with the proposed approach is with the combination of loss components.",
      "What if the chosen random samples are part-missing etc. samples?",
      "Reducing \u03b1 in L_{ACD} allows each shape to have its own UV coordinates to some extent.",
      "L_{ACD} can easily force the model to find different UV coordinates for similar instances also (not only part missing instances).",
      "The model might be too sensitive and dataset dependent for the ideal gradual decreasing of \u03b1.",
      "Even similar instances might have different UV coordinates.",
      "The authors argue that somehow they can find an ideal point where the end-goal is satisfied.",
      "The model contains too many moving parts and hence is not a robust approach."
    ]
  },
  {
    "paper_id": "2107.04867v1",
    "submission_id": "vLVEZr_66Ik",
    "submission_title": "Learning 3D Dense Correspondence via Canonical Point Autoencoder",
    "review_id": "t6dW4prsvlq",
    "input": {
      "title": "Learning 3D Dense Correspondence via Canonical Point Autoencoder",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The algorithm proposed by the authors seems to be novel and differs from previous comparable approaches.\n- Related work is adequately cited.\n- The authors show empirically that their algorithm, Cluster-Margin, is both more efficient and more effective than CoreSet and BADGE in practice.\n- The algorithm clearly outperforms CoreSet, BADGE, Margin, and Random on the Open Images dataset.\n- The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result.\n- Cluster-Margin also outperforms all other methods on CIFAR10 and CIFAR100 and obtains a similar performance on SVHN.\n- The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.\n- The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.\n- This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.\n- The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.\n- log(k) is an upper bound on the improvement of query complexity for any sampler.\n- The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.\n- The paper is very clear and well organized.\n- The authors detail the hyper-parameters and compute details used for the experiments.\n- The Cluster-Margin algorithm is also explained in detail.\n- The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods.\n- The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.",
    "review_points_list": [
      "The algorithm proposed by the authors seems to be novel and differs from previous comparable approaches.",
      "Related work is adequately cited.",
      "The authors show empirically that their algorithm, Cluster-Margin, is both more efficient and more effective than CoreSet and BADGE in practice.",
      "The algorithm clearly outperforms CoreSet, BADGE, Margin, and Random on the Open Images dataset.",
      "The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result.",
      "Cluster-Margin also outperforms all other methods on CIFAR10 and CIFAR100 and obtains a similar performance on SVHN.",
      "The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.",
      "The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.",
      "This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.",
      "The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.",
      "log(k) is an upper bound on the improvement of query complexity for any sampler.",
      "The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.",
      "The paper is very clear and well organized.",
      "The authors detail the hyper-parameters and compute details used for the experiments.",
      "The Cluster-Margin algorithm is also explained in detail.",
      "The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods.",
      "The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm."
    ]
  },
  {
    "paper_id": "2111.07372v1",
    "submission_id": "x8k1nAoGu1U",
    "submission_title": "Fast Doubly-Adaptive MCMC to Estimate the Gibbs Partition Function with Weak Mixing Time Bounds",
    "review_id": "MbBi90BGAgo",
    "input": {
      "title": "Fast Doubly-Adaptive MCMC to Estimate the Gibbs Partition Function with Weak Mixing Time Bounds",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The reviewer thinks this is a good paper.\n- As claimed by the authors, they introduce a new method that is proven to outperform the state of art algorithms.\n- The experiments also justify this.\n- However, the reviewer thinks this paper is not very clear.\n- The reviewer is not familiar with this problem and feels it's a little hard to follow this paper.\n- The reviewer will point out some confusing parts in 'Limitations'.",
    "review_points_list": [
      "The reviewer thinks this is a good paper.",
      "As claimed by the authors, they introduce a new method that is proven to outperform the state of art algorithms.",
      "The experiments also justify this.",
      "However, the reviewer thinks this paper is not very clear.",
      "The reviewer is not familiar with this problem and feels it's a little hard to follow this paper.",
      "The reviewer will point out some confusing parts in 'Limitations'."
    ]
  },
  {
    "paper_id": "2111.07372v1",
    "submission_id": "x8k1nAoGu1U",
    "submission_title": "Fast Doubly-Adaptive MCMC to Estimate the Gibbs Partition Function with Weak Mixing Time Bounds",
    "review_id": "AyD4Veae_G1",
    "input": {
      "title": "Fast Doubly-Adaptive MCMC to Estimate the Gibbs Partition Function with Weak Mixing Time Bounds",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Except for the presentation of the basic algorithm (which is fairly classical), the paper is difficult to read.\n- It is difficult to understand the contributions, the results, I was quite confused even after reading the full paper.\n- The discussion and the proofs use a lot of external references, which require each time to understand other conventions, notations, concepts.\n- It would be much better to recap the required results in a Section in the supplement paper, to ease the reading.\n- I have tried to check the proof of Theorem 2.4 in the supplementary version for example, and I found it quite difficult to follow.\n- I would definitely prefer in the supplement paper to get complete and detailed arguments, not a sketch of proofs with external references.\n- When you cite an external result in a paper is definitely better to get a precise reference to the theorem or proposition which is used, it is very complicated otherwise.\n- I am surprised not to see in the complexity bounds the initial distribution of the Markov chain.\n- The authors use the results of Jiang, Sun, Fan (2018) [Theorem 1 and 2] which both assumed that the MC is stationary.\n- It would be interesting to know how the authors plan to work with the non-stationary case.\n- The assumption of knowing an upper bound of the spectral gap seems difficult to me.\n- The estimators are, except for examples, generally extremely pessimistic, especially for general state chains.\n- I find the discussion at the beginning of Section 2 difficult to follow.\n- Lemma 1 is difficult to understand because some quantities which are presented are not defined (what is \u0394_i ? )\n- Line 177: 'estimating means.. union bound)' is difficult to understand as it is stated.",
    "review_points_list": [
      "Except for the presentation of the basic algorithm (which is fairly classical), the paper is difficult to read.",
      "It is difficult to understand the contributions, the results, I was quite confused even after reading the full paper.",
      "The discussion and the proofs use a lot of external references, which require each time to understand other conventions, notations, concepts.",
      "It would be much better to recap the required results in a Section in the supplement paper, to ease the reading.",
      "I have tried to check the proof of Theorem 2.4 in the supplementary version for example, and I found it quite difficult to follow.",
      "I would definitely prefer in the supplement paper to get complete and detailed arguments, not a sketch of proofs with external references.",
      "When you cite an external result in a paper is definitely better to get a precise reference to the theorem or proposition which is used, it is very complicated otherwise.",
      "I am surprised not to see in the complexity bounds the initial distribution of the Markov chain.",
      "The authors use the results of Jiang, Sun, Fan (2018) [Theorem 1 and 2] which both assumed that the MC is stationary.",
      "It would be interesting to know how the authors plan to work with the non-stationary case.",
      "The assumption of knowing an upper bound of the spectral gap seems difficult to me.",
      "The estimators are, except for examples, generally extremely pessimistic, especially for general state chains.",
      "I find the discussion at the beginning of Section 2 difficult to follow.",
      "Lemma 1 is difficult to understand because some quantities which are presented are not defined (what is \u0394_i ? )",
      "Line 177: 'estimating means.. union bound)' is difficult to understand as it is stated."
    ]
  },
  {
    "paper_id": "2111.07372v1",
    "submission_id": "x8k1nAoGu1U",
    "submission_title": "Fast Doubly-Adaptive MCMC to Estimate the Gibbs Partition Function with Weak Mixing Time Bounds",
    "review_id": "zc85nLVmZMC",
    "input": {
      "title": "Fast Doubly-Adaptive MCMC to Estimate the Gibbs Partition Function with Weak Mixing Time Bounds",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The problem of approximating the partition function of discrete probabilistic models is relevant and has a lot of ML applications.\n- This paper mainly focuses on improving previous methods based on paired product estimators by introducing an improved mean estimator that does not require black box (approximately) independent samples.\n- Based on previous work on trace averaging, they introduce an adaptive mean estimator, and theoretically show that the resulting method is superior to the state of the art.\n- The final algorithms (Alg. 2 in the paper) and their upper bounds are an interesting contribution, albeit not completely novel, since both adaptive parts (cooling and mean estimation) are largely based on previous work.\n- I see two major downsides with this paper:\n- - The exposition of the main theoretical results in section 2 suffers from lack of clarity.\n- Both sections 2.1 and 2.2 are heavy on notation, and contain very little intuitive explanation.\n- - The experimental section only discusses very small toy examples, which makes me wonder whether the proposed algorithms would actually be applicable to any practically relevant ML problem.",
    "review_points_list": [
      "The problem of approximating the partition function of discrete probabilistic models is relevant and has a lot of ML applications.",
      "This paper mainly focuses on improving previous methods based on paired product estimators by introducing an improved mean estimator that does not require black box (approximately) independent samples.",
      "Based on previous work on trace averaging, they introduce an adaptive mean estimator, and theoretically show that the resulting method is superior to the state of the art.",
      "The final algorithms (Alg. 2 in the paper) and their upper bounds are an interesting contribution, albeit not completely novel, since both adaptive parts (cooling and mean estimation) are largely based on previous work.",
      "I see two major downsides with this paper:",
      "- The exposition of the main theoretical results in section 2 suffers from lack of clarity.",
      "Both sections 2.1 and 2.2 are heavy on notation, and contain very little intuitive explanation.",
      "- The experimental section only discusses very small toy examples, which makes me wonder whether the proposed algorithms would actually be applicable to any practically relevant ML problem."
    ]
  },
  {
    "paper_id": "2111.07372v1",
    "submission_id": "x8k1nAoGu1U",
    "submission_title": "Fast Doubly-Adaptive MCMC to Estimate the Gibbs Partition Function with Weak Mixing Time Bounds",
    "review_id": "eW1g6jZ-14",
    "input": {
      "title": "Fast Doubly-Adaptive MCMC to Estimate the Gibbs Partition Function with Weak Mixing Time Bounds",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The method is well motivated and the theoretical analysis is very thorough.\n- The usage of the word adaptive (as an auto-decision on the number of steps) is highly misleading.\n- An entire line of work exists where the word adaptive refers to changing the transition kernel to improve the efficiency of the MCMC.\n- In line 77 describing Huber and Schott's estimator, [1] makes statements on estimating $z=\text{log}(Z)$. Please refer to the discussion 2 paragraphs before algorithm 2.2 in [1] ([29] in reviewed paper).\n- Maybe I am missing something but in order to apply linearity of expectations to a product and to compute an unbiased estimator of a quotient, the log domain makes more sense.\n- However please correct me if I am missing something.\n- Please consider comparison with Annealed Importance Sampling (AIS) [3] which samples a single transition at each temperature such that stationary samples at each temperature aren't needed.\n- I may have missed a nuance which prohibits the use of AIS, and if that is the case I am willing to change my rating.\n- If AIS can indeed be used in this scenario, the second 'adaptation' can only be justified thorough empirical evaluation.\n- Please add error bars to all plots not just Fig 1.e.\n- Please use larger font in plots.\n- Originality: Existing problem, novel solution which combines [1,4] using original tools.\n- Quality: Theory is very rigorous, empirical evaluation lacking.\n- Clarity: Motivations are well explained, plots need work and experimental evaluation is lacking.\n- Significance: Unclear, refer to comment regarding AIS in Weaknesses.\n- I am willing to update my review, especially my overall score, based on a strong rebuttal arguing that either AIS is not applicable in this task or is demonstrably bad when empirically evaluated against the method.",
    "review_points_list": [
      "The method is well motivated and the theoretical analysis is very thorough.",
      "The usage of the word adaptive (as an auto-decision on the number of steps) is highly misleading.",
      "An entire line of work exists where the word adaptive refers to changing the transition kernel to improve the efficiency of the MCMC.",
      "In line 77 describing Huber and Schott's estimator, [1] makes statements on estimating $z=\text{log}(Z)$. Please refer to the discussion 2 paragraphs before algorithm 2.2 in [1] ([29] in reviewed paper).",
      "Maybe I am missing something but in order to apply linearity of expectations to a product and to compute an unbiased estimator of a quotient, the log domain makes more sense.",
      "However please correct me if I am missing something.",
      "Please consider comparison with Annealed Importance Sampling (AIS) [3] which samples a single transition at each temperature such that stationary samples at each temperature aren't needed.",
      "I may have missed a nuance which prohibits the use of AIS, and if that is the case I am willing to change my rating.",
      "If AIS can indeed be used in this scenario, the second 'adaptation' can only be justified thorough empirical evaluation.",
      "Please add error bars to all plots not just Fig 1.e.",
      "Please use larger font in plots.",
      "Originality: Existing problem, novel solution which combines [1,4] using original tools.",
      "Quality: Theory is very rigorous, empirical evaluation lacking.",
      "Clarity: Motivations are well explained, plots need work and experimental evaluation is lacking.",
      "Significance: Unclear, refer to comment regarding AIS in Weaknesses.",
      "I am willing to update my review, especially my overall score, based on a strong rebuttal arguing that either AIS is not applicable in this task or is demonstrably bad when empirically evaluated against the method."
    ]
  },
  {
    "paper_id": "2109.14727v1",
    "submission_id": "xVLzpMOexqo",
    "submission_title": "Dr Jekyll & Mr Hyde: the strange case of off-policy policy updates",
    "review_id": "mLU1yeP5ITb",
    "input": {
      "title": "Dr Jekyll & Mr Hyde: the strange case of off-policy policy updates",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The work is novel. It brings together a collection of previous work and resolves some open questions in the theory of policy gradient methods.\n- It provides theoretical grounding for the long-established engineering technique of using off-policy updates to improve RL performance, an algorithm design with convergence guarantees, and more.\n- The authors clearly identify related work and place it in context in their paper.\n- This is a comprehensive look at the theoretical underpinnings of off-policy policy gradient methods. Claims are systematically introduced, proved, and eventually experimentally verified.\n- In the appendix) the proofs are clearly laid out, with proof sketches explaining complicated proofs as necessary.\n- The paper also includes the chain-MDP experiment that elegantly demonstrates how their method learns the globally optimal policy when traditional policy gradient approaches fail.\n- This experiment shows the theoretical advantages manifest in practice.\n- They also demonstrate their method in a simple Deep-RL setting.\n- The authors clearly identify and discuss limitations of their work.\n- The greatest limitation of the work is that convergence proofs don\u2019t necessarily cover the deep RL case, but that is unsurprising.\n- The paper is written very clearly, and is a pleasure to read.\n- At each stage of the derivation, the importance, implications, and potential pitfalls are identified.\n- The derivation of their final result proceeds logically and methodically from related work.\n- As a small suggestion, consider adding a brief explanation/proof sketch of Theorem 2 in the main text, because it is a key theorem and its truth is not obvious. It is explained well in the appendix.\n- The results are important, both because they provide theoretical grounding for common RL engineering strategies, and because it is likely to lead to a long line of further work in applying their results to more complex domains.",
    "review_points_list": [
      "The work is novel. It brings together a collection of previous work and resolves some open questions in the theory of policy gradient methods.",
      "It provides theoretical grounding for the long-established engineering technique of using off-policy updates to improve RL performance, an algorithm design with convergence guarantees, and more.",
      "The authors clearly identify related work and place it in context in their paper.",
      "This is a comprehensive look at the theoretical underpinnings of off-policy policy gradient methods. Claims are systematically introduced, proved, and eventually experimentally verified.",
      "In the appendix) the proofs are clearly laid out, with proof sketches explaining complicated proofs as necessary.",
      "The paper also includes the chain-MDP experiment that elegantly demonstrates how their method learns the globally optimal policy when traditional policy gradient approaches fail.",
      "This experiment shows the theoretical advantages manifest in practice.",
      "They also demonstrate their method in a simple Deep-RL setting.",
      "The authors clearly identify and discuss limitations of their work.",
      "The greatest limitation of the work is that convergence proofs don\u2019t necessarily cover the deep RL case, but that is unsurprising.",
      "The paper is written very clearly, and is a pleasure to read.",
      "At each stage of the derivation, the importance, implications, and potential pitfalls are identified.",
      "The derivation of their final result proceeds logically and methodically from related work.",
      "As a small suggestion, consider adding a brief explanation/proof sketch of Theorem 2 in the main text, because it is a key theorem and its truth is not obvious. It is explained well in the appendix.",
      "The results are important, both because they provide theoretical grounding for common RL engineering strategies, and because it is likely to lead to a long line of further work in applying their results to more complex domains."
    ]
  },
  {
    "paper_id": "2109.14727v1",
    "submission_id": "xVLzpMOexqo",
    "submission_title": "Dr Jekyll & Mr Hyde: the strange case of off-policy policy updates",
    "review_id": "KVjmaGjxI_",
    "input": {
      "title": "Dr Jekyll & Mr Hyde: the strange case of off-policy policy updates",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The main contribution of the paper is a new theoretical framework for designing new actor critic methods which are more robust to the common problem of converging to suboptimal policies. By defining an update rule which can be applied under any state density, it is possible to combine data from exploratory policies which cover the state space and thus avoid early convergence to suboptimal policies. The authors show an example of such an approach with their J&K algorithm.\n- The authors define an update rule which can be applied under any state density and thus avoid early convergence to suboptimal policies. The authors show an example of such an approach with their J&K algorithm. The J&K algorithm is shown to be more robust to the common problem of converging to suboptimal policies.\n- The authors only consider the direct and softmax parameterization of the policy to prove their theoretical claims. This is a limitation which the authors acknowledge and is left as a future work.\n- The authors provide empirical results to support the claim over the generality of their method.\n- line 35: designates ?\n- line 40: Define n_t before using it\n- line 75: Define adv before using it\n- line 676: Lemmas are denoted as Theorems a, b",
    "review_points_list": [
      "The main contribution of the paper is a new theoretical framework for designing new actor critic methods which are more robust to the common problem of converging to suboptimal policies. By defining an update rule which can be applied under any state density, it is possible to combine data from exploratory policies which cover the state space and thus avoid early convergence to suboptimal policies. The authors show an example of such an approach with their J&K algorithm.",
      "The authors define an update rule which can be applied under any state density and thus avoid early convergence to suboptimal policies. The authors show an example of such an approach with their J&K algorithm. The J&K algorithm is shown to be more robust to the common problem of converging to suboptimal policies.",
      "The authors only consider the direct and softmax parameterization of the policy to prove their theoretical claims. This is a limitation which the authors acknowledge and is left as a future work.",
      "The authors provide empirical results to support the claim over the generality of their method.",
      "line 35: designates ?",
      "line 40: Define n_t before using it",
      "line 75: Define adv before using it",
      "line 676: Lemmas are denoted as Theorems a, b"
    ]
  },
  {
    "paper_id": "2109.14727v1",
    "submission_id": "xVLzpMOexqo",
    "submission_title": "Dr Jekyll & Mr Hyde: the strange case of off-policy policy updates",
    "review_id": "4LHjnEf1xU",
    "input": {
      "title": "Dr Jekyll & Mr Hyde: the strange case of off-policy policy updates",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I find that the idea of explicitly separating exploration and exploitation makes sense for policy-based RL methods.\n- The theoretical contributions are particularly interesting and I would have liked to see them developed further, especially with regards to doing updates with arbitrary $d(s)$ using samples.\n- Generally, the experiments were well-done and thorough although I have certain concerns about the deep RL section.\n- The writing was satisfactory overall although there were a few parts I would have like to have clarified.\n- The proofs were well-written and clear as far as I could tell.\n- There is a line of work on off-policy actor-critic algorithms that I haven't seen mentioned [1,2,3], which feature different state-distribution weightings and analyze these algorithms theoretically and empirically.\n- While all state-distribution weightings are subsumed in a general $d(s)$ in this paper, I would have liked some discussion on what weighting should be used then.\n- Currently, C4 and C4-s are fairly loose constraints on $d_t$ and $\\\"]I think it would be interesting to look into this further and see what forms of d_t are theoretically advantageous, beyond simply covering all the states.\n- In the experiments, a mix of the the on-policy state distribution and an exploratory policy's state distribution is used. Perhaps there could be some theory to support this choice?\n- One issue to consider would be the compatibility of a specific $d(s)$ with sampling. In particular, these previous algorithms [1,2,3] can usually be run in an online fashion (updating at every step or at every episode). In this paper, it hasn't been discussed much although there is the mention of experience-replay to help.\n- Even with experience replay, there are many sampling strategies that could be used and it would be interesting if the theory could guide it.\n- I find theorem 2 to be a nice result since it gives necessary and sufficient conditions for arbitrary state distributions $d_t(s)$. I have various questions about the lines that follow and the interpretations of this result though.\n- Line 107-110: Could you clarify how this is related to generalized policy iteration? I'm not sure how this theorem is helping towards a generalized policy iteration theorem or what this GPI theorem would say.\n- Line 118-119: 'the convergence properties of policy gradient and undiscounted updates require the same set of assumptions and conditions'. Could you clarify this statement?\n- Line 123: 'prove that off-policy updates... are necessary to guarantee convergence to optimality'. Why is this true? I don't see how this follows from the theorem.\n- Line 125-128: Although the initial state distribution doesn't have to cover the space, it isn't clear that this approach solves the exploration issue theoretically.\n- Concerning condition C4 and theorem 3 (the convergence rate), why is that we can\\&#39;t just choose \\\"]In the deep RL experiments, J&H uses value-based methods for each part. This confuses me since the original motivation seemed to be to improve the behaviour of policy gradient algorithms.\n- About the finite MDP experiments, I didn't see the performance of just Q-learning with exploration bonuses. How does that perform compared to J&H?\n- In the finite MDP experiments, how important is it to decay epsilon for the performance?\n- Have you tried a version where Hyde (the exploratory agent) gets to choose all the actions and Jekyll only learns off-policy from the data? In principle, it seems like with the right replay mechanism, this could do well too.",
    "review_points_list": [
      "I find that the idea of explicitly separating exploration and exploitation makes sense for policy-based RL methods.",
      "The theoretical contributions are particularly interesting and I would have liked to see them developed further, especially with regards to doing updates with arbitrary $d(s)$ using samples.",
      "Generally, the experiments were well-done and thorough although I have certain concerns about the deep RL section.",
      "The writing was satisfactory overall although there were a few parts I would have like to have clarified.",
      "The proofs were well-written and clear as far as I could tell.",
      "There is a line of work on off-policy actor-critic algorithms that I haven't seen mentioned [1,2,3], which feature different state-distribution weightings and analyze these algorithms theoretically and empirically.",
      "While all state-distribution weightings are subsumed in a general $d(s)$ in this paper, I would have liked some discussion on what weighting should be used then.",
      "Currently, C4 and C4-s are fairly loose constraints on $d_t$ and $\\\"]I think it would be interesting to look into this further and see what forms of d_t are theoretically advantageous, beyond simply covering all the states.",
      "In the experiments, a mix of the the on-policy state distribution and an exploratory policy's state distribution is used. Perhaps there could be some theory to support this choice?",
      "One issue to consider would be the compatibility of a specific $d(s)$ with sampling. In particular, these previous algorithms [1,2,3] can usually be run in an online fashion (updating at every step or at every episode). In this paper, it hasn't been discussed much although there is the mention of experience-replay to help.",
      "Even with experience replay, there are many sampling strategies that could be used and it would be interesting if the theory could guide it.",
      "I find theorem 2 to be a nice result since it gives necessary and sufficient conditions for arbitrary state distributions $d_t(s)$. I have various questions about the lines that follow and the interpretations of this result though.",
      "Line 107-110: Could you clarify how this is related to generalized policy iteration? I'm not sure how this theorem is helping towards a generalized policy iteration theorem or what this GPI theorem would say.",
      "Line 118-119: 'the convergence properties of policy gradient and undiscounted updates require the same set of assumptions and conditions'. Could you clarify this statement?",
      "Line 123: 'prove that off-policy updates... are necessary to guarantee convergence to optimality'. Why is this true? I don't see how this follows from the theorem.",
      "Line 125-128: Although the initial state distribution doesn't have to cover the space, it isn't clear that this approach solves the exploration issue theoretically.",
      "Concerning condition C4 and theorem 3 (the convergence rate), why is that we can\\&#39;t just choose \\\"]In the deep RL experiments, J&H uses value-based methods for each part. This confuses me since the original motivation seemed to be to improve the behaviour of policy gradient algorithms.",
      "About the finite MDP experiments, I didn't see the performance of just Q-learning with exploration bonuses. How does that perform compared to J&H?",
      "In the finite MDP experiments, how important is it to decay epsilon for the performance?",
      "Have you tried a version where Hyde (the exploratory agent) gets to choose all the actions and Jekyll only learns off-policy from the data? In principle, it seems like with the right replay mechanism, this could do well too."
    ]
  },
  {
    "paper_id": "2109.14727v1",
    "submission_id": "xVLzpMOexqo",
    "submission_title": "Dr Jekyll & Mr Hyde: the strange case of off-policy policy updates",
    "review_id": "mivovYp8rN",
    "input": {
      "title": "Dr Jekyll & Mr Hyde: the strange case of off-policy policy updates",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- It is difficult to ascertain the significance of the results / ideas in the paper.\n- The claimed primary contribution seems to be the convergence of Eq 3 under some step-size schedule; however, this is not particularly novel and seems to follow quickly from the policy improvement theorem and standard results in stochastic approximation (unless I am misunderstanding the result).\n- All of the results are exclusively in the fully-parameterized regime with exact access to Q functions; while in this regime, off-policy updates do converge to the optimal policy, this breaks as soon as either condition is broken, for example when dealing with arbitrary function classes F or imperfect estimates of Q (e.g. approximate policy iteration).\n- Given that both of these things hold when applying RL on any non-toy problem, I am not convinced about the relevance of the ideas / results derived in the paper.\n- It would be very interesting to see analysis as to how quickly (or slowly) these results break under these more realistic assumptions.\n- I think something of this form would strengthen the paper significantly.\n- It would be useful to explicitly highlight why using the on-policy distribution is bad based on the formal results in your paper.\n- While it is clear intuitively that the on-policy distribution will visit some states sparingly, it is not clear from the text to what degree this slows down convergence.\n- This paper proposes J&H as a mechanism to ensure that the policy is updated on a wide state distribution instead of the narrow on-policy distribution -- why should this mechanism be preferred over the standard mechanism of using a replay buffer to achieve the same effect?\n- The replay buffer is a very common mechanism, and used with almost all recent practical actor-critic methods (e.g SAC, DQN)\n- The current experiments in the chain / random MDP / 4 room domains are in very toy settings (all either completely tabular, or in general, no need for generalization).\n- Echoing my previous comment earlier, while these results do affirm the theoretical results, they provide very little intuition for how this kind of method will do on more standard domains that policy gradient and actor critic methods are applied to (as an example, Gym or Atari).\n- For example, I imagine in many domains of interest with large state spaces, a dithering based strategy will perform better than this decoupled exploration / exploitation behavior, because the number of interesting states is simply dwarfed by the number of less useful states.\n- Minor notes: - Is a formal definition of \u03b4(s) provided in the main text?",
    "review_points_list": [
      "It is difficult to ascertain the significance of the results / ideas in the paper.",
      "The claimed primary contribution seems to be the convergence of Eq 3 under some step-size schedule; however, this is not particularly novel and seems to follow quickly from the policy improvement theorem and standard results in stochastic approximation (unless I am misunderstanding the result).",
      "All of the results are exclusively in the fully-parameterized regime with exact access to Q functions; while in this regime, off-policy updates do converge to the optimal policy, this breaks as soon as either condition is broken, for example when dealing with arbitrary function classes F or imperfect estimates of Q (e.g. approximate policy iteration).",
      "Given that both of these things hold when applying RL on any non-toy problem, I am not convinced about the relevance of the ideas / results derived in the paper.",
      "It would be very interesting to see analysis as to how quickly (or slowly) these results break under these more realistic assumptions.",
      "I think something of this form would strengthen the paper significantly.",
      "It would be useful to explicitly highlight why using the on-policy distribution is bad based on the formal results in your paper.",
      "While it is clear intuitively that the on-policy distribution will visit some states sparingly, it is not clear from the text to what degree this slows down convergence.",
      "This paper proposes J&H as a mechanism to ensure that the policy is updated on a wide state distribution instead of the narrow on-policy distribution -- why should this mechanism be preferred over the standard mechanism of using a replay buffer to achieve the same effect?",
      "The replay buffer is a very common mechanism, and used with almost all recent practical actor-critic methods (e.g SAC, DQN)",
      "The current experiments in the chain / random MDP / 4 room domains are in very toy settings (all either completely tabular, or in general, no need for generalization).",
      "Echoing my previous comment earlier, while these results do affirm the theoretical results, they provide very little intuition for how this kind of method will do on more standard domains that policy gradient and actor critic methods are applied to (as an example, Gym or Atari).",
      "For example, I imagine in many domains of interest with large state spaces, a dithering based strategy will perform better than this decoupled exploration / exploitation behavior, because the number of interesting states is simply dwarfed by the number of less useful states.",
      "Minor notes: - Is a formal definition of \u03b4(s) provided in the main text?"
    ]
  },
  {
    "paper_id": "2111.04613v2",
    "submission_id": "zlhpIYub2d0",
    "submission_title": "Variational Automatic Curriculum Learning for Sparse-Reward Cooperative Multi-Agent Problems",
    "review_id": "Z-qmDpsG8-p",
    "input": {
      "title": "Variational Automatic Curriculum Learning for Sparse-Reward Cooperative Multi-Agent Problems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper presents novel and insightful content.\n- I especially like the transition from the derived gradient in Eq (4) to the approximate implementation in Section 3.1.\n- The proposed quantization nicely connects concepts such as success buffers to the lower bound on the agent performance.\n- As such concepts are rarely connected to any theory, this is an exciting variation.\n- The experiments demonstrate good performance.\n- In combination with the convincing theoretical motivation, this seems to be a promising approach for curriculum learning in (multi-agent) RL.\n- Further, the ablations in the experimental section give a good impression of the inner workings of the method.\n- The theoretical motivation for the curriculum does not seem to carry over to the discrete variables describing the number of agents.\n- The introduced entity progression scheme seems detached from the theory.\n- While I understand that the gradient-based operator may not be computationally advisable for large N, why did the authors not subsume the number of agents into the parameter phi.\n- And with a properly adjusted noise process for exploration, it could yield an implementation more similar to the theoretical motivation.\n- Nonetheless, the overall method seems to work well.\n- I see another weakness in the performance comparison in the experimental section.\n- Apart from issues with clarity (see next section), the comparison methods did not use a curriculum over the number of agents.\n- While I understand that there may be no related method ideally suited (because of the lack of a curriculum over both goal-state and agent number), I think one ablation should be added to the experiments: VACL without the curriculum over the number of agents.\n- This would give an additional insight into the importance of the curriculum over agents and also yield a fairer comparison to the other curriculum learning methods like GoalGAN, RCG and AMIGo.\n- In the \"SVGD-Principled Update\" experiment, the (principled) gradient-based version from Eq (6) was not compared to the rejection sampling method used in Algorithm 1.\n- Instead, only a version without the rejection step has been used.\n- Why is there no such comparison in the hard-spread scenario?\n- I think it would give a good intuition of whether the rejection sampling used in VACL performs similarly to the gradient-based method.\n- The paper is well written, and the concepts were understandable.\n- However, some parts of the paper could be more concise, especially w.r.t. experimental details.\n- The rejection sampling makes use of an \"oracle\" that can identify infeasible regions.\n- However, the infeasible regions are not specified in the experimental section except for hard-spread, where (as already mentioned) rejection sampling is not evaluated.\n- The authors should clearly state whether additional knowledge was gained through the aforementionend oracle in the other environments.\n- This would allow readers to judge whether VACL had an advantage over other methods like GoalGAN due to the access to the oracle.\n- Was GoalGAN also given access to the initial samples obtained by GetEasy(n)?\n- I think it should be because it explicitly supports such seeding by initial tasks.\n- I am curious because, in line 270, the authors mention that \"GoalGAN and AMIGo takes an extremely long time to train a good neural goal-generator.\n- In Algorithm 1: A reference to the implementation of the \"Sample\" function in the appendix would be good to guide the reader.\n- How were the continuous goals phi defined in the individual experiments?\n- Unfortunately, I could not find any details on this.\n- Especially in the hide-and-seek environment, this would be interesting.\n- Further, what seed tasks are generated by the GetEasy function in the environments?\n- The discussion of the \"Choice of seed task\" in Section 4.1.2 seems to have an error.\n- The text states that \"Exp.Act.w.eval\" works better than \"Exp.Act.\" while the plots indicate the opposite.\n- I think the aforementioned points are another weakness of the paper, as some of those make the obtained results a bit less convincing.\n- The reference to the work by W\u00f6hlke et al. (citation [30] in the main paper) seems to be presented a bit misleading in the related work section.\n- Is it maybe because of a mix-up in the citations?\n- While the authors say that \"[30] propose to meta-learn f^*(\theta) to more effectively expand the curriculum distribution\", it instead seems that [30] use a different characterization of the \"active set\" as the authors proposed here.\n- In [30], the active set is defined as those parts of the task space in which the value function exhibits the largest gradient w.r.t. the task variable.\n- There exists work [1,2] that proposes a similar curriculum scheme and links it to a probabilistic inference perspective.\n- It also minimizes the KL-Divergence between q(phi) and p(phi).\n- While I don't think that this existing work hinders the novelty and originality of the proposed approach due to the different methodology, I think it should be included in the related work section.\n- In combination with the corrected description of reference [30], this would yield a better overview of methods based on value functions and/or probabilistic inference.",
    "review_points_list": [
      "The paper presents novel and insightful content.",
      "I especially like the transition from the derived gradient in Eq (4) to the approximate implementation in Section 3.1.",
      "The proposed quantization nicely connects concepts such as success buffers to the lower bound on the agent performance.",
      "As such concepts are rarely connected to any theory, this is an exciting variation.",
      "The experiments demonstrate good performance.",
      "In combination with the convincing theoretical motivation, this seems to be a promising approach for curriculum learning in (multi-agent) RL.",
      "Further, the ablations in the experimental section give a good impression of the inner workings of the method.",
      "The theoretical motivation for the curriculum does not seem to carry over to the discrete variables describing the number of agents.",
      "The introduced entity progression scheme seems detached from the theory.",
      "While I understand that the gradient-based operator may not be computationally advisable for large N, why did the authors not subsume the number of agents into the parameter phi.",
      "And with a properly adjusted noise process for exploration, it could yield an implementation more similar to the theoretical motivation.",
      "Nonetheless, the overall method seems to work well.",
      "I see another weakness in the performance comparison in the experimental section.",
      "Apart from issues with clarity (see next section), the comparison methods did not use a curriculum over the number of agents.",
      "While I understand that there may be no related method ideally suited (because of the lack of a curriculum over both goal-state and agent number), I think one ablation should be added to the experiments: VACL without the curriculum over the number of agents.",
      "This would give an additional insight into the importance of the curriculum over agents and also yield a fairer comparison to the other curriculum learning methods like GoalGAN, RCG and AMIGo.",
      "In the \"SVGD-Principled Update\" experiment, the (principled) gradient-based version from Eq (6) was not compared to the rejection sampling method used in Algorithm 1.",
      "Instead, only a version without the rejection step has been used.",
      "Why is there no such comparison in the hard-spread scenario?",
      "I think it would give a good intuition of whether the rejection sampling used in VACL performs similarly to the gradient-based method.",
      "The paper is well written, and the concepts were understandable.",
      "However, some parts of the paper could be more concise, especially w.r.t. experimental details.",
      "The rejection sampling makes use of an \"oracle\" that can identify infeasible regions.",
      "However, the infeasible regions are not specified in the experimental section except for hard-spread, where (as already mentioned) rejection sampling is not evaluated.",
      "The authors should clearly state whether additional knowledge was gained through the aforementionend oracle in the other environments.",
      "This would allow readers to judge whether VACL had an advantage over other methods like GoalGAN due to the access to the oracle.",
      "Was GoalGAN also given access to the initial samples obtained by GetEasy(n)?",
      "I think it should be because it explicitly supports such seeding by initial tasks.",
      "I am curious because, in line 270, the authors mention that \"GoalGAN and AMIGo takes an extremely long time to train a good neural goal-generator.",
      "In Algorithm 1: A reference to the implementation of the \"Sample\" function in the appendix would be good to guide the reader.",
      "How were the continuous goals phi defined in the individual experiments?",
      "Unfortunately, I could not find any details on this.",
      "Especially in the hide-and-seek environment, this would be interesting.",
      "Further, what seed tasks are generated by the GetEasy function in the environments?",
      "The discussion of the \"Choice of seed task\" in Section 4.1.2 seems to have an error.",
      "The text states that \"Exp.Act.w.eval\" works better than \"Exp.Act.\" while the plots indicate the opposite.",
      "I think the aforementioned points are another weakness of the paper, as some of those make the obtained results a bit less convincing.",
      "The reference to the work by W\u00f6hlke et al. (citation [30] in the main paper) seems to be presented a bit misleading in the related work section.",
      "Is it maybe because of a mix-up in the citations?",
      "While the authors say that \"[30] propose to meta-learn f^*(\theta) to more effectively expand the curriculum distribution\", it instead seems that [30] use a different characterization of the \"active set\" as the authors proposed here.",
      "In [30], the active set is defined as those parts of the task space in which the value function exhibits the largest gradient w.r.t. the task variable.",
      "There exists work [1,2] that proposes a similar curriculum scheme and links it to a probabilistic inference perspective.",
      "It also minimizes the KL-Divergence between q(phi) and p(phi).",
      "While I don't think that this existing work hinders the novelty and originality of the proposed approach due to the different methodology, I think it should be included in the related work section.",
      "In combination with the corrected description of reference [30], this would yield a better overview of methods based on value functions and/or probabilistic inference."
    ]
  },
  {
    "paper_id": "2111.04613v2",
    "submission_id": "zlhpIYub2d0",
    "submission_title": "Variational Automatic Curriculum Learning for Sparse-Reward Cooperative Multi-Agent Problems",
    "review_id": "mVfWW-Lirdt",
    "input": {
      "title": "Variational Automatic Curriculum Learning for Sparse-Reward Cooperative Multi-Agent Problems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper studied an important method for solving cooperative multiple agent sequential decision-making tasks by using curricula learning.\n- The authors tried to develop and analyze the solution method in a rigorous way.\n- The authors provide some good discussion on the connection to existing work.\n- The method is tested over two environments and shown to outperform a few baselines.\n- However, the motivation and some details related to the claimed contributions are not clearly explained,\n- The problems settings considered seem restrictive to homogenous agents.\n- It is a little unclear to me why Stein variational gradient descent is necessarily better than regular variational inference method.\n- It might be better to provide some more background information.\n- There are some technical details not clearly explained.\n- For example, In section 2.2.1, \u201cto update the particles, we consider an incremental transform T(\times)=\u2026\u201d.\n- Why it is necessary to introduce this transform?\n- This seems to be one of the main ingredients for deriving the gradient update of task distribution.\n- It might better if some design choices can be justified.\n- What is the number of particles used for performing Stein variational inference?\n- How sensitivity is results to it?\n- Another limitation is that the paper only considered homogenous agents and learn a shared goal-conditioned policy.\n- It might worth discussing how the approach can be generalized to heterogenous agents\u2019 cases,\n- since many real world problems involve collaboration among different types of agents.\n- I think the author should explicit demonstrate that the method can work on problems with heterogenous agents.\n- Given that the rebuttal has addressed most of my concerns, I would like to increase my score to 6.",
    "review_points_list": [
      "The paper studied an important method for solving cooperative multiple agent sequential decision-making tasks by using curricula learning.",
      "The authors tried to develop and analyze the solution method in a rigorous way.",
      "The authors provide some good discussion on the connection to existing work.",
      "The method is tested over two environments and shown to outperform a few baselines.",
      "However, the motivation and some details related to the claimed contributions are not clearly explained,",
      "The problems settings considered seem restrictive to homogenous agents.",
      "It is a little unclear to me why Stein variational gradient descent is necessarily better than regular variational inference method.",
      "It might be better to provide some more background information.",
      "There are some technical details not clearly explained.",
      "For example, In section 2.2.1, \u201cto update the particles, we consider an incremental transform T(\times)=\u2026\u201d.",
      "Why it is necessary to introduce this transform?",
      "This seems to be one of the main ingredients for deriving the gradient update of task distribution.",
      "It might better if some design choices can be justified.",
      "What is the number of particles used for performing Stein variational inference?",
      "How sensitivity is results to it?",
      "Another limitation is that the paper only considered homogenous agents and learn a shared goal-conditioned policy.",
      "It might worth discussing how the approach can be generalized to heterogenous agents\u2019 cases,",
      "since many real world problems involve collaboration among different types of agents.",
      "I think the author should explicit demonstrate that the method can work on problems with heterogenous agents.",
      "Given that the rebuttal has addressed most of my concerns, I would like to increase my score to 6."
    ]
  },
  {
    "paper_id": "2111.04613v2",
    "submission_id": "zlhpIYub2d0",
    "submission_title": "Variational Automatic Curriculum Learning for Sparse-Reward Cooperative Multi-Agent Problems",
    "review_id": "JT9tBH3kfGZ",
    "input": {
      "title": "Variational Automatic Curriculum Learning for Sparse-Reward Cooperative Multi-Agent Problems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The main idea of this paper is similar to some other curriculum RL methods, such as GoalGAN, setter and solver (https://arxiv.org/abs/1909.12892 ) and AMIGo. Due to the results of the experiments, this method achieves a great improvement on all previous work in a hide-and-seek environment. Meanwhile, VACL also achieves good performance on other tasks.\n- The main idea of this paper is similar to the GoalGAN and AMIGo.\n- However, the curriculum generator is not as tricky as the mentioned methods to learn.\n- The author uses a smooth function to represent the learning progress of a specific task instead, which achieves a higher sample efficiency.\n- The essential part of this method is to use an incremental transform T to simplify q(\\phi).\n- Due to the results, it\u2019s obvious that this transform is available.\n- I think this paper is written well.\n- The expansion of the theoretical part is very detailed and logically fluent.\n- The details of the experiments seem sufficient.\n- 1. In algorithm 1. \\geteasy(n_{0}). How to define easy tasks for agents? Are these easy tasks picked by humans? What is the difference of two \\geteasy used in \\geteasy(n_0) and \\geteasy(n_k+1)?\n- 2. Section 3.4 is not sufficient enough.\n- Considering that the main idea of VACL is to sample an easy-to-hard curriculum for agents to learn, and also the evaluation of the difficulty of tasks is also based on the V.\n- Why not add the method mentioned in section 4.1 to section 3.4? It causes me so puzzled when I first read section 4.1.\n- 3. Does the forgetting phenomenon occur in the experiments?\n- If yes, how to solve it?\n- I did not find any restrictions or guarantees if the agent forgets some tasks that have been resolved.\n- 4. For empirical, I think V cannot fully express the value of learning on the current task.\n- Maybe you can consider another metric to move tasks into Q_{act}, such as \\delta V.\n- Of course, this is just a possible optimization.\n- 5. How to ensure the upper and lower bounds of \"f\" used in eq.4?\n- Overall, the paper offers a possible solution for evaluating the difficulty of tasks.\n- The paper studies an interesting problem.\n- Its claims are well supported from both theoretical and experimental perspectives.",
    "review_points_list": [
      "The main idea of this paper is similar to some other curriculum RL methods, such as GoalGAN, setter and solver (https://arxiv.org/abs/1909.12892 ) and AMIGo. Due to the results of the experiments, this method achieves a great improvement on all previous work in a hide-and-seek environment. Meanwhile, VACL also achieves good performance on other tasks.",
      "The main idea of this paper is similar to the GoalGAN and AMIGo.",
      "However, the curriculum generator is not as tricky as the mentioned methods to learn.",
      "The author uses a smooth function to represent the learning progress of a specific task instead, which achieves a higher sample efficiency.",
      "The essential part of this method is to use an incremental transform T to simplify q(\\phi).",
      "Due to the results, it\u2019s obvious that this transform is available.",
      "I think this paper is written well.",
      "The expansion of the theoretical part is very detailed and logically fluent.",
      "The details of the experiments seem sufficient.",
      "1. In algorithm 1. \\geteasy(n_{0}). How to define easy tasks for agents? Are these easy tasks picked by humans? What is the difference of two \\geteasy used in \\geteasy(n_0) and \\geteasy(n_k+1)?",
      "2. Section 3.4 is not sufficient enough.",
      "Considering that the main idea of VACL is to sample an easy-to-hard curriculum for agents to learn, and also the evaluation of the difficulty of tasks is also based on the V.",
      "Why not add the method mentioned in section 4.1 to section 3.4? It causes me so puzzled when I first read section 4.1.",
      "3. Does the forgetting phenomenon occur in the experiments?",
      "If yes, how to solve it?",
      "I did not find any restrictions or guarantees if the agent forgets some tasks that have been resolved.",
      "4. For empirical, I think V cannot fully express the value of learning on the current task.",
      "Maybe you can consider another metric to move tasks into Q_{act}, such as \\delta V.",
      "Of course, this is just a possible optimization.",
      "5. How to ensure the upper and lower bounds of \"f\" used in eq.4?",
      "Overall, the paper offers a possible solution for evaluating the difficulty of tasks.",
      "The paper studies an interesting problem.",
      "Its claims are well supported from both theoretical and experimental perspectives."
    ]
  },
  {
    "paper_id": "2102.07804v4",
    "submission_id": "tqQ-8MuSqm",
    "submission_title": "Scaling Up Exact Neural Network Compression by ReLU Stability",
    "review_id": "_Zn73i7UXKq",
    "input": {
      "title": "Scaling Up Exact Neural Network Compression by ReLU Stability",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This work is an expanded work of the previously developed method, but the authors expanded it well with some interesting techniques.\n- The submission is technically sound overall, but some minor improvements can be expected in the experimental results.\n- The submission is well written and very clear.\n- The significance of the work is moderate. Despite the authors can attain the results about 10 times faster than the baseline, the proposed algorithm still not applicable on large networks.\n- Reviewer thinks the paper can be enhanced if the authors apply the algorithm to a small CNN.\n- The CIFAR10 and CIFAR100 datasets usually hard to be achieved high accuracy on FFDNN.\n- Fortunately, convolution can be lowered to matrix multiplication [1], the proposed algorithm can be easily expanded to CNN. Exploring this further would be helpful to the optimization community.\n- The authors mentioned the advantages of exact compression in line 33 as 'there is no risk of disproportionately affecting some inputs and others'. Please provide a concrete example of this.",
    "review_points_list": [
      "This work is an expanded work of the previously developed method, but the authors expanded it well with some interesting techniques.",
      "The submission is technically sound overall, but some minor improvements can be expected in the experimental results.",
      "The submission is well written and very clear.",
      "The significance of the work is moderate. Despite the authors can attain the results about 10 times faster than the baseline, the proposed algorithm still not applicable on large networks.",
      "Reviewer thinks the paper can be enhanced if the authors apply the algorithm to a small CNN.",
      "The CIFAR10 and CIFAR100 datasets usually hard to be achieved high accuracy on FFDNN.",
      "Fortunately, convolution can be lowered to matrix multiplication [1], the proposed algorithm can be easily expanded to CNN. Exploring this further would be helpful to the optimization community.",
      "The authors mentioned the advantages of exact compression in line 33 as 'there is no risk of disproportionately affecting some inputs and others'. Please provide a concrete example of this."
    ]
  },
  {
    "paper_id": "2102.07804v4",
    "submission_id": "tqQ-8MuSqm",
    "submission_title": "Scaling Up Exact Neural Network Compression by ReLU Stability",
    "review_id": "meNWEYAR4a5",
    "input": {
      "title": "Scaling Up Exact Neural Network Compression by ReLU Stability",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper regards the problem of decreasing the size of a neural network as one of functional equivalence.\n- The authors seek to create a smaller network which, when a particular input domain is considered, corresponds to the same function as the original.\n- This is considerably different from the prevailing goal in related literature, which is to decrease the size of the network while considering only its performance according to a particular metric, over the input domain.\n- As in previous work performed by Serra et al. (2020), the method proposed identifies the stably active and inactive neurons of the network and removes them (the former by including some of them in that of the rest of the layer, and the latter by just removing them outright).\n- Given the set of stably active and inactive neurons, the method to remove them which is proposed in this paper (Algorithm 1) is a variation of that present in Serra et al.\n- The main novelty of this work is how these neurons are identified, using a single MILP per layer.\n- The proposed method is technically sound as a whole and provides demonstrable improvement when runtime is concerned.\n- Nevertheless, I have some concerns regarding the motivation and the limitations of this paper.\n- As noted by the authors, their proposed method involves solving an MILP per each layer of the network, which is very expensive for large networks.\n- My main concern is whether this expensive procedure should be considered, given that the problem of exact compression appears to be very demanding as a task, especially since regular pruning methods (which disregard whether the compression is exact or not) work faster and with small reduction in common evaluation metrics of a neural network (e.g. accuracy).\n- The authors highlight in the Related Work section interesting cases where exact compression might be preferred, namely classification problems on imbalanced datasets, as well as robustness.\n- I believe that including such an experiment as a motivating example (i.e. for the first case, training a network for such a task, demonstrating failure of regular pruning techniques, and then demonstrating how much compression can be obtained by the exact compression scheme) would greatly strengthen the motivation behind the paper.\n- Regarding the experimental evaluation present in the paper, it sufficiently demonstrates the speedup of the proposed method, as well as how much compression can be obtained under the exact scheme, both with and without regularization.\n- I want to mention the fact that in Figure 3 and in most results in the supplementary, it appears that if there is no L1 regularization, then no nodes are removed.\n- This seems interesting (since it demonstrates that the exact compression appears to require regularization to work) and I think it requires further discussion.\n- The paper is clearly written, and I only have minor comments to make:\n- As mentioned above, I would suggest including Algorithm 2 in the main paper, since it contains most of the novelty of the work (or at the very least better explain it in Section 5).\n- There are a couple of typos/missing words, in lines 26 and 303.\n- I would suggest adding comments in Algorithm 1, to clearly identify which part of the text corresponds to which part of the pseudocode.\n- Overall, this is a good submission, but it lacks a few motivating examples to demonstrate the usefulness of exact compression. With those, I believe the significance of this work would be improved.",
    "review_points_list": [
      "This paper regards the problem of decreasing the size of a neural network as one of functional equivalence.",
      "The authors seek to create a smaller network which, when a particular input domain is considered, corresponds to the same function as the original.",
      "This is considerably different from the prevailing goal in related literature, which is to decrease the size of the network while considering only its performance according to a particular metric, over the input domain.",
      "As in previous work performed by Serra et al. (2020), the method proposed identifies the stably active and inactive neurons of the network and removes them (the former by including some of them in that of the rest of the layer, and the latter by just removing them outright).",
      "Given the set of stably active and inactive neurons, the method to remove them which is proposed in this paper (Algorithm 1) is a variation of that present in Serra et al.",
      "The main novelty of this work is how these neurons are identified, using a single MILP per layer.",
      "The proposed method is technically sound as a whole and provides demonstrable improvement when runtime is concerned.",
      "Nevertheless, I have some concerns regarding the motivation and the limitations of this paper.",
      "As noted by the authors, their proposed method involves solving an MILP per each layer of the network, which is very expensive for large networks.",
      "My main concern is whether this expensive procedure should be considered, given that the problem of exact compression appears to be very demanding as a task, especially since regular pruning methods (which disregard whether the compression is exact or not) work faster and with small reduction in common evaluation metrics of a neural network (e.g. accuracy).",
      "The authors highlight in the Related Work section interesting cases where exact compression might be preferred, namely classification problems on imbalanced datasets, as well as robustness.",
      "I believe that including such an experiment as a motivating example (i.e. for the first case, training a network for such a task, demonstrating failure of regular pruning techniques, and then demonstrating how much compression can be obtained by the exact compression scheme) would greatly strengthen the motivation behind the paper.",
      "Regarding the experimental evaluation present in the paper, it sufficiently demonstrates the speedup of the proposed method, as well as how much compression can be obtained under the exact scheme, both with and without regularization.",
      "I want to mention the fact that in Figure 3 and in most results in the supplementary, it appears that if there is no L1 regularization, then no nodes are removed.",
      "This seems interesting (since it demonstrates that the exact compression appears to require regularization to work) and I think it requires further discussion.",
      "The paper is clearly written, and I only have minor comments to make:",
      "As mentioned above, I would suggest including Algorithm 2 in the main paper, since it contains most of the novelty of the work (or at the very least better explain it in Section 5).",
      "There are a couple of typos/missing words, in lines 26 and 303.",
      "I would suggest adding comments in Algorithm 1, to clearly identify which part of the text corresponds to which part of the pseudocode.",
      "Overall, this is a good submission, but it lacks a few motivating examples to demonstrate the usefulness of exact compression. With those, I believe the significance of this work would be improved."
    ]
  },
  {
    "paper_id": "2102.07804v4",
    "submission_id": "tqQ-8MuSqm",
    "submission_title": "Scaling Up Exact Neural Network Compression by ReLU Stability",
    "review_id": "U_kg6e-wFom",
    "input": {
      "title": "Scaling Up Exact Neural Network Compression by ReLU Stability",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is interesting and impactful, but has some limitations.\n- I like the paper and I think that MILP formulations are powerful tools with broad range of applications for ReLU networks including compression, robustness, verification, etc...\n- The contribution to improve upen and scale MILP-based problem formulations in ReLU networks is an important contribution to the community on its own and hopefully many other papers can benefit from the insights presented in this work.\n- However, I do have some concerns regarding the application to compression and the resulting compression results.\n- My main concern is that the experimental results (e.g. Fig 3a, 3h, 3o) indicate that you can only start doing meaningful compression (meaningful in the sense that you can remove a significant amount of neurons) once you increase l1-regularization, which however at that point already hurts the test accuracy.\n- So with this method it seems you cannot get compressed networks without loss of accuracy compared to the best performing network.\n- The authors need to significantly improve some of its discussion and presentation of the experimental results.\n- If the authors can address these concerns sufficiently during the rebuttal I would be happy to increase my score.\n- Very insightful and impactful re-formulation of MILP-based problem formulations for ReLU networks.\n- These insights may also be useful beyond the compression community.\n- Strong introduction and presentation of related work.\n- Easy-to-follow and good writing style.\n- Cool presentation of the main contributions in Sections 5.1-5.3.\n- I learned something while reading the paper.\n- My main issues comes down to the experimental performance, mainly around Fig. 3.\n- It seems to me that you need a lot of l1-regularization in order to be able to prune any non-negligible number of neurons.\n- However, at that point the test accuracy has already dropped significantly compared to the networks that are only slightly regularized or unregularized.\n- Please consider discussing some of these aspects in more detail in the paper and try to understand (even on an intuitive level where this is coming from).\n- Alternatively, can you find scenarios where this is not the case?\n- Maybe relaxing the search space for the input space could be one way because assuming the entire [0,1] domain for MNIST, e.g., might still be too large for what is a reasonable input?\n- Even if there is not an obvious scenario where the compression is more useful without accuracy loss, the authors could be discussing other potential applications or use cases of their novel MILP-formulations in order to increase the impact of the paper and the possible applications so that other researchers can benefit from their contribution.\n- Could you discuss applications to other type of networks?\n- What about convolutional layers for example?\n- Even simple CNNs like LeNet5 could be interesting.\n- There should be a hopefully easy generalization of the formulations to convolutional layers and I would love to see some preliminary results or discussions in that direction\n- I am not a big fan of Section 5.4.\n- I think it's too formal for something that intuitively makes a lot of sense.\n- I would move all the theoretical results and the pseudo-code into the appendix for people if they are interested in seeing a very formal discussion about how neuron stability can be used for compression.\n- In the main paper, I would instead focus on a high-level summary of this section.\n- I would then use the space to expand upon some of the additional technical details with regards to Sections 5.1-5.3, i.e., move some of the material from supplementary Sections A-E into the main paper potentially even including Algorithm 2.\n- Line 26: typo: 'that not equivalent'\n- A few more interesting and recent references for your related work:\n- On robustness of pruning (line 65): https://arxiv.org/abs/2103.03014\n- 2nd order prune methods (line 73,74): https://arxiv.org/abs/2004.14340\n- The first sentence in the abstract is somewhat mis-leading.\n- It is really only true for ReLU networks I believe.\n- Maybe mention how you would handle batch-norm and data normalization in the first layer.\n- Might be obvious to some readers but potentially not to everyone.\n- Lines 121-125: Could be a little more specific what the decision variables of the MILP are?\n- That took a while to understand and could be much streamlined if you mention that more explicitly.\n- Thank you for submitting a detailed appendix and code.\n- Very helpful and very much appreciated.\n- The authors have responded to my concerns throughout the rebuttal period and clarified lingering points of confusion I raised in my initial review.\n- Specifically, they addressed all my concerns mentioned in the 'Weaknesses' section of my initial review and added additional insightful experiments.\n- I want to emphasize that the additional results definitely should make it into the final submission if accepted.\n- I have raised my score from 6 to 7.",
    "review_points_list": [
      "The paper is interesting and impactful, but has some limitations.",
      "I like the paper and I think that MILP formulations are powerful tools with broad range of applications for ReLU networks including compression, robustness, verification, etc...",
      "The contribution to improve upen and scale MILP-based problem formulations in ReLU networks is an important contribution to the community on its own and hopefully many other papers can benefit from the insights presented in this work.",
      "However, I do have some concerns regarding the application to compression and the resulting compression results.",
      "My main concern is that the experimental results (e.g. Fig 3a, 3h, 3o) indicate that you can only start doing meaningful compression (meaningful in the sense that you can remove a significant amount of neurons) once you increase l1-regularization, which however at that point already hurts the test accuracy.",
      "So with this method it seems you cannot get compressed networks without loss of accuracy compared to the best performing network.",
      "The authors need to significantly improve some of its discussion and presentation of the experimental results.",
      "If the authors can address these concerns sufficiently during the rebuttal I would be happy to increase my score.",
      "Very insightful and impactful re-formulation of MILP-based problem formulations for ReLU networks.",
      "These insights may also be useful beyond the compression community.",
      "Strong introduction and presentation of related work.",
      "Easy-to-follow and good writing style.",
      "Cool presentation of the main contributions in Sections 5.1-5.3.",
      "I learned something while reading the paper.",
      "My main issues comes down to the experimental performance, mainly around Fig. 3.",
      "It seems to me that you need a lot of l1-regularization in order to be able to prune any non-negligible number of neurons.",
      "However, at that point the test accuracy has already dropped significantly compared to the networks that are only slightly regularized or unregularized.",
      "Please consider discussing some of these aspects in more detail in the paper and try to understand (even on an intuitive level where this is coming from).",
      "Alternatively, can you find scenarios where this is not the case?",
      "Maybe relaxing the search space for the input space could be one way because assuming the entire [0,1] domain for MNIST, e.g., might still be too large for what is a reasonable input?",
      "Even if there is not an obvious scenario where the compression is more useful without accuracy loss, the authors could be discussing other potential applications or use cases of their novel MILP-formulations in order to increase the impact of the paper and the possible applications so that other researchers can benefit from their contribution.",
      "Could you discuss applications to other type of networks?",
      "What about convolutional layers for example?",
      "Even simple CNNs like LeNet5 could be interesting.",
      "There should be a hopefully easy generalization of the formulations to convolutional layers and I would love to see some preliminary results or discussions in that direction",
      "I am not a big fan of Section 5.4.",
      "I think it's too formal for something that intuitively makes a lot of sense.",
      "I would move all the theoretical results and the pseudo-code into the appendix for people if they are interested in seeing a very formal discussion about how neuron stability can be used for compression.",
      "In the main paper, I would instead focus on a high-level summary of this section.",
      "I would then use the space to expand upon some of the additional technical details with regards to Sections 5.1-5.3, i.e., move some of the material from supplementary Sections A-E into the main paper potentially even including Algorithm 2.",
      "Line 26: typo: 'that not equivalent'",
      "A few more interesting and recent references for your related work:",
      "On robustness of pruning (line 65): https://arxiv.org/abs/2103.03014",
      "2nd order prune methods (line 73,74): https://arxiv.org/abs/2004.14340",
      "The first sentence in the abstract is somewhat mis-leading.",
      "It is really only true for ReLU networks I believe.",
      "Maybe mention how you would handle batch-norm and data normalization in the first layer.",
      "Might be obvious to some readers but potentially not to everyone.",
      "Lines 121-125: Could be a little more specific what the decision variables of the MILP are?",
      "That took a while to understand and could be much streamlined if you mention that more explicitly.",
      "Thank you for submitting a detailed appendix and code.",
      "Very helpful and very much appreciated.",
      "The authors have responded to my concerns throughout the rebuttal period and clarified lingering points of confusion I raised in my initial review.",
      "Specifically, they addressed all my concerns mentioned in the 'Weaknesses' section of my initial review and added additional insightful experiments.",
      "I want to emphasize that the additional results definitely should make it into the final submission if accepted.",
      "I have raised my score from 6 to 7."
    ]
  },
  {
    "paper_id": "2102.07804v4",
    "submission_id": "tqQ-8MuSqm",
    "submission_title": "Scaling Up Exact Neural Network Compression by ReLU Stability",
    "review_id": "VFxzoSjkQI",
    "input": {
      "title": "Scaling Up Exact Neural Network Compression by ReLU Stability",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well-organized and easy to follow, with a clear introduction, methodology, and results.\n- The authors could improve the paper by providing more detailed information about the experimental setup, including the specific hyperparameters used and the computational resources required.\n- The results are impressive, showing a significant improvement over previous state-of-the-art methods.\n- However, the authors could also discuss potential limitations and future directions for the research.\n- The paper is well-written and the authors' enthusiasm is evident throughout.",
    "review_points_list": [
      "The paper is well-organized and easy to follow, with a clear introduction, methodology, and results.",
      "The authors could improve the paper by providing more detailed information about the experimental setup, including the specific hyperparameters used and the computational resources required.",
      "The results are impressive, showing a significant improvement over previous state-of-the-art methods.",
      "However, the authors could also discuss potential limitations and future directions for the research.",
      "The paper is well-written and the authors' enthusiasm is evident throughout."
    ]
  },
  {
    "paper_id": "2110.15191v1",
    "submission_id": "u7Qb7pQk8tF",
    "submission_title": "Unsupervised Domain Adaptation with Dynamics-Aware Rewards in Reinforcement Learning",
    "review_id": "SkFAA7gGT-B",
    "input": {
      "title": "Unsupervised Domain Adaptation with Dynamics-Aware Rewards in Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors want to use domain adaptation to learn a policy that will perform well in a target environment, assuming access to a source environment where it is easier to get many samples.\n- The authors propose a method called DARS, standing for dynamics-aware rewards.\n- It is based off 2 primary components. First, there is a skill learning policy. For this policy, they use a common trick in the literature: an exploratory policy \u03c0 is conditioned on some latent skill vector \u03c9.\n- As trajectories are generated, a learned q_phi(\u03c9|s) acts as a discriminator that tries to identify \u03c9 from the episode.\n- Intuitively, if the mutual information between \u03c9 and episode \u03c4 is maximized, then different \u03c9 should lead to distinguishable trajectories in the environment.\n- The specific citations for this are DIAYN and GPIM but something analogous to this has shown up in other recent papers as well.\n- They then combine this with a dynamics based reward.\n- The aim is to match distributions (goal, \u03c4) across the source environment and target environment, given the same policy \u03c0.\n- Through some derivation, you can show that when taking the KL divergence p(g,\u03c4), all terms between the two cancel out except for p_source(s_{t+1}|s_t,a_t) and p_target(s_{t+1}|s_t,a_t).\n- The ratio of these probabilities can then further be approximated by learning 2 classifiers.\n- This closely follows the Domain Adaptation with Rewards from Classifiers (DARC) paper.\n- Combined, they demonstrate that skills learned in the source domain transfer better to the target domain.\n- I found the presentation in this paper a bit dense, although that is to be expected since they are aiming to explain 2 papers worth of ideas in 1.\n- At a surface level, I personally found it confusing that \u0394r was defined opposite to how it was defined in the DARC paper (i.e as (source - target)), and I initially thought this was an error until I noticed that it was subtracted instead of added to the reward.\n- I think negating it and treating \u0394r as an additive reward bonus is slightly more intuitive.\n- However, this is a fairly minor issue, my more detailed reservation with the paper is that it doesn't feel like a very interesting research contribution.\n- To me, it feels like it is primarily about taking DARC and then replacing the source rewards with a skill learning method.\n- The 2 working together doesn't seem novel to me because they are somewhat orthogonal methods (one is skill learning in 1 env and the other is transfer learning between 2 envs).\n- Both are based on defining rewards for an RL method to optimize.\n- A priori I would assume the two would work together as long as you balanced their reward objectives appropriately, and this is basically what the paper shows (adjusting the \u03b2 weight is what affects whether the method works or not).\n- Moreover it doesn't seem like their comparisons are very strong - they are essentially comparing against a skill learning / intrinsic motivation (SMiRL, GPIM), or they are comparing against a transfer learning method (DARC with a proxy reward), and again it seems like the method is supposed to work if tuned properly.\n- It does, by a margin that appears small.\n- To me, if it a priori is supposed to work, and the improvement is fairly small, then I'm not sure the paper needs to exist.\n- This is especially true because the target problem they are solving feels narrow, as it is the intersection of 2 other problems.\n- They aim to solve 'transfer learning, between 2 environments, where we have ready access to 1 and not the other, but we also don't have rewards in the source env we have ready access to', and this doesn't feel like a common scenario of interest, which weakens significance.\n- Without an especially strong empirical result, to be strong enough for acceptance the paper needs some argument that the combination of the two is better than the sum of its parts.\n- It attempts to argue this by saying that the dynamics from the target domain are affecting the skill learning process (in the Map env visualizations).\n- I think this is basically just a consequence of 'weighting the objectives correctly' - in the limit, at \u03b2 = 0 you recover DIAYN and at \u03b2 = \u221e you recover DARC, so at some \u03b2 in between you expect to see episodes that 1) are closer to the target episodes but 2) still have diversity within that restricted part of state space, and that's effectively what we see here.\n- One of my comparisons was comparing an unsupervised (no observed reward) method against a supervised (observed reward) method, which was a mistake on my part.\n- After some more consideration, I believe the problem the paper aims to solve is more important than I previously thought.",
    "review_points_list": [
      "The authors want to use domain adaptation to learn a policy that will perform well in a target environment, assuming access to a source environment where it is easier to get many samples.",
      "The authors propose a method called DARS, standing for dynamics-aware rewards.",
      "It is based off 2 primary components. First, there is a skill learning policy. For this policy, they use a common trick in the literature: an exploratory policy \u03c0 is conditioned on some latent skill vector \u03c9.",
      "As trajectories are generated, a learned q_phi(\u03c9|s) acts as a discriminator that tries to identify \u03c9 from the episode.",
      "Intuitively, if the mutual information between \u03c9 and episode \u03c4 is maximized, then different \u03c9 should lead to distinguishable trajectories in the environment.",
      "The specific citations for this are DIAYN and GPIM but something analogous to this has shown up in other recent papers as well.",
      "They then combine this with a dynamics based reward.",
      "The aim is to match distributions (goal, \u03c4) across the source environment and target environment, given the same policy \u03c0.",
      "Through some derivation, you can show that when taking the KL divergence p(g,\u03c4), all terms between the two cancel out except for p_source(s_{t+1}|s_t,a_t) and p_target(s_{t+1}|s_t,a_t).",
      "The ratio of these probabilities can then further be approximated by learning 2 classifiers.",
      "This closely follows the Domain Adaptation with Rewards from Classifiers (DARC) paper.",
      "Combined, they demonstrate that skills learned in the source domain transfer better to the target domain.",
      "I found the presentation in this paper a bit dense, although that is to be expected since they are aiming to explain 2 papers worth of ideas in 1.",
      "At a surface level, I personally found it confusing that \u0394r was defined opposite to how it was defined in the DARC paper (i.e as (source - target)), and I initially thought this was an error until I noticed that it was subtracted instead of added to the reward.",
      "I think negating it and treating \u0394r as an additive reward bonus is slightly more intuitive.",
      "However, this is a fairly minor issue, my more detailed reservation with the paper is that it doesn't feel like a very interesting research contribution.",
      "To me, it feels like it is primarily about taking DARC and then replacing the source rewards with a skill learning method.",
      "The 2 working together doesn't seem novel to me because they are somewhat orthogonal methods (one is skill learning in 1 env and the other is transfer learning between 2 envs).",
      "Both are based on defining rewards for an RL method to optimize.",
      "A priori I would assume the two would work together as long as you balanced their reward objectives appropriately, and this is basically what the paper shows (adjusting the \u03b2 weight is what affects whether the method works or not).",
      "Moreover it doesn't seem like their comparisons are very strong - they are essentially comparing against a skill learning / intrinsic motivation (SMiRL, GPIM), or they are comparing against a transfer learning method (DARC with a proxy reward), and again it seems like the method is supposed to work if tuned properly.",
      "It does, by a margin that appears small.",
      "To me, if it a priori is supposed to work, and the improvement is fairly small, then I'm not sure the paper needs to exist.",
      "This is especially true because the target problem they are solving feels narrow, as it is the intersection of 2 other problems.",
      "They aim to solve 'transfer learning, between 2 environments, where we have ready access to 1 and not the other, but we also don't have rewards in the source env we have ready access to', and this doesn't feel like a common scenario of interest, which weakens significance.",
      "Without an especially strong empirical result, to be strong enough for acceptance the paper needs some argument that the combination of the two is better than the sum of its parts.",
      "It attempts to argue this by saying that the dynamics from the target domain are affecting the skill learning process (in the Map env visualizations).",
      "I think this is basically just a consequence of 'weighting the objectives correctly' - in the limit, at \u03b2 = 0 you recover DIAYN and at \u03b2 = \u221e you recover DARC, so at some \u03b2 in between you expect to see episodes that 1) are closer to the target episodes but 2) still have diversity within that restricted part of state space, and that's effectively what we see here.",
      "One of my comparisons was comparing an unsupervised (no observed reward) method against a supervised (observed reward) method, which was a mistake on my part.",
      "After some more consideration, I believe the problem the paper aims to solve is more important than I previously thought."
    ]
  },
  {
    "paper_id": "2110.15191v1",
    "submission_id": "u7Qb7pQk8tF",
    "submission_title": "Unsupervised Domain Adaptation with Dynamics-Aware Rewards in Reinforcement Learning",
    "review_id": "FdM4399aJR0",
    "input": {
      "title": "Unsupervised Domain Adaptation with Dynamics-Aware Rewards in Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors address the problem of unsupervised Domain Adaptation in Reinforcement Learning.\n- Combining ideas from previous work, they devise a method able to utilize an easy to sample source environment (e.g., a simulator) in order to learn a set of skills without supervision, while at the same time guarantee that these skills will be suited to the target environment (e.g., a real robotic system).\n- To achieve this, they modify the reward structure of the typical Unsupervised Reinforcement Learning setup to enable the agent to build skills that are compatible with the target environment dynamics, while penalizing exploration in regions of the source environment where the dynamics differ.\n- The proposed approach is benchmarked against state-of-the-art algorithms in a wide variety of environments with increased complexity.\n- manages to outperform previous baselines both in simulation as well as in three walking tasks on a real quadruped robot.",
    "review_points_list": [
      "The authors address the problem of unsupervised Domain Adaptation in Reinforcement Learning.",
      "Combining ideas from previous work, they devise a method able to utilize an easy to sample source environment (e.g., a simulator) in order to learn a set of skills without supervision, while at the same time guarantee that these skills will be suited to the target environment (e.g., a real robotic system).",
      "To achieve this, they modify the reward structure of the typical Unsupervised Reinforcement Learning setup to enable the agent to build skills that are compatible with the target environment dynamics, while penalizing exploration in regions of the source environment where the dynamics differ.",
      "The proposed approach is benchmarked against state-of-the-art algorithms in a wide variety of environments with increased complexity.",
      "manages to outperform previous baselines both in simulation as well as in three walking tasks on a real quadruped robot."
    ]
  },
  {
    "paper_id": "2110.15191v1",
    "submission_id": "u7Qb7pQk8tF",
    "submission_title": "Unsupervised Domain Adaptation with Dynamics-Aware Rewards in Reinforcement Learning",
    "review_id": "_ct4yXOJMN",
    "input": {
      "title": "Unsupervised Domain Adaptation with Dynamics-Aware Rewards in Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The approach trains a goal-conditioned policy which is capable of adapting to changes in dynamics between a source and target domain.\n- The method is able to train in an unsupervised fashion in target domains where data collection can be hard or expensive.\n- The approach is able to train the goal distribution, goal-based reward function and goal-conditioned policy primarily on the source domain where data collection is inexpensive, while regularising for differences in dynamics between the two domains.\n- This regularisation encourages the policy to find skills that lead to consistent results in the source and target domains while utilising an order of magnitude lower amount of data from the target domain.\n- This is particularly promising for real world robotics, especially in the context of sim2real methods, where simulated data is easy and cheap to generate but has differences in dynamics to the real world where data is also expensive to generate.\n- The approach is tested on several simulated and real world source and transfer tasks and shows promising results.\n- There are several assumptions that are key for the method to work.\n- One of the key assumptions is that there is no transition that is possible in the target domain but impossible in the source domain.\n- The approach does work on this transfer setting it effectively over-constrains the search space leading to a potentially sub-optimal solution.\n- It would be interesting to see if this assumption can be relaxed.\n- Another important assumption is that the goal distribution is consistent under dynamics changes between the source and target domains.\n- A relaxation of this assumption is derived in the supplementary material wherein the goal distribution training can be regularised to respect the source/target dynamics changes and is validated with a set of experiments.\n- It would be useful in this context to see (Map-a, Map-e) discriminator visualisations in Figure 6.\n- Overall, I am quite encouraged by the results presented in the paper, which are strong and show that the method is able to do well on a variety of control tasks both in simulation and in the real world.\n- I am particularly excited about the applications to sim2real settings where the data limitations can make learning quite hard.\n- It would be interesting to see if further reductions in the data is possible,\n- It would be great if there was an ablation study with respect to the number of real world data points used (i.e. fraction of target domain data) on some of these tasks.\n- To add further clarity to the paper, it would be useful if the approach for training the classifiers to estimate the dynamics regularisation is also detailed either in the main text or supplementary material.",
    "review_points_list": [
      "The approach trains a goal-conditioned policy which is capable of adapting to changes in dynamics between a source and target domain.",
      "The method is able to train in an unsupervised fashion in target domains where data collection can be hard or expensive.",
      "The approach is able to train the goal distribution, goal-based reward function and goal-conditioned policy primarily on the source domain where data collection is inexpensive, while regularising for differences in dynamics between the two domains.",
      "This regularisation encourages the policy to find skills that lead to consistent results in the source and target domains while utilising an order of magnitude lower amount of data from the target domain.",
      "This is particularly promising for real world robotics, especially in the context of sim2real methods, where simulated data is easy and cheap to generate but has differences in dynamics to the real world where data is also expensive to generate.",
      "The approach is tested on several simulated and real world source and transfer tasks and shows promising results.",
      "There are several assumptions that are key for the method to work.",
      "One of the key assumptions is that there is no transition that is possible in the target domain but impossible in the source domain.",
      "The approach does work on this transfer setting it effectively over-constrains the search space leading to a potentially sub-optimal solution.",
      "It would be interesting to see if this assumption can be relaxed.",
      "Another important assumption is that the goal distribution is consistent under dynamics changes between the source and target domains.",
      "A relaxation of this assumption is derived in the supplementary material wherein the goal distribution training can be regularised to respect the source/target dynamics changes and is validated with a set of experiments.",
      "It would be useful in this context to see (Map-a, Map-e) discriminator visualisations in Figure 6.",
      "Overall, I am quite encouraged by the results presented in the paper, which are strong and show that the method is able to do well on a variety of control tasks both in simulation and in the real world.",
      "I am particularly excited about the applications to sim2real settings where the data limitations can make learning quite hard.",
      "It would be interesting to see if further reductions in the data is possible,",
      "It would be great if there was an ablation study with respect to the number of real world data points used (i.e. fraction of target domain data) on some of these tasks.",
      "To add further clarity to the paper, it would be useful if the approach for training the classifiers to estimate the dynamics regularisation is also detailed either in the main text or supplementary material."
    ]
  },
  {
    "paper_id": "2011.14126v5",
    "submission_id": "z5-chidgZU3",
    "submission_title": "Risk Monotonicity in Statistical Learning",
    "review_id": "brozjunpOtj",
    "input": {
      "title": "Risk Monotonicity in Statistical Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper works on the important problem of risk-monotonic learning which has gotten much renewed interest since the discovery of the double descent phenomenon which is much more widely spread than previously thought.\n- This paper, incredibly, manages to build a risk monotonic learning algorithm for the very general setting of bounded losses, for any base learning algorithm.\n- The algorithm is shown to be risk monotone in expectation and high probability, depending on the choice of the gaps.\n- It remains very novel and surprising to me that it is at all possible to derive an algorithm which is risk monotonic in expectation for such a general setting.\n- As such, I expect this to be a high impact paper on which future papers will build to further construct improved risk monotonic algorithms, which may open up a whole new field of study for machine learning algorithms and theory.\n- Sadly, I am not well-versed enough in concentration inequalities so I could not check the proofs in the limited time I have for reviewing this paper, I hope another reviewer can step in for this.\n- If the math checks out, I definitely vote to accept this paper.\n- I did find a few minor issues and possibly mistakes, but I'm sure these issues can be resolved through the review process.\n- Most important feedback.\n- Assumption 2: can this assumption not be at odds with consistency?\n- Most important feedback.\n- 1) Assumption 2: can this assumption not be at odds with consistency?\n- I mean, if the assumption is violated, we can just instead of using B's output, use the output of B in the previous round, until the condition is actually satisfied.\n- So this seems to indicate that consistency will not be violated?\n- I guess though that an essential condition is that the risk minimizer should be in an area of P_0 with > 0 probability?\n- Maybe it would be good to clarify that explicitly.\n- 2) Proposition 9: the point mass assumption seems incompatible to Assumption 2 to me, which is a condition of Theorem 8.\n- So is there a mistake here?\n- 3) Line 341: but for beta = 0 (e.g. bounded losses), there is a cost to pay?\n- Then I find in Line 173-174 the statement 'with essentially the same excess risk rate' slightly misleading.\n- It only is shown that under the Bernstein condition beta > 0 the risk rate does not get worse significantly, right?\n- Similairly for the statement in line 340 'risk monotonicity need not come at the price ....'.\n- 4) It strikes me that we need to resort to a randomized algorithm that fulfill Assumption 2.\n- Can you provide some intuition why this was necessary?\n- Furthermore, I do appreciate that the current algorithm works with non-i.i.d. data, but is the complicated new concentration inequality necessary?\n- Why can we not use good old existing results?\n- E.g., is Theorem 6 really necessary, or can I also drop in another inequality here?\n- If so, which would I choose?\n- What makes it essential that we need this one?\n- Is it that for this specific one we can analyze the algorithm under the Bernstein condition, but could we also obtain risk monotone algorithms with a simpler technique and or inequality?\n- 5) It is never reflected on what the intuition of \rho is.\n- Do you have any idea what the consequence of this parameter is?\n- How would you set it, or would you somehow tune it on the fly?\n- I guess you may want to choose the largest or smallest value possible that still satisfies Assumption 2?\n- Can you give some small explanation.\n- 6) Algorithm 1 is a bit misleading, since the sequence of gaps cannot be generated beforehand, as the gaps depend on the outputs of the base algorithm (e.g. on B(Z_{1:k}) and the P_k's).\n- Would be good to squeeze it in between line 1 and 2: 'compute \rule  for ( \rule  , \rule )-risk monotonicity, and to eq. X for risk-monotonicity for in expectation'.\n- Please also indicate the dependence of the gaps on the P_0, Q_k's, P_k's, P_{k-1}, rho, delta, ...).\n- Would also be nice if it is indicated that rho, delta may be inputs to the Algorithm.\n- 7) Line 364-366: this remark is a bit too much info in too little space, I could not understand it.\n- Can this be explained in a bit more detail?\n- Perhaps in the appendix.\n- Why is convexity in the first argument enough for this construction, and how would the construction go exactly?\n- What kind of OCO algorithm would we need; e.g., one with sublinear regret is enough or we need something more advanced?\n- 8) Line 193: it is never clarified what is meant by easier.\n- Does it mean the gaps are bigger for the expectation case?\n- Or is there somehow a cost in the rate of convergence?\n- 9) Lines 298-300: I think this could definitely be non-trivial.\n- Also, tuning the regularization or limiting the optimization may break guarantees of the base algorithm (e.g., a fast rate).\n- So it seems there may be a trade-off still between learning speed and monotonicity....?\n- 10) In the related work, you could consider Viering, Tom, and Marco Loog.\n- It discusses even more causes of non-monotonic learning curves besides dipping and peaking.\n- Furthermore, you may be interested to know that peaking can be traced back historically already to 1989, see also Loog, Marco, et al.\n- 11) Definition 2 seems a bit confusing; is this now a Theorem or Proposition or a definition?\n- It seems like almost a theorem or proposition, but it cannot be correct.\n- I guess it should be 'Under Assumption 1 and Consistency of the Base Algorithm A is consistent'?\n- But then probably it should also mention Assumption 2, and how the gaps are specified.\n- Anyhow, it seems clear that if B is consistent, A must also be consistent, under Assumption a 1 & 2 and for both formula's of the gaps, correct?",
    "review_points_list": [
      "This paper works on the important problem of risk-monotonic learning which has gotten much renewed interest since the discovery of the double descent phenomenon which is much more widely spread than previously thought.",
      "This paper, incredibly, manages to build a risk monotonic learning algorithm for the very general setting of bounded losses, for any base learning algorithm.",
      "The algorithm is shown to be risk monotone in expectation and high probability, depending on the choice of the gaps.",
      "It remains very novel and surprising to me that it is at all possible to derive an algorithm which is risk monotonic in expectation for such a general setting.",
      "As such, I expect this to be a high impact paper on which future papers will build to further construct improved risk monotonic algorithms, which may open up a whole new field of study for machine learning algorithms and theory.",
      "Sadly, I am not well-versed enough in concentration inequalities so I could not check the proofs in the limited time I have for reviewing this paper, I hope another reviewer can step in for this.",
      "If the math checks out, I definitely vote to accept this paper.",
      "I did find a few minor issues and possibly mistakes, but I'm sure these issues can be resolved through the review process.",
      "Most important feedback.",
      "Assumption 2: can this assumption not be at odds with consistency?",
      "Most important feedback.",
      "1) Assumption 2: can this assumption not be at odds with consistency?",
      "I mean, if the assumption is violated, we can just instead of using B's output, use the output of B in the previous round, until the condition is actually satisfied.",
      "So this seems to indicate that consistency will not be violated?",
      "I guess though that an essential condition is that the risk minimizer should be in an area of P_0 with > 0 probability?",
      "Maybe it would be good to clarify that explicitly.",
      "2) Proposition 9: the point mass assumption seems incompatible to Assumption 2 to me, which is a condition of Theorem 8.",
      "So is there a mistake here?",
      "3) Line 341: but for beta = 0 (e.g. bounded losses), there is a cost to pay?",
      "Then I find in Line 173-174 the statement 'with essentially the same excess risk rate' slightly misleading.",
      "It only is shown that under the Bernstein condition beta > 0 the risk rate does not get worse significantly, right?",
      "Similairly for the statement in line 340 'risk monotonicity need not come at the price ....'.",
      "4) It strikes me that we need to resort to a randomized algorithm that fulfill Assumption 2.",
      "Can you provide some intuition why this was necessary?",
      "Furthermore, I do appreciate that the current algorithm works with non-i.i.d. data, but is the complicated new concentration inequality necessary?",
      "Why can we not use good old existing results?",
      "E.g., is Theorem 6 really necessary, or can I also drop in another inequality here?",
      "If so, which would I choose?",
      "What makes it essential that we need this one?",
      "Is it that for this specific one we can analyze the algorithm under the Bernstein condition, but could we also obtain risk monotone algorithms with a simpler technique and or inequality?",
      "5) It is never reflected on what the intuition of \rho is.",
      "Do you have any idea what the consequence of this parameter is?",
      "How would you set it, or would you somehow tune it on the fly?",
      "I guess you may want to choose the largest or smallest value possible that still satisfies Assumption 2?",
      "Can you give some small explanation.",
      "6) Algorithm 1 is a bit misleading, since the sequence of gaps cannot be generated beforehand, as the gaps depend on the outputs of the base algorithm (e.g. on B(Z_{1:k}) and the P_k's).",
      "Would be good to squeeze it in between line 1 and 2: 'compute \rule  for ( \rule  , \rule )-risk monotonicity, and to eq. X for risk-monotonicity for in expectation'.",
      "Please also indicate the dependence of the gaps on the P_0, Q_k's, P_k's, P_{k-1}, rho, delta, ...).",
      "Would also be nice if it is indicated that rho, delta may be inputs to the Algorithm.",
      "7) Line 364-366: this remark is a bit too much info in too little space, I could not understand it.",
      "Can this be explained in a bit more detail?",
      "Perhaps in the appendix.",
      "Why is convexity in the first argument enough for this construction, and how would the construction go exactly?",
      "What kind of OCO algorithm would we need; e.g., one with sublinear regret is enough or we need something more advanced?",
      "8) Line 193: it is never clarified what is meant by easier.",
      "Does it mean the gaps are bigger for the expectation case?",
      "Or is there somehow a cost in the rate of convergence?",
      "9) Lines 298-300: I think this could definitely be non-trivial.",
      "Also, tuning the regularization or limiting the optimization may break guarantees of the base algorithm (e.g., a fast rate).",
      "So it seems there may be a trade-off still between learning speed and monotonicity....?",
      "10) In the related work, you could consider Viering, Tom, and Marco Loog.",
      "It discusses even more causes of non-monotonic learning curves besides dipping and peaking.",
      "Furthermore, you may be interested to know that peaking can be traced back historically already to 1989, see also Loog, Marco, et al.",
      "11) Definition 2 seems a bit confusing; is this now a Theorem or Proposition or a definition?",
      "It seems like almost a theorem or proposition, but it cannot be correct.",
      "I guess it should be 'Under Assumption 1 and Consistency of the Base Algorithm A is consistent'?",
      "But then probably it should also mention Assumption 2, and how the gaps are specified.",
      "Anyhow, it seems clear that if B is consistent, A must also be consistent, under Assumption a 1 & 2 and for both formula's of the gaps, correct?"
    ]
  },
  {
    "paper_id": "2011.14126v5",
    "submission_id": "z5-chidgZU3",
    "submission_title": "Risk Monotonicity in Statistical Learning",
    "review_id": "gzABbnrmN-",
    "input": {
      "title": "Risk Monotonicity in Statistical Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is clearly structured and well-written, though the authors are encouraged to carefully proof-read the manuscript to avoid some typos.\n- I am not an expert on PAC-Bayesian analysis. However, as mentioned before, the non-monotonic risk behavior is a very important research question in the machine learning community and many papers have been published in understanding this phenomenon. Hence, this question that the authors study in this paper is of significant importance.\n- I do have some major concerns for the proposed algorithm.\n- My first question is that, if I understand correctly, the proposed algorithm trades the monotonic risk curve with the computation time? If this is the case, then what exactly is the trade-off between the computation time and the monotonic risk behavior?\n- My second question is that can the authors design some simple numerical experiments to explore the efficacy of the proposed algorithm. In particular, it would be more convincing to show experimentally that the algorithm indeed return an estimator with monotonic risk behavior.",
    "review_points_list": [
      "The paper is clearly structured and well-written, though the authors are encouraged to carefully proof-read the manuscript to avoid some typos.",
      "I am not an expert on PAC-Bayesian analysis. However, as mentioned before, the non-monotonic risk behavior is a very important research question in the machine learning community and many papers have been published in understanding this phenomenon. Hence, this question that the authors study in this paper is of significant importance.",
      "I do have some major concerns for the proposed algorithm.",
      "My first question is that, if I understand correctly, the proposed algorithm trades the monotonic risk curve with the computation time? If this is the case, then what exactly is the trade-off between the computation time and the monotonic risk behavior?",
      "My second question is that can the authors design some simple numerical experiments to explore the efficacy of the proposed algorithm. In particular, it would be more convincing to show experimentally that the algorithm indeed return an estimator with monotonic risk behavior."
    ]
  },
  {
    "paper_id": "2011.14126v5",
    "submission_id": "z5-chidgZU3",
    "submission_title": "Risk Monotonicity in Statistical Learning",
    "review_id": "O9Mj8x6rJY0",
    "input": {
      "title": "Risk Monotonicity in Statistical Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think the paper is fairly complete in terms of the results, and provides sufficient theoretical results and new proof ideas. I recommend it for acceptance.\n- Can you provide some examples where Assumption 1 holds but data is not i.i.d. ? Typically, we would like the behavior of the learning algorithm to be invariant to the order in which the samples are provided. Thus, we would like the property to hold independent of the order of samples. What kind of learning setting do you hope to use your monotonic algorithm where Assumption 1 holds for data is not i.i.d.? \n- Can you provide some intuition on why we could not use empirical Bernstein inequalities for setting the value of \\\\(\\zeta_k\\\\) ? Why is it natural to look at the problem of risk monotonicity in the PAC-Bayes setting ?\n- The results provided in the paper hold for all N >= N_\\\\(\\Delta\\\\) . Is it possible to show that for every N_\\\\(\\Delta\\\\) , there exists some distribution for which learning monotonically is impossible when N < N_\\\\(\\Delta\\\\) ? \n- (Minor) In lines 128-129, the authors claim that the results of [49] could not be extended to hold in expectation. Can the authors discuss why ?\n- The paper is well written otherwise. I skimmed through the proofs and they seem to be correct. \n- The proof ideas in Appendix B are quite interesting!\n- Minor comments: References [22] and [23] are identical.\n- Minor comments: Lines 36-40 regarding discussion of connections to neural networks seem to be opposite to the empirical observations.",
    "review_points_list": [
      "I think the paper is fairly complete in terms of the results, and provides sufficient theoretical results and new proof ideas. I recommend it for acceptance.",
      "Can you provide some examples where Assumption 1 holds but data is not i.i.d. ? Typically, we would like the behavior of the learning algorithm to be invariant to the order in which the samples are provided. Thus, we would like the property to hold independent of the order of samples. What kind of learning setting do you hope to use your monotonic algorithm where Assumption 1 holds for data is not i.i.d.? ",
      "Can you provide some intuition on why we could not use empirical Bernstein inequalities for setting the value of \\\\(\\zeta_k\\\\) ? Why is it natural to look at the problem of risk monotonicity in the PAC-Bayes setting ?",
      "The results provided in the paper hold for all N >= N_\\\\(\\Delta\\\\) . Is it possible to show that for every N_\\\\(\\Delta\\\\) , there exists some distribution for which learning monotonically is impossible when N < N_\\\\(\\Delta\\\\) ? ",
      "(Minor) In lines 128-129, the authors claim that the results of [49] could not be extended to hold in expectation. Can the authors discuss why ?",
      "The paper is well written otherwise. I skimmed through the proofs and they seem to be correct. ",
      "The proof ideas in Appendix B are quite interesting!",
      "Minor comments: References [22] and [23] are identical.",
      "Minor comments: Lines 36-40 regarding discussion of connections to neural networks seem to be opposite to the empirical observations."
    ]
  },
  {
    "paper_id": "2011.14126v5",
    "submission_id": "z5-chidgZU3",
    "submission_title": "Risk Monotonicity in Statistical Learning",
    "review_id": "k6qUJdZRoxA",
    "input": {
      "title": "Risk Monotonicity in Statistical Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Developing risk monotonic algorithms has gained interest in the last few years due to the 'double descent' phenomenon observed in deep learning making the topic of the paper is pretty relevant to the community.\n- I think the paper takes a good step in this direction.\n- There are some new ideas in the paper though the algorithm itself is pretty straightforward.\n- My main concerns are the practicality of the algorithm and the validity of the assumptions in practice.\n- The paper would greatly benefit from an experimental evaluation to support the approach on some real-world problems.\n- Typos:\n- Line 2: populating -> population\n- Line 175: continues -> continuous\n- Definition 2, 'converges in probability' is not clear.\n- Why is $\rho$ needed for the theorem statements? Can you not replace it by a constant?\n- Assuming access to the distribution and being able to calculate the expectation for the algorithm $B$ efficiently requires further discussion.\n- For a randomized algorithm B, you would not expect to have access to the distribution over hypothesis, so you'll have to estimate that and run B another $\text{log}(n/\text{delta})$ times?\n- Since you use the FreeGrad guarantee on a scalar, are there more direct ways to prove the desired inequality.\n- It seems to resemble a self-normalizing Martingale bounds.\n- The proofs using the ESI notation require more description.\n- It would be good to add what basic operations hold under this operator and further elaborate on the proofs.",
    "review_points_list": [
      "Developing risk monotonic algorithms has gained interest in the last few years due to the 'double descent' phenomenon observed in deep learning making the topic of the paper is pretty relevant to the community.",
      "I think the paper takes a good step in this direction.",
      "There are some new ideas in the paper though the algorithm itself is pretty straightforward.",
      "My main concerns are the practicality of the algorithm and the validity of the assumptions in practice.",
      "The paper would greatly benefit from an experimental evaluation to support the approach on some real-world problems.",
      "Typos:",
      "Line 2: populating -> population",
      "Line 175: continues -> continuous",
      "Definition 2, 'converges in probability' is not clear.",
      "Why is $\rho$ needed for the theorem statements? Can you not replace it by a constant?",
      "Assuming access to the distribution and being able to calculate the expectation for the algorithm $B$ efficiently requires further discussion.",
      "For a randomized algorithm B, you would not expect to have access to the distribution over hypothesis, so you'll have to estimate that and run B another $\text{log}(n/\text{delta})$ times?",
      "Since you use the FreeGrad guarantee on a scalar, are there more direct ways to prove the desired inequality.",
      "It seems to resemble a self-normalizing Martingale bounds.",
      "The proofs using the ESI notation require more description.",
      "It would be good to add what basic operations hold under this operator and further elaborate on the proofs."
    ]
  },
  {
    "paper_id": "2106.00311v2",
    "submission_id": "usxt30HpW66",
    "submission_title": "What\u2019s a good imputation to predict with missing values?",
    "review_id": "zXH8810_e1U",
    "input": {
      "title": "What\u2019s a good imputation to predict with missing values?",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well written and provides a well-structured overview of the results.\n- They provide a framework that gives a theoretical background for the impute-then-regress process and they look at a more general setup that does not require any structured missing data mechanisms such as MAR and etc.\n- The authors show that for almost all infinitely differentiable, smooth impute functions, there is an impute-then-regress process that is Bayes optimal.\n- They provide a constructive argument to that effect.\n- The paper also looks at the case of using conditional expectations for the imputation and how this could result in regression functions with discontinuity.\n- The authors also provide a chaining of NeuMiss and multi-layer perceptron to compute the impute-then-regress process.\n- All the claims are clearly stated and properly presented and the math seems to hold as well.",
    "review_points_list": [
      "The paper is well written and provides a well-structured overview of the results.",
      "They provide a framework that gives a theoretical background for the impute-then-regress process and they look at a more general setup that does not require any structured missing data mechanisms such as MAR and etc.",
      "The authors show that for almost all infinitely differentiable, smooth impute functions, there is an impute-then-regress process that is Bayes optimal.",
      "They provide a constructive argument to that effect.",
      "The paper also looks at the case of using conditional expectations for the imputation and how this could result in regression functions with discontinuity.",
      "The authors also provide a chaining of NeuMiss and multi-layer perceptron to compute the impute-then-regress process.",
      "All the claims are clearly stated and properly presented and the math seems to hold as well."
    ]
  },
  {
    "paper_id": "2106.00311v2",
    "submission_id": "usxt30HpW66",
    "submission_title": "What\u2019s a good imputation to predict with missing values?",
    "review_id": "y7CeuFxwYq4",
    "input": {
      "title": "What\u2019s a good imputation to predict with missing values?",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I was not familiar with general work on the validity of impute-then-regress schemes, though this submission seems to clearly move beyond the restrictive settings considered in past papers.\n- In general, there is not much related work cited on this concrete task (not that I am sure more exists).\n- The actual method proposed to take advantage of the demonstrated theory -- NeuMiss+MLP -- is not very innovative, though it is not meant to be; the point is simply that joint optimization of how to impute and how to regress is superior.\n- The proof technique of Theorem 3.1. seems to be original, though I did not examine it carefully.\n- Claims are backed up by theoretical results, the proofs of which I did not examine closely.\n- There is empirical support for the overall argument of the paper.\n- Thought it is not the focus, it might have been good to touch upon the limitations of NeuMiss.\n- I would also have liked to see a discontinuous $f^*$, though I understand that the Bayes predictor might be harder to compute.\n- I thought the paper read very well.\n- A few typos to address before CR, but I like the overall structure.\n- I don't think the prevalence of 'first impute, then regress' as a strategy for handling missing data can be understated and for this reason I find the work very compelling.\n- It is possible that in the future the standard shifts towards a joint treatment of the two tasks and this paper provides evidence for why that would be beneficial.\n- It would have been useful to comment on joint schemes beyond the one proposed here. For example, do researchers that don't want to rely on an uninterpretable method for regression have any hope of adopting / adapting the approach here?",
    "review_points_list": [
      "I was not familiar with general work on the validity of impute-then-regress schemes, though this submission seems to clearly move beyond the restrictive settings considered in past papers.",
      "In general, there is not much related work cited on this concrete task (not that I am sure more exists).",
      "The actual method proposed to take advantage of the demonstrated theory -- NeuMiss+MLP -- is not very innovative, though it is not meant to be; the point is simply that joint optimization of how to impute and how to regress is superior.",
      "The proof technique of Theorem 3.1. seems to be original, though I did not examine it carefully.",
      "Claims are backed up by theoretical results, the proofs of which I did not examine closely.",
      "There is empirical support for the overall argument of the paper.",
      "Thought it is not the focus, it might have been good to touch upon the limitations of NeuMiss.",
      "I would also have liked to see a discontinuous $f^*$, though I understand that the Bayes predictor might be harder to compute.",
      "I thought the paper read very well.",
      "A few typos to address before CR, but I like the overall structure.",
      "I don't think the prevalence of 'first impute, then regress' as a strategy for handling missing data can be understated and for this reason I find the work very compelling.",
      "It is possible that in the future the standard shifts towards a joint treatment of the two tasks and this paper provides evidence for why that would be beneficial.",
      "It would have been useful to comment on joint schemes beyond the one proposed here. For example, do researchers that don't want to rely on an uninterpretable method for regression have any hope of adopting / adapting the approach here?"
    ]
  },
  {
    "paper_id": "2106.00311v2",
    "submission_id": "usxt30HpW66",
    "submission_title": "What\u2019s a good imputation to predict with missing values?",
    "review_id": "fqy9CIF2UXb",
    "input": {
      "title": "What\u2019s a good imputation to predict with missing values?",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.\n- The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.\n- The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset. The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).\n- Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.\n- The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.\n- The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.\n- This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.\n- The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.\n- log(k) is an upper bound on the improvement of query complexity for any sampler.\n- The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.\n- The paper is very clear and well organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.\n- The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.\n- This paper is very well-written and I find it to constitute a major advance in our understanding of the standard impute-then-regress approach (which shows up in a massive number of applied papers throughout scientific literature but lacks theoretical grounding).\n- extremely well-motivated paper\n- compelling theoretical and experimental results\n- detailed numerical experiments\n- especially as the claim of Theorem 3.1 is surprising regarding the \"almost all\" imputation methods, perhaps it would be instructive providing an example problem setup and imputation method that does not lead to Bayes optimality and relating such an example to what is done in practice (perhaps such an example is contrived and basically all practical imputation methods really do fall under the coverage of Theorem 3.1)",
    "review_points_list": [
      "The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.",
      "The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.",
      "The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset. The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).",
      "Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.",
      "The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.",
      "The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.",
      "This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.",
      "The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.",
      "log(k) is an upper bound on the improvement of query complexity for any sampler.",
      "The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.",
      "The paper is very clear and well organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.",
      "The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.",
      "This paper is very well-written and I find it to constitute a major advance in our understanding of the standard impute-then-regress approach (which shows up in a massive number of applied papers throughout scientific literature but lacks theoretical grounding).",
      "extremely well-motivated paper",
      "compelling theoretical and experimental results",
      "detailed numerical experiments",
      "especially as the claim of Theorem 3.1 is surprising regarding the \"almost all\" imputation methods, perhaps it would be instructive providing an example problem setup and imputation method that does not lead to Bayes optimality and relating such an example to what is done in practice (perhaps such an example is contrived and basically all practical imputation methods really do fall under the coverage of Theorem 3.1)"
    ]
  },
  {
    "paper_id": "2106.00311v2",
    "submission_id": "usxt30HpW66",
    "submission_title": "What\u2019s a good imputation to predict with missing values?",
    "review_id": "7Mn1dy2-Qg",
    "input": {
      "title": "What\u2019s a good imputation to predict with missing values?",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper considers an important problem of learning with missing data, under a general setting with little assumptions on the oracle function or the missingness mechanism, and thus can be relevant in many practical scenarios.\n- It is also well-written overall.\n- One suggestion for clarity is to formally define \u2018almost all\u2019 in Theorem 3.1 sooner.\n- This work contains interesting and novel theoretical results.\n- In particular, I was surprised that impute-then-regress is Bayes optimal even under MNAR for almost all imputation functions, including a simple constant function.\n- I believe Proposition 4.1 is also an important result, because many existing works on imputation implicitly or explicitly target to learn the conditional imputation and oracle labeling function.\n- However, I was less convinced by the conclusion to jointly optimize imputation and regression.\n- According to the authors, for a fixed imputation function, the Bayes optimal regression function may not be continuous, and vice versa.\n- It was not clear how joint optimization addresses this, and whether the joint learning could be confused.\n- The specific choice of NeuMiss was also not very well motivated.\n- Alternatively, if the goal is not to learn the \u2018best\u2019 imputation and \u2018best\u2019 regression functions but rather to chain two architectures to optimize predictive performance, how does it compare to simply optimizing one architecture that takes as input the given observations concatenated with missingness information?\n- Another recommendation is to also evaluate on real-world benchmark dataset to compare against state-of-the-art learning from missing data.",
    "review_points_list": [
      "The paper considers an important problem of learning with missing data, under a general setting with little assumptions on the oracle function or the missingness mechanism, and thus can be relevant in many practical scenarios.",
      "It is also well-written overall.",
      "One suggestion for clarity is to formally define \u2018almost all\u2019 in Theorem 3.1 sooner.",
      "This work contains interesting and novel theoretical results.",
      "In particular, I was surprised that impute-then-regress is Bayes optimal even under MNAR for almost all imputation functions, including a simple constant function.",
      "I believe Proposition 4.1 is also an important result, because many existing works on imputation implicitly or explicitly target to learn the conditional imputation and oracle labeling function.",
      "However, I was less convinced by the conclusion to jointly optimize imputation and regression.",
      "According to the authors, for a fixed imputation function, the Bayes optimal regression function may not be continuous, and vice versa.",
      "It was not clear how joint optimization addresses this, and whether the joint learning could be confused.",
      "The specific choice of NeuMiss was also not very well motivated.",
      "Alternatively, if the goal is not to learn the \u2018best\u2019 imputation and \u2018best\u2019 regression functions but rather to chain two architectures to optimize predictive performance, how does it compare to simply optimizing one architecture that takes as input the given observations concatenated with missingness information?",
      "Another recommendation is to also evaluate on real-world benchmark dataset to compare against state-of-the-art learning from missing data."
    ]
  },
  {
    "paper_id": "2105.15089v3",
    "submission_id": "yn267zYn8Eg",
    "submission_title": "Analogous to Evolutionary Algorithm: Designing a Unified Sequence Model",
    "review_id": "D4muHcQHT-g",
    "input": {
      "title": "Analogous to Evolutionary Algorithm: Designing a Unified Sequence Model",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- It is interesting that the theory of EA is introduced to explain the rationality of Vision Transformer.\n- The authors give the comparison of the basic operator in EA with the module in transformer.\n- It is concluded that the mathematical representations of Mutation operator with FFN Module, Crossover Operator with SA Module are consistent.\n- It is better to give readers more insightful explanations on the success of transformer instead of only stating those phenomenon.\n- Serializing the multiple dimensional data into sequence with a consistent algorithm is indeed an elegant solution to adapt multi-modal data for transformer.\n- Many algorithms like those in Figure 2 can competent this task, and Hilbert algorithm is selected for serializing the input data.\n- So, what is the reason behind for the authors to make this choice.\n- It would be more convincing if those space filling curve algorithms are compared in the experiment section.",
    "review_points_list": [
      "It is interesting that the theory of EA is introduced to explain the rationality of Vision Transformer.",
      "The authors give the comparison of the basic operator in EA with the module in transformer.",
      "It is concluded that the mathematical representations of Mutation operator with FFN Module, Crossover Operator with SA Module are consistent.",
      "It is better to give readers more insightful explanations on the success of transformer instead of only stating those phenomenon.",
      "Serializing the multiple dimensional data into sequence with a consistent algorithm is indeed an elegant solution to adapt multi-modal data for transformer.",
      "Many algorithms like those in Figure 2 can competent this task, and Hilbert algorithm is selected for serializing the input data.",
      "So, what is the reason behind for the authors to make this choice.",
      "It would be more convincing if those space filling curve algorithms are compared in the experiment section."
    ]
  },
  {
    "paper_id": "2105.15089v3",
    "submission_id": "yn267zYn8Eg",
    "submission_title": "Analogous to Evolutionary Algorithm: Designing a Unified Sequence Model",
    "review_id": "II5S9m7djtf",
    "input": {
      "title": "Analogous to Evolutionary Algorithm: Designing a Unified Sequence Model",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This article has a certain degree of innovation\n- The result of this article is good\n- The writing of this article is not clear\n- This article contains too much information, the author has too many things to say. But the main contribution is not described clearly.\n- I suggest the author use a few sentences to describe the core contribution of this article and write it in the first part.\n- The framework of this method seems complex.\n- It is suggested to insert a diagram on the second page and highlight the core contribution.\n- What is the meaning of introducing EA algorithm?\n- What are the unique advantages of local population strategy in EA algorithm?\n- Why is it useful to introduce local information because EA is similar to transformer?\n- I think the introduction of EA algorithm has some over packaging.\n- Again local? The purpose of introducing transformer into CV task is to deal with the image information directly in a uniform way, without considering the sequence relationship between the image patches, and deal with the problem of CV from a global perspective.\n- This article seems to reuse some features of images, such as local information and sequence to transformer?\n- I don't think it's bad, but I think it might be contrary to the original intention of the transformer.\n- Please report the FLOPs.\n- Please add all the Efficientnet models in Fig. 6.\n- The improvement is incremental.\n- It actually introduces some priors of CNN's local information into transformer to a certain extent.\n- The idea of local is not new and needs to quote more relevant papers.\n- If the input image is not a regular rectangle, what is the impact?\n- Is the strategy adopted by the author the optimal one for 2D image arrangement?\n- I will change my score from 4 to 6.\n- The rebuttal should be merged into main paper in the next version.",
    "review_points_list": [
      "This article has a certain degree of innovation",
      "The result of this article is good",
      "The writing of this article is not clear",
      "This article contains too much information, the author has too many things to say. But the main contribution is not described clearly.",
      "I suggest the author use a few sentences to describe the core contribution of this article and write it in the first part.",
      "The framework of this method seems complex.",
      "It is suggested to insert a diagram on the second page and highlight the core contribution.",
      "What is the meaning of introducing EA algorithm?",
      "What are the unique advantages of local population strategy in EA algorithm?",
      "Why is it useful to introduce local information because EA is similar to transformer?",
      "I think the introduction of EA algorithm has some over packaging.",
      "Again local? The purpose of introducing transformer into CV task is to deal with the image information directly in a uniform way, without considering the sequence relationship between the image patches, and deal with the problem of CV from a global perspective.",
      "This article seems to reuse some features of images, such as local information and sequence to transformer?",
      "I don't think it's bad, but I think it might be contrary to the original intention of the transformer.",
      "Please report the FLOPs.",
      "Please add all the Efficientnet models in Fig. 6.",
      "The improvement is incremental.",
      "It actually introduces some priors of CNN's local information into transformer to a certain extent.",
      "The idea of local is not new and needs to quote more relevant papers.",
      "If the input image is not a regular rectangle, what is the impact?",
      "Is the strategy adopted by the author the optimal one for 2D image arrangement?",
      "I will change my score from 4 to 6.",
      "The rebuttal should be merged into main paper in the next version."
    ]
  },
  {
    "paper_id": "2110.11130v1",
    "submission_id": "x3RPoH3bCQ-",
    "submission_title": "Inverse Optimal Control Adapted to the Noise Characteristics of the Human Sensorimotor System",
    "review_id": "nPo5SLCvR_f",
    "input": {
      "title": "Inverse Optimal Control Adapted to the Noise Characteristics of the Human Sensorimotor System",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper takes a previous formulation by Todorov (2007) of the control problem faced by an agent with noise properties similar to that of the human sensorimotor system (and who acts optimally under full knowledge of its own dynamical system), and instead considers the inverted problem of how to discover the cost function parameters of this agent.\n- The authors use probabilistic methods to derive this formulation and provide an algorithm for computing the approximate likelihood of the control parameters.\n- The main contribution is thus to combine inverse optimal control in the LQG setting with the signal-dependent sensory and motor noise modeled by Todorov.\n- The authors validate that their method works in a series of well-conceived experiments using primate reaching and saccade movement simulators, real primate psychophysical reaching data (previously published) as well as a classic control problem.\n- The method does seem to work well, based on the data presented.\n- The surrounding literature seems well reviewed, and I agree that this method could in theory be applied to estimating control properties in psychophysical motor experiments, if of course, the objective is still to estimate what trade-offs a human or non-human primate is making when they move a single part of their body in a highly constrained environment (under the assumption of optimality, and that the agent controls using the same state-space basis as the model assumes).\n- Psychology and neuroscience experiments moving towards more naturalistic movements and environments will pose a major problem for this form of control work, as the state-space grows and becomes more difficult to explicitly specify.\n- The point of modeling a separation between the agent\u2019s beliefs and those of the experimenter was a little lost on me, as it\u2019s not clear to me what exact scientific application this could have.\n- I thank the authors for clarifying their motivation for modeling a separation between the agent's and experimenter's beliefs, and on reflection I agree this contribution is a valuable one.\n- I have increased my overall score accordingly, and would recommend that the authors attempt to make the points they have listed here in their response clearer in the paper if possible.\n- Thanks also for the clear response to my note about the limitations of these traditional frameworks for assessing motor behavior.\n- I agree that acknowledging this point in the limitations of the paper would be helpful for readers.",
    "review_points_list": [
      "The paper takes a previous formulation by Todorov (2007) of the control problem faced by an agent with noise properties similar to that of the human sensorimotor system (and who acts optimally under full knowledge of its own dynamical system), and instead considers the inverted problem of how to discover the cost function parameters of this agent.",
      "The authors use probabilistic methods to derive this formulation and provide an algorithm for computing the approximate likelihood of the control parameters.",
      "The main contribution is thus to combine inverse optimal control in the LQG setting with the signal-dependent sensory and motor noise modeled by Todorov.",
      "The authors validate that their method works in a series of well-conceived experiments using primate reaching and saccade movement simulators, real primate psychophysical reaching data (previously published) as well as a classic control problem.",
      "The method does seem to work well, based on the data presented.",
      "The surrounding literature seems well reviewed, and I agree that this method could in theory be applied to estimating control properties in psychophysical motor experiments, if of course, the objective is still to estimate what trade-offs a human or non-human primate is making when they move a single part of their body in a highly constrained environment (under the assumption of optimality, and that the agent controls using the same state-space basis as the model assumes).",
      "Psychology and neuroscience experiments moving towards more naturalistic movements and environments will pose a major problem for this form of control work, as the state-space grows and becomes more difficult to explicitly specify.",
      "The point of modeling a separation between the agent\u2019s beliefs and those of the experimenter was a little lost on me, as it\u2019s not clear to me what exact scientific application this could have.",
      "I thank the authors for clarifying their motivation for modeling a separation between the agent's and experimenter's beliefs, and on reflection I agree this contribution is a valuable one.",
      "I have increased my overall score accordingly, and would recommend that the authors attempt to make the points they have listed here in their response clearer in the paper if possible.",
      "Thanks also for the clear response to my note about the limitations of these traditional frameworks for assessing motor behavior.",
      "I agree that acknowledging this point in the limitations of the paper would be helpful for readers."
    ]
  },
  {
    "paper_id": "2110.11130v1",
    "submission_id": "x3RPoH3bCQ-",
    "submission_title": "Inverse Optimal Control Adapted to the Noise Characteristics of the Human Sensorimotor System",
    "review_id": "H9v_nxOycVj",
    "input": {
      "title": "Inverse Optimal Control Adapted to the Noise Characteristics of the Human Sensorimotor System",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed method is demonstrated on a wide range of tasks, including real world dataset of a rhesus monkey reaching for objects.\n- The proposed method is able to infer the parameters under partially observed trajectories.\n- Latent velocity and acceleration can also be estimated using the proposed approach.\n- Only linear dynamics and quadratic cost are considered. Although the limitation is discussed.\n- It is not clear to me if the dynamics is assumed to be known (i.e, A, B matrix). If it is known, then how is the dynamics for the monkey estimated?\n- How important is the assumption that A, B is constant? Can we work with a time varying A, B in the current framework. This will be important to extend this to iLQG settings.\n- An important application of inferring the cost parameters is using it to predict behaviors that is not in the dataset or generate controllers that can mimic the behaviors of the agent. Any thoughts on this?",
    "review_points_list": [
      "The proposed method is demonstrated on a wide range of tasks, including real world dataset of a rhesus monkey reaching for objects.",
      "The proposed method is able to infer the parameters under partially observed trajectories.",
      "Latent velocity and acceleration can also be estimated using the proposed approach.",
      "Only linear dynamics and quadratic cost are considered. Although the limitation is discussed.",
      "It is not clear to me if the dynamics is assumed to be known (i.e, A, B matrix). If it is known, then how is the dynamics for the monkey estimated?",
      "How important is the assumption that A, B is constant? Can we work with a time varying A, B in the current framework. This will be important to extend this to iLQG settings.",
      "An important application of inferring the cost parameters is using it to predict behaviors that is not in the dataset or generate controllers that can mimic the behaviors of the agent. Any thoughts on this?"
    ]
  },
  {
    "paper_id": "2110.11130v1",
    "submission_id": "x3RPoH3bCQ-",
    "submission_title": "Inverse Optimal Control Adapted to the Noise Characteristics of the Human Sensorimotor System",
    "review_id": "u0lCHoZndKI",
    "input": {
      "title": "Inverse Optimal Control Adapted to the Noise Characteristics of the Human Sensorimotor System",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Strengths:\n-   - The problem is interesting and the solution is appropriate for a limited number of use cases.\n-   - A concise background and description of LQG. Although this is nearly 1:1 from [1] I believe it is necessary to follow the notation and problem setting.\n-   - Visualizations are intuitive and easy to understand\n-   - Focus on methods that increase interpretability of behavior\n-   - Good discussion of limitations in the last section\n- Weaknesses:\n-   - It would have been good to more clearly state which matrices are given and what quantities are inferred.\n-   - Introducing an algorithm before section 3.1 would be helpful to make this more clear.\n-   - Similarly, it would have been good to detail more closely how K_t and L_t are iteratively determined.\n-   - I believe a more complete discussion about the impact of the moment matching assumption is needed. This could be done either theoretically or empirically through Monte-Carlo simulation and discussion of an intuitive example.\n-   - The related work section does a good job referring to previous work, but overall I feel like it is too dated.\n-   - \"While more recent and more general methods for optimal control in high-dimensional continuous domains exist, they rely on function approximation methods, which is useful in engineering applications but may not provide a computational level explanation of behavior\" I feel that this argument needs to be substantiated since similar approaches in the continuous inverse optimal control setting exist which could potentially be adapted to the signal-dependent noise setting [2].\n-   - Overall the applicability of the approach is very limited.\n-   - While the authors hint at a more capable integration with iLQG, I had hoped to see this in this paper already.\n-   - The evaluation is nicely visualized but more than 1-dimensional experiments are needed.\n-   - The evaluation lacks comparison to any baselines.\n-   - No ablations are done.\n- Overall, I believe the work is interesting and timely but needs improvements, focusing on the evaluation.\n-   I would also like to encourage the authors to increase the scope and applicability of the work.\n- Typos:\n-   - \"an which in general is intractable\"\n-   - \"requires a progressively larger number function evaluations\"\n- EDIT:\n-   I thank the authors for addressing my concerns with respect to the impact of the moment matching approximation and incorporating two baselines.\n-   Nonetheless, I believe that using a single experiment is not sufficient for this conference.\n-   Due to the limited experiments and limited applicability of the method (without a simple iLQG integration, which should not be a huge effort), I believe this paper needs additional work and would like to keep the current rating as is.",
    "review_points_list": [
      "Strengths:",
      "  - The problem is interesting and the solution is appropriate for a limited number of use cases.",
      "  - A concise background and description of LQG. Although this is nearly 1:1 from [1] I believe it is necessary to follow the notation and problem setting.",
      "  - Visualizations are intuitive and easy to understand",
      "  - Focus on methods that increase interpretability of behavior",
      "  - Good discussion of limitations in the last section",
      "Weaknesses:",
      "  - It would have been good to more clearly state which matrices are given and what quantities are inferred.",
      "  - Introducing an algorithm before section 3.1 would be helpful to make this more clear.",
      "  - Similarly, it would have been good to detail more closely how K_t and L_t are iteratively determined.",
      "  - I believe a more complete discussion about the impact of the moment matching assumption is needed. This could be done either theoretically or empirically through Monte-Carlo simulation and discussion of an intuitive example.",
      "  - The related work section does a good job referring to previous work, but overall I feel like it is too dated.",
      "  - \"While more recent and more general methods for optimal control in high-dimensional continuous domains exist, they rely on function approximation methods, which is useful in engineering applications but may not provide a computational level explanation of behavior\" I feel that this argument needs to be substantiated since similar approaches in the continuous inverse optimal control setting exist which could potentially be adapted to the signal-dependent noise setting [2].",
      "  - Overall the applicability of the approach is very limited.",
      "  - While the authors hint at a more capable integration with iLQG, I had hoped to see this in this paper already.",
      "  - The evaluation is nicely visualized but more than 1-dimensional experiments are needed.",
      "  - The evaluation lacks comparison to any baselines.",
      "  - No ablations are done.",
      "Overall, I believe the work is interesting and timely but needs improvements, focusing on the evaluation.",
      "  I would also like to encourage the authors to increase the scope and applicability of the work.",
      "Typos:",
      "  - \"an which in general is intractable\"",
      "  - \"requires a progressively larger number function evaluations\"",
      "EDIT:",
      "  I thank the authors for addressing my concerns with respect to the impact of the moment matching approximation and incorporating two baselines.",
      "  Nonetheless, I believe that using a single experiment is not sufficient for this conference.",
      "  Due to the limited experiments and limited applicability of the method (without a simple iLQG integration, which should not be a huge effort), I believe this paper needs additional work and would like to keep the current rating as is."
    ]
  },
  {
    "paper_id": "2010.03792v5",
    "submission_id": "zyD5AiyLuzG",
    "submission_title": "The Adaptive Doubly Robust Estimator and a Paradox Concerning Logging Policy",
    "review_id": "CrkB3i9ggS",
    "input": {
      "title": "The Adaptive Doubly Robust Estimator and a Paradox Concerning Logging Policy",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The innovation is to allow the logging policy to be unknown.\n- Adaptive fitting is introduced as an elegant solution that appears to be new.\n- Please also compare with Kallus and Uehara\u2019s mixingale sample splitting to shed light on originality.\n- The estimator and analysis are interesting.\n- I am concerned about whether the Hadad et al estimator (2019) was given a good faith implementation since its coverage is zero (when it should be 95).\n- This paper is unusually well written.\n- See comments below about specific points to clarify or assumptions to further explain.\n- The contribution is clearly explained and not overstated.\n- It is a natural progression of existing results that is relevant to empirical practice.\n- With non-Donsker\n- Nicely written\n- Nicely written\n- Nicely written\n- The Markov property is a major simplification relative to dynamic treatment effects.\n- Please give further interpretation of Assumption 2.2.\n- Unlike the other assumptions, it is not obvious.\n- What cases are being ruled out?\n- The MSE to the true R(p <? What does this mean given that R(p) is a scalar for a given p?\n- Impressively thorough\n- What is mixingale based sample splitting?\n- How does it compare?\n- It would be nice to additionally mention the sample splitting of Chiang et al [arXiv:1909.03489]\n- Please define MAB\n- What does this sentence mean?\n- Table 1: I am happy to see RMSE, SD, and CR\n- Please summarize the DGP in a clearer way, perhaps as an offset algorithm\n- It does not seem that the Hadad et al (2019) approach was given a good faith implementation.\n- If their proposed weights do not include covariates, what would be a reasonable extension with covariates?\n- Indeed, in Table 1, the coverage of AW-AIPW is even zero, which suggests this was not a reasonable implementation.",
    "review_points_list": [
      "The innovation is to allow the logging policy to be unknown.",
      "Adaptive fitting is introduced as an elegant solution that appears to be new.",
      "Please also compare with Kallus and Uehara\u2019s mixingale sample splitting to shed light on originality.",
      "The estimator and analysis are interesting.",
      "I am concerned about whether the Hadad et al estimator (2019) was given a good faith implementation since its coverage is zero (when it should be 95).",
      "This paper is unusually well written.",
      "See comments below about specific points to clarify or assumptions to further explain.",
      "The contribution is clearly explained and not overstated.",
      "It is a natural progression of existing results that is relevant to empirical practice.",
      "With non-Donsker",
      "Nicely written",
      "Nicely written",
      "Nicely written",
      "The Markov property is a major simplification relative to dynamic treatment effects.",
      "Please give further interpretation of Assumption 2.2.",
      "Unlike the other assumptions, it is not obvious.",
      "What cases are being ruled out?",
      "The MSE to the true R(p <? What does this mean given that R(p) is a scalar for a given p?",
      "Impressively thorough",
      "What is mixingale based sample splitting?",
      "How does it compare?",
      "It would be nice to additionally mention the sample splitting of Chiang et al [arXiv:1909.03489]",
      "Please define MAB",
      "What does this sentence mean?",
      "Table 1: I am happy to see RMSE, SD, and CR",
      "Please summarize the DGP in a clearer way, perhaps as an offset algorithm",
      "It does not seem that the Hadad et al (2019) approach was given a good faith implementation.",
      "If their proposed weights do not include covariates, what would be a reasonable extension with covariates?",
      "Indeed, in Table 1, the coverage of AW-AIPW is even zero, which suggests this was not a reasonable implementation."
    ]
  },
  {
    "paper_id": "2010.03792v5",
    "submission_id": "zyD5AiyLuzG",
    "submission_title": "The Adaptive Doubly Robust Estimator and a Paradox Concerning Logging Policy",
    "review_id": "erERNNk7BY",
    "input": {
      "title": "The Adaptive Doubly Robust Estimator and a Paradox Concerning Logging Policy",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well-written and the assumptions are clearly stated.\n- Adaptive experimentation is bound to become more popular.\n- Instead new approaches are needed.\n- I find it hard to imagine that someone has access to data from an adaptive experiment (and e.g., the temporal succession of treatment assignments $t=1,...,T$ is known), but does not know how the experiment was actually implemented.\n- This is in contrast to e.g., the typical setting for doubly robust estimators for estimating average treatment effects in observational data.\n- I wonder whether the novelty of the 'adaptive fitting' procedure introduced by the authors may be overstated.\n- I do agree however with the authors, that it appears that from a technical perspective, also having an estimated $\\\n- What is the take home message from the 'paradox'?\n- Can the authors provide practical recommendations about what to do in case the treatment assignment probabilities are actually known?\n- There is a typo 'wit' instead of 'with' on Page 6.\n- I am still not entirely convinced however about the practicality of the statistical setting (i.e., I am not convinced that a tech company doing adaptive experimentation would have trouble storing the experimental protocol).",
    "review_points_list": [
      "The paper is well-written and the assumptions are clearly stated.",
      "Adaptive experimentation is bound to become more popular.",
      "Instead new approaches are needed.",
      "I find it hard to imagine that someone has access to data from an adaptive experiment (and e.g., the temporal succession of treatment assignments $t=1,...,T$ is known), but does not know how the experiment was actually implemented.",
      "This is in contrast to e.g., the typical setting for doubly robust estimators for estimating average treatment effects in observational data.",
      "I wonder whether the novelty of the 'adaptive fitting' procedure introduced by the authors may be overstated.",
      "I do agree however with the authors, that it appears that from a technical perspective, also having an estimated $\\",
      "What is the take home message from the 'paradox'?",
      "Can the authors provide practical recommendations about what to do in case the treatment assignment probabilities are actually known?",
      "There is a typo 'wit' instead of 'with' on Page 6.",
      "I am still not entirely convinced however about the practicality of the statistical setting (i.e., I am not convinced that a tech company doing adaptive experimentation would have trouble storing the experimental protocol)."
    ]
  },
  {
    "paper_id": "2010.03792v5",
    "submission_id": "zyD5AiyLuzG",
    "submission_title": "The Adaptive Doubly Robust Estimator and a Paradox Concerning Logging Policy",
    "review_id": "mup5z2JydvU",
    "input": {
      "title": "The Adaptive Doubly Robust Estimator and a Paradox Concerning Logging Policy",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Off-policy evaluation with unknown and adaptive logging policies is pretty realistic setting in real-world applications.\n- The paper propose an off-policy evaluation estimator in this setting and characterize the conditions under which it can achieve asymptotic normality, which provides theoretical groundings for using this estimator.\n- One question I have is, if we apply adaptive-fitting to DM and EIPW estimators, do we achieve asymptotic normality.\n- And it would be great to also include the experiments comparing with these two baselines as reference.\n- The acronym AIPW is very confusing. I do not know what 'A' stands for and I always thought it was adaptive when I saw it. But it was not.\n- line 226 satisfies what?\n- line 360 as section 6.3 -> as discussed in Section 6.3",
    "review_points_list": [
      "Off-policy evaluation with unknown and adaptive logging policies is pretty realistic setting in real-world applications.",
      "The paper propose an off-policy evaluation estimator in this setting and characterize the conditions under which it can achieve asymptotic normality, which provides theoretical groundings for using this estimator.",
      "One question I have is, if we apply adaptive-fitting to DM and EIPW estimators, do we achieve asymptotic normality.",
      "And it would be great to also include the experiments comparing with these two baselines as reference.",
      "The acronym AIPW is very confusing. I do not know what 'A' stands for and I always thought it was adaptive when I saw it. But it was not.",
      "line 226 satisfies what?",
      "line 360 as section 6.3 -> as discussed in Section 6.3"
    ]
  },
  {
    "paper_id": "2111.04426v2",
    "submission_id": "wEFC5PY0g_0",
    "submission_title": "3D Siamese Voxel-to-BEV Tracker for Sparse Point Clouds",
    "review_id": "mxdJ9VPAmfa",
    "input": {
      "title": "3D Siamese Voxel-to-BEV Tracker for Sparse Point Clouds",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The engineering efforts on designing local and global feature embedding for template feature extraction are intuitive, which also significantly improve performance as shown in Table 4 ablation experiments.\n- Qualitative analysis on results for sparse point cloud intuitively demonstrating the usefulness of the proposed method.\n- It is still vague to me if the main contributions of this paper are very useful through current experiments:\n- Regarding shape completion, the main difference claimed in this paper compared to prior work is that the proposed method performs shape completion in the search area while [13] performs shape completion for the template.\n- Although the ablation experiments in Table 4 shows that without shape information by completion, the performance drops, it also needs to compare with shape completion on the template as [13].\n- It would be easier to compare two ideas (this paper and [13]) by adding shape completion for the template in the proposed method, and/or change the shape completion to the search area or candidate shapes for [13]'s codebase.\n- Also, intuitively it is unclear to me how performing shape completion for template or search area will make differences. Or maybe we should do both?\n- The proposed method essentially just converts the 3D voxel features into 2D by performing max pool on the z-axis.\n- It is unclear to me, how will the feature max pool on the z-axis help the later network (z-axis head) to better localize the z-axis center?\n- People will think that max-pooling is throwing away information so intuitively it should make the z-axis center estimation harder using the maxpooled BEV features.\n- This contradicts the paper\u2019s claim (line 68) that after feature pool in the z-axis, the regression on both 2D center and z-axis center become more effective and accurate.\n- Besides the above analysis, there is also no detailed analysis on this voxel-to-BEV ablation.\n- For example, in addition to the final performance analysis, can we add an experiment showing that after adding or not adding vowel-to-BEV, will the performance on center estimation (both the 2D center and z-axis center) change significantly?\n- The network design is not justified.\n- According to the paper (e.g., line 126) PointNet++ is extensively used in the method.\n- Why not use more advanced point cloud processing methods since PointNet++ is 4 years old (NeurIPS 2017).\n- It seems not reasonable to me that the evaluation (testing) is only performed on two sequences of KITTI?\n- At this moment, even the entire KITTI tracking dataset is too small and cannot be used as a robust testbed for evaluation, let alone only two sequences of it.\n- I understand that this paper is following prior work on this evaluation protocol, but I feel this protocol is not fully justified\n- For example, one can use nuScenes for more robust evaluation which has 150 sequences for validation and 150 sequences for testing with more objects.\n- Under the current evaluation protocol, I am not confident any number or analysis we obtain from the only two KITTI sequences is robustly meaningful.\n- Results on Cars might have some implications but results on Van and Cyclist should have a high variation because there are simply too few examples for those objects in two KITTI sequences.\n- I would suggest that authors add one more dataset for evaluation and comparison with other methods, either nuScenes or Waymo for example, unless there is a strong reason that we can only use the two KITTI sequences for evaluation",
    "review_points_list": [
      "The engineering efforts on designing local and global feature embedding for template feature extraction are intuitive, which also significantly improve performance as shown in Table 4 ablation experiments.",
      "Qualitative analysis on results for sparse point cloud intuitively demonstrating the usefulness of the proposed method.",
      "It is still vague to me if the main contributions of this paper are very useful through current experiments:",
      "Regarding shape completion, the main difference claimed in this paper compared to prior work is that the proposed method performs shape completion in the search area while [13] performs shape completion for the template.",
      "Although the ablation experiments in Table 4 shows that without shape information by completion, the performance drops, it also needs to compare with shape completion on the template as [13].",
      "It would be easier to compare two ideas (this paper and [13]) by adding shape completion for the template in the proposed method, and/or change the shape completion to the search area or candidate shapes for [13]'s codebase.",
      "Also, intuitively it is unclear to me how performing shape completion for template or search area will make differences. Or maybe we should do both?",
      "The proposed method essentially just converts the 3D voxel features into 2D by performing max pool on the z-axis.",
      "It is unclear to me, how will the feature max pool on the z-axis help the later network (z-axis head) to better localize the z-axis center?",
      "People will think that max-pooling is throwing away information so intuitively it should make the z-axis center estimation harder using the maxpooled BEV features.",
      "This contradicts the paper\u2019s claim (line 68) that after feature pool in the z-axis, the regression on both 2D center and z-axis center become more effective and accurate.",
      "Besides the above analysis, there is also no detailed analysis on this voxel-to-BEV ablation.",
      "For example, in addition to the final performance analysis, can we add an experiment showing that after adding or not adding vowel-to-BEV, will the performance on center estimation (both the 2D center and z-axis center) change significantly?",
      "The network design is not justified.",
      "According to the paper (e.g., line 126) PointNet++ is extensively used in the method.",
      "Why not use more advanced point cloud processing methods since PointNet++ is 4 years old (NeurIPS 2017).",
      "It seems not reasonable to me that the evaluation (testing) is only performed on two sequences of KITTI?",
      "At this moment, even the entire KITTI tracking dataset is too small and cannot be used as a robust testbed for evaluation, let alone only two sequences of it.",
      "I understand that this paper is following prior work on this evaluation protocol, but I feel this protocol is not fully justified",
      "For example, one can use nuScenes for more robust evaluation which has 150 sequences for validation and 150 sequences for testing with more objects.",
      "Under the current evaluation protocol, I am not confident any number or analysis we obtain from the only two KITTI sequences is robustly meaningful.",
      "Results on Cars might have some implications but results on Van and Cyclist should have a high variation because there are simply too few examples for those objects in two KITTI sequences.",
      "I would suggest that authors add one more dataset for evaluation and comparison with other methods, either nuScenes or Waymo for example, unless there is a strong reason that we can only use the two KITTI sequences for evaluation"
    ]
  },
  {
    "paper_id": "2111.04426v2",
    "submission_id": "wEFC5PY0g_0",
    "submission_title": "3D Siamese Voxel-to-BEV Tracker for Sparse Point Clouds",
    "review_id": "P1ER53b79TU",
    "input": {
      "title": "3D Siamese Voxel-to-BEV Tracker for Sparse Point Clouds",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Strength: The paper tackles a challenging task in autonomous driving, and the overall design of the algorithm is a sensible solution for this task.\n- Strength: Experimental results on KITTI benchmarks are great. The method surpasses existing solutions by a fairly big margin.\n- Strength: The presentation of the paper is relatively clear, and the visualizations in the paper are helpful for readers to grasp the intuitions of the design.\n- Strength: Regardless, I hope the authors release the code as they promised in the supplementary material, especially since this is an application paper, and would be useful for future research projects.\n- Weakness: The worse performance on the cyclist category seems to suggest that there are limitations in the approach. The authors argue that this is due to the lack of training data.\n- Weakness: Suppose there are not sufficient data in other categories, would the trend of the result still remain the same?\n- Weakness: Since this is an object tracking paper, it'll be helpful if authors can include videos that demonstrate the tracking outputs.\n- Weakness: Visualizations in the supplementary material are helpful but I think videos are more intuitive.\n- Weakness: Minor: is the color scheme in Fig. 3 mean anything? When I first saw this diagram, I tried mapping similar colors to certain sections but eventually failed.\n- Weakness: Minor: The paper is only tested on the KITTI dataset, and there are certain places in the whole pipeline that requires parameter tunings (such as coefficients for loss functions).\n- Weakness: What is the general guidance for parameter tuning when presented with new datasets? How do authors envision the proposed algorithm generalizes to new datasets or real autonomous driving scenarios?",
    "review_points_list": [
      "Strength: The paper tackles a challenging task in autonomous driving, and the overall design of the algorithm is a sensible solution for this task.",
      "Strength: Experimental results on KITTI benchmarks are great. The method surpasses existing solutions by a fairly big margin.",
      "Strength: The presentation of the paper is relatively clear, and the visualizations in the paper are helpful for readers to grasp the intuitions of the design.",
      "Strength: Regardless, I hope the authors release the code as they promised in the supplementary material, especially since this is an application paper, and would be useful for future research projects.",
      "Weakness: The worse performance on the cyclist category seems to suggest that there are limitations in the approach. The authors argue that this is due to the lack of training data.",
      "Weakness: Suppose there are not sufficient data in other categories, would the trend of the result still remain the same?",
      "Weakness: Since this is an object tracking paper, it'll be helpful if authors can include videos that demonstrate the tracking outputs.",
      "Weakness: Visualizations in the supplementary material are helpful but I think videos are more intuitive.",
      "Weakness: Minor: is the color scheme in Fig. 3 mean anything? When I first saw this diagram, I tried mapping similar colors to certain sections but eventually failed.",
      "Weakness: Minor: The paper is only tested on the KITTI dataset, and there are certain places in the whole pipeline that requires parameter tunings (such as coefficients for loss functions).",
      "Weakness: What is the general guidance for parameter tuning when presented with new datasets? How do authors envision the proposed algorithm generalizes to new datasets or real autonomous driving scenarios?"
    ]
  },
  {
    "paper_id": "2111.04426v2",
    "submission_id": "wEFC5PY0g_0",
    "submission_title": "3D Siamese Voxel-to-BEV Tracker for Sparse Point Clouds",
    "review_id": "8El_C2FdoI",
    "input": {
      "title": "3D Siamese Voxel-to-BEV Tracker for Sparse Point Clouds",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper outperforms the preceding works in terms of performance and computational cost, but I have some concerns about the writing quality, novelty, and ablation study.\n- The proposed method clearly outperforms the preceding state-of-the-art methods.\n- The paper has a proper baseline with improved performance, partial ablation study to support the usefulness of the proposed components, and thorough computational cost analysis for better real-world usefulness.\n- I find it interesting that a point cloud generation task used only during the training phase helps the expressiveness of the point cloud features used for localization.\n- However, I have a few concerns about this paper.\n- The quality of the writing is poor. There are too many obvious grammatical errors and unpolished sentences.\n- I believe this paper must be thoroughly proofread.\n- The proposed Template Feature Embedding Networks is a huge complicated module with heavy engineering of features without detailed ablation study in itself.\n- Especially considering the venue of the conference, I find it difficult to appreciate heavy engineering without proper theoretical study.\n- For example, ablation of global / local features and different distance functions for correlation and similarity map may be useful.\n- The Voxel-to-BEV target localization network seems to be heavily inspired by numerous preceding works in 3D object detection and I find it difficult to agree that this is a novel component.\n- This paper must cite papers such as PointPillar and SECOND, which are commonly used 3D object detection encoder that look exactly the same as the proposed module.",
    "review_points_list": [
      "This paper outperforms the preceding works in terms of performance and computational cost, but I have some concerns about the writing quality, novelty, and ablation study.",
      "The proposed method clearly outperforms the preceding state-of-the-art methods.",
      "The paper has a proper baseline with improved performance, partial ablation study to support the usefulness of the proposed components, and thorough computational cost analysis for better real-world usefulness.",
      "I find it interesting that a point cloud generation task used only during the training phase helps the expressiveness of the point cloud features used for localization.",
      "However, I have a few concerns about this paper.",
      "The quality of the writing is poor. There are too many obvious grammatical errors and unpolished sentences.",
      "I believe this paper must be thoroughly proofread.",
      "The proposed Template Feature Embedding Networks is a huge complicated module with heavy engineering of features without detailed ablation study in itself.",
      "Especially considering the venue of the conference, I find it difficult to appreciate heavy engineering without proper theoretical study.",
      "For example, ablation of global / local features and different distance functions for correlation and similarity map may be useful.",
      "The Voxel-to-BEV target localization network seems to be heavily inspired by numerous preceding works in 3D object detection and I find it difficult to agree that this is a novel component.",
      "This paper must cite papers such as PointPillar and SECOND, which are commonly used 3D object detection encoder that look exactly the same as the proposed module."
    ]
  },
  {
    "paper_id": "2111.04426v2",
    "submission_id": "wEFC5PY0g_0",
    "submission_title": "3D Siamese Voxel-to-BEV Tracker for Sparse Point Clouds",
    "review_id": "jsYdRF9In1Z",
    "input": {
      "title": "3D Siamese Voxel-to-BEV Tracker for Sparse Point Clouds",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well written, and the idea is clear. The technical section can be followed easily.\n- However, the application focus of the proposed technique is not very clear to me.\n- The main claim in the paper is that it is a framework for tracking 3D object.\n- is it single object or multiple object tracking?\n- I don't see any component of tracking here such as track initiation, termination and occlusion handling.\n- The framework seems to be a 3D detection method to me rather than any tracking frameworks.\n- Many details clarifying how it is extended for tracking single/multiple objects are not explained.\n- Considering the dataset used for the evaluation, eg KITTI, I am not convinced that how it is used for tracking single object only and how it is compared with the other methods in the KITTI leaderboards.\n- Many missing related works: The related works and the comparing frameworks seem to be very narrow and cherry picked.\n- There exist many related works in 2D MOT community (e.g. MOTChllenge or KITTI) are missed here.\n- Similarly for 3D MOT, there exist many state-of-the work methods in KITTI, NuScene, Waymo and JRDB datastes and the proposed framework could be compared with.\n- The paper does not offer any new theoretical contribution.\n- It is rather a pure application paper using built upon the existing  machine learning tools with some tweaks and minor extensions.\n- While the application papers are also well acknowledged by the NeurIPS research community, but such papers require comprehensive experimental evaluation on different benchmark datasets and comapring with many state-of-the-art frameworks to validate the efficacy of their proposed system.\n- Without this, I would be hesitant to vote for the acceptance of such a paper in this venue.\n- The experiments are tested on KITTI dataset  only using a new metric (not those used by this benchmark for MOT).\n- Why the approach was not evaluated on KITTI test set and using KITTI tracking metrics such as MOTA or HOTA?\n- I it is not clear to me how the framework can deal with non-rigid object like human (how template is defined) and if it can track human as non-rigid object\n- why it is not tested on 3D human tracking datasets such as JRDB.\n- What about other 3D tracking self-driving datasets such as NuScene or Waymo?",
    "review_points_list": [
      "The paper is well written, and the idea is clear. The technical section can be followed easily.",
      "However, the application focus of the proposed technique is not very clear to me.",
      "The main claim in the paper is that it is a framework for tracking 3D object.",
      "is it single object or multiple object tracking?",
      "I don't see any component of tracking here such as track initiation, termination and occlusion handling.",
      "The framework seems to be a 3D detection method to me rather than any tracking frameworks.",
      "Many details clarifying how it is extended for tracking single/multiple objects are not explained.",
      "Considering the dataset used for the evaluation, eg KITTI, I am not convinced that how it is used for tracking single object only and how it is compared with the other methods in the KITTI leaderboards.",
      "Many missing related works: The related works and the comparing frameworks seem to be very narrow and cherry picked.",
      "There exist many related works in 2D MOT community (e.g. MOTChllenge or KITTI) are missed here.",
      "Similarly for 3D MOT, there exist many state-of-the work methods in KITTI, NuScene, Waymo and JRDB datastes and the proposed framework could be compared with.",
      "The paper does not offer any new theoretical contribution.",
      "It is rather a pure application paper using built upon the existing  machine learning tools with some tweaks and minor extensions.",
      "While the application papers are also well acknowledged by the NeurIPS research community, but such papers require comprehensive experimental evaluation on different benchmark datasets and comapring with many state-of-the-art frameworks to validate the efficacy of their proposed system.",
      "Without this, I would be hesitant to vote for the acceptance of such a paper in this venue.",
      "The experiments are tested on KITTI dataset  only using a new metric (not those used by this benchmark for MOT).",
      "Why the approach was not evaluated on KITTI test set and using KITTI tracking metrics such as MOTA or HOTA?",
      "I it is not clear to me how the framework can deal with non-rigid object like human (how template is defined) and if it can track human as non-rigid object",
      "why it is not tested on 3D human tracking datasets such as JRDB.",
      "What about other 3D tracking self-driving datasets such as NuScene or Waymo?"
    ]
  },
  {
    "paper_id": "2111.04426v2",
    "submission_id": "wEFC5PY0g_0",
    "submission_title": "3D Siamese Voxel-to-BEV Tracker for Sparse Point Clouds",
    "review_id": "QaoZxeB4YZG",
    "input": {
      "title": "3D Siamese Voxel-to-BEV Tracker for Sparse Point Clouds",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The submission is addressing an important problem, namely object tracking in 3D point clouds.\n- The submission is clearly written, making it easy to follow.\n- The content is also well organized with enough technical details provided.\n- Generally speaking, the submission is technical sound.\n- The motivation behind various designs is clear and the experimental results partially support some of the claims.\n- However, there are also claims not fully justified experimentally.\n- For example, the submission claims it is better at handling sparse point clouds compared with previous methods including SC3D and P2B.\n- If we compare Table 1 and Table 2, when switching from all types of objects to sparse objects, only the proposed method suffers from a performance drop while all the other two baseline methods actually get better performance.\n- Therefore, it is not clear whether the claimed shape aware feature really makes the proposed method more suitable for sparse point clouds.\n- Another example is that there's no ablation studies justifying the necessity of using both global and local features in the template feature embedding module and in the shape-aware feature learning module.\n- The method is quite new and its difference from previous works are also clearly discussed.\n- The related work is adequate as far as I can tell.\n- The overall experimental results are quite impressive, which outperforms previous methods by a large margin.",
    "review_points_list": [
      "The submission is addressing an important problem, namely object tracking in 3D point clouds.",
      "The submission is clearly written, making it easy to follow.",
      "The content is also well organized with enough technical details provided.",
      "Generally speaking, the submission is technical sound.",
      "The motivation behind various designs is clear and the experimental results partially support some of the claims.",
      "However, there are also claims not fully justified experimentally.",
      "For example, the submission claims it is better at handling sparse point clouds compared with previous methods including SC3D and P2B.",
      "If we compare Table 1 and Table 2, when switching from all types of objects to sparse objects, only the proposed method suffers from a performance drop while all the other two baseline methods actually get better performance.",
      "Therefore, it is not clear whether the claimed shape aware feature really makes the proposed method more suitable for sparse point clouds.",
      "Another example is that there's no ablation studies justifying the necessity of using both global and local features in the template feature embedding module and in the shape-aware feature learning module.",
      "The method is quite new and its difference from previous works are also clearly discussed.",
      "The related work is adequate as far as I can tell.",
      "The overall experimental results are quite impressive, which outperforms previous methods by a large margin."
    ]
  },
  {
    "paper_id": "2111.04426v2",
    "submission_id": "wEFC5PY0g_0",
    "submission_title": "3D Siamese Voxel-to-BEV Tracker for Sparse Point Clouds",
    "review_id": "yZ-yVZ6S2hE",
    "input": {
      "title": "3D Siamese Voxel-to-BEV Tracker for Sparse Point Clouds",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Needs a clear comparison with previous methods.\n- The method proposed in the submission is largely based on two previous methods, P2B [12] and SC3D [13].\n- In particular, the overall two-step framework follows P2B, where the first step embeds the template feature into the search area feature, implemented by a Siamese network; and the second step localizes the target given the enhanced search area feature.\n- The main difference lies in the second step, where P2B uses a proposal based method, and this paper adopts a dense detection method, which is shown by experiments to perform much better on objects with sparse points.\n- A suggestion here would be to add qualitative results in addition to the Table 5 in the submission to show examples of these improvements.\n- Another claimed novelty of shape-aware feature learning also largely follows the scene completion regularization loss proposed in SC3D, with the difference being the specific input feature (Line 187-190).\n- A suggestion here would be to add a specific ablation study for the changes made on top of the regularization loss from SC3D, so as to justify these modifications and thereof the technical novelty.\n- Overall, I would suggest authors provide a clear comparison with previous methods that are technically related, and clarify what's inherited from them, and what's changed to better solve an existing problem.\n- It's hard to follow the method section as tons of technical details are thrown to the readers without providing enough context and motivation of why the architecture is designed so.\n- I would strongly suggest the authors to re-write the method section in the revised submission.\n- There can be more results in the experiments to help readers understand how the model is working.\n- For example, the ablation study with SC3D as mentioned in point 1, qualitative comparison with both SC3D and P2B in all four categories, especially the cyclist because the proposed method performs much worse in this category compared with SC3D.\n- Also, in Table 3 the speed comparison, the official speed of P2B is 40FPS on a NVIDIA 1080Ti GPU, however, Table 3 reports 17FPS on a NVIDIA TITAN RTX GPU, any reason why this huge gap?",
    "review_points_list": [
      "Needs a clear comparison with previous methods.",
      "The method proposed in the submission is largely based on two previous methods, P2B [12] and SC3D [13].",
      "In particular, the overall two-step framework follows P2B, where the first step embeds the template feature into the search area feature, implemented by a Siamese network; and the second step localizes the target given the enhanced search area feature.",
      "The main difference lies in the second step, where P2B uses a proposal based method, and this paper adopts a dense detection method, which is shown by experiments to perform much better on objects with sparse points.",
      "A suggestion here would be to add qualitative results in addition to the Table 5 in the submission to show examples of these improvements.",
      "Another claimed novelty of shape-aware feature learning also largely follows the scene completion regularization loss proposed in SC3D, with the difference being the specific input feature (Line 187-190).",
      "A suggestion here would be to add a specific ablation study for the changes made on top of the regularization loss from SC3D, so as to justify these modifications and thereof the technical novelty.",
      "Overall, I would suggest authors provide a clear comparison with previous methods that are technically related, and clarify what's inherited from them, and what's changed to better solve an existing problem.",
      "It's hard to follow the method section as tons of technical details are thrown to the readers without providing enough context and motivation of why the architecture is designed so.",
      "I would strongly suggest the authors to re-write the method section in the revised submission.",
      "There can be more results in the experiments to help readers understand how the model is working.",
      "For example, the ablation study with SC3D as mentioned in point 1, qualitative comparison with both SC3D and P2B in all four categories, especially the cyclist because the proposed method performs much worse in this category compared with SC3D.",
      "Also, in Table 3 the speed comparison, the official speed of P2B is 40FPS on a NVIDIA 1080Ti GPU, however, Table 3 reports 17FPS on a NVIDIA TITAN RTX GPU, any reason why this huge gap?"
    ]
  },
  {
    "paper_id": "2110.14690v1",
    "submission_id": "uk-3aIx54t",
    "submission_title": "Variational Causal Autoencoder for Interventional and Counterfactual Queries",
    "review_id": "XQRRxv__rXO",
    "input": {
      "title": "Variational Causal Autoencoder for Interventional and Counterfactual Queries",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Strengths: The paper is well written.\n- Weaknesses: The authors state that the VCAUSE was developed for causal inference, however, they also state that they assumed that the causal graph is known in the current contribution. If it is the case, why there is the need for the causal inference?\n- Although the paper is quite clearly written, there are some flows.\n- First, the role of U (exogenous) variables is not clear: is is assumed that there is 1 latent variable per 1 observed variable, as shown on Figure 1.\n- Then, these U variables are not mentioned further in the paper.\n- The VCAUSE (Definition 4.1) is defined without them.\n- It is stated that 'the latent variables Z play a similar role to the exogenous variables U' but it is very vague, and I do not see a clear correspondence.\n- Propositions 1 and 2 are important but I guess no novel, it should be a known result in deep learning.\n- I would appreciate more explanations on the design condition 2.\n- I see that it follows from Prop. 2 but it is unclear why to use neural networks without hidden layers.",
    "review_points_list": [
      "Strengths: The paper is well written.",
      "Weaknesses: The authors state that the VCAUSE was developed for causal inference, however, they also state that they assumed that the causal graph is known in the current contribution. If it is the case, why there is the need for the causal inference?",
      "Although the paper is quite clearly written, there are some flows.",
      "First, the role of U (exogenous) variables is not clear: is is assumed that there is 1 latent variable per 1 observed variable, as shown on Figure 1.",
      "Then, these U variables are not mentioned further in the paper.",
      "The VCAUSE (Definition 4.1) is defined without them.",
      "It is stated that 'the latent variables Z play a similar role to the exogenous variables U' but it is very vague, and I do not see a clear correspondence.",
      "Propositions 1 and 2 are important but I guess no novel, it should be a known result in deep learning.",
      "I would appreciate more explanations on the design condition 2.",
      "I see that it follows from Prop. 2 but it is unclear why to use neural networks without hidden layers."
    ]
  },
  {
    "paper_id": "2110.14690v1",
    "submission_id": "uk-3aIx54t",
    "submission_title": "Variational Causal Autoencoder for Interventional and Counterfactual Queries",
    "review_id": "T6QsCGhm83q",
    "input": {
      "title": "Variational Causal Autoencoder for Interventional and Counterfactual Queries",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- In general, the paper is well written and read naturally.\n- There are two key assumptions in the framework: 1) there are no hidden confounders in the causal graph; 2) the causal graph is available.\n- As also said by the author at the end, both are a bit strong.\n- Despite the two assumptions, the model first approximates the posterior of an exogenous vector Z in d dimensional for an endogenous sample X in d dimensional as well, using a graph neural network.\n- After interventional changes or counterfactual changes on Z, the modified Z can be decoded back to the endogenous variable space using a GNN to obtain its interventional appearance or counterfactual appearance.\n- The experiments are conducted in synthetic/semi-synthetic datasets with d = 7 at most.\n- The framework that combines GNN and VGAE is novel but not surprising due to its strong assumptions.\n- It is natural to model a graph-like data structure using GNN.\n- The VGAE, on the other hand, is well studied in terms of manipulation of its latent space.\n- The quality of the paper is good overall.\n- It is well written and easy to follow.\n- However, the experiments conducted are mainly from synthetic/semi-synthetic datasets.\n- And the dimenson of data sets is relatively low (7 at most).\n- The paper is good in terms of clarity on presenting the ideas, formulating the question, and conducting experiments.\n- As said above, the method is novel but carrying two strong assumptions, which is a limitation.\n- Thus, its significance is fair to a minor problem.\n- My main concerns are:\n- 1) The no-hidden-confounders assumption is quite strong.\n- 2) The data sets are synthetic/semi-synthetic.\n- The dimension is relatively low.\n- It seems that only continuous variables are considered, no discrete variables.\n- 3) It might be interesting to see the study on the dimension of Z_i (i.e. the parameter m).\n- Does that have an effect on overall results?\n- 4) The decoder might induce bias on the reconstructed sample.",
    "review_points_list": [
      "In general, the paper is well written and read naturally.",
      "There are two key assumptions in the framework: 1) there are no hidden confounders in the causal graph; 2) the causal graph is available.",
      "As also said by the author at the end, both are a bit strong.",
      "Despite the two assumptions, the model first approximates the posterior of an exogenous vector Z in d dimensional for an endogenous sample X in d dimensional as well, using a graph neural network.",
      "After interventional changes or counterfactual changes on Z, the modified Z can be decoded back to the endogenous variable space using a GNN to obtain its interventional appearance or counterfactual appearance.",
      "The experiments are conducted in synthetic/semi-synthetic datasets with d = 7 at most.",
      "The framework that combines GNN and VGAE is novel but not surprising due to its strong assumptions.",
      "It is natural to model a graph-like data structure using GNN.",
      "The VGAE, on the other hand, is well studied in terms of manipulation of its latent space.",
      "The quality of the paper is good overall.",
      "It is well written and easy to follow.",
      "However, the experiments conducted are mainly from synthetic/semi-synthetic datasets.",
      "And the dimenson of data sets is relatively low (7 at most).",
      "The paper is good in terms of clarity on presenting the ideas, formulating the question, and conducting experiments.",
      "As said above, the method is novel but carrying two strong assumptions, which is a limitation.",
      "Thus, its significance is fair to a minor problem.",
      "My main concerns are:",
      "1) The no-hidden-confounders assumption is quite strong.",
      "2) The data sets are synthetic/semi-synthetic.",
      "The dimension is relatively low.",
      "It seems that only continuous variables are considered, no discrete variables.",
      "3) It might be interesting to see the study on the dimension of Z_i (i.e. the parameter m).",
      "Does that have an effect on overall results?",
      "4) The decoder might induce bias on the reconstructed sample."
    ]
  },
  {
    "paper_id": "2110.14690v1",
    "submission_id": "uk-3aIx54t",
    "submission_title": "Variational Causal Autoencoder for Interventional and Counterfactual Queries",
    "review_id": "2dgLqRELs3C",
    "input": {
      "title": "Variational Causal Autoencoder for Interventional and Counterfactual Queries",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- From my limited knowledge of the graph deep learning and causal discovery literatures (where I know GNNs have been used), this application of a GNN-based VAE for modelling a causal graphical model seems novel and inspiring.\n- On the other hand, it is unclear what limitations of the existing methods this work is aiming to address.\n- Specifically, readers are missing a compelling description of the advantages of the GNN-based VCAUSE over CVAE-based (e.g. Karimi et al., 2020) or flow-based (Khemakhem et al., 2020) approaches.\n- Is it more general, more scalable, easier to define/implement, more stable to train...?\n- CAREFL (Khemakhem et al., 2021) seems somewhat mischaracterised in the related work section:\n- It is not evident in the text that CAREFL is not limited to two variables, and that it can model non-linear mechanisms between endogenous/observed variables.\n- It would be relevant to relate your work to Pawlowski et al. (2020).\n- Their deep SCM framework is a generalisation of Karimi et al. (2020)'s MultiCVAE\u2014supporting abduction-action-prediction for high-dimensional variables (e.g. images) with VAE-based, flow-based, or GAN-based causal mechanisms.\n- The theoretical portion of this work is interesting, principled, and well developed.\n- I appreciated the care in formulating and proving the model design requirements to match the behaviour of a given causal graph.\n- However, the empirical benchmarking (Section 5) was limited to small, synthetic tabular datasets.\n- While I understand the value of toy experiments in canonical conditions to validate basic model capabilities, the presented results did little to convince the reader to favour the proposed method over the baselines in realistic settings (e.g. larger, more complex graphs; low- and high-dimensional variables; noisy real-world data).\n- The fairness experiment (Section 6) is not very informative due to the choice of baselines.\n- In absolute terms, the VCAUSE-based fair classifier seems to perform well fairness-wise on this German Credit dataset.\n- However, it has more expressive power (computational layers) than the shallow baselines, so it does not look like a fair comparison.\n- Furthermore, no other counterfactual inference methods (e.g. MultiCVAE) were evaluated for fairness assessment, which makes the conclusions from this experiment unclear.\n- The authors claim VCAUSE can 'accurately' estimate counterfactual distributions of unknown SCMs.\n- Yet, this is impossible by definition!\n- Counterfactuals are unidentifiable without knowledge of the structural equations because they cannot be falsified based on factual data alone\u2014observational or even experimental (see e.g. Pearl, _Causality_, 2009, Ch. 7).\n- Such evaluation is possible only in synthetic settings with access to a simulator (i.e. the true data-generating process).\n- These claims are misleading and need rephrasing (see below).\n- Estimating interventions in VCAUSE (Section 4.2) seems to incur a reconstruction error on the intervened variables (i.e. $do(\textbf{X}_\textbf{I} := \boldsymbol{\textalpha})$ results in \textbf{X}_\textbf{I}!=\boldsymbol{\textalpha}$), though the implications are never discussed in the paper.\n- The paper is overall very well written and well structured.\n- The authors present thorough additional theoretical and experimental details in the supplement, along with sharing the code.\n- No justification is presented for the use of PIWAE for training.\n- Why is it necessary? Does the model fail to converge with the vanilla ELBO?\n- Minor suggestions:\n- The distinction between $\textbf{F}=\text{\\{f}_i}\\$ and \\tilde{\textbf{F}}=\\{\\tilde{\text{f}_i}\\}$ is confusing and could be made a lot more explicit in the text.\n- As written, the integrals are computing expectations, not the intended pushforward distributions.\n- These expectations are 'double-counting' the \textbf{Z}$ variables.\n- Either make them double integrals with $\text{iint}\text{... d}\textbf{Z}\text{, d}\textbf{Z}^\textbf{I}$ or explicitly specify the indices of \textbf{Z} over which $p$ and $q_\textphi$ are being evaluated.\n- The sudden switch from using $\textbf{U}$ to $\textbf{Z}$ in Section 4 was jarring.\n- Consider explaining early the differences between these two sets of variables.\n- It would be helpful to include visualisations of the distributions entailed by (at least some of) the SCMs used in the experiments to give a sense of the tasks' difficulty and encoded assumptions.\n- The work presents interesting ideas that may be further extended and applied to varied types of data.\n- Nevertheless, there does not appear to be strong enough discussion or evidence to convince readers to adopt this methodology rather than existing ones.\n- Under the assumption that the authors will include the discussed clarifications in the final version of the paper, I am increasing my recommendation by 1.",
    "review_points_list": [
      "From my limited knowledge of the graph deep learning and causal discovery literatures (where I know GNNs have been used), this application of a GNN-based VAE for modelling a causal graphical model seems novel and inspiring.",
      "On the other hand, it is unclear what limitations of the existing methods this work is aiming to address.",
      "Specifically, readers are missing a compelling description of the advantages of the GNN-based VCAUSE over CVAE-based (e.g. Karimi et al., 2020) or flow-based (Khemakhem et al., 2020) approaches.",
      "Is it more general, more scalable, easier to define/implement, more stable to train...?",
      "CAREFL (Khemakhem et al., 2021) seems somewhat mischaracterised in the related work section:",
      "It is not evident in the text that CAREFL is not limited to two variables, and that it can model non-linear mechanisms between endogenous/observed variables.",
      "It would be relevant to relate your work to Pawlowski et al. (2020).",
      "Their deep SCM framework is a generalisation of Karimi et al. (2020)'s MultiCVAE\u2014supporting abduction-action-prediction for high-dimensional variables (e.g. images) with VAE-based, flow-based, or GAN-based causal mechanisms.",
      "The theoretical portion of this work is interesting, principled, and well developed.",
      "I appreciated the care in formulating and proving the model design requirements to match the behaviour of a given causal graph.",
      "However, the empirical benchmarking (Section 5) was limited to small, synthetic tabular datasets.",
      "While I understand the value of toy experiments in canonical conditions to validate basic model capabilities, the presented results did little to convince the reader to favour the proposed method over the baselines in realistic settings (e.g. larger, more complex graphs; low- and high-dimensional variables; noisy real-world data).",
      "The fairness experiment (Section 6) is not very informative due to the choice of baselines.",
      "In absolute terms, the VCAUSE-based fair classifier seems to perform well fairness-wise on this German Credit dataset.",
      "However, it has more expressive power (computational layers) than the shallow baselines, so it does not look like a fair comparison.",
      "Furthermore, no other counterfactual inference methods (e.g. MultiCVAE) were evaluated for fairness assessment, which makes the conclusions from this experiment unclear.",
      "The authors claim VCAUSE can 'accurately' estimate counterfactual distributions of unknown SCMs.",
      "Yet, this is impossible by definition!",
      "Counterfactuals are unidentifiable without knowledge of the structural equations because they cannot be falsified based on factual data alone\u2014observational or even experimental (see e.g. Pearl, _Causality_, 2009, Ch. 7).",
      "Such evaluation is possible only in synthetic settings with access to a simulator (i.e. the true data-generating process).",
      "These claims are misleading and need rephrasing (see below).",
      "Estimating interventions in VCAUSE (Section 4.2) seems to incur a reconstruction error on the intervened variables (i.e. $do(\textbf{X}_\textbf{I} := \boldsymbol{\textalpha})$ results in \textbf{X}_\textbf{I}!=\boldsymbol{\textalpha}$), though the implications are never discussed in the paper.",
      "The paper is overall very well written and well structured.",
      "The authors present thorough additional theoretical and experimental details in the supplement, along with sharing the code.",
      "No justification is presented for the use of PIWAE for training.",
      "Why is it necessary? Does the model fail to converge with the vanilla ELBO?",
      "Minor suggestions:",
      "The distinction between $\textbf{F}=\text{\\{f}_i}\\$ and \\tilde{\textbf{F}}=\\{\\tilde{\text{f}_i}\\}$ is confusing and could be made a lot more explicit in the text.",
      "As written, the integrals are computing expectations, not the intended pushforward distributions.",
      "These expectations are 'double-counting' the \textbf{Z}$ variables.",
      "Either make them double integrals with $\text{iint}\text{... d}\textbf{Z}\text{, d}\textbf{Z}^\textbf{I}$ or explicitly specify the indices of \textbf{Z} over which $p$ and $q_\textphi$ are being evaluated.",
      "The sudden switch from using $\textbf{U}$ to $\textbf{Z}$ in Section 4 was jarring.",
      "Consider explaining early the differences between these two sets of variables.",
      "It would be helpful to include visualisations of the distributions entailed by (at least some of) the SCMs used in the experiments to give a sense of the tasks' difficulty and encoded assumptions.",
      "The work presents interesting ideas that may be further extended and applied to varied types of data.",
      "Nevertheless, there does not appear to be strong enough discussion or evidence to convince readers to adopt this methodology rather than existing ones.",
      "Under the assumption that the authors will include the discussed clarifications in the final version of the paper, I am increasing my recommendation by 1."
    ]
  },
  {
    "paper_id": "2110.14690v1",
    "submission_id": "uk-3aIx54t",
    "submission_title": "Variational Causal Autoencoder for Interventional and Counterfactual Queries",
    "review_id": "N00wgG23YwE",
    "input": {
      "title": "Variational Causal Autoencoder for Interventional and Counterfactual Queries",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The question of how to accurately answer causal queries with machine learning models from observational data given knowledge of the underlying causal graph is of practical relevance in some use cases (see limitations outlined in 'Significance' below), and not yet extensively studied in literature.\n- The application of graph variational autoencoders to this setting is to the best of my knowledge novel.\n- However, the manuscript's exposition is relatively sparse in details as to why this direction of research would be expected to lead to performance gains.\n- VCAUSE is proposed as a broadly-applicable tool for answering causal queries from observational data when the underlying causal graph is available\n- I am concerned that the presented evaluation is not representative enough to substantiate claims that VCAUSE is in general better able to estimate observational, interventional and counterfactual distributions.\n- The experimental evaluation only evaluated graphs with 3 and 7 nodes, whereas in practice significantly larger graph sizes are commonly encountered (e.g., in biology where structures with 100s to 1000s of nodes are not uncommon).\n- A better understanding of the importance of the properties of the modelled SCM on VCAUSE would be particularly important because Table 2 indicates that the relative performance of VCAUSE appears to depend strongly on the underlying SCM.\n- Several relevant reference baselines are missing from the experimental comparison (Table 2), e.g. learning the parameters of an SCM directly using neural networks [1], additive noise models [2] which can be parameterized by different regressor classes (see e.g. [3]) and non-linear structural equation models (SEMs) [4].\n- Different approaches were used for hyperparameter optimization for each of the compared baselines (Appendix D.2).\n- It is therefore unclear if differences in observed performance (Tables 2 and 12) are due to inherent properties of the models or the different hyperparameter optimization strategies and budgets.\n- The same hyperparameter optimization strategy with a fixed hyperparameter optimization budget should have been employed to enable a fair comparison of methods on equal grounds.\n- In addition, there are several VCAUSE hyperparameters for which only the final selected values are presented (Appendix D.2) but no details are given as to *how* they were selected (learning rate, epochs, K, latent variable dimension, number of neurons, ...).\n- Presumably, these values are the result of manual optimization - if so, this should be transparently stated in the manuscript including information as to whether or not held-out performance results were used to optimize these hyperparameters (risk of overfitting).\n- The application of VCAUSE to use cases in counterfactual fairness (Section 6) is interesting but no state-of-the-art baselines are presented for comparison.\n- It is therefore unclear if VCAUSE performs better, equally well or worse in the counterfactual fairness setting than other methods that parameterise an SCM.\n- In addition, uncertainty and statistical significance metrics for the experiments in Section 6 are missing.\n- The motivational element appears to be missing in the paper's story line.\n- Why do we expect that mimicking an SCM using a graph VAE is a more efficacious approach than alternatives (and therefore embark on this line of research)?\n- In Table 2 (main) and Table 12 (appendix), the caption indicates that all metrics are given in percentages.\n- However, the authors do not state what reference values were used to compute the percentages.\n- In addition, even if the reference values were indicated, I would generally prefer to be shown the absolute values, since some metrics are not on a linear scale (e.g. MSE) which makes interpretation as percentages difficult.\n- The computational characteristics of VCAUSE and how they compare to existing alternatives are missing.\n- Compute time details are in general missing from the manuscript (the Paper Checklist refers to Appendix D but no compute time information is provided therein).\n- The overall impact of the presented work is limited because of the restrictive assumptions (availability of a faithful causal graph and no hidden confounding) that hold true in a very limited set of settings and can in practice not be verified from data alone [5].\n- For practical use cases that VCAUSE would be considered for, there therefore exists the risk that the assumptions would likely be at least partially violated.\n- In addition, the manuscript's claims are only substantiated with experimental evidence for small directed acyclic graphs (DAGs), and it is therefore currently unclear if VCAUSE offers relative benefits in settings with larger numbers of nodes.\n- Given the absence of several baselines in the experimental comparison, I am unsure if the complexity of processing the causal graph through a graph neural network (GNN) is necessary.\n- What motivates this approach over simpler existing ones (e.g. parameterising the SCM using neural networks [1] or additive noise models [2]) that would justify the added complexity?\n- What is the inductive bias introduced by VCAUSE that one would expect to lead to performance benefits?",
    "review_points_list": [
      "The question of how to accurately answer causal queries with machine learning models from observational data given knowledge of the underlying causal graph is of practical relevance in some use cases (see limitations outlined in 'Significance' below), and not yet extensively studied in literature.",
      "The application of graph variational autoencoders to this setting is to the best of my knowledge novel.",
      "However, the manuscript's exposition is relatively sparse in details as to why this direction of research would be expected to lead to performance gains.",
      "VCAUSE is proposed as a broadly-applicable tool for answering causal queries from observational data when the underlying causal graph is available",
      "I am concerned that the presented evaluation is not representative enough to substantiate claims that VCAUSE is in general better able to estimate observational, interventional and counterfactual distributions.",
      "The experimental evaluation only evaluated graphs with 3 and 7 nodes, whereas in practice significantly larger graph sizes are commonly encountered (e.g., in biology where structures with 100s to 1000s of nodes are not uncommon).",
      "A better understanding of the importance of the properties of the modelled SCM on VCAUSE would be particularly important because Table 2 indicates that the relative performance of VCAUSE appears to depend strongly on the underlying SCM.",
      "Several relevant reference baselines are missing from the experimental comparison (Table 2), e.g. learning the parameters of an SCM directly using neural networks [1], additive noise models [2] which can be parameterized by different regressor classes (see e.g. [3]) and non-linear structural equation models (SEMs) [4].",
      "Different approaches were used for hyperparameter optimization for each of the compared baselines (Appendix D.2).",
      "It is therefore unclear if differences in observed performance (Tables 2 and 12) are due to inherent properties of the models or the different hyperparameter optimization strategies and budgets.",
      "The same hyperparameter optimization strategy with a fixed hyperparameter optimization budget should have been employed to enable a fair comparison of methods on equal grounds.",
      "In addition, there are several VCAUSE hyperparameters for which only the final selected values are presented (Appendix D.2) but no details are given as to *how* they were selected (learning rate, epochs, K, latent variable dimension, number of neurons, ...).",
      "Presumably, these values are the result of manual optimization - if so, this should be transparently stated in the manuscript including information as to whether or not held-out performance results were used to optimize these hyperparameters (risk of overfitting).",
      "The application of VCAUSE to use cases in counterfactual fairness (Section 6) is interesting but no state-of-the-art baselines are presented for comparison.",
      "It is therefore unclear if VCAUSE performs better, equally well or worse in the counterfactual fairness setting than other methods that parameterise an SCM.",
      "In addition, uncertainty and statistical significance metrics for the experiments in Section 6 are missing.",
      "The motivational element appears to be missing in the paper's story line.",
      "Why do we expect that mimicking an SCM using a graph VAE is a more efficacious approach than alternatives (and therefore embark on this line of research)?",
      "In Table 2 (main) and Table 12 (appendix), the caption indicates that all metrics are given in percentages.",
      "However, the authors do not state what reference values were used to compute the percentages.",
      "In addition, even if the reference values were indicated, I would generally prefer to be shown the absolute values, since some metrics are not on a linear scale (e.g. MSE) which makes interpretation as percentages difficult.",
      "The computational characteristics of VCAUSE and how they compare to existing alternatives are missing.",
      "Compute time details are in general missing from the manuscript (the Paper Checklist refers to Appendix D but no compute time information is provided therein).",
      "The overall impact of the presented work is limited because of the restrictive assumptions (availability of a faithful causal graph and no hidden confounding) that hold true in a very limited set of settings and can in practice not be verified from data alone [5].",
      "For practical use cases that VCAUSE would be considered for, there therefore exists the risk that the assumptions would likely be at least partially violated.",
      "In addition, the manuscript's claims are only substantiated with experimental evidence for small directed acyclic graphs (DAGs), and it is therefore currently unclear if VCAUSE offers relative benefits in settings with larger numbers of nodes.",
      "Given the absence of several baselines in the experimental comparison, I am unsure if the complexity of processing the causal graph through a graph neural network (GNN) is necessary.",
      "What motivates this approach over simpler existing ones (e.g. parameterising the SCM using neural networks [1] or additive noise models [2]) that would justify the added complexity?",
      "What is the inductive bias introduced by VCAUSE that one would expect to lead to performance benefits?"
    ]
  },
  {
    "paper_id": "2110.00529v1",
    "submission_id": "vCthaJ4ywT",
    "submission_title": "Unsupervised Motion Representation Learning with Capsule Autoencoders",
    "review_id": "i6FZYYp2rO4",
    "input": {
      "title": "Unsupervised Motion Representation Learning with Capsule Autoencoders",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I cannot figure out the relation between the proposed autoencoder and the traditional capsule network. This paper needs to make a clear description on its work with respect to the capsule network.\n- This paper fails to present experiments on more common motion datasets, like movingMNIST, and thus I cannot clearly tell the advantages of the proposed method over previous ones.\n- The authors fail to provide a study on the importance of two-level motion modeling. For example, it should compare with a simple baseline of one-level modeling with the same number of snippets.\n- I would like to see more experiments on motion representation learning on more realistic datasets, like cloud points for scene flow estimation, RGB videos for optical flow estimation.\n- The idea of two-level motion modeling has appeared in many video action recognition works. For example: V4D:4D Convolutional Neural Networks for Video-level Representation Learning [ICLR 2020]. It should discuss these works in the related work section.",
    "review_points_list": [
      "I cannot figure out the relation between the proposed autoencoder and the traditional capsule network. This paper needs to make a clear description on its work with respect to the capsule network.",
      "This paper fails to present experiments on more common motion datasets, like movingMNIST, and thus I cannot clearly tell the advantages of the proposed method over previous ones.",
      "The authors fail to provide a study on the importance of two-level motion modeling. For example, it should compare with a simple baseline of one-level modeling with the same number of snippets.",
      "I would like to see more experiments on motion representation learning on more realistic datasets, like cloud points for scene flow estimation, RGB videos for optical flow estimation.",
      "The idea of two-level motion modeling has appeared in many video action recognition works. For example: V4D:4D Convolutional Neural Networks for Video-level Representation Learning [ICLR 2020]. It should discuss these works in the related work section."
    ]
  },
  {
    "paper_id": "2110.00529v1",
    "submission_id": "vCthaJ4ywT",
    "submission_title": "Unsupervised Motion Representation Learning with Capsule Autoencoders",
    "review_id": "wjr18MWcg4Z",
    "input": {
      "title": "Unsupervised Motion Representation Learning with Capsule Autoencoders",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well-structured.\n- Experimental results are promising.\n- I found the description of the model very hard to follow (both the snipped and segment learning). For someone that is not familiar to CapsNet, it basically is impossible to understand what is happening. Basics of CapsNet should be recalled to build a parallel with the proposal.\n- The authors noted a few works that employ capsule networks in motion representation in Related Works [3,30, 47] but did not attempt to compare against them in the experiments.\n- 2D projected inputs were used instead of 3D pose sequence, did the authors try to experiment with the original 3D sequences?\n- It would be interesting to see what has the model learnt on the skeleton dataset.\n- The work is original. Capsule Nets have been designed especially to do this.\n- Few works that were cited introduced ways of representing 'images'. A comparison should have been made to see if the introduction of 'motion' really is bringing something to the Table.\n- The model section should be clarified, making references to what a CapsNet is (formal definition).\n- The proposed method could have an impact on motion representation.",
    "review_points_list": [
      "The paper is well-structured.",
      "Experimental results are promising.",
      "I found the description of the model very hard to follow (both the snipped and segment learning). For someone that is not familiar to CapsNet, it basically is impossible to understand what is happening. Basics of CapsNet should be recalled to build a parallel with the proposal.",
      "The authors noted a few works that employ capsule networks in motion representation in Related Works [3,30, 47] but did not attempt to compare against them in the experiments.",
      "2D projected inputs were used instead of 3D pose sequence, did the authors try to experiment with the original 3D sequences?",
      "It would be interesting to see what has the model learnt on the skeleton dataset.",
      "The work is original. Capsule Nets have been designed especially to do this.",
      "Few works that were cited introduced ways of representing 'images'. A comparison should have been made to see if the introduction of 'motion' really is bringing something to the Table.",
      "The model section should be clarified, making references to what a CapsNet is (formal definition).",
      "The proposed method could have an impact on motion representation."
    ]
  },
  {
    "paper_id": "2110.00529v1",
    "submission_id": "vCthaJ4ywT",
    "submission_title": "Unsupervised Motion Representation Learning with Capsule Autoencoders",
    "review_id": "DAttrJOjlld",
    "input": {
      "title": "Unsupervised Motion Representation Learning with Capsule Autoencoders",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper presents a novel capsule architecture (MCAE) to learn motion patterns in an unsupervised manner.\n- Experimental evaluations on both synthetic and real data, comparisons with previous approaches, and analysis all support the strengths of this work.\n- The paper should be accepted, but the following questions/comments should be addressed to improve the clarity of the work.\n- How are the templates learned/obtained?\n- Are they a set of learned parameters, which are trained with the full system in an end-to-end manner?\n- $d$ is not defined - since the network works on 2d points, and $A$ is a $3\times3$ matrix, I assume $d=2$, but it should be stated explicitly.\n- How is the accuracy obtained in the ablation study?\n- Is it the same as the MLP used for the motion classification experiments?\n- How is the LSTM used in Eq. 3 to encode the SniCaps?\n- What operation is used to combine each $C_i^\text{Sni}$ into a single representation/vector?\n- Is this behavior common for many different motion classes in Section 4.3?\n- Is $\nu$ the result of a sigmoid or softmax activation?",
    "review_points_list": [
      "The paper presents a novel capsule architecture (MCAE) to learn motion patterns in an unsupervised manner.",
      "Experimental evaluations on both synthetic and real data, comparisons with previous approaches, and analysis all support the strengths of this work.",
      "The paper should be accepted, but the following questions/comments should be addressed to improve the clarity of the work.",
      "How are the templates learned/obtained?",
      "Are they a set of learned parameters, which are trained with the full system in an end-to-end manner?",
      "$d$ is not defined - since the network works on 2d points, and $A$ is a $3\times3$ matrix, I assume $d=2$, but it should be stated explicitly.",
      "How is the accuracy obtained in the ablation study?",
      "Is it the same as the MLP used for the motion classification experiments?",
      "How is the LSTM used in Eq. 3 to encode the SniCaps?",
      "What operation is used to combine each $C_i^\text{Sni}$ into a single representation/vector?",
      "Is this behavior common for many different motion classes in Section 4.3?",
      "Is $\nu$ the result of a sigmoid or softmax activation?"
    ]
  },
  {
    "paper_id": "2110.07579v1",
    "submission_id": "x1Lp2bOlVIo",
    "submission_title": "Diffusion Normalizing Flow",
    "review_id": "INQgZEElIDS",
    "input": {
      "title": "Diffusion Normalizing Flow",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper serves as a natural extension of [1] and [2], which have a fixed inference process that slowly transforms an arbitrary data distribution into an unstructured prior and learn to revert the dynamic.\n- This paper proposes to parameterize the inference part so that the transformation of the data into an unstructured noise can be more efficient (as illustrated by Fig 4).\n- Two limitations of the proposed methods: 1. Computational time: Despite the generality this new framework provides, I suspect training will take much more time since one would have to backprop through the entire trajectory.\n- Backpropagation through the entire path also raises another problem \u2014 the increase in memory.\n- This work proposes an 'adjoint' method and claims to have constant memory consumption (in the number of integration steps).\n- However, I found it to be not entirely true, as the algorithm requires caching all intermediate states x_i, which means it is still technically O(N).\n- I see this as a limitation since having to backprop through the entire trajectory means it will make it harder to scale up to larger datasets.\n- A real constant-memory adjoint method would not require storing all the intermediate states, such as neural ODE, and another recent work [4], which suggests using the stochastic adjoint sensitivity method proposed by [5].\n- Presentation and clarity also need some work; see the following points for more detail.\n- I don't think we can simply drop all the constants as claimed in L142.\n- For example, the normalizing constants of the Gaussians will depend on the variance, which is the diffusion coefficients of the SDEs, unless these coefficients are either constant or not trained.\n- Overall I find the derivation in Section 3.1 very confusing; perhaps having a detailed derivation in the appendix will help.\n- Is there a runtime comparison between DDPM and the proposed method in training? e.g. how much time does it take to make one parameter update, fixing the model size?\n- It is claimed that DiffFlow is a combination of flows and diffusion models (e.g. L179).\n- It's not very clear to me how NF is integrated into this framework.\n- Do you compose flows with diffusion models? Or it's just a matter of interpretation?\n- Aside from the use of the equivalent ODE for density evaluation (which is originally proposed by [6], is there other reasons to introduce the more general marginal-equivalent SDEs, i.e. eq (17)?\n- Also, why not report the ELBO of the SDE?\n- What is the concept of 'layer' within this paper?\n- e.g. in L231, it says DiffFlow uses no more than 5 layers.\n- Is it the size of the network that parameterizes f, g, and s?\n- The statement of Theorem 1 is very handwavy, and so is the proof.\n- is equivalent to', under what condition?\n- In the proof it seems it requires fixing p_B(x_i|x_{i-1})=p_F(x_i|x_{i-1}),\n- what does it mean by it's possible when g is small, e.g. a Gaussian approximation will suffice?\n- It doesn't feel like a rigorous proof.\n- L36: I'd put 'continuous-time' normalizing flows, instead of just normalizing flows\n- L100: $f:\textbf{R}^d\times \textbf{R}\rightarrow \textbf{R}^d$\n- L103 $p_F$ is defined to be the distribution over trajectories, but then in L106 it's used as the score, which is the gradient of the marginal density.\n- This is not accurate.\n- Eq (10): why does it hold?\n- Is it the data processing inequality?\n- Please clarify.\n- L192: noising transformation?\n- In Appendix A, [39] is cited, but is not displayed in the paper.\n- The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods.\n- The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.",
    "review_points_list": [
      "The paper serves as a natural extension of [1] and [2], which have a fixed inference process that slowly transforms an arbitrary data distribution into an unstructured prior and learn to revert the dynamic.",
      "This paper proposes to parameterize the inference part so that the transformation of the data into an unstructured noise can be more efficient (as illustrated by Fig 4).",
      "Two limitations of the proposed methods: 1. Computational time: Despite the generality this new framework provides, I suspect training will take much more time since one would have to backprop through the entire trajectory.",
      "Backpropagation through the entire path also raises another problem \u2014 the increase in memory.",
      "This work proposes an 'adjoint' method and claims to have constant memory consumption (in the number of integration steps).",
      "However, I found it to be not entirely true, as the algorithm requires caching all intermediate states x_i, which means it is still technically O(N).",
      "I see this as a limitation since having to backprop through the entire trajectory means it will make it harder to scale up to larger datasets.",
      "A real constant-memory adjoint method would not require storing all the intermediate states, such as neural ODE, and another recent work [4], which suggests using the stochastic adjoint sensitivity method proposed by [5].",
      "Presentation and clarity also need some work; see the following points for more detail.",
      "I don't think we can simply drop all the constants as claimed in L142.",
      "For example, the normalizing constants of the Gaussians will depend on the variance, which is the diffusion coefficients of the SDEs, unless these coefficients are either constant or not trained.",
      "Overall I find the derivation in Section 3.1 very confusing; perhaps having a detailed derivation in the appendix will help.",
      "Is there a runtime comparison between DDPM and the proposed method in training? e.g. how much time does it take to make one parameter update, fixing the model size?",
      "It is claimed that DiffFlow is a combination of flows and diffusion models (e.g. L179).",
      "It's not very clear to me how NF is integrated into this framework.",
      "Do you compose flows with diffusion models? Or it's just a matter of interpretation?",
      "Aside from the use of the equivalent ODE for density evaluation (which is originally proposed by [6], is there other reasons to introduce the more general marginal-equivalent SDEs, i.e. eq (17)?",
      "Also, why not report the ELBO of the SDE?",
      "What is the concept of 'layer' within this paper?",
      "e.g. in L231, it says DiffFlow uses no more than 5 layers.",
      "Is it the size of the network that parameterizes f, g, and s?",
      "The statement of Theorem 1 is very handwavy, and so is the proof.",
      "is equivalent to', under what condition?",
      "In the proof it seems it requires fixing p_B(x_i|x_{i-1})=p_F(x_i|x_{i-1}),",
      "what does it mean by it's possible when g is small, e.g. a Gaussian approximation will suffice?",
      "It doesn't feel like a rigorous proof.",
      "L36: I'd put 'continuous-time' normalizing flows, instead of just normalizing flows",
      "L100: $f:\textbf{R}^d\times \textbf{R}\rightarrow \textbf{R}^d$",
      "L103 $p_F$ is defined to be the distribution over trajectories, but then in L106 it's used as the score, which is the gradient of the marginal density.",
      "This is not accurate.",
      "Eq (10): why does it hold?",
      "Is it the data processing inequality?",
      "Please clarify.",
      "L192: noising transformation?",
      "In Appendix A, [39] is cited, but is not displayed in the paper.",
      "The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods.",
      "The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm."
    ]
  },
  {
    "paper_id": "2110.07579v1",
    "submission_id": "x1Lp2bOlVIo",
    "submission_title": "Diffusion Normalizing Flow",
    "review_id": "HLKDCR7vX6M",
    "input": {
      "title": "Diffusion Normalizing Flow",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The idea seems to be new.\n- Indeed, the proposed DiffFlow is one type of the Neural SDEs, where the volatility only depends on time variable.\n- The idea and the comparison to diffusion model and normalizing flow is clearly presented in the figure and one theoretical result is provided to link the three different methods.",
    "review_points_list": [
      "The idea seems to be new.",
      "Indeed, the proposed DiffFlow is one type of the Neural SDEs, where the volatility only depends on time variable.",
      "The idea and the comparison to diffusion model and normalizing flow is clearly presented in the figure and one theoretical result is provided to link the three different methods."
    ]
  },
  {
    "paper_id": "2110.07579v1",
    "submission_id": "x1Lp2bOlVIo",
    "submission_title": "Diffusion Normalizing Flow",
    "review_id": "gwW4MrbPYcl",
    "input": {
      "title": "Diffusion Normalizing Flow",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think it is a nice insight that diffusion models can be thought of as relaxed normalizing flows.\n- The method to learn a more expressive forward process is new, although it is straightforward and does not really resolve key issues in learning more expressive forward processes.\n- For example, it is well known that the affine forward processes allow for sampling of q(x_t | x_0) for arbitrary t, allowing for fast training by picking random t; furthermore, variance of training and evaluation can be reduced by Rao-Blackwellizing the variational lower bound into x_0 MSE prediction losses.\n- Both properties do not seem true with the presented method when f is a neural network, and the computational complexity tradeoffs should be studied more thoroughly (e.g. what is the quantitative benefit of slower training time vs better sample quality or log likelihood?)\n- While it is interesting to learn more expressive forward processes, it is not clear why the method needs to be presented as a combination of diffusion and normalizing flows:\n- It seems clear enough to present the method as learning a more expressive forward process for diffusion models.\n- Also, I found it difficult to understand the description of time discretization in Section 3.3.\n- In Section 4.1, I am surprised that DDPM 'blurs density details.'\n- Shouldn't it be possible to resolve this by carefully tuning the noise schedule?\n- What hyperparameters were used for this experiment?\n- I find Table 4 slightly misleading.\n- It is true that the FID scores are better than DDPM for small N, but for large N, the FID scores of DDPM are around 3, and it seems that the presented method does not approach that score.\n- Why does the table omit log likelihoods and FID scores from published methods that perform better, e.g. from Score-Based Generative Modeling through Stochastic Differential Equations by Song et al?\n- The paper claims state-of-the-art NLL (line 246), but it is not.\n- The main limitation of the paper is that as it is presented, the results do not significantly improve upon the baseline enough to warrant the more complex training procedure and model construction,\n- There is no adequate study of the training time (or FLOPS) vs NLL or sample quality,\n- And in some cases, the results are presented in a slightly misleading way (e.g. Table 4).",
    "review_points_list": [
      "I think it is a nice insight that diffusion models can be thought of as relaxed normalizing flows.",
      "The method to learn a more expressive forward process is new, although it is straightforward and does not really resolve key issues in learning more expressive forward processes.",
      "For example, it is well known that the affine forward processes allow for sampling of q(x_t | x_0) for arbitrary t, allowing for fast training by picking random t; furthermore, variance of training and evaluation can be reduced by Rao-Blackwellizing the variational lower bound into x_0 MSE prediction losses.",
      "Both properties do not seem true with the presented method when f is a neural network, and the computational complexity tradeoffs should be studied more thoroughly (e.g. what is the quantitative benefit of slower training time vs better sample quality or log likelihood?)",
      "While it is interesting to learn more expressive forward processes, it is not clear why the method needs to be presented as a combination of diffusion and normalizing flows:",
      "It seems clear enough to present the method as learning a more expressive forward process for diffusion models.",
      "Also, I found it difficult to understand the description of time discretization in Section 3.3.",
      "In Section 4.1, I am surprised that DDPM 'blurs density details.'",
      "Shouldn't it be possible to resolve this by carefully tuning the noise schedule?",
      "What hyperparameters were used for this experiment?",
      "I find Table 4 slightly misleading.",
      "It is true that the FID scores are better than DDPM for small N, but for large N, the FID scores of DDPM are around 3, and it seems that the presented method does not approach that score.",
      "Why does the table omit log likelihoods and FID scores from published methods that perform better, e.g. from Score-Based Generative Modeling through Stochastic Differential Equations by Song et al?",
      "The paper claims state-of-the-art NLL (line 246), but it is not.",
      "The main limitation of the paper is that as it is presented, the results do not significantly improve upon the baseline enough to warrant the more complex training procedure and model construction,",
      "There is no adequate study of the training time (or FLOPS) vs NLL or sample quality,",
      "And in some cases, the results are presented in a slightly misleading way (e.g. Table 4)."
    ]
  },
  {
    "paper_id": "2110.07579v1",
    "submission_id": "x1Lp2bOlVIo",
    "submission_title": "Diffusion Normalizing Flow",
    "review_id": "GAqdYsxLoXv",
    "input": {
      "title": "Diffusion Normalizing Flow",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is clear enough to understand, although there are some typos in a few places (mentioned below).\n- The novel contribution of making the drift component non-linear is relevant in the context of this line of research : discrete Markov chains (DDPM [1], etc.), to equivalent continuous formulations with the help of SDEs [2], to a variety of SDEs where the drift component is learnt as well instead of being prefixed.\n- Relevant examples have been shown in 2D data as well as image sampling to highlight the advantages of this method compared to the previous version (DDPM).\n- Although the continuous formulation (SDE) is mentioned, the paper converts it back to a discrete Markov chain and trains it accordingly.\n- Figures 5, 8 and 9 illustrate the relevance of the current method compared to DDPM and FFJORD.\n- They make a convincing argument for the use of a trainable forward process.\n- Lines 182-184 make a convincing argument for why this particular type of 2D data was chosen.\n- It is all the more encouraging that even though finer details are better, it is not at the expense of likelihood/NLL (in many cases).\n- A major significance is that the number of sampling steps can be quite low compared to the original formulation (Table 4) and yet the quality of generated samples does not significantly deteriorate as much as the baseline (DDPM).\n- Table 3 compares the NLL and FID of previous relevant methods for CIFAR10.\n- DDIM [3] is missing from the list, as it is also a discrete formulation like DDPM but uses a different sampling scheme.\n- It is a relevant comparison since DDIM also aims to reduce the number of training steps.\n- Although, the method proposed is significantly different from the motivation of DDIM, in that DDIM preserves the DDPM formulation and only changes the sampling scheme, while the paper changes the forward process itself.\n- The appendix mentions the resources used to complete each experiment.\n- It needs to be seen whether computational efficiency could be improved.\n- Code has been provided to reproduce the experiments.\n- Line 87 says x(0) = z and x(T) = x, but lines 121-122 say x(T) = x and x(0) = z.\n- I assume the latter, it is good if this is clarified.\n- Line 55 : the forward process from x* to z* ?\n- Line 166 : (to add) in Figure 3*\n- Line 192 : noi*sing\n- Line 198 : to*pological?\n- Figure 5 : Frac*tal tree\n- Line 239 : using*\n- I stand by my original evaluation of accepting this paper: The novel contribution of making the drift component non-linear is relevant in the context of this line of research\n- I found their methodology to be well motivated\n- The pros and cons of each design step have been mentioned\n- Enough experiments have been performed to explore the method, with the pros and cons\n- Code has been provided for reproduceability\n- Computational resources used for each experiment have been mentioned\n- Reviewers' comments have been responded to sufficiently and honestly\n- If the other reviewers feel there are still some unanswered questions, or comments that have not been responded to, please let us know.\n- I think this paper deserves to be accepted.",
    "review_points_list": [
      "The paper is clear enough to understand, although there are some typos in a few places (mentioned below).",
      "The novel contribution of making the drift component non-linear is relevant in the context of this line of research : discrete Markov chains (DDPM [1], etc.), to equivalent continuous formulations with the help of SDEs [2], to a variety of SDEs where the drift component is learnt as well instead of being prefixed.",
      "Relevant examples have been shown in 2D data as well as image sampling to highlight the advantages of this method compared to the previous version (DDPM).",
      "Although the continuous formulation (SDE) is mentioned, the paper converts it back to a discrete Markov chain and trains it accordingly.",
      "Figures 5, 8 and 9 illustrate the relevance of the current method compared to DDPM and FFJORD.",
      "They make a convincing argument for the use of a trainable forward process.",
      "Lines 182-184 make a convincing argument for why this particular type of 2D data was chosen.",
      "It is all the more encouraging that even though finer details are better, it is not at the expense of likelihood/NLL (in many cases).",
      "A major significance is that the number of sampling steps can be quite low compared to the original formulation (Table 4) and yet the quality of generated samples does not significantly deteriorate as much as the baseline (DDPM).",
      "Table 3 compares the NLL and FID of previous relevant methods for CIFAR10.",
      "DDIM [3] is missing from the list, as it is also a discrete formulation like DDPM but uses a different sampling scheme.",
      "It is a relevant comparison since DDIM also aims to reduce the number of training steps.",
      "Although, the method proposed is significantly different from the motivation of DDIM, in that DDIM preserves the DDPM formulation and only changes the sampling scheme, while the paper changes the forward process itself.",
      "The appendix mentions the resources used to complete each experiment.",
      "It needs to be seen whether computational efficiency could be improved.",
      "Code has been provided to reproduce the experiments.",
      "Line 87 says x(0) = z and x(T) = x, but lines 121-122 say x(T) = x and x(0) = z.",
      "I assume the latter, it is good if this is clarified.",
      "Line 55 : the forward process from x* to z* ?",
      "Line 166 : (to add) in Figure 3*",
      "Line 192 : noi*sing",
      "Line 198 : to*pological?",
      "Figure 5 : Frac*tal tree",
      "Line 239 : using*",
      "I stand by my original evaluation of accepting this paper: The novel contribution of making the drift component non-linear is relevant in the context of this line of research",
      "I found their methodology to be well motivated",
      "The pros and cons of each design step have been mentioned",
      "Enough experiments have been performed to explore the method, with the pros and cons",
      "Code has been provided for reproduceability",
      "Computational resources used for each experiment have been mentioned",
      "Reviewers' comments have been responded to sufficiently and honestly",
      "If the other reviewers feel there are still some unanswered questions, or comments that have not been responded to, please let us know.",
      "I think this paper deserves to be accepted."
    ]
  },
  {
    "paper_id": "2106.15845v2",
    "submission_id": "vwgsqRorzz",
    "submission_title": "Edge Representation Learning with Hypergraphs",
    "review_id": "3aLz67_TWyp",
    "input": {
      "title": "Edge Representation Learning with Hypergraphs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper proposes a simple method to explicitly represent edge information which builds on the literature in message passing GNNs and leverages an intuitive graph duality structure.\n- This approach is clearly presented, easy to follow, and achieves good results, suggesting significant potential in better incorporating edge information within current GNN models.\n- Moreover, the paper conducts a thorough empirical analysis, and convincingly argues for the value of edge information in the field of graph representation learning.\n- However, the paper has some key limitations that need to be addressed.\n- First, the novelty of the approach seems limited, and appears to be somewhat overstated.\n- In particular, the related works mentioned in the paper seem highly similar in essence to the separate components (pooling, DHT) being proposed, and the differences raised (e.g., lines 106-107) do not come across as conceptually substantial.\n- In my view, the main strength of this paper lies in highlighting the value of edge information, and performing a thorough empirical study toward showing this point, and arguing how this approach manages to bridge this gap.\n- Therefore, I suggest that the authors emphasize their arguments more, and develop their work more along this direction.\n- Second, the EHGNN framework, as the authors acknowledge, does not jointly capture both node and edge information.\n- Indeed, EHGNN successfully captures edge information in its representations, and in doing so vastly outperforms standard GNNs which only implicitly handle edges, but (1) this is not surprising, as the model is explicitly modelled for this setting, and, more importantly, (2) this model then suffers in terms of capturing node information, which then motivates the use of a parallel second model for standard node representation learning.\n- Therefore, this framework is not conceptually more powerful than existing models, as it simply applies these models on a dual graph, and this limits its significance.\n- Hence, a more balanced presentation of the results, framing EHGNN more in terms of a means of highlighting the current gaps in edge representation learning, and less so as a standalone model, should be considered.\n- I agree with the authors' comment in the supplementary material that a joint model is an interesting avenue for future work, but also think that this view should be better reflected in the main body of the paper, and that such a model is what is ideally needed to make this paper more conceptually significant.\n- Finally, I have some minor comments about the writing of the paper.\n- For example, I find that the tasks in the experimental section should be defined within the main body of the paper, as I had to search for these definitions and infer them from the supplementary material to fully understand the results and the discussions.\n- Moreover, concepts such as the compression ratio in that section should also be made clearer and be presented more carefully.\n- All in all, the paper makes a thorough empirical study to confirm intuitions about the importance of edge representations within graph representation learning.\n- However, its proposed approach, EHGNN, is not sufficiently novel, and fails to properly capture node information, which current GNNs do well.\n- This limits its applicability without combining with a standard GNN, and makes that the model itself does not provide any conceptual improvement over existing models.\n- Hence, this paper does not currently make sufficient contributions in my opinion to justify acceptance.",
    "review_points_list": [
      "The paper proposes a simple method to explicitly represent edge information which builds on the literature in message passing GNNs and leverages an intuitive graph duality structure.",
      "This approach is clearly presented, easy to follow, and achieves good results, suggesting significant potential in better incorporating edge information within current GNN models.",
      "Moreover, the paper conducts a thorough empirical analysis, and convincingly argues for the value of edge information in the field of graph representation learning.",
      "However, the paper has some key limitations that need to be addressed.",
      "First, the novelty of the approach seems limited, and appears to be somewhat overstated.",
      "In particular, the related works mentioned in the paper seem highly similar in essence to the separate components (pooling, DHT) being proposed, and the differences raised (e.g., lines 106-107) do not come across as conceptually substantial.",
      "In my view, the main strength of this paper lies in highlighting the value of edge information, and performing a thorough empirical study toward showing this point, and arguing how this approach manages to bridge this gap.",
      "Therefore, I suggest that the authors emphasize their arguments more, and develop their work more along this direction.",
      "Second, the EHGNN framework, as the authors acknowledge, does not jointly capture both node and edge information.",
      "Indeed, EHGNN successfully captures edge information in its representations, and in doing so vastly outperforms standard GNNs which only implicitly handle edges, but (1) this is not surprising, as the model is explicitly modelled for this setting, and, more importantly, (2) this model then suffers in terms of capturing node information, which then motivates the use of a parallel second model for standard node representation learning.",
      "Therefore, this framework is not conceptually more powerful than existing models, as it simply applies these models on a dual graph, and this limits its significance.",
      "Hence, a more balanced presentation of the results, framing EHGNN more in terms of a means of highlighting the current gaps in edge representation learning, and less so as a standalone model, should be considered.",
      "I agree with the authors' comment in the supplementary material that a joint model is an interesting avenue for future work, but also think that this view should be better reflected in the main body of the paper, and that such a model is what is ideally needed to make this paper more conceptually significant.",
      "Finally, I have some minor comments about the writing of the paper.",
      "For example, I find that the tasks in the experimental section should be defined within the main body of the paper, as I had to search for these definitions and infer them from the supplementary material to fully understand the results and the discussions.",
      "Moreover, concepts such as the compression ratio in that section should also be made clearer and be presented more carefully.",
      "All in all, the paper makes a thorough empirical study to confirm intuitions about the importance of edge representations within graph representation learning.",
      "However, its proposed approach, EHGNN, is not sufficiently novel, and fails to properly capture node information, which current GNNs do well.",
      "This limits its applicability without combining with a standard GNN, and makes that the model itself does not provide any conceptual improvement over existing models.",
      "Hence, this paper does not currently make sufficient contributions in my opinion to justify acceptance."
    ]
  },
  {
    "paper_id": "2106.15845v2",
    "submission_id": "vwgsqRorzz",
    "submission_title": "Edge Representation Learning with Hypergraphs",
    "review_id": "cyCsgaASaXL",
    "input": {
      "title": "Edge Representation Learning with Hypergraphs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Overall the approach is simple and easy to implement.\n- However, I have the following concerns:\n- Novelty: Converting an input graph to a hypergraph to get edge representations is a known approach.\n- The authors combine this with graph convolution network which is also common in graph representation learning.\n- This limits the novelty of the approach.\n- Further, HyperCluster and HyperDrop are also simple implementations of clustering and dropping nodes.\n- Experiments - Dataset Size and Time: The authors have shown results on several tasks including edge and graph reconstruction, graph generation and graph and node classification.\n- However, most of these data sets are small with no more than 6000 edges.\n- As they are changing to edge space, the authors should show how the model performs on big data sets as well as the time taken in comparison to node based approaches to showcase the utility of the approach.\n- Experiments - Baselines and Performance: For node and graph classification, authors have not compared their results with the state-of-the-art methods.\n- For e.g., graph classification using HGP-SL gets accuracy of 84.91% and 80.96% on PROTEINS and D&D respectively.\n- The authors achieve an accuracy of 75.39% and 78.39% which is lower.\n- Similarly, node classification using GCN-LPA achieves accuracy of 88.5% and 78.7% on CORA and Citeseer respectively.\n- HyperDrop achieves a performance of around 75-80% and 65-70% respectively.\n- Please comment on the difference in numbers between state-of-the-art and paper's performance.\n- For edge and graph reconstruction, the authors should show performance comparison with approaches such as Structural Deep Network Embedding (SDNE) which has shown to perform well on this task.",
    "review_points_list": [
      "Overall the approach is simple and easy to implement.",
      "However, I have the following concerns:",
      "Novelty: Converting an input graph to a hypergraph to get edge representations is a known approach.",
      "The authors combine this with graph convolution network which is also common in graph representation learning.",
      "This limits the novelty of the approach.",
      "Further, HyperCluster and HyperDrop are also simple implementations of clustering and dropping nodes.",
      "Experiments - Dataset Size and Time: The authors have shown results on several tasks including edge and graph reconstruction, graph generation and graph and node classification.",
      "However, most of these data sets are small with no more than 6000 edges.",
      "As they are changing to edge space, the authors should show how the model performs on big data sets as well as the time taken in comparison to node based approaches to showcase the utility of the approach.",
      "Experiments - Baselines and Performance: For node and graph classification, authors have not compared their results with the state-of-the-art methods.",
      "For e.g., graph classification using HGP-SL gets accuracy of 84.91% and 80.96% on PROTEINS and D&D respectively.",
      "The authors achieve an accuracy of 75.39% and 78.39% which is lower.",
      "Similarly, node classification using GCN-LPA achieves accuracy of 88.5% and 78.7% on CORA and Citeseer respectively.",
      "HyperDrop achieves a performance of around 75-80% and 65-70% respectively.",
      "Please comment on the difference in numbers between state-of-the-art and paper's performance.",
      "For edge and graph reconstruction, the authors should show performance comparison with approaches such as Structural Deep Network Embedding (SDNE) which has shown to perform well on this task."
    ]
  },
  {
    "paper_id": "2106.15845v2",
    "submission_id": "vwgsqRorzz",
    "submission_title": "Edge Representation Learning with Hypergraphs",
    "review_id": "-bkzFwiV2UY",
    "input": {
      "title": "Edge Representation Learning with Hypergraphs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper has a good motivation and focuses on an interesting problem.\n- Intuitively, accurate edge representations may be as effective as node representations for graph-based tasks.\n- Existing works mostly pay attention to node representation learning and how to learn useful edge representation is under-explored.\n- The authors propose to transform normal graphs to hypergraph, so as to fulfill message passing among edges.\n- This proposed idea is good.\n- MANY researchers can come up with such an idea.\n- Modeling the edges as another type of nodes, the original graph can be seen as a bipartite graph, and it is common to transform bipartite graphs to hypergraphs in a wide range of graph-based tasks.\n- When performing the message-passing among edges (nodes in the hypergraph), the proposed method needs to look up the adjacency matrix to find neighboring nodes.\n- The process is similar to that of hypergraph neural networks which have been proposed and studied several years ago.\n- The authors claimed that \u201cAlthough acquiring the neighboring node set from the incidence matrix costs O(m), compared to using the adjacency matrix which costs O(n), this cost can be ignored by using the sparse implementation of DHT explained above\u201d in page 5.\n- Actually, both the hypergraph incident matrix and the graph adjacency matrix can have sparse implementations.\n- This cannot be the advantage of the proposed framework.\n- As for the pooling methods, it is not clear what the advantages of HyperCluster and HyperDrop when compared with methods such as DiffPool.\n- These two pooling methods cannot be trained in an end-to-end way, which is the advantage of DiffPool.\n- Besides, these two pooling methods are intuitively designed.\n- No new ideas are provided in this part.\n- The quality of the presentation is good and this paper is easy to follow.\n- However, the experimental results are insignificant.\n- Only small improvements are observed, which would question the necessity of applying the proposed framework to graph-based tasks.",
    "review_points_list": [
      "The paper has a good motivation and focuses on an interesting problem.",
      "Intuitively, accurate edge representations may be as effective as node representations for graph-based tasks.",
      "Existing works mostly pay attention to node representation learning and how to learn useful edge representation is under-explored.",
      "The authors propose to transform normal graphs to hypergraph, so as to fulfill message passing among edges.",
      "This proposed idea is good.",
      "MANY researchers can come up with such an idea.",
      "Modeling the edges as another type of nodes, the original graph can be seen as a bipartite graph, and it is common to transform bipartite graphs to hypergraphs in a wide range of graph-based tasks.",
      "When performing the message-passing among edges (nodes in the hypergraph), the proposed method needs to look up the adjacency matrix to find neighboring nodes.",
      "The process is similar to that of hypergraph neural networks which have been proposed and studied several years ago.",
      "The authors claimed that \u201cAlthough acquiring the neighboring node set from the incidence matrix costs O(m), compared to using the adjacency matrix which costs O(n), this cost can be ignored by using the sparse implementation of DHT explained above\u201d in page 5.",
      "Actually, both the hypergraph incident matrix and the graph adjacency matrix can have sparse implementations.",
      "This cannot be the advantage of the proposed framework.",
      "As for the pooling methods, it is not clear what the advantages of HyperCluster and HyperDrop when compared with methods such as DiffPool.",
      "These two pooling methods cannot be trained in an end-to-end way, which is the advantage of DiffPool.",
      "Besides, these two pooling methods are intuitively designed.",
      "No new ideas are provided in this part.",
      "The quality of the presentation is good and this paper is easy to follow.",
      "However, the experimental results are insignificant.",
      "Only small improvements are observed, which would question the necessity of applying the proposed framework to graph-based tasks."
    ]
  },
  {
    "paper_id": "1910.12799v2",
    "submission_id": "uSQQH7Fj5U",
    "submission_title": "Deep learning is adaptive to intrinsic dimensionality of model smoothness in anisotropic Besov space",
    "review_id": "B-NQdDykfjA",
    "input": {
      "title": "Deep learning is adaptive to intrinsic dimensionality of model smoothness in anisotropic Besov space",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper present new strong results which combines expressivity and generalization bounds on deep neural networks.\n- The adaptivity to the average smoothness instead of the worst case smoothness is particularly interesting.\n- For these reasons, I recommend the paper to be accepted.\n- It would be great to comment more on the dependency of the different quantities on $n,d$ and other parameters.\n- The current theorems are difficult to parse.\n- For example, $N$ is proportional to the number of non zero parameters?\n- For $\tilde{\beta}$ to not be of order $1/d$, $m$ needs to scale with $d$, is $L_1(d)$ linear in $d$ then?\n- I think adding a few remarks would go a long way in improving the readability of these results.\n- While I think this represents an interesting theoretical work for the approximation/function space estimation community,\n- I wonder how much this approach can help understand practical success of deep learning (in particular, I disagree with the last sentence of the conclusion ''these analyses strongly support the practical success of deep learning from a theoretical perspective\u2019\u2019).\n- In particular, numerous work have demonstrated that one cannot disentangle computational and statistical aspects in deep learning.\n- Furthermore, the theorems have a sparsity requirement, which is usually not the case for practically trained neural networks.\n- Typos: reference to Theorem 6 in Theorem 2? Reference to equation 8 bottom of page 6?\n- Thank you to the authors for the response.\n- I am satisfied with the paper and the updates mentioned by the authors.\n- I keep the same rating.",
    "review_points_list": [
      "This paper present new strong results which combines expressivity and generalization bounds on deep neural networks.",
      "The adaptivity to the average smoothness instead of the worst case smoothness is particularly interesting.",
      "For these reasons, I recommend the paper to be accepted.",
      "It would be great to comment more on the dependency of the different quantities on $n,d$ and other parameters.",
      "The current theorems are difficult to parse.",
      "For example, $N$ is proportional to the number of non zero parameters?",
      "For $\tilde{\beta}$ to not be of order $1/d$, $m$ needs to scale with $d$, is $L_1(d)$ linear in $d$ then?",
      "I think adding a few remarks would go a long way in improving the readability of these results.",
      "While I think this represents an interesting theoretical work for the approximation/function space estimation community,",
      "I wonder how much this approach can help understand practical success of deep learning (in particular, I disagree with the last sentence of the conclusion ''these analyses strongly support the practical success of deep learning from a theoretical perspective\u2019\u2019).",
      "In particular, numerous work have demonstrated that one cannot disentangle computational and statistical aspects in deep learning.",
      "Furthermore, the theorems have a sparsity requirement, which is usually not the case for practically trained neural networks.",
      "Typos: reference to Theorem 6 in Theorem 2? Reference to equation 8 bottom of page 6?",
      "Thank you to the authors for the response.",
      "I am satisfied with the paper and the updates mentioned by the authors.",
      "I keep the same rating."
    ]
  },
  {
    "paper_id": "1910.12799v2",
    "submission_id": "uSQQH7Fj5U",
    "submission_title": "Deep learning is adaptive to intrinsic dimensionality of model smoothness in anisotropic Besov space",
    "review_id": "1vd11rr2XxP",
    "input": {
      "title": "Deep learning is adaptive to intrinsic dimensionality of model smoothness in anisotropic Besov space",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I am tending positive on the paper.\n- There are a few questions.\n- Is it true that the composition of two anisotropic Besov functions is still an anisotropic Besov function?\n- If so, I don't see the merit of considering two models of the true functions in Section 2.2, as deep composition can also be viewed as a special case of affine composition model, and vice versa.\n- Per definition of $\tilde{\beta}$ in Equation (1), when $\beta_j$ is approximately equal, there is still the curse of data dimensionality.\n- However, when only a small fraction of $\beta_j$'s are small (severe fluctuation of the target function in these directions), the result is free of the curse.\n- In such a case, is it possible that the target function may be approximated first by a function only supported on those significant coordinates, and then approximate the function on those significant coordinates?\n- It seems that this argument translates finally to some low-dimensional structures in data.\n- Can the authors kindly comment on this?\n- A practical motivation of studying anisotropic Besov spaces seems missing.",
    "review_points_list": [
      "I am tending positive on the paper.",
      "There are a few questions.",
      "Is it true that the composition of two anisotropic Besov functions is still an anisotropic Besov function?",
      "If so, I don't see the merit of considering two models of the true functions in Section 2.2, as deep composition can also be viewed as a special case of affine composition model, and vice versa.",
      "Per definition of $\tilde{\beta}$ in Equation (1), when $\beta_j$ is approximately equal, there is still the curse of data dimensionality.",
      "However, when only a small fraction of $\beta_j$'s are small (severe fluctuation of the target function in these directions), the result is free of the curse.",
      "In such a case, is it possible that the target function may be approximated first by a function only supported on those significant coordinates, and then approximate the function on those significant coordinates?",
      "It seems that this argument translates finally to some low-dimensional structures in data.",
      "Can the authors kindly comment on this?",
      "A practical motivation of studying anisotropic Besov spaces seems missing."
    ]
  },
  {
    "paper_id": "1910.12799v2",
    "submission_id": "uSQQH7Fj5U",
    "submission_title": "Deep learning is adaptive to intrinsic dimensionality of model smoothness in anisotropic Besov space",
    "review_id": "7u0wStwKTBf",
    "input": {
      "title": "Deep learning is adaptive to intrinsic dimensionality of model smoothness in anisotropic Besov space",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper studies adaptivity properties of deep networks, a topic which has recently gained a lot of attention, as it can yield an understanding of what kind of functions deep learning can learn efficiently, and more efficiently than other standard procedures such as kernels.\n- It provides a comprehensive study of adaptivity of neural networks to anisotropic smoothness, which is a useful prior, and has not been previously studied in this context.\n- In this sense, I find the paper significant and novel.\n- It is also very well written.\n- I thus recommend acceptance.\n- A few minor comments:\n- the authors briefly mention a motivation for anisotropic smoothness in the context of invariances on image problems.\n- This seems quite interesting but the current explanation is very brief - I encourage the authors to expand further on this, and perhaps on other motivating examples.\n- why is tilde{beta} in (1) defined like this instead of just as the harmonic mean?\n- I find that this makes the rates with +1 instead of +d a bit puzzling to parse, and would find it more natural to just have the harmonic mean, so that you immediately recognize the usual rate when all the betas are equal (but I leave this choice to the authors).\n- some typos: L199: d beta -> beta / d?\n- L301: why the red text?\n- Thank you for the response.\n- I think these additional comments on motivating examples would be useful in the paper, so please do include them in the final version.",
    "review_points_list": [
      "The paper studies adaptivity properties of deep networks, a topic which has recently gained a lot of attention, as it can yield an understanding of what kind of functions deep learning can learn efficiently, and more efficiently than other standard procedures such as kernels.",
      "It provides a comprehensive study of adaptivity of neural networks to anisotropic smoothness, which is a useful prior, and has not been previously studied in this context.",
      "In this sense, I find the paper significant and novel.",
      "It is also very well written.",
      "I thus recommend acceptance.",
      "A few minor comments:",
      "the authors briefly mention a motivation for anisotropic smoothness in the context of invariances on image problems.",
      "This seems quite interesting but the current explanation is very brief - I encourage the authors to expand further on this, and perhaps on other motivating examples.",
      "why is tilde{beta} in (1) defined like this instead of just as the harmonic mean?",
      "I find that this makes the rates with +1 instead of +d a bit puzzling to parse, and would find it more natural to just have the harmonic mean, so that you immediately recognize the usual rate when all the betas are equal (but I leave this choice to the authors).",
      "some typos: L199: d beta -> beta / d?",
      "L301: why the red text?",
      "Thank you for the response.",
      "I think these additional comments on motivating examples would be useful in the paper, so please do include them in the final version."
    ]
  },
  {
    "paper_id": "2110.09246v1",
    "submission_id": "ympqhd5gE9",
    "submission_title": "Single Layer Predictive Normalized Maximum Likelihood for Out-of-Distribution Detection",
    "review_id": "caP5zn2s4a",
    "input": {
      "title": "Single Layer Predictive Normalized Maximum Likelihood for Out-of-Distribution Detection",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Decent. The author derived a closed-form expression for pNML regret and empirically illustrated consistent improvement over recent approaches. The proposal appears to be simple and effective, and should be of interest to the NeurIPS community.\n- The derivation appears to be technically sound.\n- The experiment setup used is standard among the OOD community.\n- The paper is well structured and clearly written.\n- However, the description of experiment setup can be improved.\n- Specifically, please provide sufficient detail about how pNML is built on top of each methods (e.g., ODIN+pNML, Gram+pNML, etc).\n- Specifically, it is not clear to me how the score for Gram+pNML is generated, since this method does not seems to modify the base architecture.\n- If author is building on Gram method by simply computing pNML score by using the last layer of the architecture used by Gram, should the result be same as Baseline+pNML?",
    "review_points_list": [
      "Decent. The author derived a closed-form expression for pNML regret and empirically illustrated consistent improvement over recent approaches. The proposal appears to be simple and effective, and should be of interest to the NeurIPS community.",
      "The derivation appears to be technically sound.",
      "The experiment setup used is standard among the OOD community.",
      "The paper is well structured and clearly written.",
      "However, the description of experiment setup can be improved.",
      "Specifically, please provide sufficient detail about how pNML is built on top of each methods (e.g., ODIN+pNML, Gram+pNML, etc).",
      "Specifically, it is not clear to me how the score for Gram+pNML is generated, since this method does not seems to modify the base architecture.",
      "If author is building on Gram method by simply computing pNML score by using the last layer of the architecture used by Gram, should the result be same as Baseline+pNML?"
    ]
  },
  {
    "paper_id": "2110.09246v1",
    "submission_id": "ympqhd5gE9",
    "submission_title": "Single Layer Predictive Normalized Maximum Likelihood for Out-of-Distribution Detection",
    "review_id": "09rxVFcVTH",
    "input": {
      "title": "Single Layer Predictive Normalized Maximum Likelihood for Out-of-Distribution Detection",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Pros\n- - the proposed method is novel\n- - the proposed method is empirically strong\n- - the submission is well-written and clear\n- - the proposed method does not introduce high computational overhead unlike methods that require retraining\n- - the proposed method does not require additional data\n- Cons/Questions\n- Can the authors clarify how pNML is used together with other OOD detection methods in Table 1 and Table 2?\n- Fundamentally the success of this method relies on the quality of the feature extractor.\n- I think the authors should acknowledge this fact in their discussion in section 4.2\n- I wonder if there are more analyses the authors can do to support their empirical evaluation.\n- qualitatively, how is this proposed method different from existing measures such as the Baseline method?",
    "review_points_list": [
      "Pros",
      "- the proposed method is novel",
      "- the proposed method is empirically strong",
      "- the submission is well-written and clear",
      "- the proposed method does not introduce high computational overhead unlike methods that require retraining",
      "- the proposed method does not require additional data",
      "Cons/Questions",
      "Can the authors clarify how pNML is used together with other OOD detection methods in Table 1 and Table 2?",
      "Fundamentally the success of this method relies on the quality of the feature extractor.",
      "I think the authors should acknowledge this fact in their discussion in section 4.2",
      "I wonder if there are more analyses the authors can do to support their empirical evaluation.",
      "qualitatively, how is this proposed method different from existing measures such as the Baseline method?"
    ]
  },
  {
    "paper_id": "2110.09246v1",
    "submission_id": "ympqhd5gE9",
    "submission_title": "Single Layer Predictive Normalized Maximum Likelihood for Out-of-Distribution Detection",
    "review_id": "Xz7gqqOozxv",
    "input": {
      "title": "Single Layer Predictive Normalized Maximum Likelihood for Out-of-Distribution Detection",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is overall well written and well-motivated and the contributions are clear.\n- I have some concerns with the magnitude and significance of the contributions in the paper, but of course these are my own opinions and I would like to hear the authors opinions.\n- The 'single-layer' neural network discussed in the paper is really just a softmax linear classifier/multi-class logistic regression. In terms of writing, to avoid potential confusion for readers I believe it should just be referred to by a more standard name, such as logistic regression.\n- The application for DNNs also only applies to training the final layer, which reduces the problem to logistic regression since the static network is just a fixed feature transform, in contrast to actually training the entire network.\n- This aspect seems slightly swept under the rug, and maybe deserves more insight into the tradeoffs in the two potential approaches.\n- The theory presented in the paper also seem more suited to be labeled corollaries rather than substantial theoretical contributions - they involve plugging the results derived in one paper (Zhuang et. al 2020) into the definitions for logistic regression and the NML distribution.\n- The experimental results seem solid, although I am not familiar with prior work in OOD detection, the metrics used, and what numbers constitute a strong result.\n- Therefore, I will not make a strong claim in this area.\n- Have the authors compared fine-tuning the last layer of the neural network with NML, versus training the all layers of the network?\n- This would also be an interesting ablation study because the full neural network would have higher regret due to the more expressive model class, and it would be interesting to see how this plays together with OOD detection.\n- Is a more expressive class better or worse for this task?",
    "review_points_list": [
      "The paper is overall well written and well-motivated and the contributions are clear.",
      "I have some concerns with the magnitude and significance of the contributions in the paper, but of course these are my own opinions and I would like to hear the authors opinions.",
      "The 'single-layer' neural network discussed in the paper is really just a softmax linear classifier/multi-class logistic regression. In terms of writing, to avoid potential confusion for readers I believe it should just be referred to by a more standard name, such as logistic regression.",
      "The application for DNNs also only applies to training the final layer, which reduces the problem to logistic regression since the static network is just a fixed feature transform, in contrast to actually training the entire network.",
      "This aspect seems slightly swept under the rug, and maybe deserves more insight into the tradeoffs in the two potential approaches.",
      "The theory presented in the paper also seem more suited to be labeled corollaries rather than substantial theoretical contributions - they involve plugging the results derived in one paper (Zhuang et. al 2020) into the definitions for logistic regression and the NML distribution.",
      "The experimental results seem solid, although I am not familiar with prior work in OOD detection, the metrics used, and what numbers constitute a strong result.",
      "Therefore, I will not make a strong claim in this area.",
      "Have the authors compared fine-tuning the last layer of the neural network with NML, versus training the all layers of the network?",
      "This would also be an interesting ablation study because the full neural network would have higher regret due to the more expressive model class, and it would be interesting to see how this plays together with OOD detection.",
      "Is a more expressive class better or worse for this task?"
    ]
  },
  {
    "paper_id": "2104.12112v2",
    "submission_id": "x2lBl0GRav5",
    "submission_title": "An Improved Analysis and Rates for Variance Reduction under Without-replacement Sampling Orders ",
    "review_id": "cQiobiDf28M",
    "input": {
      "title": "An Improved Analysis and Rates for Variance Reduction under Without-replacement Sampling Orders ",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I believe that the result of this paper is new, especially the use of a new weighted norm in this case.\n- In fact, the algorithm can be cast into a variant of the ARock method [Peng et al, 2015], but the use of without-replacement is new.\n- The use of damped step is not new, which has been widely used in fixed-point methods as well as in optimization.\n- The key idea of analysis is to show that the corresponding fixed-point mapping is nonexpansive, which allows to use a damped step and achieve O(1/k) rate in epoch.\n- However, the convergence rate is not really encouraging even it is comparable with GD.\n- The reason is that this method requires to store n auxiliary vectors as in SAGA, making it less practical when n and d are large.\n- The paper is well written and well-motivated in general.\n- It does have both algorithmic and theoretical contributions.\n- The technicality sounds and the analysis seems to be nontrivial.\n- Overall, the paper has nice contribution in terms of new algorithm, especially when using without-replacement strategy.\n- Is the damped step in Algorithm 1 really the key to achieve the O(1/k) rate?\n- In fact, it is not needed for the strongly convex case.\n- I have a feeling that this is only needed if the fixed-point mapping is only non-expansive.\n- Could the authors clarify and discuss this point, because it is highlighted in the paper?\n- It seems that the nonexpansiveness of T is rather trivial since it is constituted by a proximal gradient operator which is nonexpansive for such a chosen stepsize.\n- Does it need any other properties to guarantee the non-expansiveness of T in (11)?\n- The comparison with SVRG and SAGA using randomized reshuffling rule seems to not make sense.\n- These variants may not work with without-replacement rules unless an appropriate variant (e.g., in [18,37]) is used.\n- The authors may use [18] for SVRG, but for SAGA, which variant is used in the experiments?\n- The weighted norm only depends on z0 and z*, and does not depend on the landscape of the problem.\n- This is a very interesting aspect of the new method.\n- Can you also add more discussion on this aspect to elaborate the new contribution?",
    "review_points_list": [
      "I believe that the result of this paper is new, especially the use of a new weighted norm in this case.",
      "In fact, the algorithm can be cast into a variant of the ARock method [Peng et al, 2015], but the use of without-replacement is new.",
      "The use of damped step is not new, which has been widely used in fixed-point methods as well as in optimization.",
      "The key idea of analysis is to show that the corresponding fixed-point mapping is nonexpansive, which allows to use a damped step and achieve O(1/k) rate in epoch.",
      "However, the convergence rate is not really encouraging even it is comparable with GD.",
      "The reason is that this method requires to store n auxiliary vectors as in SAGA, making it less practical when n and d are large.",
      "The paper is well written and well-motivated in general.",
      "It does have both algorithmic and theoretical contributions.",
      "The technicality sounds and the analysis seems to be nontrivial.",
      "Overall, the paper has nice contribution in terms of new algorithm, especially when using without-replacement strategy.",
      "Is the damped step in Algorithm 1 really the key to achieve the O(1/k) rate?",
      "In fact, it is not needed for the strongly convex case.",
      "I have a feeling that this is only needed if the fixed-point mapping is only non-expansive.",
      "Could the authors clarify and discuss this point, because it is highlighted in the paper?",
      "It seems that the nonexpansiveness of T is rather trivial since it is constituted by a proximal gradient operator which is nonexpansive for such a chosen stepsize.",
      "Does it need any other properties to guarantee the non-expansiveness of T in (11)?",
      "The comparison with SVRG and SAGA using randomized reshuffling rule seems to not make sense.",
      "These variants may not work with without-replacement rules unless an appropriate variant (e.g., in [18,37]) is used.",
      "The authors may use [18] for SVRG, but for SAGA, which variant is used in the experiments?",
      "The weighted norm only depends on z0 and z*, and does not depend on the landscape of the problem.",
      "This is a very interesting aspect of the new method.",
      "Can you also add more discussion on this aspect to elaborate the new contribution?"
    ]
  },
  {
    "paper_id": "2104.12112v2",
    "submission_id": "x2lBl0GRav5",
    "submission_title": "An Improved Analysis and Rates for Variance Reduction under Without-replacement Sampling Orders ",
    "review_id": "yRI-LvhFLqw",
    "input": {
      "title": "An Improved Analysis and Rates for Variance Reduction under Without-replacement Sampling Orders ",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.\n- The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.\n- The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset. The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).\n- Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.\n- The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.\n- The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.\n- This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.\n- The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.\n- log(k) is an upper bound on the improvement of query complexity for any sampler.\n- The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.\n- The paper is very clear and well-organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.\n- The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.\n- Clarity. The paper is clearly written and well-organized.\n- Interesting proofs. The proofs of the theoretical results of the paper are non-standard and, therefore, valuable. In addition, the proofs are easy to follow and do not contain inaccuracies.\n- Weak guarantees in the convex case. In the convex case (i.e., all fi are convex), the authors establish complexity bounds ensuring that dist(\u2225\u2207F(xkn) - \u2202r(xkn)\u22252, 0) = ming\u2208\u2202r(xkn)\u2225\u2207f(xkn) + g\u22252 \u2264 \u03b5. In other papers and, in particular, in [18], bounds are obtained to ensure F(xkn) - F(x*) \u2264 \u03b5 (no regularization). When the objective is convex and smooth it is possible that the gradient is small but functional suboptimality is huge.\n- Complexity bounds depend on 1/n\u2016z0 - z*\u20162\u03c0 or 2. This norm has implicit dependence on the heterogeneity of local loss functions fi. Indeed, if z0 is close to x*, then for RR C \u223c \u03b1^2/n \u2211i=1n\u2016\u2207fi(x*)\u2016 where C is the factor appearing in all upper bounds.\n- Results are weaker than state-of-the-art ones. In view of the first weakness, the complexity bounds in the convex case are weaker by default since they do not provide guarantees for the functional suboptimality.\n- Incomplete comparison with the related work. The paper tries to create an impression that the obtained results are the current state-of-the-art.",
    "review_points_list": [
      "The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.",
      "The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.",
      "The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset. The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).",
      "Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.",
      "The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.",
      "The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.",
      "This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.",
      "The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.",
      "log(k) is an upper bound on the improvement of query complexity for any sampler.",
      "The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.",
      "The paper is very clear and well-organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.",
      "The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.",
      "Clarity. The paper is clearly written and well-organized.",
      "Interesting proofs. The proofs of the theoretical results of the paper are non-standard and, therefore, valuable. In addition, the proofs are easy to follow and do not contain inaccuracies.",
      "Weak guarantees in the convex case. In the convex case (i.e., all fi are convex), the authors establish complexity bounds ensuring that dist(\u2225\u2207F(xkn) - \u2202r(xkn)\u22252, 0) = ming\u2208\u2202r(xkn)\u2225\u2207f(xkn) + g\u22252 \u2264 \u03b5. In other papers and, in particular, in [18], bounds are obtained to ensure F(xkn) - F(x*) \u2264 \u03b5 (no regularization). When the objective is convex and smooth it is possible that the gradient is small but functional suboptimality is huge.",
      "Complexity bounds depend on 1/n\u2016z0 - z*\u20162\u03c0 or 2. This norm has implicit dependence on the heterogeneity of local loss functions fi. Indeed, if z0 is close to x*, then for RR C \u223c \u03b1^2/n \u2211i=1n\u2016\u2207fi(x*)\u2016 where C is the factor appearing in all upper bounds.",
      "Results are weaker than state-of-the-art ones. In view of the first weakness, the complexity bounds in the convex case are weaker by default since they do not provide guarantees for the functional suboptimality.",
      "Incomplete comparison with the related work. The paper tries to create an impression that the obtained results are the current state-of-the-art."
    ]
  },
  {
    "paper_id": "2104.12112v2",
    "submission_id": "x2lBl0GRav5",
    "submission_title": "An Improved Analysis and Rates for Variance Reduction under Without-replacement Sampling Orders ",
    "review_id": "zVPuYD4HAv",
    "input": {
      "title": "An Improved Analysis and Rates for Variance Reduction under Without-replacement Sampling Orders ",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Prox-DFinito, which is a shuffling based variance reduction algorithm.\n- The theoretical results show that the cyclic sampling, random reshuffling and shuffling-once versions of the algorithm achieve the same convergence rate as GD (up to logarithmic factors) on general convex and strongly convex functions.\n- The paper also proposes a new heuristic to get good sampling orders based on a new norm.\n- The theoretical results look good and the empirical evaluation support the theory.\n- The claim that the optimal cyclic sampling can achieve a sample complexity of $\tilde{O}(L^2/\boldsymbol{\textit{epsilon}})$, which is independent of $n$.\n- Without looking at all the $n$ functions at least once, good convergence cannot be achieved - consider the case where a fraction of the functions have minima very far away from others.\n- Even to determine the optimal cyclic order, at least $\boldsymbol{\textit{Omega}}(n)$ computation must be done.\n- The authors should clarify this.\n- The empirical evaluation for the optimal cycling sampling order seems to be done on an artificial dataset of quadratics that share the same minima.\n- This does not give sufficient indication to whether the proposed optimal cyclic sampling order would work in practice.\n- Can the authors provide evaluation on real datasets?",
    "review_points_list": [
      "Prox-DFinito, which is a shuffling based variance reduction algorithm.",
      "The theoretical results show that the cyclic sampling, random reshuffling and shuffling-once versions of the algorithm achieve the same convergence rate as GD (up to logarithmic factors) on general convex and strongly convex functions.",
      "The paper also proposes a new heuristic to get good sampling orders based on a new norm.",
      "The theoretical results look good and the empirical evaluation support the theory.",
      "The claim that the optimal cyclic sampling can achieve a sample complexity of $\tilde{O}(L^2/\boldsymbol{\textit{epsilon}})$, which is independent of $n$.",
      "Without looking at all the $n$ functions at least once, good convergence cannot be achieved - consider the case where a fraction of the functions have minima very far away from others.",
      "Even to determine the optimal cyclic order, at least $\boldsymbol{\textit{Omega}}(n)$ computation must be done.",
      "The authors should clarify this.",
      "The empirical evaluation for the optimal cycling sampling order seems to be done on an artificial dataset of quadratics that share the same minima.",
      "This does not give sufficient indication to whether the proposed optimal cyclic sampling order would work in practice.",
      "Can the authors provide evaluation on real datasets?"
    ]
  },
  {
    "paper_id": "2111.03874v1",
    "submission_id": "vqzAfN-BoA_",
    "submission_title": "Towards Calibrated Model for Long-Tailed Visual Recognition from Prior Perspective",
    "review_id": "Tl5_a944s1h",
    "input": {
      "title": "Towards Calibrated Model for Long-Tailed Visual Recognition from Prior Perspective",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper reveals an interesting problem in existing mixup-based long-tailed recognition (LT) methods, i.e., they will generate more head-head pairs since there exist more samples from the head classes.\n- The proposed methods are theoretically analyzed.\n- Extensive results show the effectiveness of the proposed method.\n- When this paper analyzes the bias issue of mixup, it assumes the instance number is exponential with \u03bb. I wonder whether the result is the same when the instance number is not exponential with \u03bb, since real-world datasets may not follow such a way.\n- For the proposed compensated cross-entropy loss, it is very similar to the balance softmax [1], which is also obtained from the Bayesian inference's perspective.\n- Moreover, similar ideas of logit adjustment and rebalanced mixup have been deeply explored in the work [2,3]. Although this is not the drawback of this paper, I do not think this loss can be regarded as an important contribution.\n- In the final algorithm, there are actually two phases, i.e., first mixup training for T1 steps, and then non-mixup training for T2-T1 steps.\n- I understand this is a trick to improve performance [4], but I wonder how effective the first phase is, since the main contribution of this paper is at phase 1, i.e., UniMix.\n- As proposed in this paper, mixup leads to bias distribution (since generating more head-head pairs) and has a negligible contribution to model calibration.\n- Regarding this, why do existing mixup-based methods also obtain very promising performance?  Does this mean that model calibration may not be an essential metric for the long-tailed recognition problem?\n- Following question 4, according to Tables 3 and D1, LDAM is harmful to model calibration.\n- However, LDAM is also effective and helps handle the imbalance issue.\n- Does this mean that a method with worse model calibration does not essentially mean a bad long-tailed method, and a method with better model calibration does also not mean a better long-tailed method?\n- These two concerns are important since this paper is based on model calibration.\n- Why not compare to MiSLAS [5]. This paper analyzes mixup for model calibration and thus is very related to the submission.\n- One interesting thing is that from the results reported in two papers, although MiSLAS only uses Mixup and ignores the head-head pair bias, it obtain even better accuracy and lower ECE than the method in this submission.\n- I understand there may exist some differences in methodology (1-stage method v.s. 2-stage method), but it would be better for authors to also discuss MiSLAS and compared with it.\n- In addition, one interesting thing is that MiSLAS finds that mixup is beneficial to representation learning and bad for classifier learning.\n- From this perspective, the head-head bias seems to mainly influence classifier learning.\n- Could you discuss this?\n- The most important contribution of this paper is that it theoretically and empirically reveals an interesting problem in existing mixup-based long-tailed recognition (LT) methods, i.e., they will generate more head-head pairs that may lead to more imbalanced learning.\n- To address the argued problem, this paper proposes a new method, consisting of (1) a Unimix strategy for generating more tail pairs and (2) a Bayias loss for rebalancing the optimization.\n- Nevertheless, the performance improvement of Unimix over mixup is limited, while most performance improvement is derived from the Bayias loss (c.f. Table 3 in the submission and the new results in the response).\n- Moreover, the novelty of the Bayias loss is limited, considering the logits adjustment loss [1] and balanced softmax loss [2]. For the balanced test set, these losses perform similarly.\n- Although the authors argue that the extension of Bayias loss with $\\\\$log(C)$ to $\\\\$log(\u03c0')$ can help to handle imbalanced test class distribution when the test class distribution $\u03c0'$ is known [3], I think that it is very difficult to obtain the test class distribution in real-world applications [4], so the practicability and contribution of the extension are limited.\n- Considering the above advantages and limitations, the paper seems really a borderline paper and is difficult to decide.\n- Therefore, I return to consider the value and contribution of this paper to the LT community.\n- In my view, although the performance and novelty of the proposed method are not that promising, this paper theoretically reveals an important head-head bias problem in the existing mixup-based LT method, which is insightful to the LT community and even inspires more augmentation-based LT methods.\n- Considering that performance-only judgment should not be encouraged in the current AI community and novelty can be varied, I believe the contribution of this paper is good enough and decide to increase my score to 7.\n- Even so, I encourage the authors to further improve the proposed method for better performance, keep exploring augmentation-based LT methods, and try to solve more practical test-agnostic LT task in the future.\n- Thanks again for your effort.",
    "review_points_list": [
      "This paper reveals an interesting problem in existing mixup-based long-tailed recognition (LT) methods, i.e., they will generate more head-head pairs since there exist more samples from the head classes.",
      "The proposed methods are theoretically analyzed.",
      "Extensive results show the effectiveness of the proposed method.",
      "When this paper analyzes the bias issue of mixup, it assumes the instance number is exponential with \u03bb. I wonder whether the result is the same when the instance number is not exponential with \u03bb, since real-world datasets may not follow such a way.",
      "For the proposed compensated cross-entropy loss, it is very similar to the balance softmax [1], which is also obtained from the Bayesian inference's perspective.",
      "Moreover, similar ideas of logit adjustment and rebalanced mixup have been deeply explored in the work [2,3]. Although this is not the drawback of this paper, I do not think this loss can be regarded as an important contribution.",
      "In the final algorithm, there are actually two phases, i.e., first mixup training for T1 steps, and then non-mixup training for T2-T1 steps.",
      "I understand this is a trick to improve performance [4], but I wonder how effective the first phase is, since the main contribution of this paper is at phase 1, i.e., UniMix.",
      "As proposed in this paper, mixup leads to bias distribution (since generating more head-head pairs) and has a negligible contribution to model calibration.",
      "Regarding this, why do existing mixup-based methods also obtain very promising performance?  Does this mean that model calibration may not be an essential metric for the long-tailed recognition problem?",
      "Following question 4, according to Tables 3 and D1, LDAM is harmful to model calibration.",
      "However, LDAM is also effective and helps handle the imbalance issue.",
      "Does this mean that a method with worse model calibration does not essentially mean a bad long-tailed method, and a method with better model calibration does also not mean a better long-tailed method?",
      "These two concerns are important since this paper is based on model calibration.",
      "Why not compare to MiSLAS [5]. This paper analyzes mixup for model calibration and thus is very related to the submission.",
      "One interesting thing is that from the results reported in two papers, although MiSLAS only uses Mixup and ignores the head-head pair bias, it obtain even better accuracy and lower ECE than the method in this submission.",
      "I understand there may exist some differences in methodology (1-stage method v.s. 2-stage method), but it would be better for authors to also discuss MiSLAS and compared with it.",
      "In addition, one interesting thing is that MiSLAS finds that mixup is beneficial to representation learning and bad for classifier learning.",
      "From this perspective, the head-head bias seems to mainly influence classifier learning.",
      "Could you discuss this?",
      "The most important contribution of this paper is that it theoretically and empirically reveals an interesting problem in existing mixup-based long-tailed recognition (LT) methods, i.e., they will generate more head-head pairs that may lead to more imbalanced learning.",
      "To address the argued problem, this paper proposes a new method, consisting of (1) a Unimix strategy for generating more tail pairs and (2) a Bayias loss for rebalancing the optimization.",
      "Nevertheless, the performance improvement of Unimix over mixup is limited, while most performance improvement is derived from the Bayias loss (c.f. Table 3 in the submission and the new results in the response).",
      "Moreover, the novelty of the Bayias loss is limited, considering the logits adjustment loss [1] and balanced softmax loss [2]. For the balanced test set, these losses perform similarly.",
      "Although the authors argue that the extension of Bayias loss with $\\\\$log(C)$ to $\\\\$log(\u03c0')$ can help to handle imbalanced test class distribution when the test class distribution $\u03c0'$ is known [3], I think that it is very difficult to obtain the test class distribution in real-world applications [4], so the practicability and contribution of the extension are limited.",
      "Considering the above advantages and limitations, the paper seems really a borderline paper and is difficult to decide.",
      "Therefore, I return to consider the value and contribution of this paper to the LT community.",
      "In my view, although the performance and novelty of the proposed method are not that promising, this paper theoretically reveals an important head-head bias problem in the existing mixup-based LT method, which is insightful to the LT community and even inspires more augmentation-based LT methods.",
      "Considering that performance-only judgment should not be encouraged in the current AI community and novelty can be varied, I believe the contribution of this paper is good enough and decide to increase my score to 7.",
      "Even so, I encourage the authors to further improve the proposed method for better performance, keep exploring augmentation-based LT methods, and try to solve more practical test-agnostic LT task in the future.",
      "Thanks again for your effort."
    ]
  },
  {
    "paper_id": "2111.03874v1",
    "submission_id": "vqzAfN-BoA_",
    "submission_title": "Towards Calibrated Model for Long-Tailed Visual Recognition from Prior Perspective",
    "review_id": "dJXHPJC8AZ",
    "input": {
      "title": "Towards Calibrated Model for Long-Tailed Visual Recognition from Prior Perspective",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This work is very similar to previous papers [1] and [2]. Concretely, the proposed Bayias loss (Eq.15) is the same as logit adjustment [1] (Eq. 11 in [1]) for long-tailed recognition.\n- [2] analyze long-tailed recognition from the calibration view. Algorithm 1 in this paper is also the same as [2], i.e., adding mixup in Stage-1 and using re-balanced loss in Stage-2.\n- The paper emphasizes calibration, but only provides visualization results to illustrate, rather than quantitative results (Expected Calibration Error, Brier Score, and Probabilistic sharpness) in the experiment part.\n- A lot of theoretical analysis seems meaningless.\n- Balanced Softmax [3] (experiment results please refer to [4]) can get **45.1%** top-1 accuracy on CIAFR-100-LT, $\rho=100$. While the proposed Bayias loss just gets **43.52%** (**both without mixup**).\n- Balanced Sofemax [3] (experiment results please refer to [4]) **without mixup** can get **69.8%** top-1 accuracy on iNaturalist 2018. While the proposed Bayias loss **with mixup** just gets **69.15%**.\n- The proposed method is **overall lower** than MiSLAS [2] in terms of Expected Calibration Error on all long-tailed benchmarks.\n- The proposed method is **overall lower** than MiSLAS [2] in terms of top-1 recognition accuracy on all long-tailed benchmarks.\n- It is a reasonable and related fair comparison because both two models add mixup operation.\n- 1) Based on Algorithm 1, I don't think the proposed method is E2E. Since it also contains two stages, which is similar to LDAM+DRW (Table 1: LDAM+DRW E2E [x])\n- 2) Both UniMix Factor and UniMix Sampler generate samples, which is mainly a $\theta$-Aug sample of the tail composite with $x_i$ from the head. I don't think more balanced $\theta$-Aug samples will lead to better model recognition performance.\n- 3) What is the definition of $f$ in Eq. (6)?\n- Ref: [1], [2], [3], [4]",
    "review_points_list": [
      "This work is very similar to previous papers [1] and [2]. Concretely, the proposed Bayias loss (Eq.15) is the same as logit adjustment [1] (Eq. 11 in [1]) for long-tailed recognition.",
      "[2] analyze long-tailed recognition from the calibration view. Algorithm 1 in this paper is also the same as [2], i.e., adding mixup in Stage-1 and using re-balanced loss in Stage-2.",
      "The paper emphasizes calibration, but only provides visualization results to illustrate, rather than quantitative results (Expected Calibration Error, Brier Score, and Probabilistic sharpness) in the experiment part.",
      "A lot of theoretical analysis seems meaningless.",
      "Balanced Softmax [3] (experiment results please refer to [4]) can get **45.1%** top-1 accuracy on CIAFR-100-LT, $\rho=100$. While the proposed Bayias loss just gets **43.52%** (**both without mixup**).",
      "Balanced Sofemax [3] (experiment results please refer to [4]) **without mixup** can get **69.8%** top-1 accuracy on iNaturalist 2018. While the proposed Bayias loss **with mixup** just gets **69.15%**.",
      "The proposed method is **overall lower** than MiSLAS [2] in terms of Expected Calibration Error on all long-tailed benchmarks.",
      "The proposed method is **overall lower** than MiSLAS [2] in terms of top-1 recognition accuracy on all long-tailed benchmarks.",
      "It is a reasonable and related fair comparison because both two models add mixup operation.",
      "1) Based on Algorithm 1, I don't think the proposed method is E2E. Since it also contains two stages, which is similar to LDAM+DRW (Table 1: LDAM+DRW E2E [x])",
      "2) Both UniMix Factor and UniMix Sampler generate samples, which is mainly a $\theta$-Aug sample of the tail composite with $x_i$ from the head. I don't think more balanced $\theta$-Aug samples will lead to better model recognition performance.",
      "3) What is the definition of $f$ in Eq. (6)?",
      "Ref: [1], [2], [3], [4]"
    ]
  },
  {
    "paper_id": "2111.03874v1",
    "submission_id": "vqzAfN-BoA_",
    "submission_title": "Towards Calibrated Model for Long-Tailed Visual Recognition from Prior Perspective",
    "review_id": "LPMY_GOyLrS",
    "input": {
      "title": "Towards Calibrated Model for Long-Tailed Visual Recognition from Prior Perspective",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The method seems to follow a different rebalancing approach compared to other work (e.g. Remix [1]).\n- The empirical results show a substantial improvement in terms of accuracy over other baselines.\n- Comparison in terms of ECE scores confirm that the method improves calibration.\n- The paper lacks in terms of clarity and it is often difficult to understand what the authors mean. The paper needs to be substantially improved from this point of view.\n- One of the main claims of the authors is that the proposed method improves the model calibration w.r.t. Mixup on unbalanced datasets. The plots reported by the authors seem to suggest that this is true, but those plots show the accuracy VS confidence tradeoff, that can be misleading.\n- The authors report quantitative measurements in terms of ECE and MCE. It has been showed that ECE scores suffer of several shortcomings [3]. I think that it would be useful to provide a quantitative comparison also in terms of other metrics like ACE and TACE scores [2], which are more robust than ECE.\n- It is unclear why best performances and calibration are obtained by joining UniMix+Bayias. The authors provided an ablation study in Table 3 but there is not a proper discussion to explain these results.\n- The authors claim (lines 42-48) that one of the main contributions is the introduction of the $\\xi\\text{-Aug}$ notation for Mixup (Section 2). I am struggling to understand where is the novelty, since it seems to me that this is a fairly common notation used to describe Mixup. Could the authors expand on this point?\n- All the experimental results do not report the standard deviation over accuracy. Are the reported results just on a single seed? Please provide additional details regarding this point.\n- There is not a proper discussion of the shortcomings of this method. It seems to me that joining UniMix+Bayias has a higher computational overhead compared to other approaches (e.g. Remix [1]). I would like to see a discussion about this point.",
    "review_points_list": [
      "The method seems to follow a different rebalancing approach compared to other work (e.g. Remix [1]).",
      "The empirical results show a substantial improvement in terms of accuracy over other baselines.",
      "Comparison in terms of ECE scores confirm that the method improves calibration.",
      "The paper lacks in terms of clarity and it is often difficult to understand what the authors mean. The paper needs to be substantially improved from this point of view.",
      "One of the main claims of the authors is that the proposed method improves the model calibration w.r.t. Mixup on unbalanced datasets. The plots reported by the authors seem to suggest that this is true, but those plots show the accuracy VS confidence tradeoff, that can be misleading.",
      "The authors report quantitative measurements in terms of ECE and MCE. It has been showed that ECE scores suffer of several shortcomings [3]. I think that it would be useful to provide a quantitative comparison also in terms of other metrics like ACE and TACE scores [2], which are more robust than ECE.",
      "It is unclear why best performances and calibration are obtained by joining UniMix+Bayias. The authors provided an ablation study in Table 3 but there is not a proper discussion to explain these results.",
      "The authors claim (lines 42-48) that one of the main contributions is the introduction of the $\\xi\\text{-Aug}$ notation for Mixup (Section 2). I am struggling to understand where is the novelty, since it seems to me that this is a fairly common notation used to describe Mixup. Could the authors expand on this point?",
      "All the experimental results do not report the standard deviation over accuracy. Are the reported results just on a single seed? Please provide additional details regarding this point.",
      "There is not a proper discussion of the shortcomings of this method. It seems to me that joining UniMix+Bayias has a higher computational overhead compared to other approaches (e.g. Remix [1]). I would like to see a discussion about this point."
    ]
  },
  {
    "paper_id": "2111.03874v1",
    "submission_id": "vqzAfN-BoA_",
    "submission_title": "Towards Calibrated Model for Long-Tailed Visual Recognition from Prior Perspective",
    "review_id": "89zxq3rbKA",
    "input": {
      "title": "Towards Calibrated Model for Long-Tailed Visual Recognition from Prior Perspective",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well written and all the figures are well illustrated.\n- The theoretical analysis is interesting and provide strong support to the proposed method.\n- The experiment is thorough and cover different aspects of the ablation studies.\n- The performance is promising\n- Although the author somehow shows the performance on head/medium/tail classes using the confusion matrix, it will be nice to provide the number and table in the final version.",
    "review_points_list": [
      "The paper is well written and all the figures are well illustrated.",
      "The theoretical analysis is interesting and provide strong support to the proposed method.",
      "The experiment is thorough and cover different aspects of the ablation studies.",
      "The performance is promising",
      "Although the author somehow shows the performance on head/medium/tail classes using the confusion matrix, it will be nice to provide the number and table in the final version."
    ]
  },
  {
    "paper_id": "2005.01209v2",
    "submission_id": "y8y6GJUL01H",
    "submission_title": "No-regret Online Learning over Riemannian Manifolds",
    "review_id": "w4srLQuwxro",
    "input": {
      "title": "No-regret Online Learning over Riemannian Manifolds",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The lower bound proceeds analogously to the Euclidean case.\n- The contribution of this lower bound is on noting the Busemann functions can be used with the lower bound technique coming from the Euclidean case.\n- The proofs in the full information setting are a simple consequence of the existing theory and the geometric lemma of Zhang and Sra.\n- The regret in this setting is increased (with respect to the Euclidean case) by a factor of a natural geometric constant depending on the diameter of the optimization set and a lower bound on the sectional curvature of the manifold.\n- The analysis is an immediate consequence of the Euclidean analysis and a previously given geometric lemma in Zhang and Sra 2016.\n- The main contribution of this work is, in my view, the algorithm for the bandit case, which requires more geometric machinery to be obtained.\n- The final pseudoregret upper bound worsens with respect to the Euclidean case by a factor that contains some 'constants' that among other things, depend on the dimension.\n- This is a nice result, but I think that regardless of the final value, a bound on those 'constants' should be provided.\n- Some important 'constants' are not worked out: epsilon(n) and rho\n- Their magnitude should be provided in the form of a bound.\n- The 'constants' depend on the dimension, bound on the sectional curvature and diameter, and the paper without providing a magnitude of these constants is incomplete.\n- In Table 1: the lower bounds should use Omega\n- Pseudocode of Algorithm 1 is not using the learning rates provided as input.\n- In the equalities before (27), after 'Applying Lemma 9 again, we obtain', after the first equality I believe one should be adding the 1/V_delta times the integral of the divergence (as opposed to substracting).\n- I believe the same conclusion reached in (27) can be reached though.\n- In the last page of the appendix, I believe there is a kappa missing in the second summand of the rhs of the first inequality (and then the error carries forward) after 'Moreover, we get'\n- Also, the last equality of that set of lines seems to have the wrong constants.\n- In particular, the r disappears despite of it being part of delta.\n- And the 2 that is in front of T^{3/4} seems to belong to the sqrt{Delta} inside the parentheses.\n- The learning rate in the hyperbolic case seems to have been taken constant.\n- Which I guess it is fine since the aim is to showcase the applicability of the method, but it should be reported in the main paper.\n- About the learning rate in the SPD, I might be wrong, but I think L should be equal to D in this case and therefore it should be eta_t = sqrt{tanh(Dkappa)/(Dkappa t)}, which is not the same thing that appears in the code\n- In the comparison with related work it is said that '[12], [37], [38], [36] assume prior knowledge of loss functions which is different from the framework of our R-OCO'.\n- While this is true, and as pointed out above, the analysis of some theorems in 37 is almost identical to the analysis of the full information case in this paper, while you seem to be implying they are very different things.\n- This is essentially because the analysis provided is a mirror descent like analysis (but working with the ell_2 norm only)\n- Other works have made other uses of mirror descent analyses in Riemannian manifolds, and though they apply to the offline setting, there are connections between those and the online learning setting.\n- For instance the paper 'Global Riemannian Acceleration in Hyperbolic and Spherical Spaces' defines a mirror descent type of method and combines it with a gradient descent method to obtain acceleration.\n- l277 while it is true that f_t is 2-strongly convex, a citation to such a result should be provided, since it is not obvious a priori this is the case for someone that does not work in the field.\n- The Assumption environment contains a typo so all assumptions say 'Assmuption'\n- l41 'can be much expensive' rephrase\n- l88 'However, These studies' typo in capitalization\n- l122 'A function...' -> 'A differentiable function'\n- l143 'with the diameter D' ->  'with diameter D'\n- l163 'Theorems 1 and 2 also reveals' -> 'Theorems 1 and 2 also reveal'\n- l179 'In the following of this section' -> In the rest of this section\n- Algorithm 2. The for has two 'do's\n- l203 In equation (2) it should be tilde{g}_t instead of tilde{g_t} \n- l206 'expected gradient descent method' Do you mean stochastic gradient descent method? If not, please clarify or provide a citation that defines expected gradient method\n- l220 space missing after '(2). Note that in l213 there is a space after '(1)'\n- l224 'qudratic' typo\n- l235 'The first part of the lemma proceeds the result in [18]' rephrase\n- l237 'that transform' ->  'that transforms'\n- l256 '5-7 holds' -> '5-7 hold'\n- l443 'lisence' -> 'license'\n- The lines in the appendix should be numbered.\n- In the equation below (5) there is f(x^star) that should be f_t(x^star). Same for the equation after (6)\n- by the strong convexity' -> 'by the strong convexity' \n- in the second line of the inequality preceding (11), there is an L that should be a 1\n- Lemma 10 'Let M be a n-dimensional' ->  'Let M be an n-dimensional'\n- is consist of' -> 'consists of'\n- In (19) the first V_r should have (x) not (kappa)\n- proof of lemma 2 'without the loss of generality' ->  'without loss of generality'\n- after (25). It says it is by Lemma 6 but it is by Lemma 1\n- and become a Jacobi field' -> 'and becomes a Jacobi field'\n- After 'Let us look back on the function', there is gamma_{0}(s). This notation is not consistent with the notation used before, that had the s in the subscript.\n- In the equation below that one you have gamma_1(s) = exp_{xi(s)}(V(s)) but it should be gamma_1(s) = exp_{xi(s)}(V(xi(s)))\n- lemma 11 'with the diameter D' -> 'with diameter D' ; Also 'are a series of smooth functions and there exists' ->  'be a series of smooth functions and assume there exists'\n- page 25 'To estimate the term E' E is not using mathbb. Same at the end of the page",
    "review_points_list": [
      "The lower bound proceeds analogously to the Euclidean case.",
      "The contribution of this lower bound is on noting the Busemann functions can be used with the lower bound technique coming from the Euclidean case.",
      "The proofs in the full information setting are a simple consequence of the existing theory and the geometric lemma of Zhang and Sra.",
      "The regret in this setting is increased (with respect to the Euclidean case) by a factor of a natural geometric constant depending on the diameter of the optimization set and a lower bound on the sectional curvature of the manifold.",
      "The analysis is an immediate consequence of the Euclidean analysis and a previously given geometric lemma in Zhang and Sra 2016.",
      "The main contribution of this work is, in my view, the algorithm for the bandit case, which requires more geometric machinery to be obtained.",
      "The final pseudoregret upper bound worsens with respect to the Euclidean case by a factor that contains some 'constants' that among other things, depend on the dimension.",
      "This is a nice result, but I think that regardless of the final value, a bound on those 'constants' should be provided.",
      "Some important 'constants' are not worked out: epsilon(n) and rho",
      "Their magnitude should be provided in the form of a bound.",
      "The 'constants' depend on the dimension, bound on the sectional curvature and diameter, and the paper without providing a magnitude of these constants is incomplete.",
      "In Table 1: the lower bounds should use Omega",
      "Pseudocode of Algorithm 1 is not using the learning rates provided as input.",
      "In the equalities before (27), after 'Applying Lemma 9 again, we obtain', after the first equality I believe one should be adding the 1/V_delta times the integral of the divergence (as opposed to substracting).",
      "I believe the same conclusion reached in (27) can be reached though.",
      "In the last page of the appendix, I believe there is a kappa missing in the second summand of the rhs of the first inequality (and then the error carries forward) after 'Moreover, we get'",
      "Also, the last equality of that set of lines seems to have the wrong constants.",
      "In particular, the r disappears despite of it being part of delta.",
      "And the 2 that is in front of T^{3/4} seems to belong to the sqrt{Delta} inside the parentheses.",
      "The learning rate in the hyperbolic case seems to have been taken constant.",
      "Which I guess it is fine since the aim is to showcase the applicability of the method, but it should be reported in the main paper.",
      "About the learning rate in the SPD, I might be wrong, but I think L should be equal to D in this case and therefore it should be eta_t = sqrt{tanh(Dkappa)/(Dkappa t)}, which is not the same thing that appears in the code",
      "In the comparison with related work it is said that '[12], [37], [38], [36] assume prior knowledge of loss functions which is different from the framework of our R-OCO'.",
      "While this is true, and as pointed out above, the analysis of some theorems in 37 is almost identical to the analysis of the full information case in this paper, while you seem to be implying they are very different things.",
      "This is essentially because the analysis provided is a mirror descent like analysis (but working with the ell_2 norm only)",
      "Other works have made other uses of mirror descent analyses in Riemannian manifolds, and though they apply to the offline setting, there are connections between those and the online learning setting.",
      "For instance the paper 'Global Riemannian Acceleration in Hyperbolic and Spherical Spaces' defines a mirror descent type of method and combines it with a gradient descent method to obtain acceleration.",
      "l277 while it is true that f_t is 2-strongly convex, a citation to such a result should be provided, since it is not obvious a priori this is the case for someone that does not work in the field.",
      "The Assumption environment contains a typo so all assumptions say 'Assmuption'",
      "l41 'can be much expensive' rephrase",
      "l88 'However, These studies' typo in capitalization",
      "l122 'A function...' -> 'A differentiable function'",
      "l143 'with the diameter D' ->  'with diameter D'",
      "l163 'Theorems 1 and 2 also reveals' -> 'Theorems 1 and 2 also reveal'",
      "l179 'In the following of this section' -> In the rest of this section",
      "Algorithm 2. The for has two 'do's",
      "l203 In equation (2) it should be tilde{g}_t instead of tilde{g_t} ",
      "l206 'expected gradient descent method' Do you mean stochastic gradient descent method? If not, please clarify or provide a citation that defines expected gradient method",
      "l220 space missing after '(2). Note that in l213 there is a space after '(1)'",
      "l224 'qudratic' typo",
      "l235 'The first part of the lemma proceeds the result in [18]' rephrase",
      "l237 'that transform' ->  'that transforms'",
      "l256 '5-7 holds' -> '5-7 hold'",
      "l443 'lisence' -> 'license'",
      "The lines in the appendix should be numbered.",
      "In the equation below (5) there is f(x^star) that should be f_t(x^star). Same for the equation after (6)",
      "by the strong convexity' -> 'by the strong convexity' ",
      "in the second line of the inequality preceding (11), there is an L that should be a 1",
      "Lemma 10 'Let M be a n-dimensional' ->  'Let M be an n-dimensional'",
      "is consist of' -> 'consists of'",
      "In (19) the first V_r should have (x) not (kappa)",
      "proof of lemma 2 'without the loss of generality' ->  'without loss of generality'",
      "after (25). It says it is by Lemma 6 but it is by Lemma 1",
      "and become a Jacobi field' -> 'and becomes a Jacobi field'",
      "After 'Let us look back on the function', there is gamma_{0}(s). This notation is not consistent with the notation used before, that had the s in the subscript.",
      "In the equation below that one you have gamma_1(s) = exp_{xi(s)}(V(s)) but it should be gamma_1(s) = exp_{xi(s)}(V(xi(s)))",
      "lemma 11 'with the diameter D' -> 'with diameter D' ; Also 'are a series of smooth functions and there exists' ->  'be a series of smooth functions and assume there exists'",
      "page 25 'To estimate the term E' E is not using mathbb. Same at the end of the page"
    ]
  },
  {
    "paper_id": "2005.01209v2",
    "submission_id": "y8y6GJUL01H",
    "submission_title": "No-regret Online Learning over Riemannian Manifolds",
    "review_id": "FmqWzJxi6_R",
    "input": {
      "title": "No-regret Online Learning over Riemannian Manifolds",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I find the main idea of the paper to be a reasonable continuation of previous trends in Riemannian Optimization, thus I am not surprised by its originality.\n- Riemannian methods have gained interest during the last years due to applications in important problems relevant to neurips community (e.g. operator scaling).\n- Technically, the work adapts directly theoretical analysis from the Euclidean case taken from previous work, surpassing obstacles occurring by the geometry of manifolds.\n- In the convex case, the well-known law of cosines developed in [37] (which has been used in numerous papers in the area) turns to be enough for a simple adaptation, but in the strongly convex case the authors develop a way to compute the gradient of the integral of a volume form exploiting the assumption that the manifold is homogeneous and the existence of Killing vector fields implied by it.\n- They also prove a sub-convexity property for the same 'smoothed loss function' and the deviation from convexity turns out not to affect the final regret bound critically.\n- This is because the extra 'Riemannian' term appears in the bound as \u03bbT and there is anyway a term 2\u03b1cT even in the Euclidean case.\n- I think that the proof of commutativity of gradient and integral can still be done in the manifold case and without homogeneity.\n- The integral of a differential form can be written by definition as the sum of pullbacks of the function through different charts of a coordinate system choosing some partition of unity.\n- Here the manifold is of negative curvature, thus the ball B\u03b4(x) can be covered only by one system of coordinates (geodesically normal coordinates based at point x).\n- Thus the covariant derivative at x is going to become covariant derivative at 0 in the geodesically normal coordinate system (should be easy to check using the definition of derivative with limits) and now you have the derivative of an integral over the lift of B\u03b4(x) in the tangent space TxM.\n- You can now put the derivative inside the integral, do the chain rule, and use that the differential of geodesically normal coordinates at the origin is the identity and arrive to the result.\n- Do I miss something?\n- Regarding the sub-convexity result (lemma 2), I again doubt that homogeneity is essential but didn't have time to check in detail.\n- I worry a bit about the constant \u03c1 which is defined as the supremum of the divergence of a vector field over the working geodesically convex domain.\n- At least this constant is 0 in the Euclidean case because the isometry \u03d5 can be chosen to be the identity thus V=0 and the Euclidean case is recovered, still it is pretty unclear how such a constant depends on the curvature and a bound for the domain K.\n- Could for instance \u03c1 depending exponentially bad on the domain?\n- This is important in my opinion and an answer could be provided by a formula of divergence based on the determinant of the metric and partial derivatives of it, that the authors could find easily on the internet.\n- Regarding related work, I am not familiar enough with the literature in online learning to have a strong opinion, the paper though explains clearly the difference with [28], which seems to be in the same topic.\n- The paper is technically adequate for the area of Riemannian Optimization.\n- As noted above, I think that it introduces unnecessary technicalities and assumptions.\n- I would like to see some intuitive explanation for the necessity of homogeneous assumption and the resulting existence of Killing vector fields, homogeneous manifolds though are already a rich class of practical cases for machine learning tasks.\n- The paper is sufficiently complete, two things that I think are important:\n- i) I don't see the reason that manifolds of positive curvature are not treated, usually optimization behaviors even better on positive curvature.\n- Such an algorithm on the sphere (which is homogeneous) could serve as excellent basis for online PCA which is an important problem.\n- ii) I find the experimental section quite poor because it considers only the (in most cases) strongly convex problem of Karcher mean estimation.\n- Another problem to implement on SPD manifold which is just geodesically convex is operator scaling.\n- The paper is in general clearly written, there are parts that are difficult to be followed by readers without strong background in geometry, but this is the case with lots of papers in the area.\n- Below are some minor comments about readability and typos:\n- Algorithm 1: the step-size \u03b7t is missing\n- Lemma 10: I find the notation Vr(p) misleading, since the volume of the ball of radius r centered at p does not depend on p because of homogeneity.\n- 224: 'quadratic'\n- I don't understand the reason that the step-size is denoted \u03b7t in full-information and \u03bd in bandit (since the last is also time-dependent).\n- I see that the authors adopted the notation from the relevant Euclidean papers, but since both cases are presented in the same paper now, one notation needs to be used.\n- The results are added to the big literature of Riemannian algorithms, with significance for neurips community due to its practical applications.\n- The authors comment that do not treat the even more practical case of retraction-based gradient descent which would be useful, but still the exponential map is computable in SPD and hyperbolic space.\n- Overall, I believe that the paper contains non groundbreaking but good to know results towards the correct direction.\n- I believe that the paper is a good contribution, but has issues that could make a second reviewing round beneficial.\n- Thus in my opinion it is slightly above acceptance.",
    "review_points_list": [
      "I find the main idea of the paper to be a reasonable continuation of previous trends in Riemannian Optimization, thus I am not surprised by its originality.",
      "Riemannian methods have gained interest during the last years due to applications in important problems relevant to neurips community (e.g. operator scaling).",
      "Technically, the work adapts directly theoretical analysis from the Euclidean case taken from previous work, surpassing obstacles occurring by the geometry of manifolds.",
      "In the convex case, the well-known law of cosines developed in [37] (which has been used in numerous papers in the area) turns to be enough for a simple adaptation, but in the strongly convex case the authors develop a way to compute the gradient of the integral of a volume form exploiting the assumption that the manifold is homogeneous and the existence of Killing vector fields implied by it.",
      "They also prove a sub-convexity property for the same 'smoothed loss function' and the deviation from convexity turns out not to affect the final regret bound critically.",
      "This is because the extra 'Riemannian' term appears in the bound as \u03bbT and there is anyway a term 2\u03b1cT even in the Euclidean case.",
      "I think that the proof of commutativity of gradient and integral can still be done in the manifold case and without homogeneity.",
      "The integral of a differential form can be written by definition as the sum of pullbacks of the function through different charts of a coordinate system choosing some partition of unity.",
      "Here the manifold is of negative curvature, thus the ball B\u03b4(x) can be covered only by one system of coordinates (geodesically normal coordinates based at point x).",
      "Thus the covariant derivative at x is going to become covariant derivative at 0 in the geodesically normal coordinate system (should be easy to check using the definition of derivative with limits) and now you have the derivative of an integral over the lift of B\u03b4(x) in the tangent space TxM.",
      "You can now put the derivative inside the integral, do the chain rule, and use that the differential of geodesically normal coordinates at the origin is the identity and arrive to the result.",
      "Do I miss something?",
      "Regarding the sub-convexity result (lemma 2), I again doubt that homogeneity is essential but didn't have time to check in detail.",
      "I worry a bit about the constant \u03c1 which is defined as the supremum of the divergence of a vector field over the working geodesically convex domain.",
      "At least this constant is 0 in the Euclidean case because the isometry \u03d5 can be chosen to be the identity thus V=0 and the Euclidean case is recovered, still it is pretty unclear how such a constant depends on the curvature and a bound for the domain K.",
      "Could for instance \u03c1 depending exponentially bad on the domain?",
      "This is important in my opinion and an answer could be provided by a formula of divergence based on the determinant of the metric and partial derivatives of it, that the authors could find easily on the internet.",
      "Regarding related work, I am not familiar enough with the literature in online learning to have a strong opinion, the paper though explains clearly the difference with [28], which seems to be in the same topic.",
      "The paper is technically adequate for the area of Riemannian Optimization.",
      "As noted above, I think that it introduces unnecessary technicalities and assumptions.",
      "I would like to see some intuitive explanation for the necessity of homogeneous assumption and the resulting existence of Killing vector fields, homogeneous manifolds though are already a rich class of practical cases for machine learning tasks.",
      "The paper is sufficiently complete, two things that I think are important:",
      "i) I don't see the reason that manifolds of positive curvature are not treated, usually optimization behaviors even better on positive curvature.",
      "Such an algorithm on the sphere (which is homogeneous) could serve as excellent basis for online PCA which is an important problem.",
      "ii) I find the experimental section quite poor because it considers only the (in most cases) strongly convex problem of Karcher mean estimation.",
      "Another problem to implement on SPD manifold which is just geodesically convex is operator scaling.",
      "The paper is in general clearly written, there are parts that are difficult to be followed by readers without strong background in geometry, but this is the case with lots of papers in the area.",
      "Below are some minor comments about readability and typos:",
      "Algorithm 1: the step-size \u03b7t is missing",
      "Lemma 10: I find the notation Vr(p) misleading, since the volume of the ball of radius r centered at p does not depend on p because of homogeneity.",
      "224: 'quadratic'",
      "I don't understand the reason that the step-size is denoted \u03b7t in full-information and \u03bd in bandit (since the last is also time-dependent).",
      "I see that the authors adopted the notation from the relevant Euclidean papers, but since both cases are presented in the same paper now, one notation needs to be used.",
      "The results are added to the big literature of Riemannian algorithms, with significance for neurips community due to its practical applications.",
      "The authors comment that do not treat the even more practical case of retraction-based gradient descent which would be useful, but still the exponential map is computable in SPD and hyperbolic space.",
      "Overall, I believe that the paper contains non groundbreaking but good to know results towards the correct direction.",
      "I believe that the paper is a good contribution, but has issues that could make a second reviewing round beneficial.",
      "Thus in my opinion it is slightly above acceptance."
    ]
  },
  {
    "paper_id": "2005.01209v2",
    "submission_id": "y8y6GJUL01H",
    "submission_title": "No-regret Online Learning over Riemannian Manifolds",
    "review_id": "HfibYNBY30D",
    "input": {
      "title": "No-regret Online Learning over Riemannian Manifolds",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is easy to read and follow.\n- The subtleties when working on Riemannian manifolds are addressed well.\n- The applications of online learning on Riemannian manifolds are questionable.\n- I would strongly recommend using Fr\u00e9chet mean instead Karcher mean in the paper. The two refer to the same thing, but Karcher himself has noted that terminology of 'Karcher mean' arose in the 90's and misassigns contribution.\n- I would also recommend incorporating some more recent work on the application of Fr\u00e9chet means.\n- In particular, the Riemannian batch normalization algorithms of could be of potential interest, as one must maintain a moving average of previous data points as one updates the network.\n- The proposed method is technically sound and the paper is well structured.\n- Outside of my comments, I believe this to be a strong paper.\n- As such, I tend to accept.",
    "review_points_list": [
      "The paper is easy to read and follow.",
      "The subtleties when working on Riemannian manifolds are addressed well.",
      "The applications of online learning on Riemannian manifolds are questionable.",
      "I would strongly recommend using Fr\u00e9chet mean instead Karcher mean in the paper. The two refer to the same thing, but Karcher himself has noted that terminology of 'Karcher mean' arose in the 90's and misassigns contribution.",
      "I would also recommend incorporating some more recent work on the application of Fr\u00e9chet means.",
      "In particular, the Riemannian batch normalization algorithms of could be of potential interest, as one must maintain a moving average of previous data points as one updates the network.",
      "The proposed method is technically sound and the paper is well structured.",
      "Outside of my comments, I believe this to be a strong paper.",
      "As such, I tend to accept."
    ]
  },
  {
    "paper_id": "2112.07436v2",
    "submission_id": "xQGYquca0gB",
    "submission_title": "Neural Production Systems",
    "review_id": "RvBpJYH7MSj",
    "input": {
      "title": "Neural Production Systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This product is well-designed with a user-friendly interface.\n- The customer service was excellent and very responsive.\n- I found the pricing to be very reasonable for the features offered.\n- However, the shipping was delayed which was disappointing.\n- The mobile app needs improvement in terms of usability.",
    "review_points_list": [
      "This product is well-designed with a user-friendly interface.",
      "The customer service was excellent and very responsive.",
      "I found the pricing to be very reasonable for the features offered.",
      "However, the shipping was delayed which was disappointing.",
      "The mobile app needs improvement in terms of usability."
    ]
  },
  {
    "paper_id": "2112.07436v2",
    "submission_id": "xQGYquca0gB",
    "submission_title": "Neural Production Systems",
    "review_id": "5qeJ6tVk4Oo",
    "input": {
      "title": "Neural Production Systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think the idea is very exciting and has a lot of promise.\n- The algorithms creatively combine a range of deep learning techniques.\n- Unfortunately, I think in its current state this work suffers from two limitations.\n- The current set of experiments only demonstrate marginal improvements over the baselines in some cases.\n- There is typically only one baseline evaluated for each experiment, and it is not clearly specified why this baseline was chosen or whether it represents the current state-of-the-art.\n- It is not entirely transparent how the algorithm is applied to the different experiments.\n- The algorithm is applied inconsistently to the different experiments.\n- The model is only intended as a preliminary test.\n- Important aspects of the implementation have to be manually tailored to a particular task.\n- The parallel version of the algorithm works better on tasks involving multiple closely interacting objects.\n- The sequential version of the algorithm works better on tasks involving more spatially distributed objects.\n- The current formulation seems to be overly tailored to physical reasoning tasks.\n- The current formulation lacks the more general expressive power of the original production systems.\n- Many of the design decisions regarding how rules are selected and applied seem as though they have been made specifically with physical reasoning in mind.\n- I think it might be more conservatively described as a method for efficiently modeling sparse interactions for the purposes of physical reasoning.\n- Some of the notation is inconsistent or unclear.\n- Inconsistent or unclear notation can lead to confusion.\n- In the Appendix, it says that Table 3 in the paper is wrong and that Table 9 reflects the correct results.\n- It would be helpful to include pointers to the specific relevant sections in the Appendix.\n- The authors have made improvements to the algorithm, clarified the criteria for selecting baselines, and performed more extensive experiments.\n- The improved algorithm clearly outperforms other approaches on a range of tasks.\n- This is a significant improvement over the original results.\n- I believe the paper merits acceptance and am updating my score to a 7.",
    "review_points_list": [
      "I think the idea is very exciting and has a lot of promise.",
      "The algorithms creatively combine a range of deep learning techniques.",
      "Unfortunately, I think in its current state this work suffers from two limitations.",
      "The current set of experiments only demonstrate marginal improvements over the baselines in some cases.",
      "There is typically only one baseline evaluated for each experiment, and it is not clearly specified why this baseline was chosen or whether it represents the current state-of-the-art.",
      "It is not entirely transparent how the algorithm is applied to the different experiments.",
      "The algorithm is applied inconsistently to the different experiments.",
      "The model is only intended as a preliminary test.",
      "Important aspects of the implementation have to be manually tailored to a particular task.",
      "The parallel version of the algorithm works better on tasks involving multiple closely interacting objects.",
      "The sequential version of the algorithm works better on tasks involving more spatially distributed objects.",
      "The current formulation seems to be overly tailored to physical reasoning tasks.",
      "The current formulation lacks the more general expressive power of the original production systems.",
      "Many of the design decisions regarding how rules are selected and applied seem as though they have been made specifically with physical reasoning in mind.",
      "I think it might be more conservatively described as a method for efficiently modeling sparse interactions for the purposes of physical reasoning.",
      "Some of the notation is inconsistent or unclear.",
      "Inconsistent or unclear notation can lead to confusion.",
      "In the Appendix, it says that Table 3 in the paper is wrong and that Table 9 reflects the correct results.",
      "It would be helpful to include pointers to the specific relevant sections in the Appendix.",
      "The authors have made improvements to the algorithm, clarified the criteria for selecting baselines, and performed more extensive experiments.",
      "The improved algorithm clearly outperforms other approaches on a range of tasks.",
      "This is a significant improvement over the original results.",
      "I believe the paper merits acceptance and am updating my score to a 7."
    ]
  },
  {
    "paper_id": "2112.07436v2",
    "submission_id": "xQGYquca0gB",
    "submission_title": "Neural Production Systems",
    "review_id": "obDjfhJukQ",
    "input": {
      "title": "Neural Production Systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I found this paper very interesting. Although inspired by an old concept (i.e., production systems), its deep learning adaptation is far from trivial.\n- The reported experiments are convincing. In particular, the authors show that NPS can learn arithmetic rules, map rules to MNIST transformation, work in richer visual settings and perform future-state predictions (such as predicting the number of future steps in action-conditioned world models) better than GNNs.\n- Rules are differentiable, and could be learned in the context of a broader framework.\n- How does the model scale with respect to the number of entities/rules considered?\n- Figure 1 is not colour-blind friendly.\n- It might be useful to report results for individual games in Table 5, with the number of entities/rules considered.",
    "review_points_list": [
      "I found this paper very interesting. Although inspired by an old concept (i.e., production systems), its deep learning adaptation is far from trivial.",
      "The reported experiments are convincing. In particular, the authors show that NPS can learn arithmetic rules, map rules to MNIST transformation, work in richer visual settings and perform future-state predictions (such as predicting the number of future steps in action-conditioned world models) better than GNNs.",
      "Rules are differentiable, and could be learned in the context of a broader framework.",
      "How does the model scale with respect to the number of entities/rules considered?",
      "Figure 1 is not colour-blind friendly.",
      "It might be useful to report results for individual games in Table 5, with the number of entities/rules considered."
    ]
  },
  {
    "paper_id": "2112.07436v2",
    "submission_id": "xQGYquca0gB",
    "submission_title": "Neural Production Systems",
    "review_id": "ubmurL82qW",
    "input": {
      "title": "Neural Production Systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- NPS is a novel system for visual reasoning.\n- The computational components borrow heavily from attention mechanisms but separately represent rules to apply.\n- The authors test a large number of total tasks, targeting different aspects of NPS.\n- Using the first set of experimental results, they are able to provide the recommendation that sequential application is better for sparse interactions.\n- I would have appreciated a more straightforward introduction that was heavier on visuals.\n- The paragraph beginning at section 64 discusses going from raw observations to slots, which is not what NPS does.\n- It takes up a lot of real estate in the introduction and gave me the impression that the paper focused on going from raw data to slots.\n- The algorithm should specify that j indexes M (num slots).\n- The steps in algorithm 1 should be consistent with the main text.\n- It omits the primary slot selection.\n- L208: an -> a?\n- The figure cuts off the text.\n- 'Entity abstraction in visual model-based reinforcement learning.' is cited twice?\n- How would you contrast NPS to a transformer trained on the same tasks, but with a rule 'memory store'?\n- I found Figure 1, which provides a visualization of rules before they're introduced, which I found confusing.\n- It would help with clarity to add more visualizations of the NPS system into the main text (or to at least pull the algorithm into the main text).\n- The potential impact for differentiable reasoning is enormous.\n- The aim of this paper is to take a step towards goal by showing a reasoning system on a variety of restricted settings that are straightforward to analyze.\n- On many tasks, NPS is compared to only one baseline and provides a small performance improvement.\n- E.g., on shapes stack, bouncing balls (test), and sprites, NPS is within 1-2 points of the baseline (and well within the error bars).\n- On physics env and Atari, NPS has a more sizable gain, but is still within the error bars.\n- Visual Grounding of Learned Physical Models. Li et. al, 2020.\n- Learning visual predictive models of physics for playing billiards. Fragkiadaki et. al., 2017.",
    "review_points_list": [
      "NPS is a novel system for visual reasoning.",
      "The computational components borrow heavily from attention mechanisms but separately represent rules to apply.",
      "The authors test a large number of total tasks, targeting different aspects of NPS.",
      "Using the first set of experimental results, they are able to provide the recommendation that sequential application is better for sparse interactions.",
      "I would have appreciated a more straightforward introduction that was heavier on visuals.",
      "The paragraph beginning at section 64 discusses going from raw observations to slots, which is not what NPS does.",
      "It takes up a lot of real estate in the introduction and gave me the impression that the paper focused on going from raw data to slots.",
      "The algorithm should specify that j indexes M (num slots).",
      "The steps in algorithm 1 should be consistent with the main text.",
      "It omits the primary slot selection.",
      "L208: an -> a?",
      "The figure cuts off the text.",
      "'Entity abstraction in visual model-based reinforcement learning.' is cited twice?",
      "How would you contrast NPS to a transformer trained on the same tasks, but with a rule 'memory store'?",
      "I found Figure 1, which provides a visualization of rules before they're introduced, which I found confusing.",
      "It would help with clarity to add more visualizations of the NPS system into the main text (or to at least pull the algorithm into the main text).",
      "The potential impact for differentiable reasoning is enormous.",
      "The aim of this paper is to take a step towards goal by showing a reasoning system on a variety of restricted settings that are straightforward to analyze.",
      "On many tasks, NPS is compared to only one baseline and provides a small performance improvement.",
      "E.g., on shapes stack, bouncing balls (test), and sprites, NPS is within 1-2 points of the baseline (and well within the error bars).",
      "On physics env and Atari, NPS has a more sizable gain, but is still within the error bars.",
      "Visual Grounding of Learned Physical Models. Li et. al, 2020.",
      "Learning visual predictive models of physics for playing billiards. Fragkiadaki et. al., 2017."
    ]
  },
  {
    "paper_id": "2303.13763v3",
    "submission_id": "xyoFSmocONi",
    "submission_title": "Structure-Aware Random Fourier Kernel for Graphs",
    "review_id": "1K8mpfLqyfs",
    "input": {
      "title": "Structure-Aware Random Fourier Kernel for Graphs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The article is well written, quite clear.\n- The method proposed is interesting, and, to the best of my knowledge quite new.\n- The method supposes to have already a good embedding of the graph, which is rather limiting.\n- Some points in the experiments are not very clear.\n- The advantages and limitations of the approach could be better underlined.\n- I find the method well detailed and clear.\n- As far as I understand, this embedding is not learned in conjunction with the kernel and is considered as fixed.\n- One needs to: 1) either have a good pre-trained GNN 2) or re-train a GNN on the data.\n- It would have been good to point out that this complexity also depends on having a good GNN.\n- Did the authors test with other embeddings that are less dependent on a GNN?\n- I think that ref [1] can be interesting in this context.\n- The Variational EM part is quite 'classical' for this kind of problems and seems relevant to me.\n- I am a bit skeptical about the message brought by this experiment.\n- I find that the conclusion that 'GPSRF > all GP models' is a bit misleading.\n- I think it would have been interesting to discuss a little bit why this idea is new.\n- I think that some works approach the same idea of learning the law of frequencies according to the data [3,4,5].\n- One point that I thought was worth highlighting is the fact that the method in question can take into account/model uncertainty in the prediction.\n- I think that this property is interesting and should be emphasized, because, to the best of my knowledge, it is rarely taken into account in the context of graphs.\n- I think it should be mitigated that methods relying on traditional kernels and Laplacian are wether 'inefficient for them to capture the structural smoothness in graph data' and 'they ignore the rich features of objects and may not be capable to model complicated functions over large-scale graphs'.\n- It is precisely what they are attempting to do, based on the prior that 'close' nodes (in the topology of the graph) should share similar features, and, as always, the fact that these methods sometimes struggle with the learning task depends on the dataset.\n- I don't understand the interest of an experiment that considers only the base kernel (without the graph part).\n- It is to illustrate that the hierarchical Bayesian approach to learn the RF law is interesting?\n- Because I think that some works approach the same idea of learning the law of frequencies according to the data [3,4,5]\n- It is really interesting to compare with GPP\n- Especially since the performances are only calculated on one train/validation/test split.\n- For me it is difficult to see that the difference between the two is statistically significant.",
    "review_points_list": [
      "The article is well written, quite clear.",
      "The method proposed is interesting, and, to the best of my knowledge quite new.",
      "The method supposes to have already a good embedding of the graph, which is rather limiting.",
      "Some points in the experiments are not very clear.",
      "The advantages and limitations of the approach could be better underlined.",
      "I find the method well detailed and clear.",
      "As far as I understand, this embedding is not learned in conjunction with the kernel and is considered as fixed.",
      "One needs to: 1) either have a good pre-trained GNN 2) or re-train a GNN on the data.",
      "It would have been good to point out that this complexity also depends on having a good GNN.",
      "Did the authors test with other embeddings that are less dependent on a GNN?",
      "I think that ref [1] can be interesting in this context.",
      "The Variational EM part is quite 'classical' for this kind of problems and seems relevant to me.",
      "I am a bit skeptical about the message brought by this experiment.",
      "I find that the conclusion that 'GPSRF > all GP models' is a bit misleading.",
      "I think it would have been interesting to discuss a little bit why this idea is new.",
      "I think that some works approach the same idea of learning the law of frequencies according to the data [3,4,5].",
      "One point that I thought was worth highlighting is the fact that the method in question can take into account/model uncertainty in the prediction.",
      "I think that this property is interesting and should be emphasized, because, to the best of my knowledge, it is rarely taken into account in the context of graphs.",
      "I think it should be mitigated that methods relying on traditional kernels and Laplacian are wether 'inefficient for them to capture the structural smoothness in graph data' and 'they ignore the rich features of objects and may not be capable to model complicated functions over large-scale graphs'.",
      "It is precisely what they are attempting to do, based on the prior that 'close' nodes (in the topology of the graph) should share similar features, and, as always, the fact that these methods sometimes struggle with the learning task depends on the dataset.",
      "I don't understand the interest of an experiment that considers only the base kernel (without the graph part).",
      "It is to illustrate that the hierarchical Bayesian approach to learn the RF law is interesting?",
      "Because I think that some works approach the same idea of learning the law of frequencies according to the data [3,4,5]",
      "It is really interesting to compare with GPP",
      "Especially since the performances are only calculated on one train/validation/test split.",
      "For me it is difficult to see that the difference between the two is statistically significant."
    ]
  },
  {
    "paper_id": "2303.13763v3",
    "submission_id": "xyoFSmocONi",
    "submission_title": "Structure-Aware Random Fourier Kernel for Graphs",
    "review_id": "jhVuGEeH5zs",
    "input": {
      "title": "Structure-Aware Random Fourier Kernel for Graphs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Use of GCNN to define a graph based kernel is new to me.\n- Combining subgraph embedding with Fourier kennel is interesting and might be very useful for many graph based tasks.\n- Advantage of this method is that it can capture features and graph structure in one kernel and the run time complexity is very less O(N).\n- Paper is well written and has clarity and is technically sound.\n- Experiment section is well planned and has been compared with many possible state of the art methods.\n- Paper has also discussed the possible negative social impact.\n- This model is applicable when an object is in a graph. Does it also applicable for tasks when the data object is a graph like protein classification etc?\n- Following related work is missing.\n- Nikolentzos, G., Meladianos, P., Tixier, A.J.P., Skianis, K. and Vazirgiannis, M., 2018, October. Kernel graph convolutional neural networks. In International conference on artificial neural networks (pp. 22-32). Springer, Cham.",
    "review_points_list": [
      "Use of GCNN to define a graph based kernel is new to me.",
      "Combining subgraph embedding with Fourier kennel is interesting and might be very useful for many graph based tasks.",
      "Advantage of this method is that it can capture features and graph structure in one kernel and the run time complexity is very less O(N).",
      "Paper is well written and has clarity and is technically sound.",
      "Experiment section is well planned and has been compared with many possible state of the art methods.",
      "Paper has also discussed the possible negative social impact.",
      "This model is applicable when an object is in a graph. Does it also applicable for tasks when the data object is a graph like protein classification etc?",
      "Following related work is missing.",
      "Nikolentzos, G., Meladianos, P., Tixier, A.J.P., Skianis, K. and Vazirgiannis, M., 2018, October. Kernel graph convolutional neural networks. In International conference on artificial neural networks (pp. 22-32). Springer, Cham."
    ]
  },
  {
    "paper_id": "2303.13763v3",
    "submission_id": "xyoFSmocONi",
    "submission_title": "Structure-Aware Random Fourier Kernel for Graphs",
    "review_id": "HKP7XfqQnTD",
    "input": {
      "title": "Structure-Aware Random Fourier Kernel for Graphs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- A key contribution of the paper is the idea of using local sub-graph structure around each node in order to define a structure-ware Bayesian graph kernel.\n- It combines several ideas of spectral kernel representation, RFFs and GP's to proposes an interesting idea that leverages local neighborhood of a node for graph learning.\n- Paper is well written and technically strong and addresses several aspects of proposed framework including choice of distributions, convergence, label distribution impact, sample size, effect thresholding and so on.\n- It also provides a Bayesian and computationally efficient algorithm to estimate model parameters.\n- Another aspect of Graph learning that is not considered in this work is most real-world graphs (random graphs with large N) are sparse with fewer edges and how does this impact EM modeling, convergence and results.",
    "review_points_list": [
      "A key contribution of the paper is the idea of using local sub-graph structure around each node in order to define a structure-ware Bayesian graph kernel.",
      "It combines several ideas of spectral kernel representation, RFFs and GP's to proposes an interesting idea that leverages local neighborhood of a node for graph learning.",
      "Paper is well written and technically strong and addresses several aspects of proposed framework including choice of distributions, convergence, label distribution impact, sample size, effect thresholding and so on.",
      "It also provides a Bayesian and computationally efficient algorithm to estimate model parameters.",
      "Another aspect of Graph learning that is not considered in this work is most real-world graphs (random graphs with large N) are sparse with fewer edges and how does this impact EM modeling, convergence and results."
    ]
  },
  {
    "paper_id": "2503.07848v2",
    "submission_id": "yw5KKWraUk7",
    "submission_title": "Explicable Reward Design for Reinforcement Learning Agents",
    "review_id": "zpzF5ovaXCv",
    "input": {
      "title": "Explicable Reward Design for Reinforcement Learning Agents",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- the work is original and novel, but some existing methodologies need further comparison, see limitations below\n- the work is technically sound, and all claims are supported by proofs\n- the writing is very clear and precise, and well organized\n- I think it needs to be better motivated in the introduction, e.g. to state up-front what the use-cases of the method are, where it could be applied in practice, and where it could fail\n- the assumptions of requiring the optimal policy set on the task seems to exclude a large number of use cases, which is important to discuss early on\n- the work is quite significant as reward design, sparsity and interpretability are all important topics currently studied in RL\n- it is not fully clear that the method is 'better' than other methods, since not many have been discussed (see limitations below)\n- the experiments only seem to consider simple baselines which does not answer this matter",
    "review_points_list": [
      "the work is original and novel, but some existing methodologies need further comparison, see limitations below",
      "the work is technically sound, and all claims are supported by proofs",
      "the writing is very clear and precise, and well organized",
      "I think it needs to be better motivated in the introduction, e.g. to state up-front what the use-cases of the method are, where it could be applied in practice, and where it could fail",
      "the assumptions of requiring the optimal policy set on the task seems to exclude a large number of use cases, which is important to discuss early on",
      "the work is quite significant as reward design, sparsity and interpretability are all important topics currently studied in RL",
      "it is not fully clear that the method is 'better' than other methods, since not many have been discussed (see limitations below)",
      "the experiments only seem to consider simple baselines which does not answer this matter"
    ]
  },
  {
    "paper_id": "2503.07848v2",
    "submission_id": "yw5KKWraUk7",
    "submission_title": "Explicable Reward Design for Reinforcement Learning Agents",
    "review_id": "9yVcvG0YyAL",
    "input": {
      "title": "Explicable Reward Design for Reinforcement Learning Agents",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well-written and easy to follow.\n- The related work section is extensive and provides a good overview of related literature on methods that address reward function design.\n- I am not fully convinced that sparseness is a desirable characteristic for a reward function.\n- I understand the reward functions are often sparse in real world environments and it is necessary to design learning algorithms that can work for them.\n- However, the authors note sparseness as a \u201cpreferred characteristic\u201d alongside informativeness\n- Settings highlighted to support this such as pedagogical and robotic applications might have to work with sparse rewards.\n- However, I view this sparsity as a limitation to overcome rather than a characteristic to be desired.\n- More discussion to support why we want sparseness would clarify the thesis of the paper.\n- Results in 2a suggest that PBRS still outperforms all variants of the proposed method notwithstanding that the proposed method has more parameters that needs to be optimized.\n- Results in 4a suggest something similar - the proposed method (one variant) outperforms PBRS only slightly.\n- It isn\u2019t clear whether this justifies the optimization necessary to acquire the parameters that achieves this for the proposed method while PBRS seems to work out of the box.",
    "review_points_list": [
      "The paper is well-written and easy to follow.",
      "The related work section is extensive and provides a good overview of related literature on methods that address reward function design.",
      "I am not fully convinced that sparseness is a desirable characteristic for a reward function.",
      "I understand the reward functions are often sparse in real world environments and it is necessary to design learning algorithms that can work for them.",
      "However, the authors note sparseness as a \u201cpreferred characteristic\u201d alongside informativeness",
      "Settings highlighted to support this such as pedagogical and robotic applications might have to work with sparse rewards.",
      "However, I view this sparsity as a limitation to overcome rather than a characteristic to be desired.",
      "More discussion to support why we want sparseness would clarify the thesis of the paper.",
      "Results in 2a suggest that PBRS still outperforms all variants of the proposed method notwithstanding that the proposed method has more parameters that needs to be optimized.",
      "Results in 4a suggest something similar - the proposed method (one variant) outperforms PBRS only slightly.",
      "It isn\u2019t clear whether this justifies the optimization necessary to acquire the parameters that achieves this for the proposed method while PBRS seems to work out of the box."
    ]
  },
  {
    "paper_id": "2503.07848v2",
    "submission_id": "yw5KKWraUk7",
    "submission_title": "Explicable Reward Design for Reinforcement Learning Agents",
    "review_id": "1jqdBaVDmT",
    "input": {
      "title": "Explicable Reward Design for Reinforcement Learning Agents",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The user interface is intuitive and user-friendly.\n- The software performance is satisfactory and runs smoothly.\n- The customer support response time could be improved.\n- More customization options would be beneficial for users.\n- It would be great to have additional tutorial resources for new users.",
    "review_points_list": [
      "The user interface is intuitive and user-friendly.",
      "The software performance is satisfactory and runs smoothly.",
      "The customer support response time could be improved.",
      "More customization options would be beneficial for users.",
      "It would be great to have additional tutorial resources for new users."
    ]
  },
  {
    "paper_id": "1808.03518v1",
    "submission_id": "x2pF7Tt_S5u",
    "submission_title": "Memory Efficient Meta-Learning with Large Images",
    "review_id": "NYMOP-k8qG-",
    "input": {
      "title": "Memory Efficient Meta-Learning with Large Images",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper is nice since it tackles the memory issue that has been a problem for a long time in the meta-learning field and the proposed solution is generally applicable for many meta-learning methods.\n- However, I wish some clarity problems and analysis are improved during the rebuttal period.\n- This paper is well written and easy to follow.\n- This paper tackles an important problem in the meta-learning domain, which is limited scalability due to the memory-intensive computation of training of support sets of tasks.\n- By overcoming the above issue, this paper achieves the SOTA performance on two few-shot benchmark datasets.\n- Could the authors report memory savings and whether the performance drops for the same image sizes (e.g., 84) when we use LITE?\n- I wonder how much we can enlarge the image size or task size by using LITE with a single GPU?\n- In Table 1, could the authors report GPU hours (or Wall Clock Time) at the test time of each method?\n- I wonder how much we can save time when we use the meta-learning methods compared with transfer learning as the authors described in the introduction.\n- In Table 1, could the authors report the results with 224 EN-B0?\n- Could the authors add discussion on [1] that is a method for large-scale meta-learning?\n- [1] Shin et al. Large-Scale Meta-Learning with Continual Trajectory Shifting, ICML 2021.",
    "review_points_list": [
      "This paper is nice since it tackles the memory issue that has been a problem for a long time in the meta-learning field and the proposed solution is generally applicable for many meta-learning methods.",
      "However, I wish some clarity problems and analysis are improved during the rebuttal period.",
      "This paper is well written and easy to follow.",
      "This paper tackles an important problem in the meta-learning domain, which is limited scalability due to the memory-intensive computation of training of support sets of tasks.",
      "By overcoming the above issue, this paper achieves the SOTA performance on two few-shot benchmark datasets.",
      "Could the authors report memory savings and whether the performance drops for the same image sizes (e.g., 84) when we use LITE?",
      "I wonder how much we can enlarge the image size or task size by using LITE with a single GPU?",
      "In Table 1, could the authors report GPU hours (or Wall Clock Time) at the test time of each method?",
      "I wonder how much we can save time when we use the meta-learning methods compared with transfer learning as the authors described in the introduction.",
      "In Table 1, could the authors report the results with 224 EN-B0?",
      "Could the authors add discussion on [1] that is a method for large-scale meta-learning?",
      "[1] Shin et al. Large-Scale Meta-Learning with Continual Trajectory Shifting, ICML 2021."
    ]
  },
  {
    "paper_id": "1808.03518v1",
    "submission_id": "x2pF7Tt_S5u",
    "submission_title": "Memory Efficient Meta-Learning with Large Images",
    "review_id": "PlqLJuqWSF",
    "input": {
      "title": "Memory Efficient Meta-Learning with Large Images",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well-written and well-structured.\n- The problem that they try to solve is very important and also very challenging.\n- The idea seems to be generalizable to different meta-learning techniques.\n- They show it for CNAPS and ProtoNets.\n- Their method is based on the idea to update the parameters of the model with the whole train set of the task but backpropagate through only a subset of the task.\n- I think the mathematical study of this really helps the paper.\n- Since this is mathematically correct, it might open new directions for new meta-learning algorithms.\n- Optimization-based algorithms like MAML that require several inner steps are still cannot get much improvement from this method.\n- I looked at the supplementary material and the part that discussed MAML, however, I could not understand why it is not possible to limit the back-propagation on only a few samples from the train set.\n- Can you please explain more about this?\n- Some other related work like (Meta-learning with implicit gradients) can be used to solve the same problem.\n- It seems that related work did not thoroughly cover other approaches for solving the memory issue in meta-learning.\n- Has there been any other work that tackles this issue?\n- I am aware that it might not be possible to compare directly, however, it is good to discuss them.\n- I thank the authors for clarifying reviewers' questions.\n- I strongly suggest the authors modify the paper based on reviewers' requests.\n- Especially, point 5 in reviewer wfg9's comment and experiments that were done for reviewer ES9N's comments.\n- After discussing with other reviewers and reading their comments, I decided to stick with my initial review score of 6.",
    "review_points_list": [
      "The paper is well-written and well-structured.",
      "The problem that they try to solve is very important and also very challenging.",
      "The idea seems to be generalizable to different meta-learning techniques.",
      "They show it for CNAPS and ProtoNets.",
      "Their method is based on the idea to update the parameters of the model with the whole train set of the task but backpropagate through only a subset of the task.",
      "I think the mathematical study of this really helps the paper.",
      "Since this is mathematically correct, it might open new directions for new meta-learning algorithms.",
      "Optimization-based algorithms like MAML that require several inner steps are still cannot get much improvement from this method.",
      "I looked at the supplementary material and the part that discussed MAML, however, I could not understand why it is not possible to limit the back-propagation on only a few samples from the train set.",
      "Can you please explain more about this?",
      "Some other related work like (Meta-learning with implicit gradients) can be used to solve the same problem.",
      "It seems that related work did not thoroughly cover other approaches for solving the memory issue in meta-learning.",
      "Has there been any other work that tackles this issue?",
      "I am aware that it might not be possible to compare directly, however, it is good to discuss them.",
      "I thank the authors for clarifying reviewers' questions.",
      "I strongly suggest the authors modify the paper based on reviewers' requests.",
      "Especially, point 5 in reviewer wfg9's comment and experiments that were done for reviewer ES9N's comments.",
      "After discussing with other reviewers and reading their comments, I decided to stick with my initial review score of 6."
    ]
  },
  {
    "paper_id": "1808.03518v1",
    "submission_id": "x2pF7Tt_S5u",
    "submission_title": "Memory Efficient Meta-Learning with Large Images",
    "review_id": "XsSWeD80ZE4",
    "input": {
      "title": "Memory Efficient Meta-Learning with Large Images",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- the paper is considering an interesting aspect of the meta-learning problem (holding constant the method but using larger input images) that as far as I know hasn't been considered before\n- the proposed method and its motivating analysis seem sound\n- the experimental comparison is also fair and highlights the benefit of using the large image input based on their proposed approximation\n- Why not consider mini-ImageNet or tiered-ImageNet benchmarks in which most work uses 84x84 inputs?\n- It would be interesting to see the benefit of larger inputs on those commonly used benchmarks\n- I think an ablation experiment showing how the quality and speed of training varies with the approximation parameter H would also have been useful to evaluate the method\n- I also think first-order maml with a larger input would be a useful baseline to see the effect of using larger inputs in a different way than what the authors propose\n- the paper is very well-written\n- It motives the problem well and has a clear description of the proposed solution\n- the experiments also seem to be conducted fairly and are informative\n- I think the results in the paper could be useful to researchers as they show a way to improve quality of meta-learning models simply by increasing the image resolution\n- One concern I have is that the authors include MAML in the class of methods for which the proposed approximation applies but in the end, do not implement or show results for the method since because of the memory required to retain the inner loop\u2019s computation graph, training may still need to be scaled to smaller images or smaller tasks.\n- I am wondering if its actually useful to include discussion of MAML then in the paper if the paper doesn't have a concrete proposal/implementation of the approximation of second-order MAML that allows it to be trained on larger images?",
    "review_points_list": [
      "the paper is considering an interesting aspect of the meta-learning problem (holding constant the method but using larger input images) that as far as I know hasn't been considered before",
      "the proposed method and its motivating analysis seem sound",
      "the experimental comparison is also fair and highlights the benefit of using the large image input based on their proposed approximation",
      "Why not consider mini-ImageNet or tiered-ImageNet benchmarks in which most work uses 84x84 inputs?",
      "It would be interesting to see the benefit of larger inputs on those commonly used benchmarks",
      "I think an ablation experiment showing how the quality and speed of training varies with the approximation parameter H would also have been useful to evaluate the method",
      "I also think first-order maml with a larger input would be a useful baseline to see the effect of using larger inputs in a different way than what the authors propose",
      "the paper is very well-written",
      "It motives the problem well and has a clear description of the proposed solution",
      "the experiments also seem to be conducted fairly and are informative",
      "I think the results in the paper could be useful to researchers as they show a way to improve quality of meta-learning models simply by increasing the image resolution",
      "One concern I have is that the authors include MAML in the class of methods for which the proposed approximation applies but in the end, do not implement or show results for the method since because of the memory required to retain the inner loop\u2019s computation graph, training may still need to be scaled to smaller images or smaller tasks.",
      "I am wondering if its actually useful to include discussion of MAML then in the paper if the paper doesn't have a concrete proposal/implementation of the approximation of second-order MAML that allows it to be trained on larger images?"
    ]
  },
  {
    "paper_id": "2107.09584v2",
    "submission_id": "zdTW91r2wKO",
    "submission_title": "Active 3D Shape Reconstruction from Vision and Touch",
    "review_id": "0fKmiNbgsDw",
    "input": {
      "title": "Active 3D Shape Reconstruction from Vision and Touch",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- On the method originality This paper mainly has two contributions which are the modified reconstruction network based on [48], and the active search policy of grasp parameters. The whole design is reasonable and novel to me.\n- The whole design is reasonable and novel to me.\n- However, since the modification on the network and the policies are a little direct and intuitive to me, which makes the technical contribution a little limited.\n- My major concern on the experiments is that they are all experimented in simulation.\n- Since the object is easy to find or 3D printed in the real world, the robot hand (Allegro) is not that expensive (compared to Shadow robot hand), the tactile sensor is open-source for manufacturing with low-cost.\n- And after [48] which has already put forward the discussion of vision-touch learning, I think at this moment, a real-world experiment is needed.\n- I wonder if the simple policy will also work in the real world, the evident challenges would be natural occlusion of object shape, and the displacement after touching.\n- If the training requires fairly large amount of data, how about apply some simple sim2real strategy?\n- As touch may involves many contact-rich processes, I am suspicious of how well the simulation can mimic the behavior of real touching.\n- If the pipeline only works with simulation, the applicability will be largely limited.\n- The writing of this paper is quite clear, especially the description about the difference on the reconstruction network.\n- The whole work is easy to read and follow.\n- The integration of vision and touch modalities are important for many applications, especially on robot.\n- 3D shape reconstruction is a key problem when revealing the underlying 3D geometric information from the observations.\n- I think it is a rather under explored area.\n- Though I have some concerns about the technical contribution and the experiments, I also admit I may set a rather high bar.\n- As the vision-touching learning problem is interesting, important and less explored, I am positive on this work.",
    "review_points_list": [
      "On the method originality This paper mainly has two contributions which are the modified reconstruction network based on [48], and the active search policy of grasp parameters. The whole design is reasonable and novel to me.",
      "The whole design is reasonable and novel to me.",
      "However, since the modification on the network and the policies are a little direct and intuitive to me, which makes the technical contribution a little limited.",
      "My major concern on the experiments is that they are all experimented in simulation.",
      "Since the object is easy to find or 3D printed in the real world, the robot hand (Allegro) is not that expensive (compared to Shadow robot hand), the tactile sensor is open-source for manufacturing with low-cost.",
      "And after [48] which has already put forward the discussion of vision-touch learning, I think at this moment, a real-world experiment is needed.",
      "I wonder if the simple policy will also work in the real world, the evident challenges would be natural occlusion of object shape, and the displacement after touching.",
      "If the training requires fairly large amount of data, how about apply some simple sim2real strategy?",
      "As touch may involves many contact-rich processes, I am suspicious of how well the simulation can mimic the behavior of real touching.",
      "If the pipeline only works with simulation, the applicability will be largely limited.",
      "The writing of this paper is quite clear, especially the description about the difference on the reconstruction network.",
      "The whole work is easy to read and follow.",
      "The integration of vision and touch modalities are important for many applications, especially on robot.",
      "3D shape reconstruction is a key problem when revealing the underlying 3D geometric information from the observations.",
      "I think it is a rather under explored area.",
      "Though I have some concerns about the technical contribution and the experiments, I also admit I may set a rather high bar.",
      "As the vision-touching learning problem is interesting, important and less explored, I am positive on this work."
    ]
  },
  {
    "paper_id": "2107.09584v2",
    "submission_id": "zdTW91r2wKO",
    "submission_title": "Active 3D Shape Reconstruction from Vision and Touch",
    "review_id": "OwepdVCO9Lg",
    "input": {
      "title": "Active 3D Shape Reconstruction from Vision and Touch",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Strengths: - The authors introduce the task of active 3D reconstruction, which presents a different setting for reconstruction by leveraging exploration rather than static data, and develop a simulator and environment to enable the task.\n- - The authors extend the previously proposed chart-based reconstruction method to their setting to better leverage positional information, as well as incorporate additional information collected from exploration.\n- - The authors use 4 learning settings across a number of data-driven policies to evaluate their approach, including an oracle that represents an upper bound on the performance of the method.\n- - Experiments demonstrate the usefulness of active touch through the improved performance on 3D shape reconstruction of the learned policies.\n- - The paper is well-written, especially when providing an overview of all the policies and baselines used in the experiments.\n- Weaknesses: - There are a few design decisions that were skimmed over (e.g., How was 50 selected to be the size of the action space? How was N (max # expected touch charts) determined?)\n- - The authors use mesh representations, in contrast to point cloud representations used by Smith et al. [48], which introduces additional parameterization with needing to learn an autoencoder to reduce the dimensionality of the features used in learning the policies.\n- - Since the autoencoder's objective is to minimize the CD between an input mesh and output point cloud, did the authors try directly using point clouds in their pipeline instead of meshes (i.e., the main difference from [48] being the composition of 2 GCNs for the mesh deformation model?)\n- - While Table 1 demonstrates better reconstruction in terms of CD, the variance is noticeably higher. Is there any intuition for why this may occur?\n- Thank you to the authors for addressing and clarifying the concerns raised. My rating remains unchanged.",
    "review_points_list": [
      "Strengths: - The authors introduce the task of active 3D reconstruction, which presents a different setting for reconstruction by leveraging exploration rather than static data, and develop a simulator and environment to enable the task.",
      "- The authors extend the previously proposed chart-based reconstruction method to their setting to better leverage positional information, as well as incorporate additional information collected from exploration.",
      "- The authors use 4 learning settings across a number of data-driven policies to evaluate their approach, including an oracle that represents an upper bound on the performance of the method.",
      "- Experiments demonstrate the usefulness of active touch through the improved performance on 3D shape reconstruction of the learned policies.",
      "- The paper is well-written, especially when providing an overview of all the policies and baselines used in the experiments.",
      "Weaknesses: - There are a few design decisions that were skimmed over (e.g., How was 50 selected to be the size of the action space? How was N (max # expected touch charts) determined?)",
      "- The authors use mesh representations, in contrast to point cloud representations used by Smith et al. [48], which introduces additional parameterization with needing to learn an autoencoder to reduce the dimensionality of the features used in learning the policies.",
      "- Since the autoencoder's objective is to minimize the CD between an input mesh and output point cloud, did the authors try directly using point clouds in their pipeline instead of meshes (i.e., the main difference from [48] being the composition of 2 GCNs for the mesh deformation model?)",
      "- While Table 1 demonstrates better reconstruction in terms of CD, the variance is noticeably higher. Is there any intuition for why this may occur?",
      "Thank you to the authors for addressing and clarifying the concerns raised. My rating remains unchanged."
    ]
  },
  {
    "paper_id": "2107.09584v2",
    "submission_id": "zdTW91r2wKO",
    "submission_title": "Active 3D Shape Reconstruction from Vision and Touch",
    "review_id": "yH1DbMpv5Cs",
    "input": {
      "title": "Active 3D Shape Reconstruction from Vision and Touch",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I would like to begin by listing several positives with this paper:\n- - It addresses an important problem (3D reconstruction) and tries to do so using a new active perception paradigm.\n- - The paper is well written and motivated.\n- - The experiments are extensive and convincing.\n- I like the ideas in the paper and the proposed approach. In the following, I will focus on comments, questions, and suggestions for improvement.\n- It would be beneficial to differentiate between related previous work [48,59] and the proposed work. The main difference is active perception, but this can be made clearer.\n- Figure 2 is missing some labels. What are the top and bottom rows?\n- Regarding related work, there is some existing literature on the idea of 'Shape from interaction' which would have been nice to discuss. In general, the paper could do a better job of crediting previous papers that present similar ideas. Here's a start:\n- Shape from interaction, Michel, Zabulis, Argyros, 2014\n- The paper uses charts for reconstruction but does not cite the most relevant paper:\n- A papier-m\u00e2ch\u00e9 approach to learning 3d surface generation, Groueix et al. 2018\n- Line 133 mentions 4 touch readings, but it isn't immediately obvious why it's 4 (mention 4 fingers of the robot).\n- The simulator sounds great. Will this also be released publicly?\n- Is the figure 4 legend correct? Red is denoted as vision and touch but takes only vision signals in the top part.\n- I generally like the proposed approach and do not have too many complaints.\n- Regarding results and experiments:\n- - The results in table 1 show only a marginal improvement over [48], could the authors comment on why?\n- - I would have liked to see results on real data, but I understand this is a hard problem.\n- Overall, this is a great paper that I would like to see published. If the authors can propose a plan to fix the issues above in the rebuttal, that would be great.",
    "review_points_list": [
      "I would like to begin by listing several positives with this paper:",
      "- It addresses an important problem (3D reconstruction) and tries to do so using a new active perception paradigm.",
      "- The paper is well written and motivated.",
      "- The experiments are extensive and convincing.",
      "I like the ideas in the paper and the proposed approach. In the following, I will focus on comments, questions, and suggestions for improvement.",
      "It would be beneficial to differentiate between related previous work [48,59] and the proposed work. The main difference is active perception, but this can be made clearer.",
      "Figure 2 is missing some labels. What are the top and bottom rows?",
      "Regarding related work, there is some existing literature on the idea of 'Shape from interaction' which would have been nice to discuss. In general, the paper could do a better job of crediting previous papers that present similar ideas. Here's a start:",
      "Shape from interaction, Michel, Zabulis, Argyros, 2014",
      "The paper uses charts for reconstruction but does not cite the most relevant paper:",
      "A papier-m\u00e2ch\u00e9 approach to learning 3d surface generation, Groueix et al. 2018",
      "Line 133 mentions 4 touch readings, but it isn't immediately obvious why it's 4 (mention 4 fingers of the robot).",
      "The simulator sounds great. Will this also be released publicly?",
      "Is the figure 4 legend correct? Red is denoted as vision and touch but takes only vision signals in the top part.",
      "I generally like the proposed approach and do not have too many complaints.",
      "Regarding results and experiments:",
      "- The results in table 1 show only a marginal improvement over [48], could the authors comment on why?",
      "- I would have liked to see results on real data, but I understand this is a hard problem.",
      "Overall, this is a great paper that I would like to see published. If the authors can propose a plan to fix the issues above in the rebuttal, that would be great."
    ]
  },
  {
    "paper_id": "2107.09584v2",
    "submission_id": "zdTW91r2wKO",
    "submission_title": "Active 3D Shape Reconstruction from Vision and Touch",
    "review_id": "zoZzaoPsTpS",
    "input": {
      "title": "Active 3D Shape Reconstruction from Vision and Touch",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper addresses an interesting problem.\n- However it can be improved considering the following points.\n- Some of the listed previous works also focus on improving 3D reconstruction through tactile exploration, e.g. choosing where to touch next without exhaustive exploration also demonstrating experiments using real data.\n- Please clarify and highlight the differences of your work in comparison\n- Another related work that can be included: Active tactile exploration with uncertainty and travel cost for fast shape estimation of unknown objects.\n- The experiments are only conducted in simulation, how would the results be affected in terms of noise and uncertainty which would be increased in case of real data.\n- The difference in performance in Table 1 looks quite small.\n- Why is [48] chosen as a baseline among all related works, please motivate the choice, also motivate the choice of baselines for the exploration experiments.\n- Could you report the value of K (number of touches/grasps) in experiments?\n- Could you summarize the main findings from the experiments based on all the exploration strategies?",
    "review_points_list": [
      "The paper addresses an interesting problem.",
      "However it can be improved considering the following points.",
      "Some of the listed previous works also focus on improving 3D reconstruction through tactile exploration, e.g. choosing where to touch next without exhaustive exploration also demonstrating experiments using real data.",
      "Please clarify and highlight the differences of your work in comparison",
      "Another related work that can be included: Active tactile exploration with uncertainty and travel cost for fast shape estimation of unknown objects.",
      "The experiments are only conducted in simulation, how would the results be affected in terms of noise and uncertainty which would be increased in case of real data.",
      "The difference in performance in Table 1 looks quite small.",
      "Why is [48] chosen as a baseline among all related works, please motivate the choice, also motivate the choice of baselines for the exploration experiments.",
      "Could you report the value of K (number of touches/grasps) in experiments?",
      "Could you summarize the main findings from the experiments based on all the exploration strategies?"
    ]
  },
  {
    "paper_id": "2110.02900v1",
    "submission_id": "xfskdMFkuTS",
    "submission_title": "Meta Internal Learning",
    "review_id": "WJ7Grt9kv6",
    "input": {
      "title": "Meta Internal Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The idea of employing hypernetwork to train both generators and discriminators is very interesting, and the motivation of fast inference is convincing enough for me.\n- My main concern is on the quality of the results (Figure 3 and 4).\n- I partly agree (but with some conditions) that if there is no shortage of unlabeled images, single-image GAN is unjustifiable.\n- This must go with conditions that the test image performance is better than or at least comparable to the original SinGAN.\n- Zooming at Figure 4, however, the quality of the results does not seem to match with SinGAN (even on train data with the model trained on the larger dataset!).\n- For example, the V5000 results does not look crisp nor realistic when looking at the boundaries of the buildings.\n- These qualitative results do not match with the quantitative results shown in Table 1 and Table 3.\n- This needs more explanations.\n- In Table 3, using a smaller dataset gives better results on training data, and this trend is opposite in the test data.\n- What would be the explanation for the former case?\n- + why doesn\u2019t this go along with the qualitative results in Figure 4?\n- Speaking of the results, I don\u2019t see the benefit of the availability to interpolate between single image GANs (Figure 3).\n- I understand that the framework allows this to perform and indeed this is new, but cannot see what kinds of advantage it would bring by doing so.\n- This needs more discussion, or reduce the weight it takes in the paper (Currently, it is mentioned with the other major contributions).\n- In addition, one of the contributions that the authors argue is that they are the first (as far as they know) to perform adversarial training with hypernetworks.\n- In fact, there exists a very similar work that did use hypernetwork for generator and train it using the adversarial loss: \u201cGenerative Models as Distributions of Functions\u201d.\n- Although it does not use the hypernetwork scheme for both generator and discriminator, this is noteworthy.\n- However, I do not think this compromises the novelty much since the work is quite recent and has not been published anywhere yet.\n- The organization of the paper can be also improved.\n- For example, in my personal opinion, it looks better to spare more space in Backgound section for introducing the intuition behind the SinGAN and its characteristics than providing the technical details (like eq. (2), (3), and (4)), which are not important to understand the main idea and context.\n- Overall, the idea is interesting and the advantages of using the framework are clearly seen.\n- However, since the results do not go along with the first two benefits (Line 24 \u2013 Line 27), which are very critical, it is hard to give a strong score to the paper.\n- Update: Raised score to 6, please see the comment.",
    "review_points_list": [
      "The idea of employing hypernetwork to train both generators and discriminators is very interesting, and the motivation of fast inference is convincing enough for me.",
      "My main concern is on the quality of the results (Figure 3 and 4).",
      "I partly agree (but with some conditions) that if there is no shortage of unlabeled images, single-image GAN is unjustifiable.",
      "This must go with conditions that the test image performance is better than or at least comparable to the original SinGAN.",
      "Zooming at Figure 4, however, the quality of the results does not seem to match with SinGAN (even on train data with the model trained on the larger dataset!).",
      "For example, the V5000 results does not look crisp nor realistic when looking at the boundaries of the buildings.",
      "These qualitative results do not match with the quantitative results shown in Table 1 and Table 3.",
      "This needs more explanations.",
      "In Table 3, using a smaller dataset gives better results on training data, and this trend is opposite in the test data.",
      "What would be the explanation for the former case?",
      "+ why doesn\u2019t this go along with the qualitative results in Figure 4?",
      "Speaking of the results, I don\u2019t see the benefit of the availability to interpolate between single image GANs (Figure 3).",
      "I understand that the framework allows this to perform and indeed this is new, but cannot see what kinds of advantage it would bring by doing so.",
      "This needs more discussion, or reduce the weight it takes in the paper (Currently, it is mentioned with the other major contributions).",
      "In addition, one of the contributions that the authors argue is that they are the first (as far as they know) to perform adversarial training with hypernetworks.",
      "In fact, there exists a very similar work that did use hypernetwork for generator and train it using the adversarial loss: \u201cGenerative Models as Distributions of Functions\u201d.",
      "Although it does not use the hypernetwork scheme for both generator and discriminator, this is noteworthy.",
      "However, I do not think this compromises the novelty much since the work is quite recent and has not been published anywhere yet.",
      "The organization of the paper can be also improved.",
      "For example, in my personal opinion, it looks better to spare more space in Backgound section for introducing the intuition behind the SinGAN and its characteristics than providing the technical details (like eq. (2), (3), and (4)), which are not important to understand the main idea and context.",
      "Overall, the idea is interesting and the advantages of using the framework are clearly seen.",
      "However, since the results do not go along with the first two benefits (Line 24 \u2013 Line 27), which are very critical, it is hard to give a strong score to the paper.",
      "Update: Raised score to 6, please see the comment."
    ]
  },
  {
    "paper_id": "2110.02900v1",
    "submission_id": "xfskdMFkuTS",
    "submission_title": "Meta Internal Learning",
    "review_id": "6Pjd9v9p1Z5",
    "input": {
      "title": "Meta Internal Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The idea of using a larger dataset to speed up the training of single-image GANs on a single image is promising.\n- Using hypernetworks and meta-learning may be one suitable approach for this.\n- The method in this paper seems to deliver promising results while only needing 5 minutes of fine-tuning for a given image.\n- It would be more interesting to see how well this approach performs on more complex images and how much it benefits from large-scale training in this case.\n- SinGAN-like approaches are not good at modeling complex structures/objects and it seems to me that using hypernetworks would be most helpful in these cases.\n- Landscapes do not contain many complex structures so it would be better to test this approach on other datasets, e.g. LSUN churches or something similar.\n- Is it necessary to train an image encoder as you do given that there are many pre-trained image encoders already available?\n- Have you tried using a pretrained (frozen) image encoder as conditioning for your hypernetworks?\n- While I get that your approach supports applications that are not supported by traditional single-image GANs (e.g. image interpolation and mixing) I think it would still be beneficial to compare against at least some of the original applications directly in the main paper (unconditional synthesis, harmonization, editing, retargeting, ...).\n- At the moment this is all hidden in the supplementary which makes it difficult to directly qualitatively compare your approach to the baselines.\n- I believe some (most) of section 2 (2.1 can be summarized in one para like 2.2) can be moved to the supplemental to free up more space to run more experiments and evaluations.\n- Similarly, section 3 can be shortened (e.g., equations 9-11 are a repetition of equations 6-8).\n- Overall, I believe this paper would benefit from a more thorough analysis of the approach on different datasets (that also contain more complex structures than landscapes), more direct comparisons to the baselines on some applications (generation, harmonization, editing, ...), and possibly running a user study to get direct comparisons between the different models besides SIFID/diversity (both of which have been shown to have weaknesses).\n- Update: Raised score to 6, see comment.",
    "review_points_list": [
      "The idea of using a larger dataset to speed up the training of single-image GANs on a single image is promising.",
      "Using hypernetworks and meta-learning may be one suitable approach for this.",
      "The method in this paper seems to deliver promising results while only needing 5 minutes of fine-tuning for a given image.",
      "It would be more interesting to see how well this approach performs on more complex images and how much it benefits from large-scale training in this case.",
      "SinGAN-like approaches are not good at modeling complex structures/objects and it seems to me that using hypernetworks would be most helpful in these cases.",
      "Landscapes do not contain many complex structures so it would be better to test this approach on other datasets, e.g. LSUN churches or something similar.",
      "Is it necessary to train an image encoder as you do given that there are many pre-trained image encoders already available?",
      "Have you tried using a pretrained (frozen) image encoder as conditioning for your hypernetworks?",
      "While I get that your approach supports applications that are not supported by traditional single-image GANs (e.g. image interpolation and mixing) I think it would still be beneficial to compare against at least some of the original applications directly in the main paper (unconditional synthesis, harmonization, editing, retargeting, ...).",
      "At the moment this is all hidden in the supplementary which makes it difficult to directly qualitatively compare your approach to the baselines.",
      "I believe some (most) of section 2 (2.1 can be summarized in one para like 2.2) can be moved to the supplemental to free up more space to run more experiments and evaluations.",
      "Similarly, section 3 can be shortened (e.g., equations 9-11 are a repetition of equations 6-8).",
      "Overall, I believe this paper would benefit from a more thorough analysis of the approach on different datasets (that also contain more complex structures than landscapes), more direct comparisons to the baselines on some applications (generation, harmonization, editing, ...), and possibly running a user study to get direct comparisons between the different models besides SIFID/diversity (both of which have been shown to have weaknesses).",
      "Update: Raised score to 6, see comment."
    ]
  },
  {
    "paper_id": "2110.02900v1",
    "submission_id": "xfskdMFkuTS",
    "submission_title": "Meta Internal Learning",
    "review_id": "ASk1sgbS34s",
    "input": {
      "title": "Meta Internal Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well-written, and the proposed approach is simple and intuitive. The authors motivate the problem well.\n- Experiments are thorough and demonstrate efficacy of the proposed approach qualitatively and quantitatively. The authors also define new tasks such as interpolation and feedforward modeling which enables new capacities in single-image GAN models.\n- The proposed approach employs hyper-networks in SinGAN models, which is an instance of apply X to Y.\n- Considering that hyper-networks are applied to other generative models and various discriminative models, this makes novelty of the proposed approach moderate.\n- There are existing works such as [A] that use hyper-networks in generative models.\n- There are also recent works such as [B, C, D] which also use hyper-networks for generation (but are not published by the submission deadline for this conference).\n- However, the good results and improvements of the proposed approach can make up for this.\n- The authors note the limitation of their work in terms of model size, convergence, runtime and GPU memory usage in section 6, but do not provide further details.\n- It would be good to have comparisons with SinGAN on this.",
    "review_points_list": [
      "The paper is well-written, and the proposed approach is simple and intuitive. The authors motivate the problem well.",
      "Experiments are thorough and demonstrate efficacy of the proposed approach qualitatively and quantitatively. The authors also define new tasks such as interpolation and feedforward modeling which enables new capacities in single-image GAN models.",
      "The proposed approach employs hyper-networks in SinGAN models, which is an instance of apply X to Y.",
      "Considering that hyper-networks are applied to other generative models and various discriminative models, this makes novelty of the proposed approach moderate.",
      "There are existing works such as [A] that use hyper-networks in generative models.",
      "There are also recent works such as [B, C, D] which also use hyper-networks for generation (but are not published by the submission deadline for this conference).",
      "However, the good results and improvements of the proposed approach can make up for this.",
      "The authors note the limitation of their work in terms of model size, convergence, runtime and GPU memory usage in section 6, but do not provide further details.",
      "It would be good to have comparisons with SinGAN on this."
    ]
  },
  {
    "paper_id": "2110.02900v1",
    "submission_id": "xfskdMFkuTS",
    "submission_title": "Meta Internal Learning",
    "review_id": "9QVbCWEr_I",
    "input": {
      "title": "Meta Internal Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well written and easy to follow.\n- The author has provided solid theoretical analysis of the proposed method.\n- The idea of leverage hyper-net to generate the model weights for generator and discriminator is quite novel and intuitive.\n- The paper has made a meaningful progress to generalize the single-sample GAN models to multi-sample case.\n- A collection of variants (shared gen/dis hyper) are also studied to validate the effectiveness of the proposed method.\n- The author has also provided code for reference.\n- The author has pointed out the model size might be one of the limitations.\n- I would like to know if there is any failure case existing w.r.t the the generation quality under some circumstances? For example, does the proposed method also works for human face images, etc?",
    "review_points_list": [
      "The paper is well written and easy to follow.",
      "The author has provided solid theoretical analysis of the proposed method.",
      "The idea of leverage hyper-net to generate the model weights for generator and discriminator is quite novel and intuitive.",
      "The paper has made a meaningful progress to generalize the single-sample GAN models to multi-sample case.",
      "A collection of variants (shared gen/dis hyper) are also studied to validate the effectiveness of the proposed method.",
      "The author has also provided code for reference.",
      "The author has pointed out the model size might be one of the limitations.",
      "I would like to know if there is any failure case existing w.r.t the the generation quality under some circumstances? For example, does the proposed method also works for human face images, etc?"
    ]
  },
  {
    "paper_id": "2112.13287v1",
    "submission_id": "twz1QqzU0Hp",
    "submission_title": "A No-go Theorem for Robust Acceleration in the Hyperbolic Plane",
    "review_id": "I0QC5Wsqav-",
    "input": {
      "title": "A No-go Theorem for Robust Acceleration in the Hyperbolic Plane",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The main idea and techniques presented in this paper surprised me by their originality. I have never seen this kind of arguments applied in deriving lower bounds for optimization, so, to the best of my knowledge this paper is quite novel.\n- The related work is cited properly, there are 2-3 papers in Riemannian acceleration that could be included and discussed though.\n- The paper is a complete work presenting a lower bound in the noisy setting. As the authors mention, the only limitation of this work is that does not tackle the exact gradient oracle setting (without noise).\n- The authors prove also in theorem 6 that the assumption of a function with $O(r)$ condition number in the hyperbolic plane is not restricting.\n- However, there are many parts of the paper that seem problematic to me:\n- 1. The constant $c$ which bounds the distribution should be between $0$ and $1 and potentially $c \\rightarrow 0$, in which case $\\log(c) \\rightarrow -\\infty$.\n- How is this possible to happen in Theorem 3?\n- If you do the same in Lemma 5, it means that you reduce the options by a negative number.\n- You can still put $c=1$ and vanish $\\log(c)$ term though.\n- In any case, I do not understand why this $c$-bound on the distribution is essential for the analysis.\n- 2. When $C \\rightarrow 0$ the same as above happens with the $\\log(C)$ term, which is weird since the noise is assumed to be small.\n- I particularly like the intuitive explanation in section 2.2.\n- The paper is well-written and the main results clearly stated.\n- There are points though that more explanation could be added, see my previous comments.",
    "review_points_list": [
      "The main idea and techniques presented in this paper surprised me by their originality. I have never seen this kind of arguments applied in deriving lower bounds for optimization, so, to the best of my knowledge this paper is quite novel.",
      "The related work is cited properly, there are 2-3 papers in Riemannian acceleration that could be included and discussed though.",
      "The paper is a complete work presenting a lower bound in the noisy setting. As the authors mention, the only limitation of this work is that does not tackle the exact gradient oracle setting (without noise).",
      "The authors prove also in theorem 6 that the assumption of a function with $O(r)$ condition number in the hyperbolic plane is not restricting.",
      "However, there are many parts of the paper that seem problematic to me:",
      "1. The constant $c$ which bounds the distribution should be between $0$ and $1 and potentially $c \\rightarrow 0$, in which case $\\log(c) \\rightarrow -\\infty$.",
      "How is this possible to happen in Theorem 3?",
      "If you do the same in Lemma 5, it means that you reduce the options by a negative number.",
      "You can still put $c=1$ and vanish $\\log(c)$ term though.",
      "In any case, I do not understand why this $c$-bound on the distribution is essential for the analysis.",
      "2. When $C \\rightarrow 0$ the same as above happens with the $\\log(C)$ term, which is weird since the noise is assumed to be small.",
      "I particularly like the intuitive explanation in section 2.2.",
      "The paper is well-written and the main results clearly stated.",
      "There are points though that more explanation could be added, see my previous comments."
    ]
  },
  {
    "paper_id": "2112.13287v1",
    "submission_id": "twz1QqzU0Hp",
    "submission_title": "A No-go Theorem for Robust Acceleration in the Hyperbolic Plane",
    "review_id": "waZxYYd3nVf",
    "input": {
      "title": "A No-go Theorem for Robust Acceleration in the Hyperbolic Plane",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- It is unclear to me how strong/applicable the negative result is. Specifically, does it say anything on problems like matrix completion [9, 28, 33], dictionary learning [11, 26], robust subspace recovery [39], mixture models [18]? Is acceleration not possible in these problems?  The authors might want to discuss the connections.\n- I am not sure if the proof is correct and I have some questions.\n- If the underlying optimization algorithm can only query function values but cannot get gradients, then the proof of this paper still applies and the number of the query needed would also be $\nOmega(r)$, where $r$ is the condition number.\n- From the equation right above line 235, it looks like the linear dependency on the condition number $r$ is solely due to the number of points is $n = \nexp( \nTheta(r) )$ (right below line 234) in the Hyperbolic 2-space.\n- That is, the $\nOmega(r)$ complexity does not depend on whether the algorithm has the gradient information or not, which means that the gradient information does not help!? Something wrong?\n- In this rebuttal, can the authors provide an intuition why the proof can be reduced to playing a game?\n- This paper is not self-contained from my perspective.\n- For example, the authors should provide derivations of Fact 2.\n- Also, the argument on line 170-175 does not appear to be rigorous.\n- It would be helpful if the authors can provide the details in the supplementary and/or in this rebuttal.",
    "review_points_list": [
      "It is unclear to me how strong/applicable the negative result is. Specifically, does it say anything on problems like matrix completion [9, 28, 33], dictionary learning [11, 26], robust subspace recovery [39], mixture models [18]? Is acceleration not possible in these problems?  The authors might want to discuss the connections.",
      "I am not sure if the proof is correct and I have some questions.",
      "If the underlying optimization algorithm can only query function values but cannot get gradients, then the proof of this paper still applies and the number of the query needed would also be $\nOmega(r)$, where $r$ is the condition number.",
      "From the equation right above line 235, it looks like the linear dependency on the condition number $r$ is solely due to the number of points is $n = \nexp( \nTheta(r) )$ (right below line 234) in the Hyperbolic 2-space.",
      "That is, the $\nOmega(r)$ complexity does not depend on whether the algorithm has the gradient information or not, which means that the gradient information does not help!? Something wrong?",
      "In this rebuttal, can the authors provide an intuition why the proof can be reduced to playing a game?",
      "This paper is not self-contained from my perspective.",
      "For example, the authors should provide derivations of Fact 2.",
      "Also, the argument on line 170-175 does not appear to be rigorous.",
      "It would be helpful if the authors can provide the details in the supplementary and/or in this rebuttal."
    ]
  },
  {
    "paper_id": "2112.13287v1",
    "submission_id": "twz1QqzU0Hp",
    "submission_title": "A No-go Theorem for Robust Acceleration in the Hyperbolic Plane",
    "review_id": "2SaCfhwoKW6",
    "input": {
      "title": "A No-go Theorem for Robust Acceleration in the Hyperbolic Plane",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The result is interesting and has many application for machine learning on hyperbolic space.\n- The proof technique is clever and is an overall nice construction.\n- The proofs and constructions are clear and the intuition is well explained and provides good insight.\n- The proof is currently a bit limited in scope. In particular, it may be helpful to touch upon cases where the curvature $K$ of the hyperbolic space is not $-1$. These have seen practical use, but I expect the result to be quite similar.\n- The paper is compact and well structured, and the central result is important both from a theoretical and practical standpoint.\n- I advocate acceptance.",
    "review_points_list": [
      "The result is interesting and has many application for machine learning on hyperbolic space.",
      "The proof technique is clever and is an overall nice construction.",
      "The proofs and constructions are clear and the intuition is well explained and provides good insight.",
      "The proof is currently a bit limited in scope. In particular, it may be helpful to touch upon cases where the curvature $K$ of the hyperbolic space is not $-1$. These have seen practical use, but I expect the result to be quite similar.",
      "The paper is compact and well structured, and the central result is important both from a theoretical and practical standpoint.",
      "I advocate acceptance."
    ]
  },
  {
    "paper_id": "2112.13287v1",
    "submission_id": "twz1QqzU0Hp",
    "submission_title": "A No-go Theorem for Robust Acceleration in the Hyperbolic Plane",
    "review_id": "q-j8eRFShL",
    "input": {
      "title": "A No-go Theorem for Robust Acceleration in the Hyperbolic Plane",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Because the number of queries we should expect to have if acceleration in the hyperbolic plane is possible is only asserted, rather than shown (sentence at line 151), I am having some trouble reconciling the 'no robust acceleration' claim with the guarantee of Theorem 3 -- maybe it would be helpful if this was spelled out in detail (i.e. both a precise illustration of this claim in line 151 and a precise definition of what is taken to be an accelerated method in this context).\n- In particular, is the claim '... Nesterov-like acceleration in the hyperbolic plane [is] possible' equivalent to the existence of a guarantee like the one in Theorem 2? I think this equation is not labeled correctly ($d$ should be the squared distance to the optimum / the squared diameter of the domain; I'm looking at Theorem 7 in the cited reference [13]).\n- Then if I interpret a formula like this in the context here, we have $L = r$ and $d = r^2', and ignoring the noise term and the local linear rate would give a formula $\\mathrm{dist}(x_k, x^\\star) \\leq r^3 / k^2$, so to get within distance $1$ wouldn't we expect to need time $O(r^{3/2})'? (should it be within distance $r$ instead?)\n- If we're using the local linear rate here to get the prediction, this feels like it might not preclude the existence of accelerated methods.\n- If the intention was rather to demonstrate that the lower bound proved here is met by a non-accelerated gradient descent method (hence ruling out the possibility for acceleration to exist), it might be nice to have this discussed in detail as well.\n- I am not up-to-date on the latest rates for smooth strongly geodesically convex optimization, but if I look at the cited reference [37], (Theorem 13 and Theorem 15), it seems like these rates are not necessarily inconsistent with the possibility of having an accelerated method (the key is that relative to the Euclidean setting, these rates may have extra unsavory dependences involving $\\zeta(\\kappa, r) \\approx r$ here; I would appreciate correction if sharper rates have already been established).\n- In general, the possibility of having these 'extra constants' appear in the rates relative to the Euclidean setting makes me feel that it may be hard to use a query complexity lower bound to show the impossibility of acceleration without better upper bounds for vanilla gradient descent: for example, adding an 'extra $r$' into the numerator as above (corresponding to a curvature term like the $\\zeta(\\kappa, r)$ in [37]) would lead us to expect to need $r$ queries to get within distance $O(r)$ with an accelerated method, which would be consistent with Theorem 3's lower bound.\n- I would appreciate some clarification on these points (I apologize if I am missing something obvious).\n- It would be nice to see additional comparisons to some pieces of related work, e.g. [1-2] below -- do these works suffer from the same limitations as the ones mentioned in lines 30-38?\n- Have the authors considered higher-dimensional analogs of their lower bound -- for example for optimization on the hyperbolic space $\\mathbb{H}^d$, or Hadamard manifolds of negative curvature? This feels out-of-scope, but it may be interesting to know whether the same ideas have direct implications for general negatively-curved spaces.\n- Line 149: missing a 'plane'\n- Line 151: might want to consistently call this the 'plane' since 'models' for the hyperbolic plane aren't discussed?\n- Theorem 3: first 'at' should be 'and'?\n- Line 212: 'expected logarithm of the number of options'\n- Proof of Theorem 3: the specific simplification here requires $r \\geq 1'; maybe express this in the hypotheses\n- Equation before line 235: loose parenthesis in the numerator\n- Line 235: 'at' should be 'and'",
    "review_points_list": [
      "Because the number of queries we should expect to have if acceleration in the hyperbolic plane is possible is only asserted, rather than shown (sentence at line 151), I am having some trouble reconciling the 'no robust acceleration' claim with the guarantee of Theorem 3 -- maybe it would be helpful if this was spelled out in detail (i.e. both a precise illustration of this claim in line 151 and a precise definition of what is taken to be an accelerated method in this context).",
      "In particular, is the claim '... Nesterov-like acceleration in the hyperbolic plane [is] possible' equivalent to the existence of a guarantee like the one in Theorem 2? I think this equation is not labeled correctly ($d$ should be the squared distance to the optimum / the squared diameter of the domain; I'm looking at Theorem 7 in the cited reference [13]).",
      "Then if I interpret a formula like this in the context here, we have $L = r$ and $d = r^2', and ignoring the noise term and the local linear rate would give a formula $\\mathrm{dist}(x_k, x^\\star) \\leq r^3 / k^2$, so to get within distance $1$ wouldn't we expect to need time $O(r^{3/2})'? (should it be within distance $r$ instead?)",
      "If we're using the local linear rate here to get the prediction, this feels like it might not preclude the existence of accelerated methods.",
      "If the intention was rather to demonstrate that the lower bound proved here is met by a non-accelerated gradient descent method (hence ruling out the possibility for acceleration to exist), it might be nice to have this discussed in detail as well.",
      "I am not up-to-date on the latest rates for smooth strongly geodesically convex optimization, but if I look at the cited reference [37], (Theorem 13 and Theorem 15), it seems like these rates are not necessarily inconsistent with the possibility of having an accelerated method (the key is that relative to the Euclidean setting, these rates may have extra unsavory dependences involving $\\zeta(\\kappa, r) \\approx r$ here; I would appreciate correction if sharper rates have already been established).",
      "In general, the possibility of having these 'extra constants' appear in the rates relative to the Euclidean setting makes me feel that it may be hard to use a query complexity lower bound to show the impossibility of acceleration without better upper bounds for vanilla gradient descent: for example, adding an 'extra $r$' into the numerator as above (corresponding to a curvature term like the $\\zeta(\\kappa, r)$ in [37]) would lead us to expect to need $r$ queries to get within distance $O(r)$ with an accelerated method, which would be consistent with Theorem 3's lower bound.",
      "I would appreciate some clarification on these points (I apologize if I am missing something obvious).",
      "It would be nice to see additional comparisons to some pieces of related work, e.g. [1-2] below -- do these works suffer from the same limitations as the ones mentioned in lines 30-38?",
      "Have the authors considered higher-dimensional analogs of their lower bound -- for example for optimization on the hyperbolic space $\\mathbb{H}^d$, or Hadamard manifolds of negative curvature? This feels out-of-scope, but it may be interesting to know whether the same ideas have direct implications for general negatively-curved spaces.",
      "Line 149: missing a 'plane'",
      "Line 151: might want to consistently call this the 'plane' since 'models' for the hyperbolic plane aren't discussed?",
      "Theorem 3: first 'at' should be 'and'?",
      "Line 212: 'expected logarithm of the number of options'",
      "Proof of Theorem 3: the specific simplification here requires $r \\geq 1'; maybe express this in the hypotheses",
      "Equation before line 235: loose parenthesis in the numerator",
      "Line 235: 'at' should be 'and'"
    ]
  },
  {
    "paper_id": "2106.04913v1",
    "submission_id": "yLyXqdsYho",
    "submission_title": "On Margin-Based Cluster Recovery with Oracle Queries",
    "review_id": "IatEXIPn73F",
    "input": {
      "title": "On Margin-Based Cluster Recovery with Oracle Queries",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This work makes significant progress on a natural, important problem in both clustering and active learning.\n- The results are very clean, and likely of broad interest to the learning theory community.\n- The techniques, while relatively simple, are an interesting mix of combinatorial, probabilistic, and inference based methods that could easily be of use in future work.\n- The paper is well-written, and has careful analysis of their relation to margin parameters in prior work.\n- The proofs I checked seemed sound, and no outlandish claims are made otherwise.\n- My only real complaints are due to a few missing references.\n- The \u201cConvex Hull Expansion Trick\u201d is not novel.\n- The same trick was introduced by Hopkins, Kane, Lovett, and Mahajan (COLT 2020) to bound the inference dimension of clusters (when considering halfspaces under TNC noise).\n- However their analysis recovers a slightly worse query complexity bound, and may be of narrower scope than the general pseudometric variant considered in this work.\n- The analysis is also quite different, as HKLM rely on LP duality.\n- Second, the coslicing dimension lower bound generalizes a result due to Dasgupta (in \u201cAnalysis of a greedy active learning strategy\u201d).\n- This should be mentioned.\n- In fact I would say it is a strength of the result, the authors show that Dasgupta\u2019s classic bound is essentially the only barrier to cluster recovery in this setting!\n- Finally a few minor notes:\n- Usually query complexity is included in computational complexity, so it doesn\u2019t make much sense to say your algorithm uses exp(m) queries but runs in poly(m) time.\n- Plus, the regime you consider is only really interesting for n >> 2^m (otherwise you can\u2019t do inference), so poly(m) vs exp(m) runtime doesn\u2019t really make a difference anyway.\n- I think the terminology \u201coutputs C deterministically",
    "review_points_list": [
      "This work makes significant progress on a natural, important problem in both clustering and active learning.",
      "The results are very clean, and likely of broad interest to the learning theory community.",
      "The techniques, while relatively simple, are an interesting mix of combinatorial, probabilistic, and inference based methods that could easily be of use in future work.",
      "The paper is well-written, and has careful analysis of their relation to margin parameters in prior work.",
      "The proofs I checked seemed sound, and no outlandish claims are made otherwise.",
      "My only real complaints are due to a few missing references.",
      "The \u201cConvex Hull Expansion Trick\u201d is not novel.",
      "The same trick was introduced by Hopkins, Kane, Lovett, and Mahajan (COLT 2020) to bound the inference dimension of clusters (when considering halfspaces under TNC noise).",
      "However their analysis recovers a slightly worse query complexity bound, and may be of narrower scope than the general pseudometric variant considered in this work.",
      "The analysis is also quite different, as HKLM rely on LP duality.",
      "Second, the coslicing dimension lower bound generalizes a result due to Dasgupta (in \u201cAnalysis of a greedy active learning strategy\u201d).",
      "This should be mentioned.",
      "In fact I would say it is a strength of the result, the authors show that Dasgupta\u2019s classic bound is essentially the only barrier to cluster recovery in this setting!",
      "Finally a few minor notes:",
      "Usually query complexity is included in computational complexity, so it doesn\u2019t make much sense to say your algorithm uses exp(m) queries but runs in poly(m) time.",
      "Plus, the regime you consider is only really interesting for n >> 2^m (otherwise you can\u2019t do inference), so poly(m) vs exp(m) runtime doesn\u2019t really make a difference anyway.",
      "I think the terminology \u201coutputs C deterministically"
    ]
  },
  {
    "paper_id": "2106.04913v1",
    "submission_id": "yLyXqdsYho",
    "submission_title": "On Margin-Based Cluster Recovery with Oracle Queries",
    "review_id": "KGAtIR_Pfp0",
    "input": {
      "title": "On Margin-Based Cluster Recovery with Oracle Queries",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Although all three of [Ashtiani et al. \u201816], [Bressan et al. \u201820], and this work manage to only use O(log n) queries, this way of writing the bound tunnel visions on the dependence on the number of points n and ignores the number of clusters k and the margin gamma.\n- This way of writing the bound tunnel visions on the dependence on the number of points n ignores the number of clusters k and the margin gamma.\n- [Ashtiani et al. \u201816]: O(k log n + k^2 / gamma^4 log k)\n- [Bressan et al. \u201820]: O(k log n (k^2 m^2 log k + 2^m (m / gamma log (m / gamma))^m)\n- This work: O(k^2 m^5 (1 + 1/gamma)^m log (1 + 1/gamma) log n)\n- This work has better dependence compared to [Bressan et al.\u2019 20] but worse dependence compared to [Ashtiani et al. \u201816].\n- This work is an improvement to the ellipsoid margin case.\n- Ellipsoids make sense over spheres when one expects the features to be on different scales.\n- The appearance of m in the exponent makes them not that useful.\n- The problem dimension is chosen to be quite small: 2, 4, 6, or 8.\n- This paper is missing an experimental section, and so the question of how the proposed algorithm practically compares to its two predecessors is left open.\n- Exactly how much the generalized margin properties allow one to capture additional interesting cases is worth considering.\n- The paper proves that several other properties imply the one-versus-all margin, including the SVM margin, alpha-center proximity, and (1 + eps)-perturbation resilience.\n- This result can be viewed as a nice theoretical contribution on past work.\n- The practical consequences were given a closer look, but I'd still lean towards acceptance to NeurIPS.\n- Line 243: Equation (2) does not appear to be centered properly.",
    "review_points_list": [
      "Although all three of [Ashtiani et al. \u201816], [Bressan et al. \u201820], and this work manage to only use O(log n) queries, this way of writing the bound tunnel visions on the dependence on the number of points n and ignores the number of clusters k and the margin gamma.",
      "This way of writing the bound tunnel visions on the dependence on the number of points n ignores the number of clusters k and the margin gamma.",
      "[Ashtiani et al. \u201816]: O(k log n + k^2 / gamma^4 log k)",
      "[Bressan et al. \u201820]: O(k log n (k^2 m^2 log k + 2^m (m / gamma log (m / gamma))^m)",
      "This work: O(k^2 m^5 (1 + 1/gamma)^m log (1 + 1/gamma) log n)",
      "This work has better dependence compared to [Bressan et al.\u2019 20] but worse dependence compared to [Ashtiani et al. \u201816].",
      "This work is an improvement to the ellipsoid margin case.",
      "Ellipsoids make sense over spheres when one expects the features to be on different scales.",
      "The appearance of m in the exponent makes them not that useful.",
      "The problem dimension is chosen to be quite small: 2, 4, 6, or 8.",
      "This paper is missing an experimental section, and so the question of how the proposed algorithm practically compares to its two predecessors is left open.",
      "Exactly how much the generalized margin properties allow one to capture additional interesting cases is worth considering.",
      "The paper proves that several other properties imply the one-versus-all margin, including the SVM margin, alpha-center proximity, and (1 + eps)-perturbation resilience.",
      "This result can be viewed as a nice theoretical contribution on past work.",
      "The practical consequences were given a closer look, but I'd still lean towards acceptance to NeurIPS.",
      "Line 243: Equation (2) does not appear to be centered properly."
    ]
  },
  {
    "paper_id": "2106.04913v1",
    "submission_id": "yLyXqdsYho",
    "submission_title": "On Margin-Based Cluster Recovery with Oracle Queries",
    "review_id": "yjCh5d1bvEf",
    "input": {
      "title": "On Margin-Based Cluster Recovery with Oracle Queries",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The first problem considered is where a label is defined by a convex body with a margin, such that if the convex body is expanded outwards by a small factor times its diameter, it does not intersect any new points.\n- The algorithm to find a cluster samples points, draws a convex body around those of the same label, and then grows the body by a constant factor, about the center of mass of the points.\n- The authors show with high probability the new body either contains a significant number of new points of the same label (or contains all points of the label).\n- This is done by combining two separate combinatorical results, the first by Naszodi which bounds the number of vertices of the body, and the second a recent breakthrough of Kupavskii which gives the VC-dimension of this object.\n- While the overview is quite straightforward, the details are not.\n- The authors then consider more general spaces, and define a one-vs-all margin similar to above, but without the requirements of Euclidean space, or even convexity.\n- They show that it generalizes the clustering notions of center proximity and perturbation stability.\n- They then demonstrate that such a margin implies learnability, and show how to plug it in to an analogue of the previous algorithm, to again learn clusters using a small number of label queries.\n- This demonstrates that their framework can be applied to a range of setting.\n- I found the results in this paper to be interesting and also deep while still being accessible.\n- I would anticipate them being applied to other learning problems in related fields as well.\n- Minor comments:\n- I think the authors should expand on the comment in line 245 on fixing the pseudometrics in advance, and how this differs from what is done in line 141.\n- I found this confusing.\n- The abstract and introduction inexplicably seem to think that R^m and Euclidean space are the same thing.\n- The opening assertion that queries identifying a point's cluster and queries determining whether a pair are in the same cluster are the equivalent, but this is only true if k is small and one a representative of each cluster at hand.\n- Typos: k-uple should be k-tuple.",
    "review_points_list": [
      "The first problem considered is where a label is defined by a convex body with a margin, such that if the convex body is expanded outwards by a small factor times its diameter, it does not intersect any new points.",
      "The algorithm to find a cluster samples points, draws a convex body around those of the same label, and then grows the body by a constant factor, about the center of mass of the points.",
      "The authors show with high probability the new body either contains a significant number of new points of the same label (or contains all points of the label).",
      "This is done by combining two separate combinatorical results, the first by Naszodi which bounds the number of vertices of the body, and the second a recent breakthrough of Kupavskii which gives the VC-dimension of this object.",
      "While the overview is quite straightforward, the details are not.",
      "The authors then consider more general spaces, and define a one-vs-all margin similar to above, but without the requirements of Euclidean space, or even convexity.",
      "They show that it generalizes the clustering notions of center proximity and perturbation stability.",
      "They then demonstrate that such a margin implies learnability, and show how to plug it in to an analogue of the previous algorithm, to again learn clusters using a small number of label queries.",
      "This demonstrates that their framework can be applied to a range of setting.",
      "I found the results in this paper to be interesting and also deep while still being accessible.",
      "I would anticipate them being applied to other learning problems in related fields as well.",
      "Minor comments:",
      "I think the authors should expand on the comment in line 245 on fixing the pseudometrics in advance, and how this differs from what is done in line 141.",
      "I found this confusing.",
      "The abstract and introduction inexplicably seem to think that R^m and Euclidean space are the same thing.",
      "The opening assertion that queries identifying a point's cluster and queries determining whether a pair are in the same cluster are the equivalent, but this is only true if k is small and one a representative of each cluster at hand.",
      "Typos: k-uple should be k-tuple."
    ]
  },
  {
    "paper_id": "2111.08550v3",
    "submission_id": "z36cUrI0jKJ",
    "submission_title": "On Effective Scheduling of Model-based Reinforcement Learning",
    "review_id": "ef4d_VUgf1z",
    "input": {
      "title": "On Effective Scheduling of Model-based Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is good at conveying its ideas.\n- The introduction section clearly states what we are going to be dealing with.\n- The related work section does a good job of summarizing the different ways in which models have been used in MBRL.\n- I am not sure if the theoretical analysis should be placed in such a prominent place, given that it is somewhat dense with notation.\n- Perhaps the results of the analysis can be stated earlier on, or be highlighted more from the rest of this section, such that the first-time reader does not immediately have to confront the math right at the stage when they are most eager to find out about the implementation of the ideas presented in the introduction.\n- The methods section does a good job of setting up the hyper-MDP.\n- I have some questions about the execution:\n- Algorithm 1 starts with 'initialize MBPO'. Does that mean the model and policy parameters are re-initialized periodically during the lifetime of the whole algorithm?\n- The advantage calculation uses the average return of MBPO trained with the same amount of real data from original parameters. Does this mean using AutoMBPO requires logs from a previous MBPO training run (or a separate process training plain MBPO in parallel and providing such logs)?\n- The experiments section is well-designed.\n- The comparative results are in favor of the method.\n- The hyper-parameter schedules and the ablation study over the hyper-parameters are both welcome inclusions.\n- That being said, some points are unclear to me:\n- A little confused by the experiments.\n- Does AutoMBPO here mean an experiment where both MBPO and its hyper-controller are being trained in tandem, or has AutoMBPO been trained in advance, and only being applied here? If the two are being trained jointly, shouldn't we see periodic drops in performance, since MBPO gets re-initialized every time a new hyper-episode is started, according to Algorithm 1?\n- In case we are indeed training MBPO and its hyper-controller in parallel, I am a little surprised that the scheduling curves in fig. 3 can make sense throughout.\n- I'd expect the hyper-controller to make errors in the beginning of training.\n- Can you comment on this?\n- How were the hyper-parameters set for plain MBPO?\n- Is it the result of a hyper-parameter search, or carried over from previous work?\n- If they are carried over, I would be curious about the improvement of AutoMBPO over a near-optimal fixed hyper-parameter setup found by a hyper-parameter search.\n- This is especially true of the bullet-based environments which MBPO was not originally applied to.\n- All in all, this is a good paper and it would benefit the research community to accept it.\n- Do the theoretical results extend to stochastic transition functions?\n- Is it right to refer to the hyper-parameter setting problem as an MDP, given that the state does not fully describe all of the information in the system?\n- I think POMDP would be more accurate here.",
    "review_points_list": [
      "The paper is good at conveying its ideas.",
      "The introduction section clearly states what we are going to be dealing with.",
      "The related work section does a good job of summarizing the different ways in which models have been used in MBRL.",
      "I am not sure if the theoretical analysis should be placed in such a prominent place, given that it is somewhat dense with notation.",
      "Perhaps the results of the analysis can be stated earlier on, or be highlighted more from the rest of this section, such that the first-time reader does not immediately have to confront the math right at the stage when they are most eager to find out about the implementation of the ideas presented in the introduction.",
      "The methods section does a good job of setting up the hyper-MDP.",
      "I have some questions about the execution:",
      "Algorithm 1 starts with 'initialize MBPO'. Does that mean the model and policy parameters are re-initialized periodically during the lifetime of the whole algorithm?",
      "The advantage calculation uses the average return of MBPO trained with the same amount of real data from original parameters. Does this mean using AutoMBPO requires logs from a previous MBPO training run (or a separate process training plain MBPO in parallel and providing such logs)?",
      "The experiments section is well-designed.",
      "The comparative results are in favor of the method.",
      "The hyper-parameter schedules and the ablation study over the hyper-parameters are both welcome inclusions.",
      "That being said, some points are unclear to me:",
      "A little confused by the experiments.",
      "Does AutoMBPO here mean an experiment where both MBPO and its hyper-controller are being trained in tandem, or has AutoMBPO been trained in advance, and only being applied here? If the two are being trained jointly, shouldn't we see periodic drops in performance, since MBPO gets re-initialized every time a new hyper-episode is started, according to Algorithm 1?",
      "In case we are indeed training MBPO and its hyper-controller in parallel, I am a little surprised that the scheduling curves in fig. 3 can make sense throughout.",
      "I'd expect the hyper-controller to make errors in the beginning of training.",
      "Can you comment on this?",
      "How were the hyper-parameters set for plain MBPO?",
      "Is it the result of a hyper-parameter search, or carried over from previous work?",
      "If they are carried over, I would be curious about the improvement of AutoMBPO over a near-optimal fixed hyper-parameter setup found by a hyper-parameter search.",
      "This is especially true of the bullet-based environments which MBPO was not originally applied to.",
      "All in all, this is a good paper and it would benefit the research community to accept it.",
      "Do the theoretical results extend to stochastic transition functions?",
      "Is it right to refer to the hyper-parameter setting problem as an MDP, given that the state does not fully describe all of the information in the system?",
      "I think POMDP would be more accurate here."
    ]
  },
  {
    "paper_id": "2111.08550v3",
    "submission_id": "z36cUrI0jKJ",
    "submission_title": "On Effective Scheduling of Model-based Reinforcement Learning",
    "review_id": "c4Gk6yhl3M",
    "input": {
      "title": "On Effective Scheduling of Model-based Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The MBPO algorithm and DYNA-style RL algorithms are very popular at the moment, so I can see this work being of interest to the deep RL community.\n- The outer policy does seem to have a widespread improvement on standard MBPO in the mean and the theoretical analysis looks correct.\n- I see this paper more as an analysis into hyperparameters rather than a practical MBRL algorithm.\n- The need to train a PPO outer loop to me throws away all the sample efficiency that MBRL is supposed to provide, and judging form the hyperparameters in the appendix the full algorithm requires ~1e6 samples that model-free RL usually requires.\n- I would be useful to see the 'full' training curves (including the outer loop) to see who effective the outer RL is.\n- The paper often refers to this method as 'simple yet effective'. I would disagree that a bilevel deep RL problem is 'simple'.\n- 'Simple yet effective' also a suggests that its a surprise that this method works, whereas for me it is more a question of whether the extensive computational requirements are worthwhile for the task in hand.\n- It is also discussed that the empirical results verify that the theory is correct and that it is optimal to slowly increase the data percentage from low to high.\n- However, in the experiements it looks like the initial value of the ratio is set to 0.05 (Table 4), so the policy appears biased to start low.\n- I think a more uniform initial exploration is required before that claim can be made.\n- A rather specific observation I would like some clarification on: on HopperBullet the ratio quickly goes to 1.0, which suggests that MBPO should behave the same as SAC(20) within 10% of training (Fig 3), yet in the performance (Fig 2) AutoMBPO is worse that SAC(20) for the first ~10% but then is better for the remaining 90%.\n- Shouldn't the performance be the same?\n- Given the amount of computation required to run this bi-level optimization, it seems the performance increase is not really statistically significant apart from on WalkerBullet.\n- I think some discussion of the statistical significance of the results (since requires so much more computation) would benefit the reader.\n- Regarding the baselines, I would appreciate more of a discussion in the appendix regarding how PBT and RoR are implemented as baselines.",
    "review_points_list": [
      "The MBPO algorithm and DYNA-style RL algorithms are very popular at the moment, so I can see this work being of interest to the deep RL community.",
      "The outer policy does seem to have a widespread improvement on standard MBPO in the mean and the theoretical analysis looks correct.",
      "I see this paper more as an analysis into hyperparameters rather than a practical MBRL algorithm.",
      "The need to train a PPO outer loop to me throws away all the sample efficiency that MBRL is supposed to provide, and judging form the hyperparameters in the appendix the full algorithm requires ~1e6 samples that model-free RL usually requires.",
      "I would be useful to see the 'full' training curves (including the outer loop) to see who effective the outer RL is.",
      "The paper often refers to this method as 'simple yet effective'. I would disagree that a bilevel deep RL problem is 'simple'.",
      "'Simple yet effective' also a suggests that its a surprise that this method works, whereas for me it is more a question of whether the extensive computational requirements are worthwhile for the task in hand.",
      "It is also discussed that the empirical results verify that the theory is correct and that it is optimal to slowly increase the data percentage from low to high.",
      "However, in the experiements it looks like the initial value of the ratio is set to 0.05 (Table 4), so the policy appears biased to start low.",
      "I think a more uniform initial exploration is required before that claim can be made.",
      "A rather specific observation I would like some clarification on: on HopperBullet the ratio quickly goes to 1.0, which suggests that MBPO should behave the same as SAC(20) within 10% of training (Fig 3), yet in the performance (Fig 2) AutoMBPO is worse that SAC(20) for the first ~10% but then is better for the remaining 90%.",
      "Shouldn't the performance be the same?",
      "Given the amount of computation required to run this bi-level optimization, it seems the performance increase is not really statistically significant apart from on WalkerBullet.",
      "I think some discussion of the statistical significance of the results (since requires so much more computation) would benefit the reader.",
      "Regarding the baselines, I would appreciate more of a discussion in the appendix regarding how PBT and RoR are implemented as baselines."
    ]
  },
  {
    "paper_id": "2111.08550v3",
    "submission_id": "z36cUrI0jKJ",
    "submission_title": "On Effective Scheduling of Model-based Reinforcement Learning",
    "review_id": "KvnNha4Oe-E",
    "input": {
      "title": "On Effective Scheduling of Model-based Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- - The paper makes an effort to analyze the effect of real data ratio on the performance of MBRL.\n- - The analysis is based on the one by Munos and Szepesv\u00e1ri but the author did a good job in modifying the proof in the mixed data setting.\n- - The author proposes a hyper-parameters tuning method based on Reinforcement Learning.\n- - Although the idea is not new, the author did a good job by choosing the appropriate MDP setup.\n- - The experiments show good results of their proposed method.\n- - Overall, the paper is well written.\n- - The way the authors present the paper is easy to follow.\n- - There is one problem with the comment that the author made about their bound.\n- - Since Nreal = N \u00b7 |A| \u00b7 \u03b2, the ratio \u03b2/Nreal is a constant.\n- - Thus it is not clear how gradually increasing the real ratio \u03b2 is promising to achieve good performance according to the upper bound as what the authors claim.\n- - The proposed algorithm and the theoretical analysis do not have any relation.\n- - The analysis only shows that the real data ratio plays an important role in MBRL.\n- - Besides, the theory does not provide any hints in the design of the proposed algorithm.\n- - However, the authors claim that their algorithm is inspired by the theory, which is not totally correct in my humble opinion.\n- - The idea of using RL to tune hyper-parameters is not new.\n- - So not a novel contribution.\n- - Intuitively, the paper might get trapped in a no-ending route.\n- - In detail, the purpose of the paper is to improve MBRL by dynamically tuning hyper-parameters.\n- - However, the authors again propose another RL algorithm to achieve this purpose.\n- - How are you going to efficiently tune the hyper-parameters of this new RL algorithm?\n- - Please let me know if I miss something here.\n- - Have you tried your model on Humanoid and if so what was the result?",
    "review_points_list": [
      "- The paper makes an effort to analyze the effect of real data ratio on the performance of MBRL.",
      "- The analysis is based on the one by Munos and Szepesv\u00e1ri but the author did a good job in modifying the proof in the mixed data setting.",
      "- The author proposes a hyper-parameters tuning method based on Reinforcement Learning.",
      "- Although the idea is not new, the author did a good job by choosing the appropriate MDP setup.",
      "- The experiments show good results of their proposed method.",
      "- Overall, the paper is well written.",
      "- The way the authors present the paper is easy to follow.",
      "- There is one problem with the comment that the author made about their bound.",
      "- Since Nreal = N \u00b7 |A| \u00b7 \u03b2, the ratio \u03b2/Nreal is a constant.",
      "- Thus it is not clear how gradually increasing the real ratio \u03b2 is promising to achieve good performance according to the upper bound as what the authors claim.",
      "- The proposed algorithm and the theoretical analysis do not have any relation.",
      "- The analysis only shows that the real data ratio plays an important role in MBRL.",
      "- Besides, the theory does not provide any hints in the design of the proposed algorithm.",
      "- However, the authors claim that their algorithm is inspired by the theory, which is not totally correct in my humble opinion.",
      "- The idea of using RL to tune hyper-parameters is not new.",
      "- So not a novel contribution.",
      "- Intuitively, the paper might get trapped in a no-ending route.",
      "- In detail, the purpose of the paper is to improve MBRL by dynamically tuning hyper-parameters.",
      "- However, the authors again propose another RL algorithm to achieve this purpose.",
      "- How are you going to efficiently tune the hyper-parameters of this new RL algorithm?",
      "- Please let me know if I miss something here.",
      "- Have you tried your model on Humanoid and if so what was the result?"
    ]
  },
  {
    "paper_id": "1804.08450v1",
    "submission_id": "zzdf0CirJM4",
    "submission_title": "Batch Active Learning at Scale",
    "review_id": "j_UAA5BRei1",
    "input": {
      "title": "Batch Active Learning at Scale",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The suggested method seems novel.\n- Compared to the CoreSet algorithm in active learning, which computes a cover of all unlabeled pool points, Cluster-Margin essentially approximates a cover of mainly *low-confidence* pool points.\n- The submission seems technically sound.\n- The experiment results are impressive.\n- Especially, the results on Open Images are impressive, but also the results on CIFAR-10 and CIFAR-100 show good improvements over the baselines.\n- The Open Images results are great because a real-life dataset has other characteristics than smaller curated datasets ala CIFAR-10, etc, which shows promise for real-world applications of the proposed method.\n- The paper is very well written.\n- The introduction and related work are great.\n- The introduction is lacking citations, though.\n- The algorithm and experiment section are also clear and of high quality.\n- The theory section is difficult to understand and only seems to give a high-level overview of 'Cluster-MarginV'.\n- The appendix is clearer on that.\n- I believe it might be worth extracting the theory section into a separate contribution.\n- I believe the algorithm and results are sufficient on their own.\n- The fact that the theoretical motivation comes at the very end seems telling.\n- I assume the paper will be of significance for practitioners.\n- An expanded theory section could be interesting overall.\n- It would be nice to have more results on additional large datasets.\n- On the other hand, the paper already provides results for the common three datasets (CIFAR-10, CIFAR-100, and SVHN), and then provides results for the large and high-dimensional Open Images Dataset.\n- Within the constraints, this seems absolutely reasonable.\n- Strengths:\n- method novel\n- very well written\n- experiments convincing: great results on large real-life datasets\n- Potential improvements:\n- the introduction might deserve more citations\n- theoretical motivation needs to be more fleshed out (it feels a bit tacked on in its placement in the paper)\n- Questions:\n- 1. Were there any experiments run that recompute the embeddings after every acquisition round?\n- This could improve the performance as the quality of the embeddings ought to improve as more labelled data is used for training (esp given the large batch sizes).\n- 2. Could Accuracy be provided instead of mAP for the CIFAR-10, CIFAR-100 and SVHN results?\n- It is very hard to compare results as accuracy is the usual metric, and plots are not provided in the appendix either.\n- I would be happy to increase my score if the above questions are answered.\n- Algorithm 2: line 5: $HAC(E_X, \text{\normalsize \u03b5}, \text{\normalsize\u221e})$: should the last argument be 0 instead of $\text{\normalsize\u221e}$? Otherwise, Algorithm 1 will early out right away in line 1.\n- Typos:",
    "review_points_list": [
      "The suggested method seems novel.",
      "Compared to the CoreSet algorithm in active learning, which computes a cover of all unlabeled pool points, Cluster-Margin essentially approximates a cover of mainly *low-confidence* pool points.",
      "The submission seems technically sound.",
      "The experiment results are impressive.",
      "Especially, the results on Open Images are impressive, but also the results on CIFAR-10 and CIFAR-100 show good improvements over the baselines.",
      "The Open Images results are great because a real-life dataset has other characteristics than smaller curated datasets ala CIFAR-10, etc, which shows promise for real-world applications of the proposed method.",
      "The paper is very well written.",
      "The introduction and related work are great.",
      "The introduction is lacking citations, though.",
      "The algorithm and experiment section are also clear and of high quality.",
      "The theory section is difficult to understand and only seems to give a high-level overview of 'Cluster-MarginV'.",
      "The appendix is clearer on that.",
      "I believe it might be worth extracting the theory section into a separate contribution.",
      "I believe the algorithm and results are sufficient on their own.",
      "The fact that the theoretical motivation comes at the very end seems telling.",
      "I assume the paper will be of significance for practitioners.",
      "An expanded theory section could be interesting overall.",
      "It would be nice to have more results on additional large datasets.",
      "On the other hand, the paper already provides results for the common three datasets (CIFAR-10, CIFAR-100, and SVHN), and then provides results for the large and high-dimensional Open Images Dataset.",
      "Within the constraints, this seems absolutely reasonable.",
      "Strengths:",
      "method novel",
      "very well written",
      "experiments convincing: great results on large real-life datasets",
      "Potential improvements:",
      "the introduction might deserve more citations",
      "theoretical motivation needs to be more fleshed out (it feels a bit tacked on in its placement in the paper)",
      "Questions:",
      "1. Were there any experiments run that recompute the embeddings after every acquisition round?",
      "This could improve the performance as the quality of the embeddings ought to improve as more labelled data is used for training (esp given the large batch sizes).",
      "2. Could Accuracy be provided instead of mAP for the CIFAR-10, CIFAR-100 and SVHN results?",
      "It is very hard to compare results as accuracy is the usual metric, and plots are not provided in the appendix either.",
      "I would be happy to increase my score if the above questions are answered.",
      "Algorithm 2: line 5: $HAC(E_X, \text{\normalsize \u03b5}, \text{\normalsize\u221e})$: should the last argument be 0 instead of $\text{\normalsize\u221e}$? Otherwise, Algorithm 1 will early out right away in line 1.",
      "Typos:"
    ]
  },
  {
    "paper_id": "1804.08450v1",
    "submission_id": "zzdf0CirJM4",
    "submission_title": "Batch Active Learning at Scale",
    "review_id": "MyEXiCjBTbE",
    "input": {
      "title": "Batch Active Learning at Scale",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper proposes a very simple method to select samples for active learning. The method makes sense.\n- However, several severe issues are here.\n- The paper claims it aims to select very large batches for active learning, like 100K-1M. That sounds violating the principle of active learning.\n- AL is intended to reduce the number of labels (and labeling cost) as much as possible.\n- Why not just run batch learning on the large dataset?\n- Why do you use AL?\n- The paper claims that their batch selection is very scalable.\n- However, the most costly part --- the HAC step, takes a complexity of O(n^2 log(n)) , which is very expensive and not scalable at all. see line 145.\n- Although the paper says the HAC can be accelerated in practice from multi-thread implementation.\n- The complexity is still there, more than quadratic to the number of candidates.\n- Although the selection step is fast, the overall efficiency is very limited, given that the pool can be orders of magnitude larger than a batch.\n- The paper claims BatchBALD (line 86) is infeasible for large batch size in practice.\n- I think this is a wrong claim.\n- BatchBALD is greedy heuristics, and the point is added into the batch one by one.\n- It scales linearly in the size of the batch and data pool.",
    "review_points_list": [
      "The paper proposes a very simple method to select samples for active learning. The method makes sense.",
      "However, several severe issues are here.",
      "The paper claims it aims to select very large batches for active learning, like 100K-1M. That sounds violating the principle of active learning.",
      "AL is intended to reduce the number of labels (and labeling cost) as much as possible.",
      "Why not just run batch learning on the large dataset?",
      "Why do you use AL?",
      "The paper claims that their batch selection is very scalable.",
      "However, the most costly part --- the HAC step, takes a complexity of O(n^2 log(n)) , which is very expensive and not scalable at all. see line 145.",
      "Although the paper says the HAC can be accelerated in practice from multi-thread implementation.",
      "The complexity is still there, more than quadratic to the number of candidates.",
      "Although the selection step is fast, the overall efficiency is very limited, given that the pool can be orders of magnitude larger than a batch.",
      "The paper claims BatchBALD (line 86) is infeasible for large batch size in practice.",
      "I think this is a wrong claim.",
      "BatchBALD is greedy heuristics, and the point is added into the batch one by one.",
      "It scales linearly in the size of the batch and data pool."
    ]
  },
  {
    "paper_id": "2106.12688v1",
    "submission_id": "uZJJFpFl60W",
    "submission_title": "Best-case lower bounds in online learning",
    "review_id": "jsJEchchsnV",
    "input": {
      "title": "Best-case lower bounds in online learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- A solid theoretical contribution with strong connections to fairness.\n- A solid contribution to fairness for DTOL, analyzing a natural fair algorithm that does not need to know the size of the groups ahead of time, and a good discussion on how the current notion of fairness from previous work is highly dependent on the time horizon.\n- Very good characterization of the connection between fairness and lower-bounds on the regret.\n- An example of an algorithm with a sublinear regret upper bound but with a linear regret lower bound, leaving open interesting questions about the characterization of algorithms that suffer from linear best-case lower-bounds.\n- Implicit assumption on boundedness of the feasible set in the more general analysis of FTRL and some hidden assumptions on the regularizers that are not mentioned anywhere (and can even render the results false), details later.\n- A lack of motivation (very interesting theoretically, but the broad NeurIPS audience might have a hard time understanding the motivation of the work).\n- Regret bounds for the AdaGrad-like algorithms have an (apparently) extra dependence on a bound on the gradients that is not present in the original AdaGrad algorithm.\n- The result for 2 experts, although exact, seems to lack a bit of discussion/motivation;\n- Solid theoretical contribution that initiates a direction of research that, beyond the clear applications to fairness already discussed, can have connections to stability of online learning algorithms and give some intuition on algorithms that can perform 'extraordinarily' well in practice.\n- I really believe this paper is a solid theoretical contribution and initiates a direction of research that, beyond the clear applications to fairness already discussed, can have connections to stability of online learning algorithms and give some intuition on algorithms that can perform 'extraordinarily' well in practice.\n- However, I think the authors should make an extra-effort to sell this theoretical work to a broader community.\n- NeurIPS has a vast audience, and having a better discussion of why studying these best-case lower-bounds is interesting. Even the gist of the discussion on fairness is deferred to the appendix.\n- Bringing some of that discussion to the main body might already give a broader and strong motivation for the work.\n- I really enjoyed the discussion from the appendix.\n- On Section 3 the authors state that $\textbackslash{}mathcal{W}$ is a closed set, but do not mention necessarily that it is bounded.\n- However, in the definition of regret itself the supremum may easily be infinite if $\textbackslash{}mathcal{W}$ is the whole space.\n- On Theorem 1 something similar happens, where the authors assume that there is an optimal action in hindsight, which might not be true (again, take the feasible set as being the whole space).\n- A more fine-grained analysis shows that the regret against some comparison point is dependent on the regularizer at this comparison point, so boundedness is not necessary for (at least some) results to follow.\n- Since all the application in the paper only look at cases where the the feasible region is bounded, this is not a serious problem, but clearly stating these assumptions would be good.\n- Another problem is that Theorem 1 requires the regularizers to be non-negative (not mentioned) and strongly convex (mentioned, but only inside the theorem, so it is not clear that the regularizers in the paper are assumed to be strongly convex throughout).\n- These conditions should be explicitly stated and enforced, or at least the the statement of the FTRL regret bound should be adapted (subtracting the infimum of the last regularizer in the right hand side might be enough, but I haven't checked carefully).\n- These assumptions on the regularizers and/or boundedness of $\textbackslash{}mathcal{W}$ would help a lot in making the analysis in Section 2 less bumpy (without boundedness or strong-convexity, taking the infimum of the regularizer over the feasible set can lead to $-\textbackslash{}infty$).\n- In fact, if I'm not mistaken the authors themselves stumble onto these problems: on line 172 the authors EXPLICITLY use that the regularizer is non-positive on the entire feasible set.\n- Applying this same regularizer to Theorem 1 we would have that the sup is also non-positive and we could get a logarithmic regret upper bound, and this is clearly false.\n- Thus, this can make the readers very confused about which are the conditions required on the regularizers at each step for the results to hold.\n- My suggestion is to adapt Theorem 1 for the case where the regularizers may be negative, but still strongly convex (and, thus, lower-bounded).\n- The regret bounds for the AdaGrad-like algorithms seem to have an extra dependence on a bound on the gradients that is not present in the original AdaGrad algorithm.\n- I believe this FTRL-AdaGrad algorithm should get similar bounds to the original linearized version (in particular, if the functions are linear these algorithms match exactly).\n- Although this is not the focus of the paper, this extra dependency is a bit unsettling, and I couldn't verify the proof since it is not provided in the appendix.\n- So I suggest you to give the proof in the appendix, if time allows.\n- But beyond that, I think a careful analysis (possibly using the strong FTRL Lemma from McMahan) should yield bounds without the extra dependency on the bounds of the gradients.\n- I'd really love the thoughts of the authors on that.\n- The result on identifying exactly the best sequence for two experts is interesting, but I did not get much of the motivation for it.\n- The discussion on why it shows that the previous result was tight is not clear (do you mean asymptotically only? Because the constants do not seem to match).\n- But this part I might have simply misunderstood and is not a serious problem\n- A solid theoretical contribution, with a novel perspective on online optimization/learning and initiating a possibly fruitful direction of research;\n- The paper is very clear and well organized.\n- The authors detail the hyper-parameters and compute details used for the experiments.\n- The Cluster-Margin algorithm is also explained in detail.\n- The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods.\n- The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.\n- The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.",
    "review_points_list": [
      "A solid theoretical contribution with strong connections to fairness.",
      "A solid contribution to fairness for DTOL, analyzing a natural fair algorithm that does not need to know the size of the groups ahead of time, and a good discussion on how the current notion of fairness from previous work is highly dependent on the time horizon.",
      "Very good characterization of the connection between fairness and lower-bounds on the regret.",
      "An example of an algorithm with a sublinear regret upper bound but with a linear regret lower bound, leaving open interesting questions about the characterization of algorithms that suffer from linear best-case lower-bounds.",
      "Implicit assumption on boundedness of the feasible set in the more general analysis of FTRL and some hidden assumptions on the regularizers that are not mentioned anywhere (and can even render the results false), details later.",
      "A lack of motivation (very interesting theoretically, but the broad NeurIPS audience might have a hard time understanding the motivation of the work).",
      "Regret bounds for the AdaGrad-like algorithms have an (apparently) extra dependence on a bound on the gradients that is not present in the original AdaGrad algorithm.",
      "The result for 2 experts, although exact, seems to lack a bit of discussion/motivation;",
      "Solid theoretical contribution that initiates a direction of research that, beyond the clear applications to fairness already discussed, can have connections to stability of online learning algorithms and give some intuition on algorithms that can perform 'extraordinarily' well in practice.",
      "I really believe this paper is a solid theoretical contribution and initiates a direction of research that, beyond the clear applications to fairness already discussed, can have connections to stability of online learning algorithms and give some intuition on algorithms that can perform 'extraordinarily' well in practice.",
      "However, I think the authors should make an extra-effort to sell this theoretical work to a broader community.",
      "NeurIPS has a vast audience, and having a better discussion of why studying these best-case lower-bounds is interesting. Even the gist of the discussion on fairness is deferred to the appendix.",
      "Bringing some of that discussion to the main body might already give a broader and strong motivation for the work.",
      "I really enjoyed the discussion from the appendix.",
      "On Section 3 the authors state that $\textbackslash{}mathcal{W}$ is a closed set, but do not mention necessarily that it is bounded.",
      "However, in the definition of regret itself the supremum may easily be infinite if $\textbackslash{}mathcal{W}$ is the whole space.",
      "On Theorem 1 something similar happens, where the authors assume that there is an optimal action in hindsight, which might not be true (again, take the feasible set as being the whole space).",
      "A more fine-grained analysis shows that the regret against some comparison point is dependent on the regularizer at this comparison point, so boundedness is not necessary for (at least some) results to follow.",
      "Since all the application in the paper only look at cases where the the feasible region is bounded, this is not a serious problem, but clearly stating these assumptions would be good.",
      "Another problem is that Theorem 1 requires the regularizers to be non-negative (not mentioned) and strongly convex (mentioned, but only inside the theorem, so it is not clear that the regularizers in the paper are assumed to be strongly convex throughout).",
      "These conditions should be explicitly stated and enforced, or at least the the statement of the FTRL regret bound should be adapted (subtracting the infimum of the last regularizer in the right hand side might be enough, but I haven't checked carefully).",
      "These assumptions on the regularizers and/or boundedness of $\textbackslash{}mathcal{W}$ would help a lot in making the analysis in Section 2 less bumpy (without boundedness or strong-convexity, taking the infimum of the regularizer over the feasible set can lead to $-\textbackslash{}infty$).",
      "In fact, if I'm not mistaken the authors themselves stumble onto these problems: on line 172 the authors EXPLICITLY use that the regularizer is non-positive on the entire feasible set.",
      "Applying this same regularizer to Theorem 1 we would have that the sup is also non-positive and we could get a logarithmic regret upper bound, and this is clearly false.",
      "Thus, this can make the readers very confused about which are the conditions required on the regularizers at each step for the results to hold.",
      "My suggestion is to adapt Theorem 1 for the case where the regularizers may be negative, but still strongly convex (and, thus, lower-bounded).",
      "The regret bounds for the AdaGrad-like algorithms seem to have an extra dependence on a bound on the gradients that is not present in the original AdaGrad algorithm.",
      "I believe this FTRL-AdaGrad algorithm should get similar bounds to the original linearized version (in particular, if the functions are linear these algorithms match exactly).",
      "Although this is not the focus of the paper, this extra dependency is a bit unsettling, and I couldn't verify the proof since it is not provided in the appendix.",
      "So I suggest you to give the proof in the appendix, if time allows.",
      "But beyond that, I think a careful analysis (possibly using the strong FTRL Lemma from McMahan) should yield bounds without the extra dependency on the bounds of the gradients.",
      "I'd really love the thoughts of the authors on that.",
      "The result on identifying exactly the best sequence for two experts is interesting, but I did not get much of the motivation for it.",
      "The discussion on why it shows that the previous result was tight is not clear (do you mean asymptotically only? Because the constants do not seem to match).",
      "But this part I might have simply misunderstood and is not a serious problem",
      "A solid theoretical contribution, with a novel perspective on online optimization/learning and initiating a possibly fruitful direction of research;",
      "The paper is very clear and well organized.",
      "The authors detail the hyper-parameters and compute details used for the experiments.",
      "The Cluster-Margin algorithm is also explained in detail.",
      "The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods.",
      "The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.",
      "The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question."
    ]
  },
  {
    "paper_id": "2106.12688v1",
    "submission_id": "uZJJFpFl60W",
    "submission_title": "Best-case lower bounds in online learning",
    "review_id": "NnsvBrxkqMY",
    "input": {
      "title": "Best-case lower bounds in online learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Thank you for the response.\n- After reading other reviews and the author's feedback, my concerns are largely addressed.\n- I would like to raise my score to a positive evaluation (7).\n- My original concern is that the motivation for studying the best-case lower bound in general OCO problem is unclear.\n- By point (1),(2) of the first answer, the authors show that the best-case lower bound can be used to achieve group fairness beyond the expert advice setting.\n- Although group fairness is an important notion, the extension could be limited to a narrow scope of audience.\n- This concern is somewhat addressed by the third point, where authors have shown that the best-case lower bound can be used to show some negative side of the adaptive algorithms.\n- For example, the adaptive FTRL does not perform that well in extraordinarily benign environments (it seems that the adaptive FTRL even is even inferior to the linearized FTRL in such a case).\n- So, I am convinced that the best-lower bound can indeed provide a unique view to understand the adaptivity of the online learning algorithms.\n- Regarding the second question, I think the confusion might come from a lack of further discussion about the best-case lower bound.\n- For the fairness problem, the less negative regret bound means better results.\n- But, that is not the case for regret minimization.\n- So, I think it would be better to provide a more clear discussion about the signification of the best-case lower bound for both scenarios (especially for the regret minimziation part).",
    "review_points_list": [
      "Thank you for the response.",
      "After reading other reviews and the author's feedback, my concerns are largely addressed.",
      "I would like to raise my score to a positive evaluation (7).",
      "My original concern is that the motivation for studying the best-case lower bound in general OCO problem is unclear.",
      "By point (1),(2) of the first answer, the authors show that the best-case lower bound can be used to achieve group fairness beyond the expert advice setting.",
      "Although group fairness is an important notion, the extension could be limited to a narrow scope of audience.",
      "This concern is somewhat addressed by the third point, where authors have shown that the best-case lower bound can be used to show some negative side of the adaptive algorithms.",
      "For example, the adaptive FTRL does not perform that well in extraordinarily benign environments (it seems that the adaptive FTRL even is even inferior to the linearized FTRL in such a case).",
      "So, I am convinced that the best-lower bound can indeed provide a unique view to understand the adaptivity of the online learning algorithms.",
      "Regarding the second question, I think the confusion might come from a lack of further discussion about the best-case lower bound.",
      "For the fairness problem, the less negative regret bound means better results.",
      "But, that is not the case for regret minimization.",
      "So, I think it would be better to provide a more clear discussion about the signification of the best-case lower bound for both scenarios (especially for the regret minimziation part)."
    ]
  },
  {
    "paper_id": "2106.12688v1",
    "submission_id": "uZJJFpFl60W",
    "submission_title": "Best-case lower bounds in online learning",
    "review_id": "cjYX3sTpXnS",
    "input": {
      "title": "Best-case lower bounds in online learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The results seem to be an interesting generalization of previous work by allowing time-varying regularizers.\n- In particular, they show limitations on outperforming the best static expert in several standard settings (as would be necessary in a 'shifting regret' settings)\n- The extension of previous group fairness results seem relevant.\n- However, someone more familiar with the related work might be a better judge of the overall significance then me.\n- The paper is well-written and ideas easy to understand.\n- On pages 3-4, there are at least superscripts of w that should be subscripts.\n- Line 175: factor 2 is missing eta_t\n- In the math after line 206 and after 209, it seems the terms on the LHS should be divided by the number of time steps in the group.\n- Line 365: 'me' -> 'be'",
    "review_points_list": [
      "The results seem to be an interesting generalization of previous work by allowing time-varying regularizers.",
      "In particular, they show limitations on outperforming the best static expert in several standard settings (as would be necessary in a 'shifting regret' settings)",
      "The extension of previous group fairness results seem relevant.",
      "However, someone more familiar with the related work might be a better judge of the overall significance then me.",
      "The paper is well-written and ideas easy to understand.",
      "On pages 3-4, there are at least superscripts of w that should be subscripts.",
      "Line 175: factor 2 is missing eta_t",
      "In the math after line 206 and after 209, it seems the terms on the LHS should be divided by the number of time steps in the group.",
      "Line 365: 'me' -> 'be'"
    ]
  },
  {
    "paper_id": "0908.3755v3",
    "submission_id": "x2rdRAx3QF",
    "submission_title": "Self-Consistent Models and Values",
    "review_id": "g03OTRctwr",
    "input": {
      "title": "Self-Consistent Models and Values",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Overall the paper presents a novel self-consistency objective with a thorough empirical analysis of its variants on raw performance / sample efficiency (in tabular and deep RL settings), choices of search control (i.e. policy and states to use in imagined experience) and its benefits to representation learning.\n- While not all experiments show a clear cut benefit of using self-consistency in all the cases visited in this paper, the unbiased analysis itself is an important contribution.\n- As a result, I feel that this paper in its current form is a significant and relevant contribution for the model-based RL community.\n- The paper proposes a self-consistency update which offers a new take on model updates in model-based RL.\n- This update is important and distinct from most prior work in that it uses imagined (virtual) experience as opposed to ground truth (real) experience, allowing for freedom to update the model without collecting additional data from the true environment.\n- This also leads to questions about what states and policy to choose for such updates and these questions were answered in the search control strategies section (Section 4.2).\n- The self-consistency update is also motivated as a regularizer and shown to promote information \u201cflow\u201d in the presence of noisy inputs (Section 4.3 - Information Flow).\n- Three different variations of the self-consistency updates are studied -- sc-residual, sc-direct and sc-reverse with a clear explanation of how each affects updates for the policy, reward or transition model.\n- While sc-direct is the primary method, the ablations are also evaluated in the experiments providing valuable insights for future work in this area.\n- The benefits of self-consistency to representation learning are insightful, especially given that the self-consistency is used as a purely auxiliary objective where the model was not used for value estimation or policy improvement.\n- The evaluation of the method on Atari and Go show a clear sample efficiency improvement of the objective on top of the baseline methods.\n- The motivation for using value equivalent model learning in addition to MLE for the model-update choice could be made more clear in the paper.\n- Currently, I was able to understand the connection to value equivalence based on the fact that both self-consistency and value equivalence take inspiration from the bellman operator or bellman equation for their updates.\n- However, the following statements were difficult to understand.\n- Lines 76-78 (\u201cValue equivalent models could also \u2026 in literature\u201d) -- I have no idea how this can be achieved without further details.\n- This sentence seems to support the inclusion of value equivalence as a major part of this paper so further details would help.\n- Lines 124-126 (\u201cFurther, if grounded \u2026 value-equivalent setting\u201d). It is not made clear how the policy dependence of the transition model can allow for synergy with the proposed self-consistency update.\n- Is it because of the information flow? Further details on this would help as this is another important justification for the use of value equivalence.\n- Overall, the link between value equivalence and self-consistency is not explicitly addressed but rather is inferred after reading the above two sentences.\n- It is also missing from the introduction.\n- I would recommend addressing the link and the motivation for using value equivalence early on in the paper before existing value equivalent methods are introduced.\n- The experiment on information flow in Section 4.3 is an important contribution despite the lack of statistically significant differences between Dyna and SC-Direct.\n- However, I do not understand the justification for the poor reward estimates affecting self-consistency more while the poor value estimates affect Dyna more.\n- The inversion of trend from reward noise to value noise is the issue here.\n- The trends mostly have overlapping CIs other than the first figure, so I would recommend either dropping any strong claims on difference in performance or making the justifications for these trends more clear.\n- Line 312 in conclusion (last sentence): This future work sentence is not clear.\n- Why is there a need to perform policy improvement for value equivalent model-based agents in imagined experience?\n- Don\u2019t existing value equivalent model-based agents already perform policy improvement in this way e.g. [11]?",
    "review_points_list": [
      "Overall the paper presents a novel self-consistency objective with a thorough empirical analysis of its variants on raw performance / sample efficiency (in tabular and deep RL settings), choices of search control (i.e. policy and states to use in imagined experience) and its benefits to representation learning.",
      "While not all experiments show a clear cut benefit of using self-consistency in all the cases visited in this paper, the unbiased analysis itself is an important contribution.",
      "As a result, I feel that this paper in its current form is a significant and relevant contribution for the model-based RL community.",
      "The paper proposes a self-consistency update which offers a new take on model updates in model-based RL.",
      "This update is important and distinct from most prior work in that it uses imagined (virtual) experience as opposed to ground truth (real) experience, allowing for freedom to update the model without collecting additional data from the true environment.",
      "This also leads to questions about what states and policy to choose for such updates and these questions were answered in the search control strategies section (Section 4.2).",
      "The self-consistency update is also motivated as a regularizer and shown to promote information \u201cflow\u201d in the presence of noisy inputs (Section 4.3 - Information Flow).",
      "Three different variations of the self-consistency updates are studied -- sc-residual, sc-direct and sc-reverse with a clear explanation of how each affects updates for the policy, reward or transition model.",
      "While sc-direct is the primary method, the ablations are also evaluated in the experiments providing valuable insights for future work in this area.",
      "The benefits of self-consistency to representation learning are insightful, especially given that the self-consistency is used as a purely auxiliary objective where the model was not used for value estimation or policy improvement.",
      "The evaluation of the method on Atari and Go show a clear sample efficiency improvement of the objective on top of the baseline methods.",
      "The motivation for using value equivalent model learning in addition to MLE for the model-update choice could be made more clear in the paper.",
      "Currently, I was able to understand the connection to value equivalence based on the fact that both self-consistency and value equivalence take inspiration from the bellman operator or bellman equation for their updates.",
      "However, the following statements were difficult to understand.",
      "Lines 76-78 (\u201cValue equivalent models could also \u2026 in literature\u201d) -- I have no idea how this can be achieved without further details.",
      "This sentence seems to support the inclusion of value equivalence as a major part of this paper so further details would help.",
      "Lines 124-126 (\u201cFurther, if grounded \u2026 value-equivalent setting\u201d). It is not made clear how the policy dependence of the transition model can allow for synergy with the proposed self-consistency update.",
      "Is it because of the information flow? Further details on this would help as this is another important justification for the use of value equivalence.",
      "Overall, the link between value equivalence and self-consistency is not explicitly addressed but rather is inferred after reading the above two sentences.",
      "It is also missing from the introduction.",
      "I would recommend addressing the link and the motivation for using value equivalence early on in the paper before existing value equivalent methods are introduced.",
      "The experiment on information flow in Section 4.3 is an important contribution despite the lack of statistically significant differences between Dyna and SC-Direct.",
      "However, I do not understand the justification for the poor reward estimates affecting self-consistency more while the poor value estimates affect Dyna more.",
      "The inversion of trend from reward noise to value noise is the issue here.",
      "The trends mostly have overlapping CIs other than the first figure, so I would recommend either dropping any strong claims on difference in performance or making the justifications for these trends more clear.",
      "Line 312 in conclusion (last sentence): This future work sentence is not clear.",
      "Why is there a need to perform policy improvement for value equivalent model-based agents in imagined experience?",
      "Don\u2019t existing value equivalent model-based agents already perform policy improvement in this way e.g. [11]?"
    ]
  },
  {
    "paper_id": "0908.3755v3",
    "submission_id": "x2rdRAx3QF",
    "submission_title": "Self-Consistent Models and Values",
    "review_id": "xFrAQephl2u",
    "input": {
      "title": "Self-Consistent Models and Values",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper has some limitations that are well acknowledged by the authors.\n- The authors are aware of these shortcomings, and they provide a clear plan for future improvements.\n- It would be better if they included more details about the hyperparameters they used in their experiments and more information on how they selected these parameters.\n- Additionally, the authors could have included more experiments to verify the robustness of their approach under different circumstances.\n- The authors could have compared their approach with other state-of-the-art methods.\n- The paper could have been improved by including more discussion of the implications of their results for real-world applications.\n- It would be great if the authors provided more information about the computational resources they used for their experiments.\n- The authors could have also explored different variants of their approach to test its adaptability.\n- Finally, it would be nice if the authors included more visualizations to help illustrate their results.",
    "review_points_list": [
      "The paper has some limitations that are well acknowledged by the authors.",
      "The authors are aware of these shortcomings, and they provide a clear plan for future improvements.",
      "It would be better if they included more details about the hyperparameters they used in their experiments and more information on how they selected these parameters.",
      "Additionally, the authors could have included more experiments to verify the robustness of their approach under different circumstances.",
      "The authors could have compared their approach with other state-of-the-art methods.",
      "The paper could have been improved by including more discussion of the implications of their results for real-world applications.",
      "It would be great if the authors provided more information about the computational resources they used for their experiments.",
      "The authors could have also explored different variants of their approach to test its adaptability.",
      "Finally, it would be nice if the authors included more visualizations to help illustrate their results."
    ]
  },
  {
    "paper_id": "0908.3755v3",
    "submission_id": "x2rdRAx3QF",
    "submission_title": "Self-Consistent Models and Values",
    "review_id": "Qyapmo_9nj",
    "input": {
      "title": "Self-Consistent Models and Values",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is very well-written and clear.\n- Strengths: The motivation makes sense based on previous work and the proposed approach is straightforward.\n- Strengths: The empirical evaluations are thorough in looking at the different variations and their effects.\n- Weaknesses/Clarifications: The related works section (particularly the first paragraph (Line 280-292)) could have more details and comparisons.\n- Since the model is unrolled for many steps in the computation of L_SC and each step of the unrolling is not \u201cgrounded\u201d to the true data, it seems that the errors in the model and the value function would interact and compound with more unrolling steps and gradient updates.\n- Did you observe a challenge like this in your evaluations?\n- The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.\n- The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.\n- The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset. The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).\n- Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.\n- The authors also establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.\n- The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.\n- This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.\n- The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.\n- log(k) is an upper bound on the improvement of query complexity for any sampler.\n- The authors are aware and mention that their theoretical results are initial and that equating volume-based samplers and the Cluster-Margin algorithm is an open research question.\n- The paper is very clear and well organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.\n- The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.",
    "review_points_list": [
      "The paper is very well-written and clear.",
      "Strengths: The motivation makes sense based on previous work and the proposed approach is straightforward.",
      "Strengths: The empirical evaluations are thorough in looking at the different variations and their effects.",
      "Weaknesses/Clarifications: The related works section (particularly the first paragraph (Line 280-292)) could have more details and comparisons.",
      "Since the model is unrolled for many steps in the computation of L_SC and each step of the unrolling is not \u201cgrounded\u201d to the true data, it seems that the errors in the model and the value function would interact and compound with more unrolling steps and gradient updates.",
      "Did you observe a challenge like this in your evaluations?",
      "The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.",
      "The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.",
      "The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset. The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).",
      "Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.",
      "The authors also establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.",
      "The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.",
      "This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.",
      "The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.",
      "log(k) is an upper bound on the improvement of query complexity for any sampler.",
      "The authors are aware and mention that their theoretical results are initial and that equating volume-based samplers and the Cluster-Margin algorithm is an open research question.",
      "The paper is very clear and well organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.",
      "The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm."
    ]
  },
  {
    "paper_id": "0908.3755v3",
    "submission_id": "x2rdRAx3QF",
    "submission_title": "Self-Consistent Models and Values",
    "review_id": "HH4KDC7xC7w",
    "input": {
      "title": "Self-Consistent Models and Values",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.\n- The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.\n- The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset.\n- The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).\n- Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.\n- The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.\n- The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.\n- This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.\n- The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.\n- log(k) is an upper bound on the improvement of query complexity for any sampler.\n- The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.\n- The paper is very clear and well organized.\n- The authors detail the hyper-parameters and compute details used for the experiments.",
    "review_points_list": [
      "The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.",
      "The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.",
      "The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset.",
      "The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).",
      "Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.",
      "The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.",
      "The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.",
      "This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.",
      "The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.",
      "log(k) is an upper bound on the improvement of query complexity for any sampler.",
      "The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.",
      "The paper is very clear and well organized.",
      "The authors detail the hyper-parameters and compute details used for the experiments."
    ]
  },
  {
    "paper_id": "2204.00930v1",
    "submission_id": "uholDBWSVP",
    "submission_title": "Beyond Smoothness: Incorporating Low-Rank Analysis into Nonparametric Density Estimation",
    "review_id": "c8y9nOKvv8",
    "input": {
      "title": "Beyond Smoothness: Incorporating Low-Rank Analysis into Nonparametric Density Estimation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The results seem to be novel.\n- The value of this work is primarily of a theoretical nature, as the estimators are not computationally tractable (as made clear by the authors).\n- This reviewer did not very correctness of the proofs in the appendix.\n- The authors have addressed the comments that reviewers have raised while under review for previous conferences.\n- Slightly tends towards acceptance.\n- On p.2,  the authors already mentions the estimators are not computationally tractable. Briefly already state why here (or at least refer to the Main Technical Tools paragraph).\n- Could the authors comment and provide the reader with some intuition about the obtained rate ($1/\\sqrt[3]{n}$ instead of $1/\\sqrt[d]{n}$). Why should we expect a cubic root?\n- What would happen if we were to consider components with different degrees of smooth-ness (more general Holder classes) instead of Lipschitz?\n- As a follow-up question:  do you expect the obtained rates to be tight;  namely, can one construct a corresponding lower bound?\n- Further explain what the different columns of Table 1 correspond to.\n- Typos.\n- p.1  nonparametric.\n- p.3  asymptotically.\n- p.4  entries.\n- p.7  Lipschitz.",
    "review_points_list": [
      "The results seem to be novel.",
      "The value of this work is primarily of a theoretical nature, as the estimators are not computationally tractable (as made clear by the authors).",
      "This reviewer did not very correctness of the proofs in the appendix.",
      "The authors have addressed the comments that reviewers have raised while under review for previous conferences.",
      "Slightly tends towards acceptance.",
      "On p.2,  the authors already mentions the estimators are not computationally tractable. Briefly already state why here (or at least refer to the Main Technical Tools paragraph).",
      "Could the authors comment and provide the reader with some intuition about the obtained rate ($1/\\sqrt[3]{n}$ instead of $1/\\sqrt[d]{n}$). Why should we expect a cubic root?",
      "What would happen if we were to consider components with different degrees of smooth-ness (more general Holder classes) instead of Lipschitz?",
      "As a follow-up question:  do you expect the obtained rates to be tight;  namely, can one construct a corresponding lower bound?",
      "Further explain what the different columns of Table 1 correspond to.",
      "Typos.",
      "p.1  nonparametric.",
      "p.3  asymptotically.",
      "p.4  entries.",
      "p.7  Lipschitz."
    ]
  },
  {
    "paper_id": "2204.00930v1",
    "submission_id": "uholDBWSVP",
    "submission_title": "Beyond Smoothness: Incorporating Low-Rank Analysis into Nonparametric Density Estimation",
    "review_id": "Ma74aFL38ee",
    "input": {
      "title": "Beyond Smoothness: Incorporating Low-Rank Analysis into Nonparametric Density Estimation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The approach described is novel, and the theoretical results are interesting and nontrivial.\n- The authors could improve the paper by giving more context into why they are solving the problem they address.\n- In particular, given that the improvement obtained relative to standard histograms is most pronounced in high dimensions, in what settings might it be useful to have a 3 dimensional or higher density estimate of this form?\n- When the number of samples is large, does this matter for downstream analyses?\n- If so, of what sort of downstream analyses.\n- The paper should be much better polished.\n- The paper has many typos, and missing information -- some of this impedes understanding.\n- \u201cNonparametreic\u201d in the second sentence.\n- In section 1.3, what is \u201cM\u201d (i.e. \u201cM satisfies a property\u201d).\n- \u201cWho\u2019s\u201d should be \u201cwhose\u201d.\n- One can recover y\u201d, should \u201cy\u201d be \u201cx\u201d?\n- In section 1.3, what does that last sentence of the second to last paragraph mean?\n- What is \u201cour setting\u201d, and why is this an important setting to consider?\n- What is table 1?\n- This is not referenced in the main text (or maybe \u201ctable 3\u201d is a typo?),\n- and the legend \u201cExperimental results\u201d is not informative.\n- Are higher or lower values better?\n- Some sentences do not make sense grammatically.\n- E.g. in section 3, \u201cThis problem when seems be further\u2026\u201d.\n- The authors have not included line numbers, which would have been helpful for referencing certain parts of the paper.",
    "review_points_list": [
      "The approach described is novel, and the theoretical results are interesting and nontrivial.",
      "The authors could improve the paper by giving more context into why they are solving the problem they address.",
      "In particular, given that the improvement obtained relative to standard histograms is most pronounced in high dimensions, in what settings might it be useful to have a 3 dimensional or higher density estimate of this form?",
      "When the number of samples is large, does this matter for downstream analyses?",
      "If so, of what sort of downstream analyses.",
      "The paper should be much better polished.",
      "The paper has many typos, and missing information -- some of this impedes understanding.",
      "\u201cNonparametreic\u201d in the second sentence.",
      "In section 1.3, what is \u201cM\u201d (i.e. \u201cM satisfies a property\u201d).",
      "\u201cWho\u2019s\u201d should be \u201cwhose\u201d.",
      "One can recover y\u201d, should \u201cy\u201d be \u201cx\u201d?",
      "In section 1.3, what does that last sentence of the second to last paragraph mean?",
      "What is \u201cour setting\u201d, and why is this an important setting to consider?",
      "What is table 1?",
      "This is not referenced in the main text (or maybe \u201ctable 3\u201d is a typo?),",
      "and the legend \u201cExperimental results\u201d is not informative.",
      "Are higher or lower values better?",
      "Some sentences do not make sense grammatically.",
      "E.g. in section 3, \u201cThis problem when seems be further\u2026\u201d.",
      "The authors have not included line numbers, which would have been helpful for referencing certain parts of the paper."
    ]
  },
  {
    "paper_id": "2204.00930v1",
    "submission_id": "uholDBWSVP",
    "submission_title": "Beyond Smoothness: Incorporating Low-Rank Analysis into Nonparametric Density Estimation",
    "review_id": "hka3tQMwXk5",
    "input": {
      "title": "Beyond Smoothness: Incorporating Low-Rank Analysis into Nonparametric Density Estimation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The theoretical problems above are well studied in the paper.\n- All the results are rigorously presented.\n- The techniques using here are well-known and are applied appropriately to support the proofs.\n- The assumptions of the problem are reasonable and useful.\n- The experiment also sheds some light on the superiority of the proposed method in some specific cases.\n- The title: 'Beyond smoothness': I can not see what is beyond the smoothness here as we still need to assume the smoothness of true density to prove all the results.\n- Even in the case that the true density is 'low-rank', the assumptions on smoothness of product densities are required.\n- Experiments: The shown experiment is too rudiment and does not strongly support the argument in theory part.\n- The description of the experiment is too detailed while the discussion and explanation parts are short.\n- In the experiment part, the authors can conduct an simulation study to show the rate when approximating by multi-view histograms compared to the usual histograms method.\n- We can also find a number of real data sets having mixtures of product distributions law and try to compare the proposed methods on them.\n- They appear a lot in psychological field (https://arxiv.org/pdf/1904.04378.pdf), see also the papers which cite https://projecteuclid.org/journals/annals-of-statistics/volume-37/issue-6A/Identifiability-of-parameters-in-latent-structure-models-with-many-observed/10.1214/09-AOS689.full?tab=ArticleLinkCited for more information.\n- The authors may consider adding some recent references on multivariate density estimation with very fast MISE via sin kernel, such as via the Fourier integral theorem [1].\n- In particular, this work shows that when the density function has supersmooth Fourier tails, such as Gaussian distribution, the MISE rate is n^{-1/2} (up to some logarithmic term).\n- Furthermore, the usage of sin kernel also circumvents challenge with choosing covariance matrix in standard Gaussian kernel while it is able to learn the dependency in data automatically.\n- [1] N. Ho, S. G. Walker. Multivariate smoothing via the Fourier integral theorem and Fourier kernel. Arxiv preprint Arxiv: 2012.14482, 2021.",
    "review_points_list": [
      "The theoretical problems above are well studied in the paper.",
      "All the results are rigorously presented.",
      "The techniques using here are well-known and are applied appropriately to support the proofs.",
      "The assumptions of the problem are reasonable and useful.",
      "The experiment also sheds some light on the superiority of the proposed method in some specific cases.",
      "The title: 'Beyond smoothness': I can not see what is beyond the smoothness here as we still need to assume the smoothness of true density to prove all the results.",
      "Even in the case that the true density is 'low-rank', the assumptions on smoothness of product densities are required.",
      "Experiments: The shown experiment is too rudiment and does not strongly support the argument in theory part.",
      "The description of the experiment is too detailed while the discussion and explanation parts are short.",
      "In the experiment part, the authors can conduct an simulation study to show the rate when approximating by multi-view histograms compared to the usual histograms method.",
      "We can also find a number of real data sets having mixtures of product distributions law and try to compare the proposed methods on them.",
      "They appear a lot in psychological field (https://arxiv.org/pdf/1904.04378.pdf), see also the papers which cite https://projecteuclid.org/journals/annals-of-statistics/volume-37/issue-6A/Identifiability-of-parameters-in-latent-structure-models-with-many-observed/10.1214/09-AOS689.full?tab=ArticleLinkCited for more information.",
      "The authors may consider adding some recent references on multivariate density estimation with very fast MISE via sin kernel, such as via the Fourier integral theorem [1].",
      "In particular, this work shows that when the density function has supersmooth Fourier tails, such as Gaussian distribution, the MISE rate is n^{-1/2} (up to some logarithmic term).",
      "Furthermore, the usage of sin kernel also circumvents challenge with choosing covariance matrix in standard Gaussian kernel while it is able to learn the dependency in data automatically.",
      "[1] N. Ho, S. G. Walker. Multivariate smoothing via the Fourier integral theorem and Fourier kernel. Arxiv preprint Arxiv: 2012.14482, 2021."
    ]
  },
  {
    "paper_id": "2204.00930v1",
    "submission_id": "uholDBWSVP",
    "submission_title": "Beyond Smoothness: Incorporating Low-Rank Analysis into Nonparametric Density Estimation",
    "review_id": "goQqFawOT3C",
    "input": {
      "title": "Beyond Smoothness: Incorporating Low-Rank Analysis into Nonparametric Density Estimation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Theoretical results in the manuscript are substantial.\n- They only prove the existence of a low-rank estimator; they do not devise such an estimator.\n- It is surprising that there is no d in the asymptotic convergence results.\n- I did not have time to check the proof.\n- Minor comments, mostly typos:\n- In the paragraph below equation (3), x is called a matrix, even though it is a vector\n- Page 5, just before 'Main Technical Tools', should be n^{-1/3} not d^{-1/3}\n- Theorem 2.6: the first line in the statement has some indexing errors in the product\n- Equation (12): sum should be until n, and a factor of 1/n is missing",
    "review_points_list": [
      "Theoretical results in the manuscript are substantial.",
      "They only prove the existence of a low-rank estimator; they do not devise such an estimator.",
      "It is surprising that there is no d in the asymptotic convergence results.",
      "I did not have time to check the proof.",
      "Minor comments, mostly typos:",
      "In the paragraph below equation (3), x is called a matrix, even though it is a vector",
      "Page 5, just before 'Main Technical Tools', should be n^{-1/3} not d^{-1/3}",
      "Theorem 2.6: the first line in the statement has some indexing errors in the product",
      "Equation (12): sum should be until n, and a factor of 1/n is missing"
    ]
  },
  {
    "paper_id": "2102.10346v1",
    "submission_id": "yxHPRAqCqn",
    "submission_title": "Convergence Rates of Stochastic Gradient Descent under Infinite Noise Variance",
    "review_id": "YW4pokOo4ae",
    "input": {
      "title": "Convergence Rates of Stochastic Gradient Descent under Infinite Noise Variance",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper defines the concept of $p$-positive definitness for square symmetric matrices, for $p\neq 1$. This concept generalizes the concept of positive definite matrices, and the two concepts are the same when $p=2$.\n- Assumption 1 says that the Hessian matrices are uniformly $p$-positive definite.\n- Assumption A2 says that the gradient noise is the sum of two components, the second of which has a finite $p$ moment.\n- Theorem 3 shows convergence results for the SGD algorithm under Assumptions A1 and A2 for a suitable step-size.\n- Under certain assumptions, Theorems 5 and 6 prove central limit theorems for a normalized average of iterates.\n- The paper uses SGD without any modification.\n- Theorem 3 in the paper is in the same spirit as Theorem 4 of Zhang et al Neurips 2020.\n- While Theorem 3 in the paper requires $p$-positive definiteness assumptions on the Hessians and certain assumptions on the stochastic gradients, Theorem 4 in Zhang et al requires a strong-convexity assumption and the uniform finiteness of moments of the stochastic gradients.\n- The results in the paper are interesting and new to me.\n- On the negative side, the paper contains no numerical experiments,\n- and it is not clear whether the $p$-positive definiteness assumption holds in practical applications.\n- In Assumption A2, is $\\{m_t\\}$ a martingale difference sequence with respect to $\\{\\cal F_t\\}$?\n- The definition of the domain of normal attraction in (4.2) does not coincide with the definition in (2.2).\n- Line 273: Why does Assumption A3 imply that $E[|xi_t|^p]< \\\\/infty$?\n- Line 340: The calculation of $E[|m_t|^2|x_{t-1}]$ involves  $E[||z_t||^2z_tz_t^T]$. So $E[|m_t|^2|x_{t-1}]$ is not always finite if the second moment of $z$ is finite.\n- Line 358: For logistic regressions, $y_t$ is binary in practice and has a finite second moment.\n- Line 112: Typo in 'the only a few'\n- After feedback, I increased my score",
    "review_points_list": [
      "The paper defines the concept of $p$-positive definitness for square symmetric matrices, for $p\neq 1$. This concept generalizes the concept of positive definite matrices, and the two concepts are the same when $p=2$.",
      "Assumption 1 says that the Hessian matrices are uniformly $p$-positive definite.",
      "Assumption A2 says that the gradient noise is the sum of two components, the second of which has a finite $p$ moment.",
      "Theorem 3 shows convergence results for the SGD algorithm under Assumptions A1 and A2 for a suitable step-size.",
      "Under certain assumptions, Theorems 5 and 6 prove central limit theorems for a normalized average of iterates.",
      "The paper uses SGD without any modification.",
      "Theorem 3 in the paper is in the same spirit as Theorem 4 of Zhang et al Neurips 2020.",
      "While Theorem 3 in the paper requires $p$-positive definiteness assumptions on the Hessians and certain assumptions on the stochastic gradients, Theorem 4 in Zhang et al requires a strong-convexity assumption and the uniform finiteness of moments of the stochastic gradients.",
      "The results in the paper are interesting and new to me.",
      "On the negative side, the paper contains no numerical experiments,",
      "and it is not clear whether the $p$-positive definiteness assumption holds in practical applications.",
      "In Assumption A2, is $\\{m_t\\}$ a martingale difference sequence with respect to $\\{\\cal F_t\\}$?",
      "The definition of the domain of normal attraction in (4.2) does not coincide with the definition in (2.2).",
      "Line 273: Why does Assumption A3 imply that $E[|xi_t|^p]< \\\\/infty$?",
      "Line 340: The calculation of $E[|m_t|^2|x_{t-1}]$ involves  $E[||z_t||^2z_tz_t^T]$. So $E[|m_t|^2|x_{t-1}]$ is not always finite if the second moment of $z$ is finite.",
      "Line 358: For logistic regressions, $y_t$ is binary in practice and has a finite second moment.",
      "Line 112: Typo in 'the only a few'",
      "After feedback, I increased my score"
    ]
  },
  {
    "paper_id": "2102.10346v1",
    "submission_id": "yxHPRAqCqn",
    "submission_title": "Convergence Rates of Stochastic Gradient Descent under Infinite Noise Variance",
    "review_id": "00wWYjLMRM",
    "input": {
      "title": "Convergence Rates of Stochastic Gradient Descent under Infinite Noise Variance",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This work studies the convergence of SGD in the case where the noise has infinite second moment.\n- While this covers interesting practical cases, this is in contrast with most of the works on the convergence of SGD.\n- The convergence results are discussed in details and the paper is well written, although technical.\n- A good literature review is provided for stochastic approximation under assumptions that do not imply finite variance of the noise.\n- Besides, a CLT is provided for the average of the iterates, towards an alpha stable distribution.\n- My main concern is wrt to the assumptions made in theorems.\n- First, the work is limited to strongly convex functions.\n- Second the assumptions made on the noise do not seem easy to check.\n- I must admit that a real effort is made to prove that the assumptions are satisfied for Ordinary Least Square and Generalized Linear Models, but this still relies on some hypotheses.\n- The work is technical and more effort should be made on clarifying the paper.\n- the intro and literature review are quite technical.\n- The choice of alpha stable distribution in Assumption 3 is not really justified.\n- It seems specific. Why this choice? Do we know the parameters of the alpha stable distribution?\n- Specific questions:\n- - Th 5: Alpha is given by assumption 3, am I correct? Do we know alpha easily?\n- - l.290: \"Indices\"?\n- - Could you explain how to obtain 5.3 and l.363 ?\n- The work considers the infinite variance noise, which an important setting is practice.\n- However it still requires some assumptions, so the work is not that general.",
    "review_points_list": [
      "This work studies the convergence of SGD in the case where the noise has infinite second moment.",
      "While this covers interesting practical cases, this is in contrast with most of the works on the convergence of SGD.",
      "The convergence results are discussed in details and the paper is well written, although technical.",
      "A good literature review is provided for stochastic approximation under assumptions that do not imply finite variance of the noise.",
      "Besides, a CLT is provided for the average of the iterates, towards an alpha stable distribution.",
      "My main concern is wrt to the assumptions made in theorems.",
      "First, the work is limited to strongly convex functions.",
      "Second the assumptions made on the noise do not seem easy to check.",
      "I must admit that a real effort is made to prove that the assumptions are satisfied for Ordinary Least Square and Generalized Linear Models, but this still relies on some hypotheses.",
      "The work is technical and more effort should be made on clarifying the paper.",
      "the intro and literature review are quite technical.",
      "The choice of alpha stable distribution in Assumption 3 is not really justified.",
      "It seems specific. Why this choice? Do we know the parameters of the alpha stable distribution?",
      "Specific questions:",
      "- Th 5: Alpha is given by assumption 3, am I correct? Do we know alpha easily?",
      "- l.290: \"Indices\"?",
      "- Could you explain how to obtain 5.3 and l.363 ?",
      "The work considers the infinite variance noise, which an important setting is practice.",
      "However it still requires some assumptions, so the work is not that general."
    ]
  },
  {
    "paper_id": "2102.10346v1",
    "submission_id": "yxHPRAqCqn",
    "submission_title": "Convergence Rates of Stochastic Gradient Descent under Infinite Noise Variance",
    "review_id": "DolqwObfc2V",
    "input": {
      "title": "Convergence Rates of Stochastic Gradient Descent under Infinite Noise Variance",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- + The paper is organized well and is particularly clear in its math (as a CS paper).\n- + The presented convergence rate and CLT for SGD with heavy-tail noise are novel in machine learning to my knowledge. I am not sure how novel these are in probability theory.\n- + Technically, the introduced p-PD notions could be interesting tools for ML people to know. Again, not sure whether or not these are interesting for probability theorists.\n- - Several important quantities are hidden in the rate in Thm3, e.g., dependence on $x_1$, condition numbers (as the hessian is assumed to be uniform $p$-PD), dimension factors, the noise $p$-moment bound, etc. This limits the importance of the theorem.\n- - Could you comment on SGD with constant, large stepsize and with iterate-averaging/tail-averaging?\n-  Eq below l.145. $delta$ could be boldface.\n-  l.322. coefficients -> coefficient.\n-  Eqs below l.652. The first inequality is not rigorous as $x^b_t$ depends on $x_t$. I believe this is easily fixable and should not affect the correctness of the final claim. Please confirm.\n- As an ML person who has limited probability background, I think this paper is clear and clean, and is a good reading for understanding SGD in the heavy-tail noise cases.\n- However I am not sure how novel the results to probability theorists.\n- On the one hand, the two main results, Thm3 and Thms 5/6, seem to be applications of developed large number thm and CLT from existing (and quite old) probability papers\n- (perhaps with a little bit standard optimization tricks) --- I could miss some points here and please correct me if so.\n- Thus I am not sure how probability theorists view these results.\n- On the other hand, the effects of initialization, condition numbers, dimension factors, noise bound are very important for rates for ML problems, but these are all hidden in the presented result.\n- Thus the current version is a bit unsatisfactory.\n- It is very hard for me to make a decision, currently I lean slightly to a weak acceptance.",
    "review_points_list": [
      "+ The paper is organized well and is particularly clear in its math (as a CS paper).",
      "+ The presented convergence rate and CLT for SGD with heavy-tail noise are novel in machine learning to my knowledge. I am not sure how novel these are in probability theory.",
      "+ Technically, the introduced p-PD notions could be interesting tools for ML people to know. Again, not sure whether or not these are interesting for probability theorists.",
      "- Several important quantities are hidden in the rate in Thm3, e.g., dependence on $x_1$, condition numbers (as the hessian is assumed to be uniform $p$-PD), dimension factors, the noise $p$-moment bound, etc. This limits the importance of the theorem.",
      "- Could you comment on SGD with constant, large stepsize and with iterate-averaging/tail-averaging?",
      " Eq below l.145. $delta$ could be boldface.",
      " l.322. coefficients -> coefficient.",
      " Eqs below l.652. The first inequality is not rigorous as $x^b_t$ depends on $x_t$. I believe this is easily fixable and should not affect the correctness of the final claim. Please confirm.",
      "As an ML person who has limited probability background, I think this paper is clear and clean, and is a good reading for understanding SGD in the heavy-tail noise cases.",
      "However I am not sure how novel the results to probability theorists.",
      "On the one hand, the two main results, Thm3 and Thms 5/6, seem to be applications of developed large number thm and CLT from existing (and quite old) probability papers",
      "(perhaps with a little bit standard optimization tricks) --- I could miss some points here and please correct me if so.",
      "Thus I am not sure how probability theorists view these results.",
      "On the other hand, the effects of initialization, condition numbers, dimension factors, noise bound are very important for rates for ML problems, but these are all hidden in the presented result.",
      "Thus the current version is a bit unsatisfactory.",
      "It is very hard for me to make a decision, currently I lean slightly to a weak acceptance."
    ]
  },
  {
    "paper_id": "2102.10346v1",
    "submission_id": "yxHPRAqCqn",
    "submission_title": "Convergence Rates of Stochastic Gradient Descent under Infinite Noise Variance",
    "review_id": "fLIdkjZKkRq",
    "input": {
      "title": "Convergence Rates of Stochastic Gradient Descent under Infinite Noise Variance",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Each point should be a single sentence or short phrase.\n- Distinct comment, observation, strength, weakness, or question.\n- Review points should be split into individual points.\n- Follow the same structure as shown in the example.\n- Provide response in JSON format.",
    "review_points_list": [
      "Each point should be a single sentence or short phrase.",
      "Distinct comment, observation, strength, weakness, or question.",
      "Review points should be split into individual points.",
      "Follow the same structure as shown in the example.",
      "Provide response in JSON format."
    ]
  },
  {
    "paper_id": "2111.03941v6",
    "submission_id": "xNmhYNQruJX",
    "submission_title": "Time Discretization-Invariant Safe Action Repetition for Policy Gradient Methods",
    "review_id": "fibUUFW-Pcp",
    "input": {
      "title": "Time Discretization-Invariant Safe Action Repetition for Policy Gradient Methods",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This work brings \u03b4-robustness forward by incorporating it into policy-gradient methods.\n- I raise a few questions and concerns below:\n- In Proposition 2, several parameters vary at once, all of them tending to an extreme case...\n- The first paragraph in Sec 6 reminds the setting of options, which should be addressed in related work:\n- Overall, the problem is interesting and the proposed solution numerically promising, but the paper does not sufficiently challenge its method against other alternatives...\n- ...although the ideas are clearly described, there are several English mistakes that I enumerate below.\n- l. 283-284 'Note that this variant of SAR.. is \u03b4-invariant too' - proof? Justification?\n- l. 279 '$\u03bb$ is the coefficient that controls the relative strength of the first term' - it rather combines the first term with the second one by trading off distance with time difference.\n- l. 296 'While other previous ... approaches' - I did not understand the point of this sentence\n- Redundancies in l. 1 - 'discretized', 'discretization';\n- l. 3 - 'differently', 'different';\n- the' should be removed in the following:\n- l. 37 - 'the performance';\n- l. 38 - 'the trained policies';\n- ...\n- l. 4 Fig 3 caption - 'the full results';\n- l. 282 - 'the time at $s_i$', 'the repetition';\n- l. 304 - 'the training';\n- l. 305 - 'the duration';\n- l. 2 Fig 4 caption - 'the $95%$';\n- l. 342 - 'the position', 'the velocity';\n- l. 364 - 'the locality';\n- l. 18 'assume an MDP' --> 'are based on an MDP' or 'rely on an MDP'...\n- l. 21 'the MDP assumption' --> 'the MDP setting' or 'the MDP model';\n- l. 20 'are defined with continuous-time' --> 'in continuous time' (note hyphen removal as well);",
    "review_points_list": [
      "This work brings \u03b4-robustness forward by incorporating it into policy-gradient methods.",
      "I raise a few questions and concerns below:",
      "In Proposition 2, several parameters vary at once, all of them tending to an extreme case...",
      "The first paragraph in Sec 6 reminds the setting of options, which should be addressed in related work:",
      "Overall, the problem is interesting and the proposed solution numerically promising, but the paper does not sufficiently challenge its method against other alternatives...",
      "...although the ideas are clearly described, there are several English mistakes that I enumerate below.",
      "l. 283-284 'Note that this variant of SAR.. is \u03b4-invariant too' - proof? Justification?",
      "l. 279 '$\u03bb$ is the coefficient that controls the relative strength of the first term' - it rather combines the first term with the second one by trading off distance with time difference.",
      "l. 296 'While other previous ... approaches' - I did not understand the point of this sentence",
      "Redundancies in l. 1 - 'discretized', 'discretization';",
      "l. 3 - 'differently', 'different';",
      "the' should be removed in the following:",
      "l. 37 - 'the performance';",
      "l. 38 - 'the trained policies';",
      "...",
      "l. 4 Fig 3 caption - 'the full results';",
      "l. 282 - 'the time at $s_i$', 'the repetition';",
      "l. 304 - 'the training';",
      "l. 305 - 'the duration';",
      "l. 2 Fig 4 caption - 'the $95%$';",
      "l. 342 - 'the position', 'the velocity';",
      "l. 364 - 'the locality';",
      "l. 18 'assume an MDP' --> 'are based on an MDP' or 'rely on an MDP'...",
      "l. 21 'the MDP assumption' --> 'the MDP setting' or 'the MDP model';",
      "l. 20 'are defined with continuous-time' --> 'in continuous time' (note hyphen removal as well);"
    ]
  },
  {
    "paper_id": "2111.03941v6",
    "submission_id": "xNmhYNQruJX",
    "submission_title": "Time Discretization-Invariant Safe Action Repetition for Policy Gradient Methods",
    "review_id": "UUosIEL4nS",
    "input": {
      "title": "Time Discretization-Invariant Safe Action Repetition for Policy Gradient Methods",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- In general the paper was well written, the tackled problem relevant and the approach sensible.\n- The experiments included ablation studies.\n- They also included small toy examples explaining the benefits of their method.\n- One thing that was still unclear to me was why the agent would simply not learn to set the safe region as small as possible to maximize the control frequency and the achievable performance?\n- I hope the authors can explain this in their response.\n- I also point out that the assumption that the variance of the return is lower bounded may not hold.\n- Even if the discretized environment is stochastic, as the discretization time step is reduced, the effect of the stochasticity can become smaller and the outcome can become deterministic in the continuous limit.\n- For example, this will happen in the example by Munos that you cited, and actually, if one takes multiple samples and uses a mean baseline, the policy gradient variance would not explode in their example.\n- One could also construct other examples where the return variance keeps decreasing as the discretization time scale is reduced.\n- Based on this, I believe some of the claims are a bit too strong, and it should be emphasized that it relies on the assumption that the variance is lower bounded, which does not hold in general (though there are many examples where indeed the PG variance will explode, and the experiments in the appendix also demonstrated this empirically.)\n- The example is OK, but I found it somewhat artificial to just place noise on the final reward to ensure that reward variance stays lower bounded.\n- Another point that bothered me was that the choice of the size of the safe region has no effect on the task performance because there are only two states 0 and 1, and irrespective of the size of the safe region, the next action will be chosen right as the state changes.\n- On the other hand, if the state were to change continuously, wouldn't the policy with $d_i \\to 0$ also be optimal, and lead to an infinite amount action steps and an explosion of the gradient variance also for SAR (this is basically related to my previous question of why the agent does not just learn to set the safe region as small as possible)?",
    "review_points_list": [
      "In general the paper was well written, the tackled problem relevant and the approach sensible.",
      "The experiments included ablation studies.",
      "They also included small toy examples explaining the benefits of their method.",
      "One thing that was still unclear to me was why the agent would simply not learn to set the safe region as small as possible to maximize the control frequency and the achievable performance?",
      "I hope the authors can explain this in their response.",
      "I also point out that the assumption that the variance of the return is lower bounded may not hold.",
      "Even if the discretized environment is stochastic, as the discretization time step is reduced, the effect of the stochasticity can become smaller and the outcome can become deterministic in the continuous limit.",
      "For example, this will happen in the example by Munos that you cited, and actually, if one takes multiple samples and uses a mean baseline, the policy gradient variance would not explode in their example.",
      "One could also construct other examples where the return variance keeps decreasing as the discretization time scale is reduced.",
      "Based on this, I believe some of the claims are a bit too strong, and it should be emphasized that it relies on the assumption that the variance is lower bounded, which does not hold in general (though there are many examples where indeed the PG variance will explode, and the experiments in the appendix also demonstrated this empirically.)",
      "The example is OK, but I found it somewhat artificial to just place noise on the final reward to ensure that reward variance stays lower bounded.",
      "Another point that bothered me was that the choice of the size of the safe region has no effect on the task performance because there are only two states 0 and 1, and irrespective of the size of the safe region, the next action will be chosen right as the state changes.",
      "On the other hand, if the state were to change continuously, wouldn't the policy with $d_i \\to 0$ also be optimal, and lead to an infinite amount action steps and an explosion of the gradient variance also for SAR (this is basically related to my previous question of why the agent does not just learn to set the safe region as small as possible)?"
    ]
  },
  {
    "paper_id": "2111.03941v6",
    "submission_id": "xNmhYNQruJX",
    "submission_title": "Time Discretization-Invariant Safe Action Repetition for Policy Gradient Methods",
    "review_id": "7WAuRi10cNv",
    "input": {
      "title": "Time Discretization-Invariant Safe Action Repetition for Policy Gradient Methods",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- It is a good work.\n- What is V(s) in equation (5)?\n- How can we extend this method to the systems where one cannot define a notion of distance on the state space?\n- In SAR, the radius d_i is one of the outputs of the policy and needs to be learned while we learn the optimal policy.\n- What if the initialization of the policy assigns very small (or very large) radiuses in some states, and hence the algorithm will be divergent?\n- I am concerned about the effect of the initialization of the policy (specially the safe region radius d_i) on the final policy achieved by the algorithm.\n- How can we make the algorithm less sensitive to the initialization of the policy?\n- Although the authors provide figure 6 which shows that SAR produces reasonable safe regions, I was wondering how is the algorithm encouraged to find the best safe region?\n- In an intuitive sense, how the algorithm is rewarded to end up getting a policy which gets a larger safe region when the speed is low and bigger safe region when the speed is high?",
    "review_points_list": [
      "It is a good work.",
      "What is V(s) in equation (5)?",
      "How can we extend this method to the systems where one cannot define a notion of distance on the state space?",
      "In SAR, the radius d_i is one of the outputs of the policy and needs to be learned while we learn the optimal policy.",
      "What if the initialization of the policy assigns very small (or very large) radiuses in some states, and hence the algorithm will be divergent?",
      "I am concerned about the effect of the initialization of the policy (specially the safe region radius d_i) on the final policy achieved by the algorithm.",
      "How can we make the algorithm less sensitive to the initialization of the policy?",
      "Although the authors provide figure 6 which shows that SAR produces reasonable safe regions, I was wondering how is the algorithm encouraged to find the best safe region?",
      "In an intuitive sense, how the algorithm is rewarded to end up getting a policy which gets a larger safe region when the speed is low and bigger safe region when the speed is high?"
    ]
  },
  {
    "paper_id": "2502.21321v2",
    "submission_id": "wCrH0JBCFNm",
    "submission_title": "Post-Training Quantization for Vision Transformer",
    "review_id": "iFVsYIEEZj_",
    "input": {
      "title": "Post-Training Quantization for Vision Transformer",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors propose to maximize the similarity between the quantized and original feature maps by the similarity-aware loss.\n- The authors empirically find that the relative order of the attention maps is changed after quantization, resulting in significant performance degradation.\n- The authors propose a ranking loss to preserve the relative order of attention values.\n- The authors propose bias correction to reduce the accumulated error caused by quantization.\n- In Section 3.2, the motivation of using the Pearson correlation coefficient to measure the similarity between the original and quantized feature maps is not clear.\n- Why not use the Euclidean distance or the cosine similarity?\n- The effect of alternating searching is not discussed.\n- To demonstrate the effectiveness of the proposed alternating searching, it would be better for the authors to provide more results without the alternative searching.\n- In line 180, $\backslash$Delta_l$ denotes [insert missing information].\n- What do $\backslash$alpha$ and $\backslash$beta$ denote? More explanations are required.\n- Please use 'alternating' instead of 'alternative'.\n- An important metric is missing in the experiments, i.e. computational cost.\n- It would be better for the authors to provide more results in terms of Bit-Operations (BOPs) [1][2] since BOPs is an important metric to measure the computational cost.\n- The authors randomly sample a subset of the dataset for calibration. However, the effect on the number of samples is unclear.\n- It would be better for the authors to provide more results in terms of the different number of samples.\n- Reference [1] Differentiable Joint Pruning and Quantization for Hardware Efficiency. ECCV 2020.\n- Reference [2] Single Path One-Shot Neural Architecture Search with Uniform Sampling. ECCV 2020.",
    "review_points_list": [
      "The authors propose to maximize the similarity between the quantized and original feature maps by the similarity-aware loss.",
      "The authors empirically find that the relative order of the attention maps is changed after quantization, resulting in significant performance degradation.",
      "The authors propose a ranking loss to preserve the relative order of attention values.",
      "The authors propose bias correction to reduce the accumulated error caused by quantization.",
      "In Section 3.2, the motivation of using the Pearson correlation coefficient to measure the similarity between the original and quantized feature maps is not clear.",
      "Why not use the Euclidean distance or the cosine similarity?",
      "The effect of alternating searching is not discussed.",
      "To demonstrate the effectiveness of the proposed alternating searching, it would be better for the authors to provide more results without the alternative searching.",
      "In line 180, $\backslash$Delta_l$ denotes [insert missing information].",
      "What do $\backslash$alpha$ and $\backslash$beta$ denote? More explanations are required.",
      "Please use 'alternating' instead of 'alternative'.",
      "An important metric is missing in the experiments, i.e. computational cost.",
      "It would be better for the authors to provide more results in terms of Bit-Operations (BOPs) [1][2] since BOPs is an important metric to measure the computational cost.",
      "The authors randomly sample a subset of the dataset for calibration. However, the effect on the number of samples is unclear.",
      "It would be better for the authors to provide more results in terms of the different number of samples.",
      "Reference [1] Differentiable Joint Pruning and Quantization for Hardware Efficiency. ECCV 2020.",
      "Reference [2] Single Path One-Shot Neural Architecture Search with Uniform Sampling. ECCV 2020."
    ]
  },
  {
    "paper_id": "2502.21321v2",
    "submission_id": "wCrH0JBCFNm",
    "submission_title": "Post-Training Quantization for Vision Transformer",
    "review_id": "delsUQX1jNX",
    "input": {
      "title": "Post-Training Quantization for Vision Transformer",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This is a novel and effective method for the compression for the vision transformer.\n- The proposed ranking-aware loss for the self-attention layer benefits for the quantization\n- The mixed-precision quantization further promotes the performance of quantized transformer.\n- The paper is well written and organized.",
    "review_points_list": [
      "This is a novel and effective method for the compression for the vision transformer.",
      "The proposed ranking-aware loss for the self-attention layer benefits for the quantization",
      "The mixed-precision quantization further promotes the performance of quantized transformer.",
      "The paper is well written and organized."
    ]
  },
  {
    "paper_id": "2502.21321v2",
    "submission_id": "wCrH0JBCFNm",
    "submission_title": "Post-Training Quantization for Vision Transformer",
    "review_id": "fFnX145byj6",
    "input": {
      "title": "Post-Training Quantization for Vision Transformer",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The manuscript proposes a post-training quantization for vision transformer.\n- The task is urgently needed for deployment in industrial environments.\n- The related work is cited adequately, but more analysis about the relationship between the quantization of BERT and ViT should be provided.\n- The idea of the manuscript is somewhat innovative, but the method part is not very clear.\n- The quantization model with mixed-precision can get considerable results\n- More comparison between other quantization methods used on BERT should be given.\n- The method is not very clarified and some equations are very confusing\n- The strategy for obtaining different bit-widths is not clear\n- Figure 2 has no clear explanation\n- The motivation for introducing rank-loss is best to provide more sufficient evidence\n- The goal of the paper is significant in practical applications\n- The results demonstrate the method is validation\n- The method is not clear introduced, and the followers are hard to do further study on this method",
    "review_points_list": [
      "The manuscript proposes a post-training quantization for vision transformer.",
      "The task is urgently needed for deployment in industrial environments.",
      "The related work is cited adequately, but more analysis about the relationship between the quantization of BERT and ViT should be provided.",
      "The idea of the manuscript is somewhat innovative, but the method part is not very clear.",
      "The quantization model with mixed-precision can get considerable results",
      "More comparison between other quantization methods used on BERT should be given.",
      "The method is not very clarified and some equations are very confusing",
      "The strategy for obtaining different bit-widths is not clear",
      "Figure 2 has no clear explanation",
      "The motivation for introducing rank-loss is best to provide more sufficient evidence",
      "The goal of the paper is significant in practical applications",
      "The results demonstrate the method is validation",
      "The method is not clear introduced, and the followers are hard to do further study on this method"
    ]
  },
  {
    "paper_id": "2502.21321v2",
    "submission_id": "wCrH0JBCFNm",
    "submission_title": "Post-Training Quantization for Vision Transformer",
    "review_id": "iTEDOni2-n5",
    "input": {
      "title": "Post-Training Quantization for Vision Transformer",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The main claim to novelty here is that previous work has not quantized transformers, and that a special rank quantization technique is required for the self-attention component.\n- The use of rank-quantization for self-attention layers, as opposed to standard correlation used for MLP here, is not tested or justified.\n- Is quantization based on rank actually superior to other methods (e.g. similarity using the Pearson correlation coefficient?)\n- Why not use the standard Spearman correlation coefficient to evaluate rank, which is identical to the Pearson used here except on ranks?\n- A large number of hyper-parameters are manually chosen, presumably to favor the authors method: \u03b1 and \u03b2 are set to 0.5 and 1.2, trade-off parameter \u03b3 and the threshold \u03b8 in Eq. (13) are set to 0.1 and 0.2, the maximum iteration is set to 20 if not mentioned specifically.\n- How fair is this for the three other methods used in comparison (percentile-based method, EasyQuant, Bit-Split)? Have the authors made similar efforts to optimize other methods?\n- In the big picture, quantization is one possible post-processing method for the goal of reducing memory and computation, others include distillation (which the authors specifically do not use), various projection methods (e.g. fast-food transform [a]), pruning, etc.\n- It is not clear why quantization should be used instead of these many methods for the same goal, nor why it should not be used in combination.\n- It is not clear wether the three methods compared against (percentile-based method, EasyQuant, Bit-Split) represent a comprehensive collection of alternative quantization methods.\n- Yang, Z., Moczulski, M., Denil, M., De Freitas, N., Smola, A., Song, L., & Wang, Z. (2015). Deep fried convnets. In Proceedings of the IEEE International Conference on Computer Vision (pp. 1476-1483).",
    "review_points_list": [
      "The main claim to novelty here is that previous work has not quantized transformers, and that a special rank quantization technique is required for the self-attention component.",
      "The use of rank-quantization for self-attention layers, as opposed to standard correlation used for MLP here, is not tested or justified.",
      "Is quantization based on rank actually superior to other methods (e.g. similarity using the Pearson correlation coefficient?)",
      "Why not use the standard Spearman correlation coefficient to evaluate rank, which is identical to the Pearson used here except on ranks?",
      "A large number of hyper-parameters are manually chosen, presumably to favor the authors method: \u03b1 and \u03b2 are set to 0.5 and 1.2, trade-off parameter \u03b3 and the threshold \u03b8 in Eq. (13) are set to 0.1 and 0.2, the maximum iteration is set to 20 if not mentioned specifically.",
      "How fair is this for the three other methods used in comparison (percentile-based method, EasyQuant, Bit-Split)? Have the authors made similar efforts to optimize other methods?",
      "In the big picture, quantization is one possible post-processing method for the goal of reducing memory and computation, others include distillation (which the authors specifically do not use), various projection methods (e.g. fast-food transform [a]), pruning, etc.",
      "It is not clear why quantization should be used instead of these many methods for the same goal, nor why it should not be used in combination.",
      "It is not clear wether the three methods compared against (percentile-based method, EasyQuant, Bit-Split) represent a comprehensive collection of alternative quantization methods.",
      "Yang, Z., Moczulski, M., Denil, M., De Freitas, N., Smola, A., Song, L., & Wang, Z. (2015). Deep fried convnets. In Proceedings of the IEEE International Conference on Computer Vision (pp. 1476-1483)."
    ]
  },
  {
    "paper_id": "2502.13418v1",
    "submission_id": "xwGeq7I4Opv",
    "submission_title": "Perturbation-based Regret Analysis of Predictive Control in Linear Time Varying Systems",
    "review_id": "J8gGLIMmSkQ",
    "input": {
      "title": "Perturbation-based Regret Analysis of Predictive Control in Linear Time Varying Systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I had a very positive impression of the paper.\n- The writing and notation were consistent and clear.\n- Authors establish guarantees both in terms of regret, and competitive ratio, the latter of which I found quite surprising.\n- The reduction to smoothed convex optimization also seems like a useful tool.\n- I encourage acceptance (score of 7), but am I reluctant to award a higher score because the result seems like a (somewhat) incremental extension of Li et al 2019:\n- Notably, dynamic regret with a lookahead suffers excess loss lambda^k, where lambda = sqrt(condition number).\n- Certainly this work is more general, is considerably better written, and the analysis relies only on conditioning of the controllability Gramian (rather than Li et al. which work in the rather hideous cannonical controllable form).\n- But the key ideas: lookahead due to banded structure (see below in Major suggestions for more explanation), and the reduction to optimization on a finite window with an extra variable x_{t+p} corresponding to a final state are both fundamentally the contributions of the prior work.\n- In fact, I believe that the latter (the reduction from control to SOCO) could have been better attributed to the predecessor.\n- I am enthusiastic about acceptance of this paper, but view it more of an improvement of past work than a fundamental breakthrough in its own right.\n- I think the sensitivity analysis based on banded diagonal matrices is super interesting.\n- However, in light of past work (Li et al. 2019), there also seems to be an 'algorithmic proof' of the same fact.\n- Namely, I can consider the exact optimal solution to some banded optimization problem, and then I can consider the iterates produced by Nesterov's method.\n- Examining the form of the latter, the k-th iterate requires at most k-steps of lookahead, yet exhibits an O(lambda^k) convergence to the optimal.\n- Then I could argue that any k-look ahead exact solution is also close to the k-step iterate of Nesterov's algorithm.\n- Of course, 'under the hood', the analysis of Nesterov's method and the conditioning of banded diagonal matrices reflect more or less the same principle.\n- But I think that, given the use of this algorithm in past work, it would be nice to at least remark that it could be used as an alternate proof.\n- It took me a while to understand the subscript notation after the psi functions, only to realize that it corresponded to a vector index.\n- I think it would be helpful to explain that upfront.\n- The authors do a good job of keeping notation consistent and avoid overloading.\n- Still, it would have been very helpful to have seen a notation table in the appendix.\n- This is particularly useful for disambiguating hats v.s. tildes. vs no accents, and for remembering that y_t are a state variable like x_t (which is non-standard in control, where y_t are typically system outputs).",
    "review_points_list": [
      "I had a very positive impression of the paper.",
      "The writing and notation were consistent and clear.",
      "Authors establish guarantees both in terms of regret, and competitive ratio, the latter of which I found quite surprising.",
      "The reduction to smoothed convex optimization also seems like a useful tool.",
      "I encourage acceptance (score of 7), but am I reluctant to award a higher score because the result seems like a (somewhat) incremental extension of Li et al 2019:",
      "Notably, dynamic regret with a lookahead suffers excess loss lambda^k, where lambda = sqrt(condition number).",
      "Certainly this work is more general, is considerably better written, and the analysis relies only on conditioning of the controllability Gramian (rather than Li et al. which work in the rather hideous cannonical controllable form).",
      "But the key ideas: lookahead due to banded structure (see below in Major suggestions for more explanation), and the reduction to optimization on a finite window with an extra variable x_{t+p} corresponding to a final state are both fundamentally the contributions of the prior work.",
      "In fact, I believe that the latter (the reduction from control to SOCO) could have been better attributed to the predecessor.",
      "I am enthusiastic about acceptance of this paper, but view it more of an improvement of past work than a fundamental breakthrough in its own right.",
      "I think the sensitivity analysis based on banded diagonal matrices is super interesting.",
      "However, in light of past work (Li et al. 2019), there also seems to be an 'algorithmic proof' of the same fact.",
      "Namely, I can consider the exact optimal solution to some banded optimization problem, and then I can consider the iterates produced by Nesterov's method.",
      "Examining the form of the latter, the k-th iterate requires at most k-steps of lookahead, yet exhibits an O(lambda^k) convergence to the optimal.",
      "Then I could argue that any k-look ahead exact solution is also close to the k-step iterate of Nesterov's algorithm.",
      "Of course, 'under the hood', the analysis of Nesterov's method and the conditioning of banded diagonal matrices reflect more or less the same principle.",
      "But I think that, given the use of this algorithm in past work, it would be nice to at least remark that it could be used as an alternate proof.",
      "It took me a while to understand the subscript notation after the psi functions, only to realize that it corresponded to a vector index.",
      "I think it would be helpful to explain that upfront.",
      "The authors do a good job of keeping notation consistent and avoid overloading.",
      "Still, it would have been very helpful to have seen a notation table in the appendix.",
      "This is particularly useful for disambiguating hats v.s. tildes. vs no accents, and for remembering that y_t are a state variable like x_t (which is non-standard in control, where y_t are typically system outputs)."
    ]
  },
  {
    "paper_id": "2502.13418v1",
    "submission_id": "xwGeq7I4Opv",
    "submission_title": "Perturbation-based Regret Analysis of Predictive Control in Linear Time Varying Systems",
    "review_id": "u0SSmKOUG4B",
    "input": {
      "title": "Perturbation-based Regret Analysis of Predictive Control in Linear Time Varying Systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Tackling the control of linear time varying systems is certainly of interest.\n- The main algorithms and the statement of the results are satisfying and easy enough to understand.\n- At a very high level, the proof ideas are also conveyed clearly.\n- While I'd be very interested to see a sensitivity analysis with respect to the prediction accuracy, it is more than reasonable to leave this for future work.\n- I'd be happy to know if the authors have any ideas regarding this matter.\n- I do have a few issues:\n- While the exposition made me think the results are plausible, I did not find it sufficiently convincing.\n- I tried looking a bit in the supplementary material, but the proofs there are quite long and technical and will take me very long to go over.\n- Ideally, I would like to see a concrete proof sketch in the main text or perhaps even a full proof composed of informative/technical side lemmas that are proved in the appendix.\n- In any case, it is not currently clear to me how the intermediate results in the main text come together to conclude the main results.\n- The definition of the cost seems non-standard to me.\n- In particular, the additive relation between the state and control costs.\n- Is it necessary?\n- If so, while this includes the standard LQR costs, its necessity should be discussed.\n- Assumption 4 (all costs are minimized at 0 with value 0) is also non-standard.\n- While the authors explain how it may be removed, the explanation is very short.\n- After some thought, I find it likely that their explanation is indeed correct.\n- Nonetheless, I think it should be explained in further detail and proved formally.\n- This would likely go to the supplementary material but I think its inclusion is necessary since the assumption is otherwise very restrictive.\n- Overall I think this is a very good work, but with the non-trivial caveat that I have no reasonable way to verify the veracity of the results.",
    "review_points_list": [
      "Tackling the control of linear time varying systems is certainly of interest.",
      "The main algorithms and the statement of the results are satisfying and easy enough to understand.",
      "At a very high level, the proof ideas are also conveyed clearly.",
      "While I'd be very interested to see a sensitivity analysis with respect to the prediction accuracy, it is more than reasonable to leave this for future work.",
      "I'd be happy to know if the authors have any ideas regarding this matter.",
      "I do have a few issues:",
      "While the exposition made me think the results are plausible, I did not find it sufficiently convincing.",
      "I tried looking a bit in the supplementary material, but the proofs there are quite long and technical and will take me very long to go over.",
      "Ideally, I would like to see a concrete proof sketch in the main text or perhaps even a full proof composed of informative/technical side lemmas that are proved in the appendix.",
      "In any case, it is not currently clear to me how the intermediate results in the main text come together to conclude the main results.",
      "The definition of the cost seems non-standard to me.",
      "In particular, the additive relation between the state and control costs.",
      "Is it necessary?",
      "If so, while this includes the standard LQR costs, its necessity should be discussed.",
      "Assumption 4 (all costs are minimized at 0 with value 0) is also non-standard.",
      "While the authors explain how it may be removed, the explanation is very short.",
      "After some thought, I find it likely that their explanation is indeed correct.",
      "Nonetheless, I think it should be explained in further detail and proved formally.",
      "This would likely go to the supplementary material but I think its inclusion is necessary since the assumption is otherwise very restrictive.",
      "Overall I think this is a very good work, but with the non-trivial caveat that I have no reasonable way to verify the veracity of the results."
    ]
  },
  {
    "paper_id": "2502.13418v1",
    "submission_id": "xwGeq7I4Opv",
    "submission_title": "Perturbation-based Regret Analysis of Predictive Control in Linear Time Varying Systems",
    "review_id": "pbm3587HlX2",
    "input": {
      "title": "Perturbation-based Regret Analysis of Predictive Control in Linear Time Varying Systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The analysis based on the assumption that at each time point, the system coefficients and random disturbances in the future $k$ time steps can be observed exactly for a sufficiently large $k$, depending implicitly on the controllability index of the system. In my opinion, this is a very strong assumption, especially the exact observation of noise. I suggest the authors to discuss extensions to inaccurate observations of noises, or give more concrete and practical examples where the random noises in the future time steps can be exactly observed.\n- In the optimization problem (2), the authors introduce the terminal cost $F(x)=\\alpha(\\|x\\|)$ with $\\alpha$ being a convex function. However, the results and assumptions of Theorem 3.3 seem to be independent of $F$. Please clarify the role of $F$. Can we choose $F$ to be the zero function in the algorithm?\n- I recommend to recall the definition of competitive ratio in the main text for the reader's convenience.\n- The authors mention in the introduction that the current framework cannot handle control constraints. However, it seems that the essential step of the analysis is to establish the Lipschitz stability of the optimizer of a convex optimization problem with respect to the loss function. Is it possible to follow the framework in https://arxiv.org/pdf/2104.09311.pdf, and handle the control constraints as an additional nonsmooth convex cost?",
    "review_points_list": [
      "The analysis based on the assumption that at each time point, the system coefficients and random disturbances in the future $k$ time steps can be observed exactly for a sufficiently large $k$, depending implicitly on the controllability index of the system. In my opinion, this is a very strong assumption, especially the exact observation of noise. I suggest the authors to discuss extensions to inaccurate observations of noises, or give more concrete and practical examples where the random noises in the future time steps can be exactly observed.",
      "In the optimization problem (2), the authors introduce the terminal cost $F(x)=\\alpha(\\|x\\|)$ with $\\alpha$ being a convex function. However, the results and assumptions of Theorem 3.3 seem to be independent of $F$. Please clarify the role of $F$. Can we choose $F$ to be the zero function in the algorithm?",
      "I recommend to recall the definition of competitive ratio in the main text for the reader's convenience.",
      "The authors mention in the introduction that the current framework cannot handle control constraints. However, it seems that the essential step of the analysis is to establish the Lipschitz stability of the optimizer of a convex optimization problem with respect to the loss function. Is it possible to follow the framework in https://arxiv.org/pdf/2104.09311.pdf, and handle the control constraints as an additional nonsmooth convex cost?"
    ]
  },
  {
    "paper_id": "2109.15015v1",
    "submission_id": "xVZx1SXb_IU",
    "submission_title": "Robust Allocations with Diversity Constraints",
    "review_id": "x9a3Sc5ovz-",
    "input": {
      "title": "Robust Allocations with Diversity Constraints",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well written and the topic is interesting.\n- The framework proposed is nice and the authors are able to incorporate a wide variety of mechanisms in the framework proposed.\n- The problem is well motivated by the computational advertising and recommendation systems settings -- though some more work from the latter could be included, e.g., Alex Beutel, Jilin Chen, Tulsee Doshi, Hai Qian, Allison Woodruff, Christine Luu, Pierre Kreitmann, Jonathan Bischof, and Ed H Chi. Putting fairness principles into practice: Challenges, metrics, and improvements.\n- Burke, R., Voida, A., Mattei, N., Sonboli, N. and Eskandanian, F., 2020. Algorithmic fairness, institutional logics, and social choice. In Harvard CRCS Workshop: AI for Social Good.\n- It's not clear to me that this is a machine learning paper or has anything to do with learning. In fact, this seems like a more EC type paper given the format and the proofs provided.\n- The second major issue I address more concretely below, but that this paper does not place itself well in the existing literature and I'm not convinced that some of these results are not already known.\n- The NNE property is known as Bossiness in the literature and is already fairly well studied. Given the pretty good background on the other issues in this paper I was surprised to see no discussion of bossiness.\n- Perhaps I am mistaken but I think this is a gross oversight of the paper and makes me think that some of these issues may have been handled already?\n- Bossiness from Papai is: 'Nonbossiness, a criterion frequently used in the context of strategyproof allocation, ensures that individuals cannot be bossy, that is, change the assignment for others, by reporting different preferences, without changing their own.'\n- This seems exactly to map here to the constraint expression of NNE.\n- See for example: P\u00e1pai, S., 2000. Strategyproof assignment by hierarchical exchange. Econometrica, 68(6), pp.1403-1433. SATTERTHWAITE, M. A., AND H. SONNENSCHEIN \u017d . 1981 : \u2018\u2018Strategy-Proof Allocation Mechanisms at Differentiable Points,\u2019\u2019 Reiew of Economic Studies, 48, 587-597. Hosseini, H. and Larson, K., 2019, May. Multiple assignment problems under lexicographic preferences.\n- Multiple assignment problems under lexicographic preferences is highly relevant and needs to be incorporated because, as you say in the paper, the constraints are a kind of second order utility function and so the strategic aspects are the centerpiece of this paper.\n- I was also curious that metrics from the healthy literature on diverse matching in the non-divisible space was not discussed. It seems that some of the metrics discussed here should be related to those.\n- Ahmed, F., Dickerson, J.P. and Fuge, M., 2017, August. Diverse weighted bipartite b-matching. In Proceedings of the 26th International Joint Conference on Artificial Intelligence (pp. 35-41). Chierichetti, F., Kumar, R., Lattanzi, S. and Vassilvtiskii, S., 2019, April. Matroids, matchings, and fairness. In The 22nd International Conference on Artificial Intelligence and Statistics (pp. 2212-2220). PMLR.\n- The statement of bossiness from Papai is: 'Nonbossiness, a criterion frequently used in the context of strategyproof allocation, ensures that individuals cannot be bossy, that is, change the assignment for others, by reporting different preferences, without changing their own.'\n- This seems exactly to map here to the constrint expression of NNE.\n- In terms of making the paper better I would suggest the authors add some kind of table of results. By the end it was hard to keep track of the results that were obtained for which rules and how the bounds helped our understanding of the overall setting.\n- It wasn't clear to me why we needed two constraint formulations and the paper didn't help clarify this -- a table would highlight where the formulations allow for tighter or loser bounds. A concrete example of the difference between the constraints would help too.\n- Lines 105-109 there is some confusion about value moving up or down I think.\n- In the formulation of 2.1 it seems that you allow free disposal, but this is not desired right? For then I could always just not assign things and have fair allocations since \\\\( \\\\) is in the set? Or perhaps I misread?\n- The experiments need more information -- averages over runs, the confidence bounds, etc. As it stands I had a very hard time interpreting the results and have somewhat little confidence in them since I don't know any error measures.\n- Also for the experiments, it would help to implement the constraints as optimization criteria to check as a baseline. I didn't see where this was done and given the size of the allocations being used a simple LP formulation should be able to handle this. As it stands the results are hard to interpret without a baseline.\n- The author response that bossiness is not directly implied I agree with, but not engaging with that literature and not clearly articulating why it is related and what the improvements for this paper are needs to be addressed. These areas are extremely closely related and the fact that you address truthfulness (hence a component of strategyproofness) and don't address bossiness is a shortcoming.\n- I am not saying you should cite all the literature but the paper should cite at least one paper on bossiness since the paper is directly addressing the same question: how bad can a report of one agent affect the allocation to other agents.",
    "review_points_list": [
      "The paper is well written and the topic is interesting.",
      "The framework proposed is nice and the authors are able to incorporate a wide variety of mechanisms in the framework proposed.",
      "The problem is well motivated by the computational advertising and recommendation systems settings -- though some more work from the latter could be included, e.g., Alex Beutel, Jilin Chen, Tulsee Doshi, Hai Qian, Allison Woodruff, Christine Luu, Pierre Kreitmann, Jonathan Bischof, and Ed H Chi. Putting fairness principles into practice: Challenges, metrics, and improvements.",
      "Burke, R., Voida, A., Mattei, N., Sonboli, N. and Eskandanian, F., 2020. Algorithmic fairness, institutional logics, and social choice. In Harvard CRCS Workshop: AI for Social Good.",
      "It's not clear to me that this is a machine learning paper or has anything to do with learning. In fact, this seems like a more EC type paper given the format and the proofs provided.",
      "The second major issue I address more concretely below, but that this paper does not place itself well in the existing literature and I'm not convinced that some of these results are not already known.",
      "The NNE property is known as Bossiness in the literature and is already fairly well studied. Given the pretty good background on the other issues in this paper I was surprised to see no discussion of bossiness.",
      "Perhaps I am mistaken but I think this is a gross oversight of the paper and makes me think that some of these issues may have been handled already?",
      "Bossiness from Papai is: 'Nonbossiness, a criterion frequently used in the context of strategyproof allocation, ensures that individuals cannot be bossy, that is, change the assignment for others, by reporting different preferences, without changing their own.'",
      "This seems exactly to map here to the constraint expression of NNE.",
      "See for example: P\u00e1pai, S., 2000. Strategyproof assignment by hierarchical exchange. Econometrica, 68(6), pp.1403-1433. SATTERTHWAITE, M. A., AND H. SONNENSCHEIN \u017d . 1981 : \u2018\u2018Strategy-Proof Allocation Mechanisms at Differentiable Points,\u2019\u2019 Reiew of Economic Studies, 48, 587-597. Hosseini, H. and Larson, K., 2019, May. Multiple assignment problems under lexicographic preferences.",
      "Multiple assignment problems under lexicographic preferences is highly relevant and needs to be incorporated because, as you say in the paper, the constraints are a kind of second order utility function and so the strategic aspects are the centerpiece of this paper.",
      "I was also curious that metrics from the healthy literature on diverse matching in the non-divisible space was not discussed. It seems that some of the metrics discussed here should be related to those.",
      "Ahmed, F., Dickerson, J.P. and Fuge, M., 2017, August. Diverse weighted bipartite b-matching. In Proceedings of the 26th International Joint Conference on Artificial Intelligence (pp. 35-41). Chierichetti, F., Kumar, R., Lattanzi, S. and Vassilvtiskii, S., 2019, April. Matroids, matchings, and fairness. In The 22nd International Conference on Artificial Intelligence and Statistics (pp. 2212-2220). PMLR.",
      "The statement of bossiness from Papai is: 'Nonbossiness, a criterion frequently used in the context of strategyproof allocation, ensures that individuals cannot be bossy, that is, change the assignment for others, by reporting different preferences, without changing their own.'",
      "This seems exactly to map here to the constrint expression of NNE.",
      "In terms of making the paper better I would suggest the authors add some kind of table of results. By the end it was hard to keep track of the results that were obtained for which rules and how the bounds helped our understanding of the overall setting.",
      "It wasn't clear to me why we needed two constraint formulations and the paper didn't help clarify this -- a table would highlight where the formulations allow for tighter or loser bounds. A concrete example of the difference between the constraints would help too.",
      "Lines 105-109 there is some confusion about value moving up or down I think.",
      "In the formulation of 2.1 it seems that you allow free disposal, but this is not desired right? For then I could always just not assign things and have fair allocations since \\\\( \\\\) is in the set? Or perhaps I misread?",
      "The experiments need more information -- averages over runs, the confidence bounds, etc. As it stands I had a very hard time interpreting the results and have somewhat little confidence in them since I don't know any error measures.",
      "Also for the experiments, it would help to implement the constraints as optimization criteria to check as a baseline. I didn't see where this was done and given the size of the allocations being used a simple LP formulation should be able to handle this. As it stands the results are hard to interpret without a baseline.",
      "The author response that bossiness is not directly implied I agree with, but not engaging with that literature and not clearly articulating why it is related and what the improvements for this paper are needs to be addressed. These areas are extremely closely related and the fact that you address truthfulness (hence a component of strategyproofness) and don't address bossiness is a shortcoming.",
      "I am not saying you should cite all the literature but the paper should cite at least one paper on bossiness since the paper is directly addressing the same question: how bad can a report of one agent affect the allocation to other agents."
    ]
  },
  {
    "paper_id": "2109.15015v1",
    "submission_id": "xVZx1SXb_IU",
    "submission_title": "Robust Allocations with Diversity Constraints",
    "review_id": "sfFedmpYsl",
    "input": {
      "title": "Robust Allocations with Diversity Constraints",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The model studied by the authors is interesting and the questions the authors explore seem new.\n- The authors do impose a lot of constraints - pareto-optimal, pigou-dalton allocation rule subject to proportionality constraints, and measure its performance against negative-externality, monotonicity criteria.\n- The allocation rules are natural and to some extent a natural implementation when introducing diversity constraints would be to maintain the old allocation rules and impose extra constraints - and this work points out that this can result in non-monotonicity and negative externality and this can be very bad if using social welfare as opposed to Nash welfare as the objective.\n- The paper is very well written.\n- The presentation could be improved a little by having some proofs or examples in the main body to help build intuition.\n- The results authors provide are interesting and provide some understanding of the effect of imposing diversity constraints.\n- There are still some aspects that are not fully explored.\n- One question is about monotonicity - the authors do not provide as thorough an analysis of this.\n- In particular it's not discussed if some PO, PD rule could obtain better than 1/2 approximation.\n- Authors also do not provide bounds for the min-max objective function.\n- For the negative externality, Nash Welfare has \u03b4 = 1, so potentially a tighter analysis can provide a better bound better than \u03b4/\u03b4 + 3, which can match the lower bound of 1/2 for any PO, PD rule.\n- The examples used in Theorem 3 and Corollary 4 is very skewed - the buyer prefers \u03b5 fraction for every unit of another item even though both are valued the same.\n- I am curious if less skewed examples can be constructed perhaps by setting proportionality constraint to be equal but allowing the values to be different.\n- There are some meta-critiques to the authors approach, the authors have anticipated and discussed these.\n- Authors could have found allocations with proportionality, non-monotonicity, no negative externality constraints and assessed how these perform on the social objectives.\n- Authors do mention this and justify their approach for the unique challenges it poses (optimizing for pareto-optimality and proportionality simultaneously is hard.)\n- Their justification is not fully convincing, but I think what they do is reasonable given what I wrote above.\n- Authors also consider the effect of introducing proportionality constraint in the ads setting - the proportionality constraint is fairly natural in the ad setting, however the value of the participants might need to be evaluated as quasi-linear utility as opposed to just the value of the allocation.\n- The analysis also becomes more involved if the auction is not truthful.\n- Authors discuss this critique and leave it as open question.\n- Overall, the results in this paper are interesting and detailed enough to warrant acceptance.\n- The paper will become stronger if some of the bounds were improved.\n- One minor note, the proof of theorem 1 is buggy.\n- In line 584, f'(\beta(1-\theta)) > f'(\beta).\n- It's not clear what z_\theta is also h(z_\theta)/max_z(h(z)) > \theta - this last inequality in particular breaks the proof and some tweak might be required to make it work.\n- Please specify how this proof can be fixed.\n- I did skim through a few other proofs and they seemed correct and thorough.",
    "review_points_list": [
      "The model studied by the authors is interesting and the questions the authors explore seem new.",
      "The authors do impose a lot of constraints - pareto-optimal, pigou-dalton allocation rule subject to proportionality constraints, and measure its performance against negative-externality, monotonicity criteria.",
      "The allocation rules are natural and to some extent a natural implementation when introducing diversity constraints would be to maintain the old allocation rules and impose extra constraints - and this work points out that this can result in non-monotonicity and negative externality and this can be very bad if using social welfare as opposed to Nash welfare as the objective.",
      "The paper is very well written.",
      "The presentation could be improved a little by having some proofs or examples in the main body to help build intuition.",
      "The results authors provide are interesting and provide some understanding of the effect of imposing diversity constraints.",
      "There are still some aspects that are not fully explored.",
      "One question is about monotonicity - the authors do not provide as thorough an analysis of this.",
      "In particular it's not discussed if some PO, PD rule could obtain better than 1/2 approximation.",
      "Authors also do not provide bounds for the min-max objective function.",
      "For the negative externality, Nash Welfare has \u03b4 = 1, so potentially a tighter analysis can provide a better bound better than \u03b4/\u03b4 + 3, which can match the lower bound of 1/2 for any PO, PD rule.",
      "The examples used in Theorem 3 and Corollary 4 is very skewed - the buyer prefers \u03b5 fraction for every unit of another item even though both are valued the same.",
      "I am curious if less skewed examples can be constructed perhaps by setting proportionality constraint to be equal but allowing the values to be different.",
      "There are some meta-critiques to the authors approach, the authors have anticipated and discussed these.",
      "Authors could have found allocations with proportionality, non-monotonicity, no negative externality constraints and assessed how these perform on the social objectives.",
      "Authors do mention this and justify their approach for the unique challenges it poses (optimizing for pareto-optimality and proportionality simultaneously is hard.)",
      "Their justification is not fully convincing, but I think what they do is reasonable given what I wrote above.",
      "Authors also consider the effect of introducing proportionality constraint in the ads setting - the proportionality constraint is fairly natural in the ad setting, however the value of the participants might need to be evaluated as quasi-linear utility as opposed to just the value of the allocation.",
      "The analysis also becomes more involved if the auction is not truthful.",
      "Authors discuss this critique and leave it as open question.",
      "Overall, the results in this paper are interesting and detailed enough to warrant acceptance.",
      "The paper will become stronger if some of the bounds were improved.",
      "One minor note, the proof of theorem 1 is buggy.",
      "In line 584, f'(\beta(1-\theta)) > f'(\beta).",
      "It's not clear what z_\theta is also h(z_\theta)/max_z(h(z)) > \theta - this last inequality in particular breaks the proof and some tweak might be required to make it work.",
      "Please specify how this proof can be fixed.",
      "I did skim through a few other proofs and they seemed correct and thorough."
    ]
  },
  {
    "paper_id": "2109.15015v1",
    "submission_id": "xVZx1SXb_IU",
    "submission_title": "Robust Allocations with Diversity Constraints",
    "review_id": "i0PF4G-1lW",
    "input": {
      "title": "Robust Allocations with Diversity Constraints",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- does the planner knows about this?\n- How is this different from the setting where you have multiple diversity constraints?\n- It would also be good to have some examples of the constraints\n- which is\n- how would this apply to user ad slots?\n- are you talking about the slots that have race/gender?\n- how would the agent express this?\n- there is a need a way to measure hurts\n- how are you defining the cost here?\n- We codify this via two desiderata capturing robustness\n- there should be some connections to your previous sentences to robustness in your context\n- w.r.t to\n- is that an objective here? rather than rule? what is a rule in your context? or allocation\n- when diversity constraints\n- does this depend on the types of the constraints\n- when you say criterion, do you mean one of the two properties in the previous sentences\n- what is the benefit of these guarantees?\n- the gap of?\n- it would be good to say a line about the observations\n- are the competing the right situation?\n- how are they competing?\n- heterogeneous agents?\n- their applications in\n- would be good to specific some concrete examples\n- are you going to shortly define this?\n- i think you define envy-free briefly but not this\n- is it the sum?\n- to achieve what property from the potential transfer\n- envy-freeness can also be implemented by the welfarist Nash Welfare\n- this can be hard to see\n- would Nash welfare implies envy-freeness\n- in fixed proportions\n- add (e.g., )\n- is this over the attributes or attributes\n- a convex polytope\n- a set of linear inequalities\n- arbitrary convex long-term constraints\n- can you elaborate?\n- one bearing the majority of this cost\n- how will the cost be transferred in such a situation?\n- negative externality to other agents\u2019 values is bounded\n- one question I have is that can they always satisfy the diversity constraints?\n- If it doesn't, how can you define the overall values?\n- reduces its own\n- his/her?\n- budget-capped valuation function\n- which is?\n- externality and monotonicity to within small constant factors\n- one is applying to the global objective and the other is applying to the agent's utility\n- If these are directly encoded into the optimization like\n- it would also be good to show this in experiments\n- Pareto-optimal or even proportional\n- how important are these notions if you were to valid them a little bit?\n- it is important to have an explicitly related work section in the paper\n- perhaps cutting out a bit more our results and 1.1 to fit in the related work\n- used allocation rules below in increasing order\n- could you just measure this by taking a derivative?\n- is there a citation for MMF or a more precise definition using max min?\n- the current one doesn't seem that precise per say\n- We now note some\n- it would be good to say they are useful later on\n- Is there a more intuitive meaning for PD?\n- Can you justify the proportionality constraint a bit more?\n- this seems to be conditional on the items that the agents receive in general\n- What other constraints do you consider beyond proportionality for fairness?\n- non-negative externality\n- are you only defining this w.r.t one agent?\n- what if more than one agent change?\n- but also, why would it increase other agents if both agents express diversity constraints?\n- I do have a concern where what if they are impossible to satisfy all the Pi's (no allocation)?\n- Definition 1\n- what if g(x) = 0 or g(y) = 0? or greater than 1?\n- there seems to be a gap between Theorem 1 and Theorem 2\n- It's kinda strange that you have a truthful result embedded when the paper is not really about it\n- I would suggest moving it or discuss it in the conclusion or discussion\n- could you also comment on the computational aspects of the problems?\n- Computational aspects of the problems??\n- Do you have any general results (similar to Theorem 2 for more general function)?\n- what about something like social welfare? max-min fairness?\n- Can you discuss what properties do the budget-capped function satisfy?\n- when this agent expresses a diversity constraint\n- did you try other types of diversity constraints?\n- How do the results change?\n- In the second double agent simulation\n- here it doesn't seem like your definition covers this case at all?\n- In the third monotonicity simulation\n- why can't you measure the same thing for the first and second simulations?\n- please increase the fonts of the figures, they are hard to see without zooming in\n- It would be good to see the exact parameters for reproducibility",
    "review_points_list": [
      "does the planner knows about this?",
      "How is this different from the setting where you have multiple diversity constraints?",
      "It would also be good to have some examples of the constraints",
      "which is",
      "how would this apply to user ad slots?",
      "are you talking about the slots that have race/gender?",
      "how would the agent express this?",
      "there is a need a way to measure hurts",
      "how are you defining the cost here?",
      "We codify this via two desiderata capturing robustness",
      "there should be some connections to your previous sentences to robustness in your context",
      "w.r.t to",
      "is that an objective here? rather than rule? what is a rule in your context? or allocation",
      "when diversity constraints",
      "does this depend on the types of the constraints",
      "when you say criterion, do you mean one of the two properties in the previous sentences",
      "what is the benefit of these guarantees?",
      "the gap of?",
      "it would be good to say a line about the observations",
      "are the competing the right situation?",
      "how are they competing?",
      "heterogeneous agents?",
      "their applications in",
      "would be good to specific some concrete examples",
      "are you going to shortly define this?",
      "i think you define envy-free briefly but not this",
      "is it the sum?",
      "to achieve what property from the potential transfer",
      "envy-freeness can also be implemented by the welfarist Nash Welfare",
      "this can be hard to see",
      "would Nash welfare implies envy-freeness",
      "in fixed proportions",
      "add (e.g., )",
      "is this over the attributes or attributes",
      "a convex polytope",
      "a set of linear inequalities",
      "arbitrary convex long-term constraints",
      "can you elaborate?",
      "one bearing the majority of this cost",
      "how will the cost be transferred in such a situation?",
      "negative externality to other agents\u2019 values is bounded",
      "one question I have is that can they always satisfy the diversity constraints?",
      "If it doesn't, how can you define the overall values?",
      "reduces its own",
      "his/her?",
      "budget-capped valuation function",
      "which is?",
      "externality and monotonicity to within small constant factors",
      "one is applying to the global objective and the other is applying to the agent's utility",
      "If these are directly encoded into the optimization like",
      "it would also be good to show this in experiments",
      "Pareto-optimal or even proportional",
      "how important are these notions if you were to valid them a little bit?",
      "it is important to have an explicitly related work section in the paper",
      "perhaps cutting out a bit more our results and 1.1 to fit in the related work",
      "used allocation rules below in increasing order",
      "could you just measure this by taking a derivative?",
      "is there a citation for MMF or a more precise definition using max min?",
      "the current one doesn't seem that precise per say",
      "We now note some",
      "it would be good to say they are useful later on",
      "Is there a more intuitive meaning for PD?",
      "Can you justify the proportionality constraint a bit more?",
      "this seems to be conditional on the items that the agents receive in general",
      "What other constraints do you consider beyond proportionality for fairness?",
      "non-negative externality",
      "are you only defining this w.r.t one agent?",
      "what if more than one agent change?",
      "but also, why would it increase other agents if both agents express diversity constraints?",
      "I do have a concern where what if they are impossible to satisfy all the Pi's (no allocation)?",
      "Definition 1",
      "what if g(x) = 0 or g(y) = 0? or greater than 1?",
      "there seems to be a gap between Theorem 1 and Theorem 2",
      "It's kinda strange that you have a truthful result embedded when the paper is not really about it",
      "I would suggest moving it or discuss it in the conclusion or discussion",
      "could you also comment on the computational aspects of the problems?",
      "Computational aspects of the problems??",
      "Do you have any general results (similar to Theorem 2 for more general function)?",
      "what about something like social welfare? max-min fairness?",
      "Can you discuss what properties do the budget-capped function satisfy?",
      "when this agent expresses a diversity constraint",
      "did you try other types of diversity constraints?",
      "How do the results change?",
      "In the second double agent simulation",
      "here it doesn't seem like your definition covers this case at all?",
      "In the third monotonicity simulation",
      "why can't you measure the same thing for the first and second simulations?",
      "please increase the fonts of the figures, they are hard to see without zooming in",
      "It would be good to see the exact parameters for reproducibility"
    ]
  },
  {
    "paper_id": "2109.15015v1",
    "submission_id": "xVZx1SXb_IU",
    "submission_title": "Robust Allocations with Diversity Constraints",
    "review_id": "JW9MeWD2EG-",
    "input": {
      "title": "Robust Allocations with Diversity Constraints",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper studies an important problem of incorporating diversity constraints into resource allocation that arises naturally in the context of ad auctions or assigning workers to tasks, among others.\n- The two requirements on the allocation rules studied in the paper are natural, and are driven by economic concerns.\n- Furthermore, the characterization of the Nash welfare rule as uniquely satisfying (approximate versions) of the two requirements adds further justification for the Nash welfare rule, beyond the many theoretical properties already known.\n- The authors further consider other common welfarist rules, and characterize their failure to satisfy the two requirements.\n- It is unclear why the Max-min fairness fits into the class of welfarist rules.\n- I am hard pressed to see the rule as maximizing the sum of concave functions of the agents' utilities.\n- The presentation of the results can be improved.\n- The paper splits the analysis into different sections (corresponding to the two requirements).\n- This makes it harder to compare the performance of the different rules.\n- Furthermore, the monotonicity properties of the SW and the MMF policies are not discussed.\n- The results in the paper are not sufficient to conclude whether the Nash welfare rule is the best possible welfarist rule for the two specified requirements.\n- The upper bounds provided for non-negative externality ($q=1/2$) are substantially larger than that for the NW rule ($q=1/4$).\n- For the monotonicity requirement, no bounds on the performance of a welfarist rule are provided.\n- Nevertheless, I find the paper makes an interesting theoretical contribution, exhibiting the good properties of the Nash welfare rule.",
    "review_points_list": [
      "The paper studies an important problem of incorporating diversity constraints into resource allocation that arises naturally in the context of ad auctions or assigning workers to tasks, among others.",
      "The two requirements on the allocation rules studied in the paper are natural, and are driven by economic concerns.",
      "Furthermore, the characterization of the Nash welfare rule as uniquely satisfying (approximate versions) of the two requirements adds further justification for the Nash welfare rule, beyond the many theoretical properties already known.",
      "The authors further consider other common welfarist rules, and characterize their failure to satisfy the two requirements.",
      "It is unclear why the Max-min fairness fits into the class of welfarist rules.",
      "I am hard pressed to see the rule as maximizing the sum of concave functions of the agents' utilities.",
      "The presentation of the results can be improved.",
      "The paper splits the analysis into different sections (corresponding to the two requirements).",
      "This makes it harder to compare the performance of the different rules.",
      "Furthermore, the monotonicity properties of the SW and the MMF policies are not discussed.",
      "The results in the paper are not sufficient to conclude whether the Nash welfare rule is the best possible welfarist rule for the two specified requirements.",
      "The upper bounds provided for non-negative externality ($q=1/2$) are substantially larger than that for the NW rule ($q=1/4$).",
      "For the monotonicity requirement, no bounds on the performance of a welfarist rule are provided.",
      "Nevertheless, I find the paper makes an interesting theoretical contribution, exhibiting the good properties of the Nash welfare rule."
    ]
  },
  {
    "paper_id": "1805.09111v1",
    "submission_id": "z-X_PpwaroO",
    "submission_title": "Computer-Aided Design as Language",
    "review_id": "aMXWMr6Ygmb",
    "input": {
      "title": "Computer-Aided Design as Language",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The novelty of this work is clear to me.\n- As one of very first attempts on generative modeling for engineering CAD sketches (there are some concurrent works), it devise a method to represent CAD sketch as a sequence of triplet tokens and combine this representation with general language modeling technique to capture both the geometric primitives and constraints.\n- The proposed special embedding and pointer strategy for its triplet representation is also interesting.\n- The results in general look good and I like the colored visualization.\n- Besides unconditional generation, one of the potential application, image-conditional generation is also thoroughly evaluated.\n- It does not compare to any prior works.\n- I understand it's the very first work for CAD sketch generation, but there are prior works (e.g. DeepSVG) that generates vector graphics, which are also parametric sketches but without constraints.\n- The authors can just compare results in the image domain.\n- The same applies to the image-conditioned generation.\n- The test set is too small.\n- A test set of 50K is only 1% compared to a training set of 4.6M (line 239-241).\n- This could result in much variance.\n- 90%-10%-10% is the general practice.\n- I hope the author to use a larger test set in the revision.\n- If not, it's better to explain why.\n- Consider to cite concurrent works on CAD generation:\n- DeepCAD: A Deep Generative Network for Computer-Aided Design Models.\n- SketchGen: Generating Constrained CAD Sketches.\n- What exactly is external sketch solver (line 288)?\n- I guess it's some sort of constraint optimizer.\n- It's better to give some detailed descriptions (including in the supplement is OK).\n- Lastly, will the dataset be released?\n- A large dataset is always beneficial to the community.",
    "review_points_list": [
      "The novelty of this work is clear to me.",
      "As one of very first attempts on generative modeling for engineering CAD sketches (there are some concurrent works), it devise a method to represent CAD sketch as a sequence of triplet tokens and combine this representation with general language modeling technique to capture both the geometric primitives and constraints.",
      "The proposed special embedding and pointer strategy for its triplet representation is also interesting.",
      "The results in general look good and I like the colored visualization.",
      "Besides unconditional generation, one of the potential application, image-conditional generation is also thoroughly evaluated.",
      "It does not compare to any prior works.",
      "I understand it's the very first work for CAD sketch generation, but there are prior works (e.g. DeepSVG) that generates vector graphics, which are also parametric sketches but without constraints.",
      "The authors can just compare results in the image domain.",
      "The same applies to the image-conditioned generation.",
      "The test set is too small.",
      "A test set of 50K is only 1% compared to a training set of 4.6M (line 239-241).",
      "This could result in much variance.",
      "90%-10%-10% is the general practice.",
      "I hope the author to use a larger test set in the revision.",
      "If not, it's better to explain why.",
      "Consider to cite concurrent works on CAD generation:",
      "DeepCAD: A Deep Generative Network for Computer-Aided Design Models.",
      "SketchGen: Generating Constrained CAD Sketches.",
      "What exactly is external sketch solver (line 288)?",
      "I guess it's some sort of constraint optimizer.",
      "It's better to give some detailed descriptions (including in the supplement is OK).",
      "Lastly, will the dataset be released?",
      "A large dataset is always beneficial to the community."
    ]
  },
  {
    "paper_id": "1805.09111v1",
    "submission_id": "z-X_PpwaroO",
    "submission_title": "Computer-Aided Design as Language",
    "review_id": "lbFvsVPWLT",
    "input": {
      "title": "Computer-Aided Design as Language",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is mostly well-written and easy to follow.\n- The proposed coding of structured 2D sketches is novel and seems useful, particularly for an effective correction of predicted objects based on constraints.\n- The dataset, which the authors plan to make public, could be useful to other applications due to its quality and structured labeling.\n- The experiments, though not extensive, show that their proposed models work as expected.\n- Run-time and train-time of the models are missing, and this makes comparisons between models and an overall efficiency/practicality evaluation hard.\n- For example, how far is the generation (unconditional and conditional) from real-time performance?\n- Comparison to similar models is missing, that is, how does the model compare in quality and speed with other vector image generation methods (conditional and unconditional)? (an extension of table 4 in appendix H).\n- Whenever reporting average, it is good practice to report standard deviation as well, to provide a sense of confidence.\n- It is important to highlight/discuss the types of failures (wrong shapes and wrong constraints) and the rates with which each happen, to give a better picture of the models' capabilities.\n- Discussion of model failure, such as the compression failure discussed in appendix G, are very valuable to the more broad transformer research, and are a good idea to include and elaborate on in the main text.\n- Side note: wrong syntax in Eq.1.",
    "review_points_list": [
      "The paper is mostly well-written and easy to follow.",
      "The proposed coding of structured 2D sketches is novel and seems useful, particularly for an effective correction of predicted objects based on constraints.",
      "The dataset, which the authors plan to make public, could be useful to other applications due to its quality and structured labeling.",
      "The experiments, though not extensive, show that their proposed models work as expected.",
      "Run-time and train-time of the models are missing, and this makes comparisons between models and an overall efficiency/practicality evaluation hard.",
      "For example, how far is the generation (unconditional and conditional) from real-time performance?",
      "Comparison to similar models is missing, that is, how does the model compare in quality and speed with other vector image generation methods (conditional and unconditional)? (an extension of table 4 in appendix H).",
      "Whenever reporting average, it is good practice to report standard deviation as well, to provide a sense of confidence.",
      "It is important to highlight/discuss the types of failures (wrong shapes and wrong constraints) and the rates with which each happen, to give a better picture of the models' capabilities.",
      "Discussion of model failure, such as the compression failure discussed in appendix G, are very valuable to the more broad transformer research, and are a good idea to include and elaborate on in the main text.",
      "Side note: wrong syntax in Eq.1."
    ]
  },
  {
    "paper_id": "1805.09111v1",
    "submission_id": "z-X_PpwaroO",
    "submission_title": "Computer-Aided Design as Language",
    "review_id": "XrUnWTm2f6Z",
    "input": {
      "title": "Computer-Aided Design as Language",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The introduction provides a clear overview of the research topic and its significance.\n- The methodology section is well-structured and detailed, making it easy to understand the study's approach.\n- The results are presented clearly with appropriate data visualizations to support the findings.\n- The discussion section effectively analyzes the results and relates them back to the research question.\n- The conclusion succinctly summarizes the main findings and implications of the study.\n- Suggestions for future research are mentioned, providing direction for further studies in the field.",
    "review_points_list": [
      "The introduction provides a clear overview of the research topic and its significance.",
      "The methodology section is well-structured and detailed, making it easy to understand the study's approach.",
      "The results are presented clearly with appropriate data visualizations to support the findings.",
      "The discussion section effectively analyzes the results and relates them back to the research question.",
      "The conclusion succinctly summarizes the main findings and implications of the study.",
      "Suggestions for future research are mentioned, providing direction for further studies in the field."
    ]
  },
  {
    "paper_id": "1805.09111v1",
    "submission_id": "z-X_PpwaroO",
    "submission_title": "Computer-Aided Design as Language",
    "review_id": "F506RDdcgnl",
    "input": {
      "title": "Computer-Aided Design as Language",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper is dealing with a practical problem that has wide industrial applications.\n- The high-level idea behind the proposed technical method (bridging 2D sketches and languages) makes sense to me.\n- The quantitative and qualitative evaluation seems OK, although I think a few more experiments could be added to make the paper stronger (see below).\n- Overall, I think this paper has contributed some technical ideas that this community can benefit from.\n- However, I still have a few questions and would like to make my final decision after reading the authors\u2019 answers:\n- A high-level comment on the motivation and application of the technical method: the paper attempts to make an analogy between 2D sketches and natural language modeling.\n- The paper mentioned that long sequences of data are a challenge, motivating the usage of PB messages.\n- The paper mentioned \u201cfrom coffee mugs to sports cars\u201d twice in the main paper and its supplemental material, yet the 2D sketches shown in the paper are not even close to the complexity of a sports car.\n- One thing that makes 2D sketches really useful in CAD applications is that they are parametric designs: the (entity, constraint) combo not only defines a particular design itself but also provides a family of similar designs if you perturb the continuous parameters (e.g., length of a line, angle of an arc) in these entities.\n- I would love to see some small experiments on the 2D sketches generated by this paper, i.e., mildly perturbing the entity parameters in the resultant 2D sketches, and see how often they lead to invalid sketches that break the constraints.",
    "review_points_list": [
      "This paper is dealing with a practical problem that has wide industrial applications.",
      "The high-level idea behind the proposed technical method (bridging 2D sketches and languages) makes sense to me.",
      "The quantitative and qualitative evaluation seems OK, although I think a few more experiments could be added to make the paper stronger (see below).",
      "Overall, I think this paper has contributed some technical ideas that this community can benefit from.",
      "However, I still have a few questions and would like to make my final decision after reading the authors\u2019 answers:",
      "A high-level comment on the motivation and application of the technical method: the paper attempts to make an analogy between 2D sketches and natural language modeling.",
      "The paper mentioned that long sequences of data are a challenge, motivating the usage of PB messages.",
      "The paper mentioned \u201cfrom coffee mugs to sports cars\u201d twice in the main paper and its supplemental material, yet the 2D sketches shown in the paper are not even close to the complexity of a sports car.",
      "One thing that makes 2D sketches really useful in CAD applications is that they are parametric designs: the (entity, constraint) combo not only defines a particular design itself but also provides a family of similar designs if you perturb the continuous parameters (e.g., length of a line, angle of an arc) in these entities.",
      "I would love to see some small experiments on the 2D sketches generated by this paper, i.e., mildly perturbing the entity parameters in the resultant 2D sketches, and see how often they lead to invalid sketches that break the constraints."
    ]
  },
  {
    "paper_id": "2211.08184v2",
    "submission_id": "wvylaMP20_b",
    "submission_title": "Improved Coresets and Sublinear Algorithms for Power Means in Euclidean Spaces",
    "review_id": "cyxIbbhcnCl",
    "input": {
      "title": "Improved Coresets and Sublinear Algorithms for Power Means in Euclidean Spaces",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper provider a solid theoretical contribution\n- It suggests a sublinear time algorithm for approximating the point that minimizes the sum of euclidian distances to the power of z over a given input set of points\n- The required number of points samples in order to obtain with probability at least a approximation to the optimal solution is Oepsilonzlogdelta polylogepsilon generalization over prior works\n- The paper also shows that we can compute a coreset for such a problem where the size of the coreset is Oepsilonz\n- Finally they show that the exponential dependency in z is necessary for computing an approximation\n- They used and improved the technique introduced by Chen by showing that it is sufficient to only consider Olog e rings\n- They suggest an improved analysis of sampling from rings\n- The state-of-the-art analysis by Feldman and Langberg reduces the problem of computing a coreset to sampling in a weighted range space of bounded VC dimension\n- They improve over the previous analyses via the chaining technique\n- I liked the paper it has a solid theory and novel ideas its written well\n- However the experimental results section is very weak see Limitations section\n- Note I couldnt check the proofs due to time constraints and since they are long",
    "review_points_list": [
      "The paper provider a solid theoretical contribution",
      "It suggests a sublinear time algorithm for approximating the point that minimizes the sum of euclidian distances to the power of z over a given input set of points",
      "The required number of points samples in order to obtain with probability at least a approximation to the optimal solution is Oepsilonzlogdelta polylogepsilon generalization over prior works",
      "The paper also shows that we can compute a coreset for such a problem where the size of the coreset is Oepsilonz",
      "Finally they show that the exponential dependency in z is necessary for computing an approximation",
      "They used and improved the technique introduced by Chen by showing that it is sufficient to only consider Olog e rings",
      "They suggest an improved analysis of sampling from rings",
      "The state-of-the-art analysis by Feldman and Langberg reduces the problem of computing a coreset to sampling in a weighted range space of bounded VC dimension",
      "They improve over the previous analyses via the chaining technique",
      "I liked the paper it has a solid theory and novel ideas its written well",
      "However the experimental results section is very weak see Limitations section",
      "Note I couldnt check the proofs due to time constraints and since they are long"
    ]
  },
  {
    "paper_id": "2211.08184v2",
    "submission_id": "wvylaMP20_b",
    "submission_title": "Improved Coresets and Sublinear Algorithms for Power Means in Euclidean Spaces",
    "review_id": "x3J5RZz7U4",
    "input": {
      "title": "Improved Coresets and Sublinear Algorithms for Power Means in Euclidean Spaces",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I already reviewed a previous version of this paper. Corrections and references were added.\n- There are still some concerns.\n- Fundamental problem in machine learning and optimization.\n- Clear writing.\n- Open Python code which is not so common these days and will be appreciated by the non-theory guys.\n- Interesting non-trivial algorithm.\n- Novel approach with potential many applications.\n- I am mainly concerned with relation to existing work and novelty.\n- For example, it is claimed that their coreset of size ~O(1/eps^2) improves the coreset of ~O(d/eps^2) by Feldman and Langberg [STOC'11].\n- However, [STOC'11] also suggested how to remove the d using the fact that the optimal center can be approximated by ~1/epsilon points, which implies a VC-dimension that is independent of d.\n- Also, when the authors write O(1/eps^2) instead of 2^{100z}*O(1/eps^2) that should mention that z is fixed.",
    "review_points_list": [
      "I already reviewed a previous version of this paper. Corrections and references were added.",
      "There are still some concerns.",
      "Fundamental problem in machine learning and optimization.",
      "Clear writing.",
      "Open Python code which is not so common these days and will be appreciated by the non-theory guys.",
      "Interesting non-trivial algorithm.",
      "Novel approach with potential many applications.",
      "I am mainly concerned with relation to existing work and novelty.",
      "For example, it is claimed that their coreset of size ~O(1/eps^2) improves the coreset of ~O(d/eps^2) by Feldman and Langberg [STOC'11].",
      "However, [STOC'11] also suggested how to remove the d using the fact that the optimal center can be approximated by ~1/epsilon points, which implies a VC-dimension that is independent of d.",
      "Also, when the authors write O(1/eps^2) instead of 2^{100z}*O(1/eps^2) that should mention that z is fixed."
    ]
  },
  {
    "paper_id": "2104.05077v3",
    "submission_id": "wPA_5Wsjt8i",
    "submission_title": "Conditional Generation Using Polynomial Expansions",
    "review_id": "1J_Kx-XBNQ8",
    "input": {
      "title": "Conditional Generation Using Polynomial Expansions",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- CoPE is a novel construction to my knowledge which can be seen as a natural continuation of the existing work such as Pi-Net or SPADE. A potentially useful reference for a similar (albeit arguably simpler) technique for incorporating interactions between multiple input variables can be found in [1].\n- The paper is generally well-written and adequately communicates the non-trivial construction of CoPE.\n- I would still appreciate if authors could provide more details on technical implementation on some of the mentioned ideas.\n- 1) As authors mention, if one of the inputs is an image a convolution can be applied for embedding it. For example, is it a problem that the dimensionality of the image should remain constant (and low) or this can be circumvented?\n- 2) Would it be anyhow beneficial to include non-linear components in computing the multiplicative update in eq. 2?\n- 3) Implementation of SNGAN-CoPE.\n- Another question is why in Appendix D matrix P has dimensionality d1 * d2 x o and not (d1 + d2) x o?\n- I'm puzzled here.\n- A more general question is why authors are specifically interested in the GAN setting and not, for example, in VAEs where the problem of ignoring conditional information is also present.\n- The benefit of considering VAEs would allow to compare models directly in likelihoods and alleviate the possibility of hacking the imperfect image-quality metrics.\n- CoPE seems to be a useful mechanism for conditioning in polynomial networks and will likely be re-used in further work.\n- Overall I don't have many concerns about the method of the evaluation.\n- I would still very much be interested in applying CoPE in a controllable, toy setting where the underlying data distribution is known to verify it indeed recovers the right interaction between variables because mere relying on metrics such as inception score is somewhat futile (this just my subjective opinion).\n- Authors addressed my questions and concerns reasonably and I'm therefore raising my score.\n- I encourage authors to incorporate the received feedback (and their replies) into the paper.",
    "review_points_list": [
      "CoPE is a novel construction to my knowledge which can be seen as a natural continuation of the existing work such as Pi-Net or SPADE. A potentially useful reference for a similar (albeit arguably simpler) technique for incorporating interactions between multiple input variables can be found in [1].",
      "The paper is generally well-written and adequately communicates the non-trivial construction of CoPE.",
      "I would still appreciate if authors could provide more details on technical implementation on some of the mentioned ideas.",
      "1) As authors mention, if one of the inputs is an image a convolution can be applied for embedding it. For example, is it a problem that the dimensionality of the image should remain constant (and low) or this can be circumvented?",
      "2) Would it be anyhow beneficial to include non-linear components in computing the multiplicative update in eq. 2?",
      "3) Implementation of SNGAN-CoPE.",
      "Another question is why in Appendix D matrix P has dimensionality d1 * d2 x o and not (d1 + d2) x o?",
      "I'm puzzled here.",
      "A more general question is why authors are specifically interested in the GAN setting and not, for example, in VAEs where the problem of ignoring conditional information is also present.",
      "The benefit of considering VAEs would allow to compare models directly in likelihoods and alleviate the possibility of hacking the imperfect image-quality metrics.",
      "CoPE seems to be a useful mechanism for conditioning in polynomial networks and will likely be re-used in further work.",
      "Overall I don't have many concerns about the method of the evaluation.",
      "I would still very much be interested in applying CoPE in a controllable, toy setting where the underlying data distribution is known to verify it indeed recovers the right interaction between variables because mere relying on metrics such as inception score is somewhat futile (this just my subjective opinion).",
      "Authors addressed my questions and concerns reasonably and I'm therefore raising my score.",
      "I encourage authors to incorporate the received feedback (and their replies) into the paper."
    ]
  },
  {
    "paper_id": "2104.05077v3",
    "submission_id": "wPA_5Wsjt8i",
    "submission_title": "Conditional Generation Using Polynomial Expansions",
    "review_id": "V1_B56uvNKv",
    "input": {
      "title": "Conditional Generation Using Polynomial Expansions",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The generation method (CoPE) proposed in this paper is closely related to Pi-net, directly designed for conditional generation (accepting two inputs at its base form, one latent and one conditional input). The authors point out several aspects which differentiate their technique from Pi-net, and I think there is significant novelty. I would suggest furthering this discussion in the main paper, since the two techniques are quite similar.\n- The experimental section (which is the main focus of the paper) considers a multitude of problems, such as class conditional generation, inverse problems, and generation of unseen attribute combinations. This demonstrates the suitability of the proposed method in various useful tasks.\n- Comparisons are made with several polynomial-like architectures, but I think it would be interesting to make comparisons with other architectures as well.\n- For example, in the conditional CIFAR-10 experiment, Karras et al. (2020) report some architectures which appear to have better IS/FID scores than the proposed CoPE technique (Figure 11b in that paper).\n- Of course, the actual scores received also depend on the size of the architecture used in each method, but I believe they should be mentioned at least.\n- I also think that the baselines considered should be the same in Tables 4 and 5 (Sections 4.1 and 4.3 respectively), to enable a better comparison of the proposed method with previous work.\n- The paper is clear in general and easy to follow.\n- I have the following comments to make which can improve the clarity of the paper.\n- - Tables should be in the beginning or the end of the page. Right now there are a few lines of text between tables which are easy to miss.\n- - I believe it would be useful to include a better explanation of the baselines used (mainly GAN-CONC and GAN-ADD), as well as the architecture of the discriminator and the order of CoPE used in the experiments (at least in the supplementary).\n- - In Figure 4, I think it would be useful to include whether the images presented are randomly picked or curated.\n- There are also a couple of very minor errors, namely Tables 1 and 4 extending beyond the limits of the page slightly, as well as a typo in line 78.\n- Overall, this is an interesting work in an equally interesting field, given the possibility of providing improvements for both image generation and inverse problems.\n- I lean towards accepting this work, especially if the issues regarding the experiments I addressed above are resolved during the rebuttal process.\n- References: Karras, T., Aittala, M., Hellsten, J., Laine, S., Lehtinen, J., & Aila, T. (2020). Training generative adversarial networks with limited data. arXiv preprint arXiv:2006.06676.\n- **Update after rebuttal:**\n- The reviewers have clarified the points I noted about the experiments, and have fully addressed my concerns.\n- I believe the added material from the feedback and all of the reviewers' responses should be included in the final version of the paper.\n- As such, I am raising my score.",
    "review_points_list": [
      "The generation method (CoPE) proposed in this paper is closely related to Pi-net, directly designed for conditional generation (accepting two inputs at its base form, one latent and one conditional input). The authors point out several aspects which differentiate their technique from Pi-net, and I think there is significant novelty. I would suggest furthering this discussion in the main paper, since the two techniques are quite similar.",
      "The experimental section (which is the main focus of the paper) considers a multitude of problems, such as class conditional generation, inverse problems, and generation of unseen attribute combinations. This demonstrates the suitability of the proposed method in various useful tasks.",
      "Comparisons are made with several polynomial-like architectures, but I think it would be interesting to make comparisons with other architectures as well.",
      "For example, in the conditional CIFAR-10 experiment, Karras et al. (2020) report some architectures which appear to have better IS/FID scores than the proposed CoPE technique (Figure 11b in that paper).",
      "Of course, the actual scores received also depend on the size of the architecture used in each method, but I believe they should be mentioned at least.",
      "I also think that the baselines considered should be the same in Tables 4 and 5 (Sections 4.1 and 4.3 respectively), to enable a better comparison of the proposed method with previous work.",
      "The paper is clear in general and easy to follow.",
      "I have the following comments to make which can improve the clarity of the paper.",
      "- Tables should be in the beginning or the end of the page. Right now there are a few lines of text between tables which are easy to miss.",
      "- I believe it would be useful to include a better explanation of the baselines used (mainly GAN-CONC and GAN-ADD), as well as the architecture of the discriminator and the order of CoPE used in the experiments (at least in the supplementary).",
      "- In Figure 4, I think it would be useful to include whether the images presented are randomly picked or curated.",
      "There are also a couple of very minor errors, namely Tables 1 and 4 extending beyond the limits of the page slightly, as well as a typo in line 78.",
      "Overall, this is an interesting work in an equally interesting field, given the possibility of providing improvements for both image generation and inverse problems.",
      "I lean towards accepting this work, especially if the issues regarding the experiments I addressed above are resolved during the rebuttal process.",
      "References: Karras, T., Aittala, M., Hellsten, J., Laine, S., Lehtinen, J., & Aila, T. (2020). Training generative adversarial networks with limited data. arXiv preprint arXiv:2006.06676.",
      "**Update after rebuttal:**",
      "The reviewers have clarified the points I noted about the experiments, and have fully addressed my concerns.",
      "I believe the added material from the feedback and all of the reviewers' responses should be included in the final version of the paper.",
      "As such, I am raising my score."
    ]
  },
  {
    "paper_id": "2104.05077v3",
    "submission_id": "wPA_5Wsjt8i",
    "submission_title": "Conditional Generation Using Polynomial Expansions",
    "review_id": "PfMokfTnAen",
    "input": {
      "title": "Conditional Generation Using Polynomial Expansions",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The main idea is simple and intuitive with sound motivation.\n- The experiments are very thorough and show clear improvements over baselines.\n- I am not an expert in this field but the writing is mostly clear but is hard to follow at the beginning of the experiment section.\n- Section 3 largely focuses on simple PNNs and their generalization to conditional settings.\n- However, right at the beginning of section 4, the authors mention SNGAN-CoPE and SPACE-CoPE without much explanation of how they are created.\n- Additionally, in section 3.2 about the logarithmic number of layers required, it was not clear how the output of the first polymer is fed to the other.\n- The initial input has two latent variables z_I and z_II which will result in a single output which is a polynomial of degree N_1. How exactly is this input to obtain a polynomial of degree N1.N2?",
    "review_points_list": [
      "The main idea is simple and intuitive with sound motivation.",
      "The experiments are very thorough and show clear improvements over baselines.",
      "I am not an expert in this field but the writing is mostly clear but is hard to follow at the beginning of the experiment section.",
      "Section 3 largely focuses on simple PNNs and their generalization to conditional settings.",
      "However, right at the beginning of section 4, the authors mention SNGAN-CoPE and SPACE-CoPE without much explanation of how they are created.",
      "Additionally, in section 3.2 about the logarithmic number of layers required, it was not clear how the output of the first polymer is fed to the other.",
      "The initial input has two latent variables z_I and z_II which will result in a single output which is a polynomial of degree N_1. How exactly is this input to obtain a polynomial of degree N1.N2?"
    ]
  },
  {
    "paper_id": "2104.05077v3",
    "submission_id": "wPA_5Wsjt8i",
    "submission_title": "Conditional Generation Using Polynomial Expansions",
    "review_id": "OeGHmBsPLiZ",
    "input": {
      "title": "Conditional Generation Using Polynomial Expansions",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed method can be applied to different conditional generation tasks. However, it is unclear how competitive the results are compared to state-of-the-art models for each application and other state-of-the-art conditional generative models that do not use polynomial neural network architectures. It seems that no such comparison is performed. In order to show the usefulness of the method, such comparisons are needed.\n- Class-conditional generation: As mentioned at line 234-236 'both SPADE and $\\Pi$-Net were not originally built for class-conditional generation', comparing with SPADE or $\\Pi$-Net might not successfully show the strength of the proposed method.\n- The FID scores for GAN-CONC, GAN-ADD, SPADE in Table 4 are very bad (e.g., 290+ for CIFAR-10), which raises questions on whether the baselines are tuned and optimized properly.\n- It would be more convincing to compare with state-of-the-art class-conditional generation methods.\n- Section 4.2: It would be useful to mention that comparison with other models are in the appendix.\n- Is there any reason why VAE is used while the other sections are discussing GANs?\n- If the goal is to show that the proposed method extends beyond GANs, it would be nice to also include the VAE results in the other sections, and discuss the related background and details (instead of directly presenting the VAE results in only one section).\n- Super-resolution: SPADE is not originally designed for super-resolution, it might be important to compare with other stronger super-resolution baselines in order to show the strength of the proposed method.\n- It is unclear if FID score alone is able to capture how good the super-resolution results are.\n- For instance, the generated high resolution images could completely ignore the low resolution images but still achieve a good FID score (e.g., unconditional generation). It would be more convincing to also report other commonly used metrics (e.g., PSNR, SSIM, etc) for super-resolution.\n- minor: It would be good to label which methods are the proposed methods in the table.\n- Will the proposed method work for denoising?",
    "review_points_list": [
      "The proposed method can be applied to different conditional generation tasks. However, it is unclear how competitive the results are compared to state-of-the-art models for each application and other state-of-the-art conditional generative models that do not use polynomial neural network architectures. It seems that no such comparison is performed. In order to show the usefulness of the method, such comparisons are needed.",
      "Class-conditional generation: As mentioned at line 234-236 'both SPADE and $\\Pi$-Net were not originally built for class-conditional generation', comparing with SPADE or $\\Pi$-Net might not successfully show the strength of the proposed method.",
      "The FID scores for GAN-CONC, GAN-ADD, SPADE in Table 4 are very bad (e.g., 290+ for CIFAR-10), which raises questions on whether the baselines are tuned and optimized properly.",
      "It would be more convincing to compare with state-of-the-art class-conditional generation methods.",
      "Section 4.2: It would be useful to mention that comparison with other models are in the appendix.",
      "Is there any reason why VAE is used while the other sections are discussing GANs?",
      "If the goal is to show that the proposed method extends beyond GANs, it would be nice to also include the VAE results in the other sections, and discuss the related background and details (instead of directly presenting the VAE results in only one section).",
      "Super-resolution: SPADE is not originally designed for super-resolution, it might be important to compare with other stronger super-resolution baselines in order to show the strength of the proposed method.",
      "It is unclear if FID score alone is able to capture how good the super-resolution results are.",
      "For instance, the generated high resolution images could completely ignore the low resolution images but still achieve a good FID score (e.g., unconditional generation). It would be more convincing to also report other commonly used metrics (e.g., PSNR, SSIM, etc) for super-resolution.",
      "minor: It would be good to label which methods are the proposed methods in the table.",
      "Will the proposed method work for denoising?"
    ]
  },
  {
    "paper_id": "2110.14189v2",
    "submission_id": "xLExSzfIDmo",
    "submission_title": "Robust Contrastive Learning Using Negative Samples with Diminished Semantics",
    "review_id": "7ei2zzeDgl5",
    "input": {
      "title": "Robust Contrastive Learning Using Negative Samples with Diminished Semantics",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The method proposes to augment the negative samples of constrative SSL methods. This has been done before in the literature ([31], [43] for example), but not necessarily for textures or image patches. The role of texture and patch-based features for supervised learning models has been studied before (e.g. [3]). Therefore, it is a combination of ideas that have been investigated before, but in its current form it is relatively novel.\n- The paper is well written. The claims and hypothesis of the authors are clearly stated, and the experiments and analysis is easy to follow.\n- The premise of the paper is clear, and the experimental section is quite extensive. That being said, there are some issues with the approach.\n- The modification of the BYOL objective is ad-hoc and not really justified. An ablation that also shows the difference in using a regular negative sample or a texture-based negative sample for this method would be useful to understand whether the reported improved performance is due to adding a negative sample or because of the particular mining strategy for the negative.\n- The improved performance for the augmented model on a few datasets (ImageNet-100 e.g.) is quite below the standard deviation of the runs and therefore not really significant.\n- For most approaches the introduction of another negative sample effectively increases the batch size of the training model or equivalently, the model is trained on more samples. An ablation showing that this does not have an effect on the regular approach would be useful.\n- Some of the reported metrics of the baseline methods do not seem to match the published results and seem to be slightly lower. For example, MoCoV2 reports improved performance well above 67.60 on Imagenet 1K when trained for longer, and MoCHi reports better performance over the MoCoV2 baseline and in this paper its reported worse performance.\n- It would be useful to have experiments with the same setup/performance as in the original papers, and with configurations that maximize the performance of a model to make sure that the reported improvements are significant and not necessarily due to differing training setups such as feeding more examples to the model.\n- For the above reasons, it is not fully well supported that the proposed method extensions and negative mining strategies show a significant advantage to the baseline methods (considering also the more complex setup involved), however, even with these doubts the paper might be of interest to the community and therefore my favorable rating.\n- After reading the rest of the reviews and the authors' response, I am still not convinced about the results using a modified BYOL and the performance discrepancy with MoCHI. However, as stated in the original review, I believe the paper might be of interest to the community despite these issues and therefore stand by my original rating.",
    "review_points_list": [
      "The method proposes to augment the negative samples of constrative SSL methods. This has been done before in the literature ([31], [43] for example), but not necessarily for textures or image patches. The role of texture and patch-based features for supervised learning models has been studied before (e.g. [3]). Therefore, it is a combination of ideas that have been investigated before, but in its current form it is relatively novel.",
      "The paper is well written. The claims and hypothesis of the authors are clearly stated, and the experiments and analysis is easy to follow.",
      "The premise of the paper is clear, and the experimental section is quite extensive. That being said, there are some issues with the approach.",
      "The modification of the BYOL objective is ad-hoc and not really justified. An ablation that also shows the difference in using a regular negative sample or a texture-based negative sample for this method would be useful to understand whether the reported improved performance is due to adding a negative sample or because of the particular mining strategy for the negative.",
      "The improved performance for the augmented model on a few datasets (ImageNet-100 e.g.) is quite below the standard deviation of the runs and therefore not really significant.",
      "For most approaches the introduction of another negative sample effectively increases the batch size of the training model or equivalently, the model is trained on more samples. An ablation showing that this does not have an effect on the regular approach would be useful.",
      "Some of the reported metrics of the baseline methods do not seem to match the published results and seem to be slightly lower. For example, MoCoV2 reports improved performance well above 67.60 on Imagenet 1K when trained for longer, and MoCHi reports better performance over the MoCoV2 baseline and in this paper its reported worse performance.",
      "It would be useful to have experiments with the same setup/performance as in the original papers, and with configurations that maximize the performance of a model to make sure that the reported improvements are significant and not necessarily due to differing training setups such as feeding more examples to the model.",
      "For the above reasons, it is not fully well supported that the proposed method extensions and negative mining strategies show a significant advantage to the baseline methods (considering also the more complex setup involved), however, even with these doubts the paper might be of interest to the community and therefore my favorable rating.",
      "After reading the rest of the reviews and the authors' response, I am still not convinced about the results using a modified BYOL and the performance discrepancy with MoCHI. However, as stated in the original review, I believe the paper might be of interest to the community despite these issues and therefore stand by my original rating."
    ]
  },
  {
    "paper_id": "2110.14189v2",
    "submission_id": "xLExSzfIDmo",
    "submission_title": "Robust Contrastive Learning Using Negative Samples with Diminished Semantics",
    "review_id": "teS0nWF2zGL",
    "input": {
      "title": "Robust Contrastive Learning Using Negative Samples with Diminished Semantics",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This is a nice paper with strong central ideas and extensive experiments.\n- The shape-texture trade-off is interesting and important, and I'm glad to see work using contrastive learning to try to control the trade-off.\n- I think the work could be improved if the authors spend a bit more time explaining the results and discussing where the lift comes from.\n- The experiments are extensive, but there are multiple effects that are not explained.\n- The two major questions that stick out to me are:\n- 1. In table 1, there are some tasks where patch-based with alpha = 2 works better, and some tasks where patch-based with alpha = 3 works better.\n- I could not find any explanation about this discrepancy.\n- Why does one method outperform in some cases, but not others?\n- Why does patch-based with alpha = 3 underperform baselines by two points on ImageNet, but alpha = 2 outperforms by two points?\n- Section 3.1 spends considerable space on exposition of the results, but does not spend enough space discussing how the method creates lift, or under what circumstances to expect lift.\n- 2. The results from Figures 4 and 5 about memory bank size are striking,\n- and I don't think that the text explanation or the analysis in appendix B.1 adequately explain it.\n- Performance consistently increases with memory bank size -- and even appears to grow faster than log-linear in memory bank size --\n- but then significantly drops at the last tested memory bank size.\n- I would expect a smoother degradation for the explanation that the benefit from a larger memory bank size is being outweighed by less impact from the non-semantic negatives\n- More experiments would be helpful to understand this phenomenon and validate the hypothesis.",
    "review_points_list": [
      "This is a nice paper with strong central ideas and extensive experiments.",
      "The shape-texture trade-off is interesting and important, and I'm glad to see work using contrastive learning to try to control the trade-off.",
      "I think the work could be improved if the authors spend a bit more time explaining the results and discussing where the lift comes from.",
      "The experiments are extensive, but there are multiple effects that are not explained.",
      "The two major questions that stick out to me are:",
      "1. In table 1, there are some tasks where patch-based with alpha = 2 works better, and some tasks where patch-based with alpha = 3 works better.",
      "I could not find any explanation about this discrepancy.",
      "Why does one method outperform in some cases, but not others?",
      "Why does patch-based with alpha = 3 underperform baselines by two points on ImageNet, but alpha = 2 outperforms by two points?",
      "Section 3.1 spends considerable space on exposition of the results, but does not spend enough space discussing how the method creates lift, or under what circumstances to expect lift.",
      "2. The results from Figures 4 and 5 about memory bank size are striking,",
      "and I don't think that the text explanation or the analysis in appendix B.1 adequately explain it.",
      "Performance consistently increases with memory bank size -- and even appears to grow faster than log-linear in memory bank size --",
      "but then significantly drops at the last tested memory bank size.",
      "I would expect a smoother degradation for the explanation that the benefit from a larger memory bank size is being outweighed by less impact from the non-semantic negatives",
      "More experiments would be helpful to understand this phenomenon and validate the hypothesis."
    ]
  },
  {
    "paper_id": "2110.14189v2",
    "submission_id": "xLExSzfIDmo",
    "submission_title": "Robust Contrastive Learning Using Negative Samples with Diminished Semantics",
    "review_id": "QwglmrutfHn",
    "input": {
      "title": "Robust Contrastive Learning Using Negative Samples with Diminished Semantics",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The idea of adding negative samples that only share the same texture as the anchor image to avoid learning the texture semantic is novel.\n- The paper has the following weaknesses:\n- The paper lacks comparison with other baselines.\n- For example, in [1], the authors proposed to use texture randomization in the augmentations which can also learn texture-invariant features.\n- Also, in [1] the authors reported higher accuracy of MoCo-v2 on ImageNet-100 (81.0%), while the MoCo-v2 accuracy in this paper is less than 78%.\n- The paper proposed to learn less about the texture semantics by adding negative samples that only share the texture sematic with the anchor images.\n- However, the texture semantics can still be helpful in some cases.\n- Similar to [1], it would be good to try to ensemble models trained with the proposed negative augmentations and without it and see whether this could improve the performance.\n- The proposed method is restricted to removing texture semantics and lack of extension to other semantics.\n- One interesting experiment to do is to remove color distortion in the augmentations of positive samples and add negative samples that share the same color distribution of the anchor image to see whether the proposed method could be helpful to avoid the color distribution shortcut.\n- The paper is well written and easy to follow.\n- the paper proposes a simple method to construct negative samples to prevent contrastive learning from learning texture information which could affect its generalization ability.\n- However, it is not always desirable to remove the texture semantics, since it is also an important semantics in image classification task.\n- Moreover, the proposed method is restricted to the texture semantics and the authors do not show that it could be extended to other semantics.\n- Therefore, the significance of the paper is limited.",
    "review_points_list": [
      "The idea of adding negative samples that only share the same texture as the anchor image to avoid learning the texture semantic is novel.",
      "The paper has the following weaknesses:",
      "The paper lacks comparison with other baselines.",
      "For example, in [1], the authors proposed to use texture randomization in the augmentations which can also learn texture-invariant features.",
      "Also, in [1] the authors reported higher accuracy of MoCo-v2 on ImageNet-100 (81.0%), while the MoCo-v2 accuracy in this paper is less than 78%.",
      "The paper proposed to learn less about the texture semantics by adding negative samples that only share the texture sematic with the anchor images.",
      "However, the texture semantics can still be helpful in some cases.",
      "Similar to [1], it would be good to try to ensemble models trained with the proposed negative augmentations and without it and see whether this could improve the performance.",
      "The proposed method is restricted to removing texture semantics and lack of extension to other semantics.",
      "One interesting experiment to do is to remove color distortion in the augmentations of positive samples and add negative samples that share the same color distribution of the anchor image to see whether the proposed method could be helpful to avoid the color distribution shortcut.",
      "The paper is well written and easy to follow.",
      "the paper proposes a simple method to construct negative samples to prevent contrastive learning from learning texture information which could affect its generalization ability.",
      "However, it is not always desirable to remove the texture semantics, since it is also an important semantics in image classification task.",
      "Moreover, the proposed method is restricted to the texture semantics and the authors do not show that it could be extended to other semantics.",
      "Therefore, the significance of the paper is limited."
    ]
  },
  {
    "paper_id": "2110.14189v2",
    "submission_id": "xLExSzfIDmo",
    "submission_title": "Robust Contrastive Learning Using Negative Samples with Diminished Semantics",
    "review_id": "gEK-5jtLJoI",
    "input": {
      "title": "Robust Contrastive Learning Using Negative Samples with Diminished Semantics",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper aims to eliminate CNNs' reliance on low-level features and improve the generalization ability of models.\n- Two negative sample generation methods are proposed.\n- These methods construct negative samples which only preserve non-semantic features.\n- This idea is straightforward and sound.\n- Experiments on multiple datasets show the robustness of models trained with non-semantic samples, verifying the efficacy of the proposed methods.\n- Detailed analysis on the texture-shape bias trade-off is provided.\n- This paper is well written.\n- It sheds light on the texture-shape bias of existing self-supervised methods.\n- The improved generalization performance would help self-supervised pre-trained models to be applied in real scenarios.",
    "review_points_list": [
      "This paper aims to eliminate CNNs' reliance on low-level features and improve the generalization ability of models.",
      "Two negative sample generation methods are proposed.",
      "These methods construct negative samples which only preserve non-semantic features.",
      "This idea is straightforward and sound.",
      "Experiments on multiple datasets show the robustness of models trained with non-semantic samples, verifying the efficacy of the proposed methods.",
      "Detailed analysis on the texture-shape bias trade-off is provided.",
      "This paper is well written.",
      "It sheds light on the texture-shape bias of existing self-supervised methods.",
      "The improved generalization performance would help self-supervised pre-trained models to be applied in real scenarios."
    ]
  },
  {
    "paper_id": "2106.06530v2",
    "submission_id": "x2TMPhseWAW",
    "submission_title": "Label Noise SGD Provably Prefers Flat Global Minimizers",
    "review_id": "gZUyqQX32uI",
    "input": {
      "title": "Label Noise SGD Provably Prefers Flat Global Minimizers",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- My main concern about this work is that it does move towards a good answer but the results are still under restrictive assumptions.\n- In contrast to standard guarantees on convergence of SGD, the theory additionally requires Lipschitzness of stochastic functions and Hessians in addition to the standard assumption on Lipschitz gradients, which are all not applicable to non-smooth deep networks.\n- I understand that at least some assumptions are required and I could see this as a necessary requirement to keep the theory somewhat simple.\n- But the function also needs to be KL for global minima and Theorem 1 assumes that initialization is close to a global minimum. This essentially eliminates the possibility of encountering a local minimum by assumptions rather than by analysis, and I find this unrealistic to apply the obtained results to practical scenarios such as training neural networks.\n- I understand the authors' argument that it is fine to assume local initialization since overparameterization helps to achieve almost zero loss, but the resulting local theory is not that interesting when combined with local-KL assumption.\n- It is also disappointing to see that one needs to have smaller lambda for smaller epsilon, which, as far as I can see, also requires decreasing the stepsize. Ideally I'd hope to see a result that allows to leverage overparameterization and achieve guarantees for non-decreasing regularization. Otherwise, it is not even clear why we should want to eliminate the assumption on small stepsizes of Blanc et al.\n- I still give the paper a weak accept because I think that the results may lead us towards understanding generalization and the factors that contribute to it. However, I cannot recommend a higher score as so many limitations are currently present.\n- I have difficulty with understanding the right column in Figure 3. The figure caption reads 'the right column displays their correlation' while the y-label is 'Test accuracy'. Could the authors clarify what exactly is shown there?",
    "review_points_list": [
      "My main concern about this work is that it does move towards a good answer but the results are still under restrictive assumptions.",
      "In contrast to standard guarantees on convergence of SGD, the theory additionally requires Lipschitzness of stochastic functions and Hessians in addition to the standard assumption on Lipschitz gradients, which are all not applicable to non-smooth deep networks.",
      "I understand that at least some assumptions are required and I could see this as a necessary requirement to keep the theory somewhat simple.",
      "But the function also needs to be KL for global minima and Theorem 1 assumes that initialization is close to a global minimum. This essentially eliminates the possibility of encountering a local minimum by assumptions rather than by analysis, and I find this unrealistic to apply the obtained results to practical scenarios such as training neural networks.",
      "I understand the authors' argument that it is fine to assume local initialization since overparameterization helps to achieve almost zero loss, but the resulting local theory is not that interesting when combined with local-KL assumption.",
      "It is also disappointing to see that one needs to have smaller lambda for smaller epsilon, which, as far as I can see, also requires decreasing the stepsize. Ideally I'd hope to see a result that allows to leverage overparameterization and achieve guarantees for non-decreasing regularization. Otherwise, it is not even clear why we should want to eliminate the assumption on small stepsizes of Blanc et al.",
      "I still give the paper a weak accept because I think that the results may lead us towards understanding generalization and the factors that contribute to it. However, I cannot recommend a higher score as so many limitations are currently present.",
      "I have difficulty with understanding the right column in Figure 3. The figure caption reads 'the right column displays their correlation' while the y-label is 'Test accuracy'. Could the authors clarify what exactly is shown there?"
    ]
  },
  {
    "paper_id": "2106.06530v2",
    "submission_id": "x2TMPhseWAW",
    "submission_title": "Label Noise SGD Provably Prefers Flat Global Minimizers",
    "review_id": "8Rk2lifnoz",
    "input": {
      "title": "Label Noise SGD Provably Prefers Flat Global Minimizers",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think the result presented in this work is interesting and a good step towards better understanding of the implicit regularization effect of SGD.\n- Moreover, I found interesting the interplay between step size and regularization showed in this work (in [1] the step size had to be very small).\n- The paper is well-written, easy to follow in general, and the results are technically non-trivial and interesting.\n- I believe that this work meets the standards of NeurIPS and I recommend acceptance.\n- In Theorem 1 it is assumed that SGD is initialized close to some approximate minimizer of $L$.\n- Since, at a high level, it seems that initializing the SGD at the global minimizer of $L$ makes it harder for it to escape, is this assumption really necessary?\n- Since we have that if the KL condition holds for some $\\\text{delta}$ it also holds for any $\\\text{delta}'< \\\text{delta}$, is $\\\text{delta}$ supposed to be in $(0, 1/2]$ in Assumption 3?\n- Why not simply have $\\\text{delta} \\\text{in} (0, 1]$?\n- [1]: G. Blanc, N. Gupta, G. Valiant, and P. Valiant.  Implicit regularization for deep neural networks driven by an ornstein-uhlenbeck like process.",
    "review_points_list": [
      "I think the result presented in this work is interesting and a good step towards better understanding of the implicit regularization effect of SGD.",
      "Moreover, I found interesting the interplay between step size and regularization showed in this work (in [1] the step size had to be very small).",
      "The paper is well-written, easy to follow in general, and the results are technically non-trivial and interesting.",
      "I believe that this work meets the standards of NeurIPS and I recommend acceptance.",
      "In Theorem 1 it is assumed that SGD is initialized close to some approximate minimizer of $L$.",
      "Since, at a high level, it seems that initializing the SGD at the global minimizer of $L$ makes it harder for it to escape, is this assumption really necessary?",
      "Since we have that if the KL condition holds for some $\\\text{delta}$ it also holds for any $\\\text{delta}'< \\\text{delta}$, is $\\\text{delta}$ supposed to be in $(0, 1/2]$ in Assumption 3?",
      "Why not simply have $\\\text{delta} \\\text{in} (0, 1]$?",
      "[1]: G. Blanc, N. Gupta, G. Valiant, and P. Valiant.  Implicit regularization for deep neural networks driven by an ornstein-uhlenbeck like process."
    ]
  },
  {
    "paper_id": "2106.06530v2",
    "submission_id": "x2TMPhseWAW",
    "submission_title": "Label Noise SGD Provably Prefers Flat Global Minimizers",
    "review_id": "SDP-72yWZtz",
    "input": {
      "title": "Label Noise SGD Provably Prefers Flat Global Minimizers",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper studies an interesting idea on optimization landscape with perturbation from noise.\n- Specifically, the work presents the behavior of optimization for regions where the gradient is small, which is termed as 'flat' region.\n- The notion of flatness is described via epsilon.\n- The neighborhood of the 'flat' region, within norm gamma in parameter space, has been considered.\n- The idea is to link SGD optimizing procedure for data with the presence of label noise to implicitly regularized learning objectives and studies the conditions where the algorithm reaches the 'flat' region or its neighborhood.\n- It is a concrete study that provides fruitful theoretical insights on the particular analysis.\n- I believe this can be useful for the community to better understand the SGD procedure in various stances.\n- However, there are some questions to be further addressed as well as related concerns (please see below).\n- In the classification setting, label noise the class-conditional noise is coherent with the setting.\n- However, in the regression setting in the main paper, label noise may not be the best term.\n- As this setting is related to the denoise score matching (SM) scheme, how does the analysis related to denoise SM?\n- Algorithm 1 is presenting noise in the uniform labels, which is confusing.\n- Moreover, in the regression setting, what is the distribution of noise?\n- and how does the distribution or property of the noise (e.g., variance) affect the analysis or the results?\n- Maybe linking to the behavior of denoise SM will be helpful for the community to further understand SGD with the type of regularization presented, as well as linking the important ideas for learning procedures.\n- In Theorem 1, the analysis shows that the optimization reaches the (epsilon,gamma)-stationary region.\n- Is such a region always better than a sharp local optimal?\n- I am not an expert in the area of this type of analysis.\n- Overall, the idea and analysis are interesting.\n- The proof is not carefully checked.\n- The major significance and impact of the analysis are not clear enough.\n- For people who may not be familiar with the particular analysis methodology, it is not easy to understand and appreciate the setting.\n- It is also unclear that what goes next when SGD reaches (epsilon,gamma)-stationary region.\n- Adding more explanations would help understand the full SGD procedure better.\n- Some minor clarifications\n- In section 2.2, it will be useful to provide more explicit links between the trace log regularization scheme to the noisy label setting to support the implicit regularizer claim.\n- In definition2, more intuition can be provided for better understanding.\n- It is an interesting metric to consider for the convergence analysis, but it will be easier to have both technical claims and interpretable explanations.",
    "review_points_list": [
      "The paper studies an interesting idea on optimization landscape with perturbation from noise.",
      "Specifically, the work presents the behavior of optimization for regions where the gradient is small, which is termed as 'flat' region.",
      "The notion of flatness is described via epsilon.",
      "The neighborhood of the 'flat' region, within norm gamma in parameter space, has been considered.",
      "The idea is to link SGD optimizing procedure for data with the presence of label noise to implicitly regularized learning objectives and studies the conditions where the algorithm reaches the 'flat' region or its neighborhood.",
      "It is a concrete study that provides fruitful theoretical insights on the particular analysis.",
      "I believe this can be useful for the community to better understand the SGD procedure in various stances.",
      "However, there are some questions to be further addressed as well as related concerns (please see below).",
      "In the classification setting, label noise the class-conditional noise is coherent with the setting.",
      "However, in the regression setting in the main paper, label noise may not be the best term.",
      "As this setting is related to the denoise score matching (SM) scheme, how does the analysis related to denoise SM?",
      "Algorithm 1 is presenting noise in the uniform labels, which is confusing.",
      "Moreover, in the regression setting, what is the distribution of noise?",
      "and how does the distribution or property of the noise (e.g., variance) affect the analysis or the results?",
      "Maybe linking to the behavior of denoise SM will be helpful for the community to further understand SGD with the type of regularization presented, as well as linking the important ideas for learning procedures.",
      "In Theorem 1, the analysis shows that the optimization reaches the (epsilon,gamma)-stationary region.",
      "Is such a region always better than a sharp local optimal?",
      "I am not an expert in the area of this type of analysis.",
      "Overall, the idea and analysis are interesting.",
      "The proof is not carefully checked.",
      "The major significance and impact of the analysis are not clear enough.",
      "For people who may not be familiar with the particular analysis methodology, it is not easy to understand and appreciate the setting.",
      "It is also unclear that what goes next when SGD reaches (epsilon,gamma)-stationary region.",
      "Adding more explanations would help understand the full SGD procedure better.",
      "Some minor clarifications",
      "In section 2.2, it will be useful to provide more explicit links between the trace log regularization scheme to the noisy label setting to support the implicit regularizer claim.",
      "In definition2, more intuition can be provided for better understanding.",
      "It is an interesting metric to consider for the convergence analysis, but it will be easier to have both technical claims and interpretable explanations."
    ]
  },
  {
    "paper_id": "2106.06530v2",
    "submission_id": "x2TMPhseWAW",
    "submission_title": "Label Noise SGD Provably Prefers Flat Global Minimizers",
    "review_id": "O0ZrePYkwRr",
    "input": {
      "title": "Label Noise SGD Provably Prefers Flat Global Minimizers",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The theoretic results provide intuition to understand the implicit regularization effect of adding label noise, which is shown empirically to be better than SGD implicit bias in some cases (like initialization from poor minima).\n- The introduced $(\textbackslash epsilon, \textbackslash gamma)$-stationary points that characterize a neighbor of a stationary point seem to be interesting for understanding the properties of a regularized objective.\n- Empirical observations about label noise are partly justified by the presented theory.\n- Based on my knowledge, the initial learning rate is generally large for large batch SGD (e.g. linear scaling rule). Could you provide references here?\n- Definition 2. The order of $\textbackslash epsilon$ vs. $\textbackslash gamma$ seems to be important, could you elaborate on this? What prevents us from setting $\textbackslash gamma \\approx \textbackslash epsilon$ as happening in linear regression? I am trying to interpret Thm1 for linear regression but find several places are not fully clear.\n- I am not sure how Thm1 helps in terms of justifying the title. The title claims label noise SGD prefers flat global 'minimizers', but Thm1 only shows convergence to an approximate stationary point. Please elaborate.\n- I am not sure how Thm1 helps in terms of justifying the experiments. Indeed $\theta^*$ could be a poor global minimizer of $L$ so that SGD cannot escape. But it remains unclear to me why $\theta_k$ in thm 1 is a good minimizer.\n- I am not sure how Thm1 helps in terms of justifying the claims on the effect of the initial large learning rate. Note that Thm1 requires $\textbackslash eta/B \textbackslash les \textbackslash sim \textbackslash gamma^2$, then why $\textbackslash eta$ is considered to be 'large' (e.g., l.276)? Are you allowing some annealing learning rate here?\n- My next question is also about Thm1: it seems to me the considered iterates are in a neighbor of $\theta^*$ (please correct me if not). Then why Thm1 could justify the 'escaping' behavior of label noise SGD in the experiments?\n- In the experiment, a lower bound is adopted to compute the proposed regularizer. As we are considering a minimization problem, why does it make sense to minimize a lower bound (instead of an upper bound) of the objective?\n- $\theta^*$ -> $\theta$\n- $\textbackslash phi$ -> $\textbackslash gamma$\n- My current feeling for this paper is a weak reject, as the claims/title/experiments are not properly justified by the theorem. Authors' feedback is welcome to help me better understand this paper.\n- A suggestion for future revision is to provide examples to illustrate the order of the important quantities in the theorem, e.g., $\textbackslash epsilon$ and $\textbackslash gamma$ and others.\n- After further discussions with the authors, my initial concerns are all solved. Therefore, I would like to raise the score and recommend accepting the paper.",
    "review_points_list": [
      "The theoretic results provide intuition to understand the implicit regularization effect of adding label noise, which is shown empirically to be better than SGD implicit bias in some cases (like initialization from poor minima).",
      "The introduced $(\textbackslash epsilon, \textbackslash gamma)$-stationary points that characterize a neighbor of a stationary point seem to be interesting for understanding the properties of a regularized objective.",
      "Empirical observations about label noise are partly justified by the presented theory.",
      "Based on my knowledge, the initial learning rate is generally large for large batch SGD (e.g. linear scaling rule). Could you provide references here?",
      "Definition 2. The order of $\textbackslash epsilon$ vs. $\textbackslash gamma$ seems to be important, could you elaborate on this? What prevents us from setting $\textbackslash gamma \\approx \textbackslash epsilon$ as happening in linear regression? I am trying to interpret Thm1 for linear regression but find several places are not fully clear.",
      "I am not sure how Thm1 helps in terms of justifying the title. The title claims label noise SGD prefers flat global 'minimizers', but Thm1 only shows convergence to an approximate stationary point. Please elaborate.",
      "I am not sure how Thm1 helps in terms of justifying the experiments. Indeed $\theta^*$ could be a poor global minimizer of $L$ so that SGD cannot escape. But it remains unclear to me why $\theta_k$ in thm 1 is a good minimizer.",
      "I am not sure how Thm1 helps in terms of justifying the claims on the effect of the initial large learning rate. Note that Thm1 requires $\textbackslash eta/B \textbackslash les \textbackslash sim \textbackslash gamma^2$, then why $\textbackslash eta$ is considered to be 'large' (e.g., l.276)? Are you allowing some annealing learning rate here?",
      "My next question is also about Thm1: it seems to me the considered iterates are in a neighbor of $\theta^*$ (please correct me if not). Then why Thm1 could justify the 'escaping' behavior of label noise SGD in the experiments?",
      "In the experiment, a lower bound is adopted to compute the proposed regularizer. As we are considering a minimization problem, why does it make sense to minimize a lower bound (instead of an upper bound) of the objective?",
      "$\theta^*$ -> $\theta$",
      "$\textbackslash phi$ -> $\textbackslash gamma$",
      "My current feeling for this paper is a weak reject, as the claims/title/experiments are not properly justified by the theorem. Authors' feedback is welcome to help me better understand this paper.",
      "A suggestion for future revision is to provide examples to illustrate the order of the important quantities in the theorem, e.g., $\textbackslash epsilon$ and $\textbackslash gamma$ and others.",
      "After further discussions with the authors, my initial concerns are all solved. Therefore, I would like to raise the score and recommend accepting the paper."
    ]
  },
  {
    "paper_id": "2403.00278v2",
    "submission_id": "wn79e85F42W",
    "submission_title": "Differentially Private Stochastic Optimization: New Results in Convex and Non-Convex Settings",
    "review_id": "yEIKjD5WS7Q",
    "input": {
      "title": "Differentially Private Stochastic Optimization: New Results in Convex and Non-Convex Settings",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think the results are mostly incremental, based on standard techniques with limited novelty.\n- Moreover, the different problems (settings) in the paper are only slightly related, making the story of the paper less coherent.\n- The author prove in different settings. Overall, I don't think the paper has sufficient novelty and new results for acceptance.\n- Existing algorithms from [BFTT19, FKT20] take super-linear time for general non-smooth convex functions. However, for the setting of GLL that the authors consider, it is immediate to see that existing algorithms give nearly linear time algorithms as smoothening GLLs is quite simple.\n- This result is basically a direct corollary of previous work.\n- The results for this section are based on private implementation of variance-reduced Frank-Wolfe algorithm similarly to the existing private algorithm for the convex setting [AFKT21, BGN21].\n- The algorithm in this paper doesn't use privacy amplification by sub-sampling (as done in [AFKT21]) hence suggesting their algorithm may not be optimal.\n- The author conjecture that their algorithm has tight bounds for the ell_1 setting for linear time algorithms. Is there evidence for this prediction?\n- Following my previous comment, I think it may be possible to improve the rates using better privacy accounting as done in [AFKT21].\n- The authors overuse the term: 'we provide the first algorithm for ...'.\n- One such example is where the authors say 'we provide the first linear time private algorithms'.\n- This sentence doesn't say anything about the utility of the algorithm and so is not very informative.\n- The linear-time algorithm doesn't give optimal bounds as [ZCH+20].\n- The authors should compare their bound to the bound obtained by linear-time version of [ZCH+20].\n- The authors should try to explain the strength of the bounds achieved in this section.\n- Currently these are worse than the smooth setting which suggest they may not be optimal.\n- The algorithm is a simple application of existing techniques.\n- I think it would be useful to add the dependence on epsilon in the bounds of the abstract as currently these are stated only for constant epsilon and makes it slightly harder to understand the privacy cost.\n- The term GLM (generalized linear models) is more common than GLL.",
    "review_points_list": [
      "I think the results are mostly incremental, based on standard techniques with limited novelty.",
      "Moreover, the different problems (settings) in the paper are only slightly related, making the story of the paper less coherent.",
      "The author prove in different settings. Overall, I don't think the paper has sufficient novelty and new results for acceptance.",
      "Existing algorithms from [BFTT19, FKT20] take super-linear time for general non-smooth convex functions. However, for the setting of GLL that the authors consider, it is immediate to see that existing algorithms give nearly linear time algorithms as smoothening GLLs is quite simple.",
      "This result is basically a direct corollary of previous work.",
      "The results for this section are based on private implementation of variance-reduced Frank-Wolfe algorithm similarly to the existing private algorithm for the convex setting [AFKT21, BGN21].",
      "The algorithm in this paper doesn't use privacy amplification by sub-sampling (as done in [AFKT21]) hence suggesting their algorithm may not be optimal.",
      "The author conjecture that their algorithm has tight bounds for the ell_1 setting for linear time algorithms. Is there evidence for this prediction?",
      "Following my previous comment, I think it may be possible to improve the rates using better privacy accounting as done in [AFKT21].",
      "The authors overuse the term: 'we provide the first algorithm for ...'.",
      "One such example is where the authors say 'we provide the first linear time private algorithms'.",
      "This sentence doesn't say anything about the utility of the algorithm and so is not very informative.",
      "The linear-time algorithm doesn't give optimal bounds as [ZCH+20].",
      "The authors should compare their bound to the bound obtained by linear-time version of [ZCH+20].",
      "The authors should try to explain the strength of the bounds achieved in this section.",
      "Currently these are worse than the smooth setting which suggest they may not be optimal.",
      "The algorithm is a simple application of existing techniques.",
      "I think it would be useful to add the dependence on epsilon in the bounds of the abstract as currently these are stated only for constant epsilon and makes it slightly harder to understand the privacy cost.",
      "The term GLM (generalized linear models) is more common than GLL."
    ]
  },
  {
    "paper_id": "2403.00278v2",
    "submission_id": "wn79e85F42W",
    "submission_title": "Differentially Private Stochastic Optimization: New Results in Convex and Non-Convex Settings",
    "review_id": "cqfyxtpA7J5",
    "input": {
      "title": "Differentially Private Stochastic Optimization: New Results in Convex and Non-Convex Settings",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper makes many novel and important contributions to the field of differentially private stochastic optimization.\n- Many results in non-Euclidean non-convex settings are novel even without privacy constraints.\n- The writing and presentation is very good and to the point.\n- The authors try to give the necessary background (in the Appendix) and explain many subtleties as required.\n- The first result is a nearly-linear time algorithm for non-smooth GLLs.\n- This contributes to a recent line of work which try to devise fast algorithms for DP-SCO.\n- This result solves a special case of the non-smooth convex landscape.\n- I think this result has an interesting consequence: *most* known high-dimensional oracle complexity lower bound instances in optimization are GLLs.\n- So this result tells us that if it is indeed the case that non-smooth DP-SCO is harder than SCO, then we need to look at *new* hard instances.\n- The smooth non-convex setting considers a polyhedral constrained setup even in standard $\text{l}_2$ setting.\n- I think that it is more natural/standard in literature to consider an $\text{l}_2$ ball (or a simple convex set with an easy oracle-access projection).\n- I wonder why did the authors not consider the later?\n- Why not consider the unconstrained setup, which would also enable comparison with some of the previous work?\n- On a related note, the non-smooth weakly convex part is not in the polyhedral constraint setting.\n- Do we need to access to a projection oracle for the claimed guarantees in Theorem 16?\n- If yes, then I could not find it mentioned in this section.\n- If no, then why is it so?\n- Since the authors make many contributions, one downside is that parts of the paper feel disconnected from each other -- it feels like a collection of results the authors were able to obtain in various settings.\n- For example: GLLs part of the paper has little to do with the non-convex setting (in terms of goal/techniques).\n- This, lots of settings and results, also led to authors' being able to put only one algorithm description (in full, as a pseudo-code) in the main paper, and the rest is deferred to the appendix.\n- The authors only provide upper bounds for the settings they consider.\n- Is there a way (perhaps from previous works?) to assess how sharp are the attained rates?",
    "review_points_list": [
      "The paper makes many novel and important contributions to the field of differentially private stochastic optimization.",
      "Many results in non-Euclidean non-convex settings are novel even without privacy constraints.",
      "The writing and presentation is very good and to the point.",
      "The authors try to give the necessary background (in the Appendix) and explain many subtleties as required.",
      "The first result is a nearly-linear time algorithm for non-smooth GLLs.",
      "This contributes to a recent line of work which try to devise fast algorithms for DP-SCO.",
      "This result solves a special case of the non-smooth convex landscape.",
      "I think this result has an interesting consequence: *most* known high-dimensional oracle complexity lower bound instances in optimization are GLLs.",
      "So this result tells us that if it is indeed the case that non-smooth DP-SCO is harder than SCO, then we need to look at *new* hard instances.",
      "The smooth non-convex setting considers a polyhedral constrained setup even in standard $\text{l}_2$ setting.",
      "I think that it is more natural/standard in literature to consider an $\text{l}_2$ ball (or a simple convex set with an easy oracle-access projection).",
      "I wonder why did the authors not consider the later?",
      "Why not consider the unconstrained setup, which would also enable comparison with some of the previous work?",
      "On a related note, the non-smooth weakly convex part is not in the polyhedral constraint setting.",
      "Do we need to access to a projection oracle for the claimed guarantees in Theorem 16?",
      "If yes, then I could not find it mentioned in this section.",
      "If no, then why is it so?",
      "Since the authors make many contributions, one downside is that parts of the paper feel disconnected from each other -- it feels like a collection of results the authors were able to obtain in various settings.",
      "For example: GLLs part of the paper has little to do with the non-convex setting (in terms of goal/techniques).",
      "This, lots of settings and results, also led to authors' being able to put only one algorithm description (in full, as a pseudo-code) in the main paper, and the rest is deferred to the appendix.",
      "The authors only provide upper bounds for the settings they consider.",
      "Is there a way (perhaps from previous works?) to assess how sharp are the attained rates?"
    ]
  },
  {
    "paper_id": "2403.00278v2",
    "submission_id": "wn79e85F42W",
    "submission_title": "Differentially Private Stochastic Optimization: New Results in Convex and Non-Convex Settings",
    "review_id": "BsHBJE1Rve",
    "input": {
      "title": "Differentially Private Stochastic Optimization: New Results in Convex and Non-Convex Settings",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think the new algorithms are interesting and the utility and convergence results seem to be strong.\n- However, my major concerns are about the algorithms and results in nonconvex setting, and I summarize it as follows:\n- It is unclear the novelty of the proposed Private Frank-Wolfe algorithm. It seems to be a straightforward application of the variance reduced stochastic Frank-Wolfe algorithm to the private setting.\n- The authors should clarify the novelty.\n- What are the main challenges for analyzing your proposed Private Frank-Wolfe algorithm? This could help readers understand the contributions of the paper.\n- The proposed Private Frank-Wolfe algorithm requires a very large batch at each iteration, suggesting that the proposed algorithm will have very bad scalability.\n- The utility guarantee of the proposed algorithm is worse than existing work. For example, in the l_2 setting, the utility guarantee is worse than the result in [ZCH+20].\n- There are no experiments to validate the effectiveness of the proposed methods in the current paper.",
    "review_points_list": [
      "I think the new algorithms are interesting and the utility and convergence results seem to be strong.",
      "However, my major concerns are about the algorithms and results in nonconvex setting, and I summarize it as follows:",
      "It is unclear the novelty of the proposed Private Frank-Wolfe algorithm. It seems to be a straightforward application of the variance reduced stochastic Frank-Wolfe algorithm to the private setting.",
      "The authors should clarify the novelty.",
      "What are the main challenges for analyzing your proposed Private Frank-Wolfe algorithm? This could help readers understand the contributions of the paper.",
      "The proposed Private Frank-Wolfe algorithm requires a very large batch at each iteration, suggesting that the proposed algorithm will have very bad scalability.",
      "The utility guarantee of the proposed algorithm is worse than existing work. For example, in the l_2 setting, the utility guarantee is worse than the result in [ZCH+20].",
      "There are no experiments to validate the effectiveness of the proposed methods in the current paper."
    ]
  },
  {
    "paper_id": "2208.00815v1",
    "submission_id": "wF-llA3k32",
    "submission_title": "Batch Multi-Fidelity Bayesian Optimization with  Deep Auto-Regressive Networks",
    "review_id": "qUMdO1-llDJ",
    "input": {
      "title": "Batch Multi-Fidelity Bayesian Optimization with  Deep Auto-Regressive Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Having a multi-fidelity model that can be trained end-to-end is an appealing property, as it allows for learning the interactions across fidelities in a unified manner rather than disjointed.\n- The batch acquisition function also arises quite naturally from the formulation of the model, meaning that the authors do not have to rely on a multitude of empirical tricks and implementation hacks to meet the desired goal.\n- The performance of the method is evaluated over benchmark functions (for assessing the quality of the multi fidelity model in isolation), while four hyper-parameter optimisation set-ups are used to validate the practical effectiveness of the BO proposal.\n- This variety of experiments successfully addresses the different potential uses that the methods proposed in the paper might have.\n- The paper is very well-written and organised.\n- The literature review adequately covers related work, and the experimental evaluation also includes a wide variety of competing methods, some of which were implemented by the authors themselves.\n- The importance of having a multi-fidelity model that is either chained or trained end-to-end has already been explored by Perdikaris et al (2017) and Cutajar et al (2019) for deep GP model constructions.\n- I think that discussing this connection could be beneficial to the paper as the superior uncertainty estimates that are typically expected of GP models should be relevant to the iterative BO procedure explored here.\n- It would be interesting to more explicitly state the potential limitations of the proposal here.\n- For example, how well does the MF model scale to large input dimensions, either in terms of computational efficiency or expressivity?\n- The paper successfully leverages weaknesses in other methods for motivating the work work described here, but there is little insight into which conditions might cause this method to underperform.\n- In the same vein of the above, the paper doesn\u2019t really hint at how the method described here can be improved or extended further in future work.\n- The paper is very well-written and a pleasure to read.\n- The proposal is well-motivated and the multi-fidelity batch acquisition function is properly explained.\n- One possible suggestion would be to include a visualisation of the multi-fidelity model itself (and how the output of the various layers feeds into the next) within the main paper itself.\n- Some very minor typos: *L2:* between *the* cost and accuracy, *L15:* reference to *alternating optimization* is a bit confusing here, *L41:* between successive queries *and* is at higher, *L83:* most commonly used *class of surrogate models are Gaussian processes*, *L114* might limit the *expressivity*, *L83:* and *References:* Certain terms (e.g. Bayesian) and conference names need to appear as capitalised in the references.\n- Besides putting forward an interesting problem to solve, the authors propose a well-rounded solution and provide multiple experiments that showcase the diversity of settings this work can be applied to.\n- Just as importantly, the paper and its writing are already in a state fit for publication, which gives me greater confidence in recommending it for acceptance.",
    "review_points_list": [
      "Having a multi-fidelity model that can be trained end-to-end is an appealing property, as it allows for learning the interactions across fidelities in a unified manner rather than disjointed.",
      "The batch acquisition function also arises quite naturally from the formulation of the model, meaning that the authors do not have to rely on a multitude of empirical tricks and implementation hacks to meet the desired goal.",
      "The performance of the method is evaluated over benchmark functions (for assessing the quality of the multi fidelity model in isolation), while four hyper-parameter optimisation set-ups are used to validate the practical effectiveness of the BO proposal.",
      "This variety of experiments successfully addresses the different potential uses that the methods proposed in the paper might have.",
      "The paper is very well-written and organised.",
      "The literature review adequately covers related work, and the experimental evaluation also includes a wide variety of competing methods, some of which were implemented by the authors themselves.",
      "The importance of having a multi-fidelity model that is either chained or trained end-to-end has already been explored by Perdikaris et al (2017) and Cutajar et al (2019) for deep GP model constructions.",
      "I think that discussing this connection could be beneficial to the paper as the superior uncertainty estimates that are typically expected of GP models should be relevant to the iterative BO procedure explored here.",
      "It would be interesting to more explicitly state the potential limitations of the proposal here.",
      "For example, how well does the MF model scale to large input dimensions, either in terms of computational efficiency or expressivity?",
      "The paper successfully leverages weaknesses in other methods for motivating the work work described here, but there is little insight into which conditions might cause this method to underperform.",
      "In the same vein of the above, the paper doesn\u2019t really hint at how the method described here can be improved or extended further in future work.",
      "The paper is very well-written and a pleasure to read.",
      "The proposal is well-motivated and the multi-fidelity batch acquisition function is properly explained.",
      "One possible suggestion would be to include a visualisation of the multi-fidelity model itself (and how the output of the various layers feeds into the next) within the main paper itself.",
      "Some very minor typos: *L2:* between *the* cost and accuracy, *L15:* reference to *alternating optimization* is a bit confusing here, *L41:* between successive queries *and* is at higher, *L83:* most commonly used *class of surrogate models are Gaussian processes*, *L114* might limit the *expressivity*, *L83:* and *References:* Certain terms (e.g. Bayesian) and conference names need to appear as capitalised in the references.",
      "Besides putting forward an interesting problem to solve, the authors propose a well-rounded solution and provide multiple experiments that showcase the diversity of settings this work can be applied to.",
      "Just as importantly, the paper and its writing are already in a state fit for publication, which gives me greater confidence in recommending it for acceptance."
    ]
  },
  {
    "paper_id": "2208.00815v1",
    "submission_id": "wF-llA3k32",
    "submission_title": "Batch Multi-Fidelity Bayesian Optimization with  Deep Auto-Regressive Networks",
    "review_id": "yu0JbEUDdGe",
    "input": {
      "title": "Batch Multi-Fidelity Bayesian Optimization with  Deep Auto-Regressive Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Multiple novel methods (surrogate model, batch acquisition function, etc) that will be of broader interest to the Bayesopt community.\n- Good overall clarity.\n- The paper benchmarks against a variety of recent algorithms from the literature and demonstrates an impressive performance improvement.\n- The paper would be improved by a more formal problem statement.\n- Lines 92-106 are largely focused on a discussion of related work.\n- It's unclear to me, for example, why eq (2) is necessary.\n- It would be helpful to better explain the action space for the algorithm.\n- For example, do fidelities have to be queried in increasing order of cost? If you query f() at high fidelity, does that mean that you get a low-fidelity measurement for free?\n- This is the case for neural network training (where high fidelity corresponds to more training steps), but not true in general.\n- I'm assuming that for each x you can evaluate f at any given fidelity.\n- However, the parametrization of the autoregressive model in (3) suggests that predicting at a given fidelity requires having data for every available measurement of x at lower fidelity.\n- This places a considerable restriction at the action space that isn't reflected in a problem definition or in sec 4.3.\n- There are ways to parametrize an autoregressive model such that it can handle missing data, but this is not discussed.\n- It was unclear to me why you need to have a separate model for each fidelity in (4).\n- Wouldn't there be a shared model that could model all of the fidelities, and thus would have more training data?\n- I'm not that familiar with the latest literature on max-value entropy search.\n- What is novel in your usage of it.\n- It was unclear to me, for example, what parts of sections 4.1 and 4.2 are new.\n- The experiments section contains a thorough ablation analysis of the impact of various surrogate models.\n- This helps provide evidence for the importance of one of the paper's contributions.\n- However, the paper's other contributions (batch acquisition function, strategy for optimizing the AF) are not analyzed.\n- I'm curious, for example, what would happen if you used a simpler acquisition function that doesn't account for interactions within the batch or used something other than MVES.",
    "review_points_list": [
      "Multiple novel methods (surrogate model, batch acquisition function, etc) that will be of broader interest to the Bayesopt community.",
      "Good overall clarity.",
      "The paper benchmarks against a variety of recent algorithms from the literature and demonstrates an impressive performance improvement.",
      "The paper would be improved by a more formal problem statement.",
      "Lines 92-106 are largely focused on a discussion of related work.",
      "It's unclear to me, for example, why eq (2) is necessary.",
      "It would be helpful to better explain the action space for the algorithm.",
      "For example, do fidelities have to be queried in increasing order of cost? If you query f() at high fidelity, does that mean that you get a low-fidelity measurement for free?",
      "This is the case for neural network training (where high fidelity corresponds to more training steps), but not true in general.",
      "I'm assuming that for each x you can evaluate f at any given fidelity.",
      "However, the parametrization of the autoregressive model in (3) suggests that predicting at a given fidelity requires having data for every available measurement of x at lower fidelity.",
      "This places a considerable restriction at the action space that isn't reflected in a problem definition or in sec 4.3.",
      "There are ways to parametrize an autoregressive model such that it can handle missing data, but this is not discussed.",
      "It was unclear to me why you need to have a separate model for each fidelity in (4).",
      "Wouldn't there be a shared model that could model all of the fidelities, and thus would have more training data?",
      "I'm not that familiar with the latest literature on max-value entropy search.",
      "What is novel in your usage of it.",
      "It was unclear to me, for example, what parts of sections 4.1 and 4.2 are new.",
      "The experiments section contains a thorough ablation analysis of the impact of various surrogate models.",
      "This helps provide evidence for the importance of one of the paper's contributions.",
      "However, the paper's other contributions (batch acquisition function, strategy for optimizing the AF) are not analyzed.",
      "I'm curious, for example, what would happen if you used a simpler acquisition function that doesn't account for interactions within the batch or used something other than MVES."
    ]
  },
  {
    "paper_id": "2208.00815v1",
    "submission_id": "wF-llA3k32",
    "submission_title": "Batch Multi-Fidelity Bayesian Optimization with  Deep Auto-Regressive Networks",
    "review_id": "aFuInLqBeEx",
    "input": {
      "title": "Batch Multi-Fidelity Bayesian Optimization with  Deep Auto-Regressive Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- High-level summary: The problem setting is relevant and of interest to the community.\n- The modeling approach seems quite an incremental contribution over previous work, and it is unclear what the effect of the model on the performance of the overall approach is.\n- Some but not much methodological novelty in the approach; it essentially uses a standard batch MES formulation with a (slightly modified compared to previous work) BNN model and  some approximations of the acquisition function to render computations tractable.\n- The main novelty is in these approximations; however, I am not convinced of the merits suggested approach.\n- The writing is generally ok (some wording issues, repetitive in some places), overall the paper is relatively easy to follow.\n- The empirical evaluation includes a good number of baselines, but is quite sparse on details and thus not clear; this section needs to be improved. In the current form, it's hard to assess the significance of the results. \n- Overall, a potentially interesting approach, but too many open questions in the current draft.\n- Not making the bar for NeurIPS in the current form.\n- The authors appear to suggest that all GP approaches have computational complexity of N^3: There is a number of ways around this...\n- In all the examples considered in the paper, the different fidelities correspond to different 'lengths'...\n- An alternative approach to pre-committing to the length of the evalution is to to not specify the fidelity of a candiate priori but perform early stopping while obtaining partial results.\n- The paper should discuss the early stopping line of work; please also explain why you consider the pre-committing approach.\n- The modeling approach is not particularly well motivated and the contribution seems quite incremental compared to previous work.\n- The main difference to the model of Li et al. is that fidelities here depend on the output of all previously modeled fidelities.\n- In particular, there is no evaluation of the model fits, and a lack of an ablation study comparing to the simpler model from Li et al. means that it's not possible to separate the effect of the model and the effect of the different approach to optimizing the acquisition function (in the case of sequential optimization).\n- This point is particular pertinent since in all of the real-world examples considered, one would expect a relatively simple (and not complex) relationship between the fidelities.\n- It's not clear that in any of the real world the examples the additional model capacity obtained by the modified structure would be all that helpful.\n- The model is motivated with 'complex, strong (nonstationary, highly nonlinear) correlations across fidelities': Can you give some more concrete examples to provide some motivation/intuition for where/in which practical applications this is / would be the case?\n- Model fitting for BNNs is known to be much more finnicky than other approaches.\n- Sec 4.1 is a bit light on discussing similarities and differences to other batch acquisition functions.\n- There seems to be a bit of a tension between the modeling approach using a BNN (much more flexible than existing GP-based formulations) and the efficient computation scheme that is based on moment moment matching.\n- Acquisition function is based on Laplace approximation, which is presumably a pretty coarse approximation.\n- The approach is based on Laplace approximation, which is presumably a pretty coarse approximation.\n- In particular, there is no evaluation of the model fits, and a lack of an ablation study comparing to the simpler model from Li et al. means that it's not possible to separate the effect of the model and the effect of the different approach to optimizing the acquisition function (in the case of sequential optimization).\n- The difference between BMBO-DARN and DNN-MFBO isn't particularly large (would be good to see p-values of a hypothesis test for the difference).\n- The real-world application evaluation seems to be quite comprehensive, a few models and quite a few baselines.\n- The authors should explain why they chose to model the problem in this way and what insights they gained from this modeling approach.\n- The model is more general and flexible than the GP-based formulations.\n- The real-world application evaluation seems to be quite comprehensive, a few models and quite a few baselines.\n- There is lack of detail on the evaluation criteria.\n- Please clarify this and be explicit about the evaluation metrics and the benchmark procedure.\n- Why don't the losses all start at the same value if the initial points are shared between methods?\n- How many function evaluations are actually performed in the experiments?\n- Some repetitive discussion of 'other approaches simplifying things' should be consolidated.\n- Can you elaborate on this? I don't think this is true, there has been a lot of work on batch and fully asynchronous candidate generation in the past (see e.g. )\n- Is this correct? this seems like an obscene difference in fidelities.\n- Is this the average time per candidate or the average time per batch?\n- How much time is spent on model fitting, how much on acqf optimization?\n- Is there an assumption that the fidelities are ordered? If so, what if that's not the case? Will things still work ok?\n- How could this approach work with continuous fidelities?\n- }",
    "review_points_list": [
      "High-level summary: The problem setting is relevant and of interest to the community.",
      "The modeling approach seems quite an incremental contribution over previous work, and it is unclear what the effect of the model on the performance of the overall approach is.",
      "Some but not much methodological novelty in the approach; it essentially uses a standard batch MES formulation with a (slightly modified compared to previous work) BNN model and  some approximations of the acquisition function to render computations tractable.",
      "The main novelty is in these approximations; however, I am not convinced of the merits suggested approach.",
      "The writing is generally ok (some wording issues, repetitive in some places), overall the paper is relatively easy to follow.",
      "The empirical evaluation includes a good number of baselines, but is quite sparse on details and thus not clear; this section needs to be improved. In the current form, it's hard to assess the significance of the results. ",
      "Overall, a potentially interesting approach, but too many open questions in the current draft.",
      "Not making the bar for NeurIPS in the current form.",
      "The authors appear to suggest that all GP approaches have computational complexity of N^3: There is a number of ways around this...",
      "In all the examples considered in the paper, the different fidelities correspond to different 'lengths'...",
      "An alternative approach to pre-committing to the length of the evalution is to to not specify the fidelity of a candiate priori but perform early stopping while obtaining partial results.",
      "The paper should discuss the early stopping line of work; please also explain why you consider the pre-committing approach.",
      "The modeling approach is not particularly well motivated and the contribution seems quite incremental compared to previous work.",
      "The main difference to the model of Li et al. is that fidelities here depend on the output of all previously modeled fidelities.",
      "In particular, there is no evaluation of the model fits, and a lack of an ablation study comparing to the simpler model from Li et al. means that it's not possible to separate the effect of the model and the effect of the different approach to optimizing the acquisition function (in the case of sequential optimization).",
      "This point is particular pertinent since in all of the real-world examples considered, one would expect a relatively simple (and not complex) relationship between the fidelities.",
      "It's not clear that in any of the real world the examples the additional model capacity obtained by the modified structure would be all that helpful.",
      "The model is motivated with 'complex, strong (nonstationary, highly nonlinear) correlations across fidelities': Can you give some more concrete examples to provide some motivation/intuition for where/in which practical applications this is / would be the case?",
      "Model fitting for BNNs is known to be much more finnicky than other approaches.",
      "Sec 4.1 is a bit light on discussing similarities and differences to other batch acquisition functions.",
      "There seems to be a bit of a tension between the modeling approach using a BNN (much more flexible than existing GP-based formulations) and the efficient computation scheme that is based on moment moment matching.",
      "Acquisition function is based on Laplace approximation, which is presumably a pretty coarse approximation.",
      "The approach is based on Laplace approximation, which is presumably a pretty coarse approximation.",
      "In particular, there is no evaluation of the model fits, and a lack of an ablation study comparing to the simpler model from Li et al. means that it's not possible to separate the effect of the model and the effect of the different approach to optimizing the acquisition function (in the case of sequential optimization).",
      "The difference between BMBO-DARN and DNN-MFBO isn't particularly large (would be good to see p-values of a hypothesis test for the difference).",
      "The real-world application evaluation seems to be quite comprehensive, a few models and quite a few baselines.",
      "The authors should explain why they chose to model the problem in this way and what insights they gained from this modeling approach.",
      "The model is more general and flexible than the GP-based formulations.",
      "The real-world application evaluation seems to be quite comprehensive, a few models and quite a few baselines.",
      "There is lack of detail on the evaluation criteria.",
      "Please clarify this and be explicit about the evaluation metrics and the benchmark procedure.",
      "Why don't the losses all start at the same value if the initial points are shared between methods?",
      "How many function evaluations are actually performed in the experiments?",
      "Some repetitive discussion of 'other approaches simplifying things' should be consolidated.",
      "Can you elaborate on this? I don't think this is true, there has been a lot of work on batch and fully asynchronous candidate generation in the past (see e.g. )",
      "Is this correct? this seems like an obscene difference in fidelities.",
      "Is this the average time per candidate or the average time per batch?",
      "How much time is spent on model fitting, how much on acqf optimization?",
      "Is there an assumption that the fidelities are ordered? If so, what if that's not the case? Will things still work ok?",
      "How could this approach work with continuous fidelities?",
      "}"
    ]
  },
  {
    "paper_id": "2208.00815v1",
    "submission_id": "wF-llA3k32",
    "submission_title": "Batch Multi-Fidelity Bayesian Optimization with  Deep Auto-Regressive Networks",
    "review_id": "YwSjAqXW6e",
    "input": {
      "title": "Batch Multi-Fidelity Bayesian Optimization with  Deep Auto-Regressive Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think the paper contains a very interesting method for modeling multiple fidelities/tasks with a cascade of Bayesian neural networks.\n- Based on the presented results, the method seems very sample efficient, but the overhead is unclear.\n- To my surprise, the sequential version of the algorithm performs worse than the batch one, which I would like to hear the authors' feedback on.\n- Missing related work on batch BO and missing details on the parallelism of the presented experiments, also lower my impression of the paper a bit.\n- I think that the paper contains two orthogonal ideas: the DARN model itself, and a clever way to approximate the mutual information for multiple points.\n- Because the effects of those are not separated by an ablation study, the effects of contributions both make are not separable.\n- The paper is easy to follow, although I would suggest to move some of the details of the benchmarks to the appendix and expand the discussion about the acquisition function (which I found too dense) and a more detailed analysis of the results.\n- In the discussion of equation (2), I am missing the OG multi-task BO reference Swersky, K., Snoek, J., & Adams, R. P. (2013). Multi-task bayesian optimization.\n- Equation 2 is one particular way of approximating the MTBO kernel, which is more general.\n- The discussion about the limitations of multi-fidelity BO is missing MTBO and potentially stacked GPs from: Golovin, D., Solnik, B., Moitra, S., Kochanski, G., Karro, J., & Sculley, D. (2017, August). Google vizier: A service for black-box optimization.\n- About equation (5): In the normal context of batch BO, the whole batch is suggested at once, then evaluated and the results incorporated into the model.\n- If this pre-batch query and model-update is followed here, wouldn't\n- max \u03bbm(k) be more meaningful if the evaluations are in parallel? Otherwise querying a batch wouldn't give any advantage.\n- The related work section is missing a discussion about batch BO methods, including (but not limited to): Wu, J., & Frazier, P. (2016). The parallel knowledge gradient method for batch Bayesian optimization.\n- Gonz\u00e1lez, J., Dai, Z., Hennig, P., & Lawrence, N. (2016, May). Batch Bayesian optimization via local penalization.\n- The method labelled as SHTL, is referred to as ABLR (adaptive Bayesian linear regression) in the paper itself.\n- The method also uses L-BFGS to optimize all parameters, which was replaced by ADAM here.\n- Not sure how much that impacts performance, but it should be pointed out in the paper.\n- It is nowhere mentioned if evaluations where carried out in parallel.\n- If they were all done sequentially, I would like to understand why the BMBO-DARN-1 performs worse.\n- Usually, batch methods are outperformed by their sequential counterpart when the batch is evaluated sequentially, but become useful when the evaluations can be performed in parallel.\n- BMBO-DARN is very performant across all shown benchmarks, but I wonder how much each contribution has, i.e., how does the auto-regressive model compare against a simpler model, but with the same acquisition function, and how would the DARN model work with MF-MES.\n- The performance is shown versus the accumulated cost, so I assume the overhead of the HMC sampling and the elaborate acquisition function is not included.\n- Especially for the XGBoost example, I would assume the overhead to be substantial.\n- What would these plots look like if this overhead is included?\n- Following up on the previous point, could you please comment on the average evaluation time for the benchmarks at the different fidelities?\n- It is really hard to judge how many configurations have been evaluated across the different benchmarks.",
    "review_points_list": [
      "I think the paper contains a very interesting method for modeling multiple fidelities/tasks with a cascade of Bayesian neural networks.",
      "Based on the presented results, the method seems very sample efficient, but the overhead is unclear.",
      "To my surprise, the sequential version of the algorithm performs worse than the batch one, which I would like to hear the authors' feedback on.",
      "Missing related work on batch BO and missing details on the parallelism of the presented experiments, also lower my impression of the paper a bit.",
      "I think that the paper contains two orthogonal ideas: the DARN model itself, and a clever way to approximate the mutual information for multiple points.",
      "Because the effects of those are not separated by an ablation study, the effects of contributions both make are not separable.",
      "The paper is easy to follow, although I would suggest to move some of the details of the benchmarks to the appendix and expand the discussion about the acquisition function (which I found too dense) and a more detailed analysis of the results.",
      "In the discussion of equation (2), I am missing the OG multi-task BO reference Swersky, K., Snoek, J., & Adams, R. P. (2013). Multi-task bayesian optimization.",
      "Equation 2 is one particular way of approximating the MTBO kernel, which is more general.",
      "The discussion about the limitations of multi-fidelity BO is missing MTBO and potentially stacked GPs from: Golovin, D., Solnik, B., Moitra, S., Kochanski, G., Karro, J., & Sculley, D. (2017, August). Google vizier: A service for black-box optimization.",
      "About equation (5): In the normal context of batch BO, the whole batch is suggested at once, then evaluated and the results incorporated into the model.",
      "If this pre-batch query and model-update is followed here, wouldn't",
      "max \u03bbm(k) be more meaningful if the evaluations are in parallel? Otherwise querying a batch wouldn't give any advantage.",
      "The related work section is missing a discussion about batch BO methods, including (but not limited to): Wu, J., & Frazier, P. (2016). The parallel knowledge gradient method for batch Bayesian optimization.",
      "Gonz\u00e1lez, J., Dai, Z., Hennig, P., & Lawrence, N. (2016, May). Batch Bayesian optimization via local penalization.",
      "The method labelled as SHTL, is referred to as ABLR (adaptive Bayesian linear regression) in the paper itself.",
      "The method also uses L-BFGS to optimize all parameters, which was replaced by ADAM here.",
      "Not sure how much that impacts performance, but it should be pointed out in the paper.",
      "It is nowhere mentioned if evaluations where carried out in parallel.",
      "If they were all done sequentially, I would like to understand why the BMBO-DARN-1 performs worse.",
      "Usually, batch methods are outperformed by their sequential counterpart when the batch is evaluated sequentially, but become useful when the evaluations can be performed in parallel.",
      "BMBO-DARN is very performant across all shown benchmarks, but I wonder how much each contribution has, i.e., how does the auto-regressive model compare against a simpler model, but with the same acquisition function, and how would the DARN model work with MF-MES.",
      "The performance is shown versus the accumulated cost, so I assume the overhead of the HMC sampling and the elaborate acquisition function is not included.",
      "Especially for the XGBoost example, I would assume the overhead to be substantial.",
      "What would these plots look like if this overhead is included?",
      "Following up on the previous point, could you please comment on the average evaluation time for the benchmarks at the different fidelities?",
      "It is really hard to judge how many configurations have been evaluated across the different benchmarks."
    ]
  },
  {
    "paper_id": "2110.02954v1",
    "submission_id": "ui0sz9Y2x9X",
    "submission_title": "A Stochastic Newton Algorithm for Distributed Convex Optimization",
    "review_id": "c122rNmTGDI",
    "input": {
      "title": "A Stochastic Newton Algorithm for Distributed Convex Optimization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is mainly well-written.\n- However, the notations are confusing and wrong.\n- The parameter T (number of rounds for local SGD) in algorithm 3 and Theorem 3 should be K in Theorem 4 and all the comparisons in this paper.\n- It is really confusing to mix with the number of newton updates.\n- For some key parameters like R,M,K and T, it would be much better if the authors can restate/emphasize their meaning before main theorems/algorithm comparisons.\n- The authors should emphasize their contributions, on the theoretical analysis and the novelty of their algorithms.\n- Using quadratic programming to solve Newton updates is a very standard technique in recent 10 years optimization literature.\n- From my perspective, the algorithm is just a combination of this technique and recently proposed local SGD in Woodworth et al.\n- The theoretical analysis is also very straight-forward.\n- The Hessian-vector product is very important in their algorithm.\n- I am very surprised that the authors do not give any explicit form/algorithm to compute this product.\n- They treat it as a black box with some outputs satisfying unbiasedness and bounded variance assumption.\n- I think we need an explicit form for that (from some literature) which satisfies the assumptions proposed.",
    "review_points_list": [
      "The paper is mainly well-written.",
      "However, the notations are confusing and wrong.",
      "The parameter T (number of rounds for local SGD) in algorithm 3 and Theorem 3 should be K in Theorem 4 and all the comparisons in this paper.",
      "It is really confusing to mix with the number of newton updates.",
      "For some key parameters like R,M,K and T, it would be much better if the authors can restate/emphasize their meaning before main theorems/algorithm comparisons.",
      "The authors should emphasize their contributions, on the theoretical analysis and the novelty of their algorithms.",
      "Using quadratic programming to solve Newton updates is a very standard technique in recent 10 years optimization literature.",
      "From my perspective, the algorithm is just a combination of this technique and recently proposed local SGD in Woodworth et al.",
      "The theoretical analysis is also very straight-forward.",
      "The Hessian-vector product is very important in their algorithm.",
      "I am very surprised that the authors do not give any explicit form/algorithm to compute this product.",
      "They treat it as a black box with some outputs satisfying unbiasedness and bounded variance assumption.",
      "I think we need an explicit form for that (from some literature) which satisfies the assumptions proposed."
    ]
  },
  {
    "paper_id": "2110.02954v1",
    "submission_id": "ui0sz9Y2x9X",
    "submission_title": "A Stochastic Newton Algorithm for Distributed Convex Optimization",
    "review_id": "vy34liMps4K",
    "input": {
      "title": "A Stochastic Newton Algorithm for Distributed Convex Optimization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Thank you to the authors for the response.\n- It was helpful, particularly in comparing quasi-self-concordance to standard self-concordance, as well as motivating the approximate Hessian-vector product.\n- May I suggest that the authors also discuss in the paper how using quasi-self-concordance compares to using scaled self-concordance, which is considered in DISCO (Zhang and Xiao, 2015), since it seems that both of those can be used for logistic regression.\n- Sounds like the authors agree that the paper needs some work in making the presentation of the results clearer and more precise, so my recommendation does not change.\n- I found the paper to be extremely dense and difficult to get through, with very complicated notation to the point where it was difficult for me to put the results into perspective.\n- Below are the main issues I ran into with the notation:\n- First, it feels very strange that the main iterates of the algorithm are indexed by T, and yet T does not appear in the bound of the main result (Theorem 4).\n- In fact, parameter T appears both in Algorithm 1 (the outer loop) and Algorithm 3 (the inner-most loop), which makes me think one of those parameters should be called something else.\n- Parameters R and K, which seem to be the main quantities used to evaluate the convergence rate, do not appear anywhere in any of the algorithms, except in Appendix D, where they appear in the definitions of other parameters, like T.\n- The definitions of all the parameters in Theorem 7 (the full version of the main result) seem to be entangled together.\n- For instance, T is defined using N and N is defined using T.\n- It is not clear to me how all those equations can be satisfied at once.\n- Other major question that is not properly addressed in the paper is:\n- How does the noisy Hessian-vector oracle arise practically, as a natural data access model?\n- I didn\u2019t see this addressed in the paper, and it is not clear to me how this was done in the experiments.\n- Finally, another definition that deserves clarification:\n- What is the relationship between quasi-self-concordance and standard concordance?\n- Is it a broader class, or a narrower class, or incomparable?\n- Overall, I find the paper very confusing and poorly written, thus it is difficult for me to even judge the merit of the contributions.",
    "review_points_list": [
      "Thank you to the authors for the response.",
      "It was helpful, particularly in comparing quasi-self-concordance to standard self-concordance, as well as motivating the approximate Hessian-vector product.",
      "May I suggest that the authors also discuss in the paper how using quasi-self-concordance compares to using scaled self-concordance, which is considered in DISCO (Zhang and Xiao, 2015), since it seems that both of those can be used for logistic regression.",
      "Sounds like the authors agree that the paper needs some work in making the presentation of the results clearer and more precise, so my recommendation does not change.",
      "I found the paper to be extremely dense and difficult to get through, with very complicated notation to the point where it was difficult for me to put the results into perspective.",
      "Below are the main issues I ran into with the notation:",
      "First, it feels very strange that the main iterates of the algorithm are indexed by T, and yet T does not appear in the bound of the main result (Theorem 4).",
      "In fact, parameter T appears both in Algorithm 1 (the outer loop) and Algorithm 3 (the inner-most loop), which makes me think one of those parameters should be called something else.",
      "Parameters R and K, which seem to be the main quantities used to evaluate the convergence rate, do not appear anywhere in any of the algorithms, except in Appendix D, where they appear in the definitions of other parameters, like T.",
      "The definitions of all the parameters in Theorem 7 (the full version of the main result) seem to be entangled together.",
      "For instance, T is defined using N and N is defined using T.",
      "It is not clear to me how all those equations can be satisfied at once.",
      "Other major question that is not properly addressed in the paper is:",
      "How does the noisy Hessian-vector oracle arise practically, as a natural data access model?",
      "I didn\u2019t see this addressed in the paper, and it is not clear to me how this was done in the experiments.",
      "Finally, another definition that deserves clarification:",
      "What is the relationship between quasi-self-concordance and standard concordance?",
      "Is it a broader class, or a narrower class, or incomparable?",
      "Overall, I find the paper very confusing and poorly written, thus it is difficult for me to even judge the merit of the contributions."
    ]
  },
  {
    "paper_id": "2110.13741v1",
    "submission_id": "tgdoUMqlwMv",
    "submission_title": "Disrupting Deep Uncertainty Estimation Without Harming Accuracy",
    "review_id": "4huOu3zGzY",
    "input": {
      "title": "Disrupting Deep Uncertainty Estimation Without Harming Accuracy",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper tackles a new problem setup of attacking the calibration of neural networks without changing the accuracy,\n- I agree that there might be a practical scenario that this threat model is more applicable than only considering adversarial examples which can also reduce the accuracy.\n- The technical contributions of the paper are not significant enough to meet the NeurIPS bar upon the literature of adversarial attacks,\n- One might argue that the proposed method is simply a rescaled version of FGSM.\n- The observation here may re-confirm the high brittleness of neural networks around its decision boundary, but further insight beyond this seems to require more non-trivial works as far as I can see: the current experimental results only demonstrate that the proposed attack works, which is not that surprising, but lack on further analysis on it.\n- It would be also nice if the paper could provide more concrete cases when the current threat model is more important than the standard adversarial examples.\n- The paper could also report the results when the attack is done by standard FGSM or PGD with the comparable size of $\bon{\rho}$ or with allowing a larger value, to show that the standard method cannot achieve what ACE (the proposed method) can achieve.\n- I also suggest the paper to discuss [Ovadia et al., 2019] in the text, as it also address the limited ability of neural networks on uncertainty estimation under distribution shifts.\n- Is the proposed attack method still applicable to adversarially robust networks?\n- It would be nice if the paper could provide a more clear comparison of ACE with the standard adversarial attack: for example, how the attack objective of prediction confidence different from the standard cross-entropy?\n- What if one applies ACE with the cross-entropy loss?\n- What would happens if one performs adversarial training using the samples found by ACE? Will the resulting network gets better robustness/calibration/generalization?",
    "review_points_list": [
      "The paper tackles a new problem setup of attacking the calibration of neural networks without changing the accuracy,",
      "I agree that there might be a practical scenario that this threat model is more applicable than only considering adversarial examples which can also reduce the accuracy.",
      "The technical contributions of the paper are not significant enough to meet the NeurIPS bar upon the literature of adversarial attacks,",
      "One might argue that the proposed method is simply a rescaled version of FGSM.",
      "The observation here may re-confirm the high brittleness of neural networks around its decision boundary, but further insight beyond this seems to require more non-trivial works as far as I can see: the current experimental results only demonstrate that the proposed attack works, which is not that surprising, but lack on further analysis on it.",
      "It would be also nice if the paper could provide more concrete cases when the current threat model is more important than the standard adversarial examples.",
      "The paper could also report the results when the attack is done by standard FGSM or PGD with the comparable size of $\bon{\rho}$ or with allowing a larger value, to show that the standard method cannot achieve what ACE (the proposed method) can achieve.",
      "I also suggest the paper to discuss [Ovadia et al., 2019] in the text, as it also address the limited ability of neural networks on uncertainty estimation under distribution shifts.",
      "Is the proposed attack method still applicable to adversarially robust networks?",
      "It would be nice if the paper could provide a more clear comparison of ACE with the standard adversarial attack: for example, how the attack objective of prediction confidence different from the standard cross-entropy?",
      "What if one applies ACE with the cross-entropy loss?",
      "What would happens if one performs adversarial training using the samples found by ACE? Will the resulting network gets better robustness/calibration/generalization?"
    ]
  },
  {
    "paper_id": "2110.13741v1",
    "submission_id": "tgdoUMqlwMv",
    "submission_title": "Disrupting Deep Uncertainty Estimation Without Harming Accuracy",
    "review_id": "G2voq23DVrB",
    "input": {
      "title": "Disrupting Deep Uncertainty Estimation Without Harming Accuracy",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The topic is quite interesting and well motivated.\n- Though lots of attack and defend techniques have been explored, they mainly focus on altering the predictions of the models.\n- This paper explores the attack techniques which only change the uncertainty estimation without causing incorrect prediction results.\n- This topic is worth exploring as the uncertainly is also important for deep neural networks besides the predictions.\n- The experimental part is impressing.\n- The paper conducts attacking on different models, settings and uses several metrics to quantify the consequences of the proposed attacking technique.\n- Some of the claims in the paper are not supported.\n- The algorithm could easily be modified for regression.\n- While no regression experiments have been conducted in the paper to demonstrate the generability of the proposed attacking technique.\n- The proposed attack technique severely harms some of the most popular techniques for estimating uncertainty.\n- No experiments have been conducted to support this claim.",
    "review_points_list": [
      "The topic is quite interesting and well motivated.",
      "Though lots of attack and defend techniques have been explored, they mainly focus on altering the predictions of the models.",
      "This paper explores the attack techniques which only change the uncertainty estimation without causing incorrect prediction results.",
      "This topic is worth exploring as the uncertainly is also important for deep neural networks besides the predictions.",
      "The experimental part is impressing.",
      "The paper conducts attacking on different models, settings and uses several metrics to quantify the consequences of the proposed attacking technique.",
      "Some of the claims in the paper are not supported.",
      "The algorithm could easily be modified for regression.",
      "While no regression experiments have been conducted in the paper to demonstrate the generability of the proposed attacking technique.",
      "The proposed attack technique severely harms some of the most popular techniques for estimating uncertainty.",
      "No experiments have been conducted to support this claim."
    ]
  },
  {
    "paper_id": "2110.13741v1",
    "submission_id": "tgdoUMqlwMv",
    "submission_title": "Disrupting Deep Uncertainty Estimation Without Harming Accuracy",
    "review_id": "q2ZBBrsefwd",
    "input": {
      "title": "Disrupting Deep Uncertainty Estimation Without Harming Accuracy",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Appears to be an original problem which is targeted, with related work fairly considered.\n- Appears to be a complete work.\n- Paper is fairly clear.\n- I appreciate the inclusion of Algorithm 1, I don't see any significant details missing.\n- My overriding concern is regarding the practicality of the given attack.\n- I understand that 'suspicion arousal' has been briefly mentioned, but I would implore the authors to provide an (extended) elaboration regarding this point, possibly with an intuitive, hypothetical example of where this attack would be uniquely relevant, and existing attacks would not be.\n- In what scenario are we interested in attacking, or defending against attacks, where the accuracy isn't reduced but the uncertainty estimates are?\n- From another perspective, if we do not currently have an adequate solution for defending against attacks which reduce accuracy, why should we be concerned with attacks which do not reduce accuracy but harm uncertainty assessment?\n- Despite the above concern, I still see the paper as clearly a complete, original work.\n- I would feel more strongly about the paper if the authors wrote up a detailed, convincing account of the practicality of their algorithm, beyond the brief mention of 'suspicion arousal' currently included.\n- The authors answered my concerns with clarity, so I am raising my score.",
    "review_points_list": [
      "Appears to be an original problem which is targeted, with related work fairly considered.",
      "Appears to be a complete work.",
      "Paper is fairly clear.",
      "I appreciate the inclusion of Algorithm 1, I don't see any significant details missing.",
      "My overriding concern is regarding the practicality of the given attack.",
      "I understand that 'suspicion arousal' has been briefly mentioned, but I would implore the authors to provide an (extended) elaboration regarding this point, possibly with an intuitive, hypothetical example of where this attack would be uniquely relevant, and existing attacks would not be.",
      "In what scenario are we interested in attacking, or defending against attacks, where the accuracy isn't reduced but the uncertainty estimates are?",
      "From another perspective, if we do not currently have an adequate solution for defending against attacks which reduce accuracy, why should we be concerned with attacks which do not reduce accuracy but harm uncertainty assessment?",
      "Despite the above concern, I still see the paper as clearly a complete, original work.",
      "I would feel more strongly about the paper if the authors wrote up a detailed, convincing account of the practicality of their algorithm, beyond the brief mention of 'suspicion arousal' currently included.",
      "The authors answered my concerns with clarity, so I am raising my score."
    ]
  },
  {
    "paper_id": "2107.03190v2",
    "submission_id": "z3tlL2MeTK2",
    "submission_title": "Nested Counterfactual Identification from Arbitrary Surrogate Experiments",
    "review_id": "B_1Mh2gcDz",
    "input": {
      "title": "Nested Counterfactual Identification from Arbitrary Surrogate Experiments",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The contribution is clearly an advance for the state of the art in causality research.\n- I personally missed some attention in better motivating the importance of nested/conditional CFs in practical application\n- Apart from that, I see no reasons for not accepting the paper.",
    "review_points_list": [
      "The contribution is clearly an advance for the state of the art in causality research.",
      "I personally missed some attention in better motivating the importance of nested/conditional CFs in practical application",
      "Apart from that, I see no reasons for not accepting the paper."
    ]
  },
  {
    "paper_id": "2107.03190v2",
    "submission_id": "z3tlL2MeTK2",
    "submission_title": "Nested Counterfactual Identification from Arbitrary Surrogate Experiments",
    "review_id": "GeD3hHCN_B",
    "input": {
      "title": "Nested Counterfactual Identification from Arbitrary Surrogate Experiments",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This is overall a very strong submission, tackling an important problem with what appears to be a technically correct approach.\n- I found the examples throughout the paper to be particularly helpful in understanding (i) how certain estimands could be connected to nested counterfactuals, and (ii) how the various theorems imply useful conclusions towards identification and estimation.\n- This is particularly important in technically dense theoretical work such as this, and I would even encourage the authors to expand on the existing examples to further improve the paper's readability.\n- I would appreciate if the authors could respond to a few minor questions about the results.\n- Theorem 5 and Theorem 7 are described as 'completeness' results, but the statements of the theorems appear to provide soundness and completeness. Could the authors clarify this?\n- It appears that this submission only provides identification results for counterfactual queries that are averaged over units, and not unit-level counterfactual identifiability results. Could the authors clarify how unit-level identification results may or not differ?",
    "review_points_list": [
      "This is overall a very strong submission, tackling an important problem with what appears to be a technically correct approach.",
      "I found the examples throughout the paper to be particularly helpful in understanding (i) how certain estimands could be connected to nested counterfactuals, and (ii) how the various theorems imply useful conclusions towards identification and estimation.",
      "This is particularly important in technically dense theoretical work such as this, and I would even encourage the authors to expand on the existing examples to further improve the paper's readability.",
      "I would appreciate if the authors could respond to a few minor questions about the results.",
      "Theorem 5 and Theorem 7 are described as 'completeness' results, but the statements of the theorems appear to provide soundness and completeness. Could the authors clarify this?",
      "It appears that this submission only provides identification results for counterfactual queries that are averaged over units, and not unit-level counterfactual identifiability results. Could the authors clarify how unit-level identification results may or not differ?"
    ]
  },
  {
    "paper_id": "2107.03190v2",
    "submission_id": "z3tlL2MeTK2",
    "submission_title": "Nested Counterfactual Identification from Arbitrary Surrogate Experiments",
    "review_id": "fMDhWQyPF53",
    "input": {
      "title": "Nested Counterfactual Identification from Arbitrary Surrogate Experiments",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well written and the motivation for the presented theoretical work is well justified.\n- Notation, definitions and assumptions are clearly stated.\n- The contributions of the proposed theoretical results have important implications for the analysis, understanding and identifiability of structural causal models\n- The practical implications beyond of the analytical tools in Algorithms 1 and 2 remain to be seen.\n- There are few typos beyond those presented in Section F of the SM\n- The paper will benefit from careful proofreading\n- The paper discusses a novel algorithm, Cluster-Margin, for active learning, which can be applied to both large and small batch sizes.\n- It also discusses the theoretical guarantees of the proposed algorithm under certain assumptions.\n- The authors have conducted experiments to compare the performance of their algorithm with those of existing similar methods such as CoreSet and BADGE.\n- The performance of the proposed algorithm is compared with that of existing methods using various metrics.\n- The paper also discusses the limitations of the proposed algorithm.\n- The authors have made a significant contribution to the field of active learning with their novel algorithm, Cluster-Margin.\n- The paper presents an empirical evaluation of the algorithm and its comparison with existing methods.\n- However, the theoretical analysis of the algorithm is limited to very specific settings and does not provide a complete understanding of the algorithm's behavior.\n- The authors' experimental results demonstrate the effectiveness of the Cluster-Margin algorithm, particularly in large-batch-size settings.\n- However, a more detailed analysis of the algorithm's performance in small-batch-size settings would be helpful.\n- The paper presents a new approach to solving the multi-class problem.\n- The main idea is to use the k-nearest neighbors method to find the most representative samples for each class.\n- It is shown that this approach outperforms the traditional methods in terms of both accuracy and computational efficiency.\n- In contrast to previous methods, this approach does not require a priori knowledge of the class distribution.\n- This is particularly useful in real-world applications where the class distribution may change over time or is unknown.\n- The authors' methodology is well-motivated and well-designed, and I appreciate how they have clearly presented the key components of their model.\n- The authors have provided a thorough analysis of their results, both quantitative and qualitative.\n- The paper is a relatively short and dense, with little background context for those outside the field.\n- Additionally, some of the notation and mathematical derivations could benefit from clarification for non-experts.\n- The paper provides a detailed analysis of the impact of the number of training samples on the performance of a machine learning model.\n- The results are clear and the authors have presented a convincing argument for the relevance of this problem.\n- However, the paper is limited in its scope, as it only considers a specific type of machine learning models and does not provide insights into the general applicability of the findings.\n- I appreciate the effort put into providing a comprehensive overview of the existing methods for solving a specific problem.\n- The authors have done an excellent job of explaining the background and motivation for this research.\n- However, the paper could benefit from a deeper analysis of the strengths and weaknesses of each method, and how they compare to each other.",
    "review_points_list": [
      "The paper is well written and the motivation for the presented theoretical work is well justified.",
      "Notation, definitions and assumptions are clearly stated.",
      "The contributions of the proposed theoretical results have important implications for the analysis, understanding and identifiability of structural causal models",
      "The practical implications beyond of the analytical tools in Algorithms 1 and 2 remain to be seen.",
      "There are few typos beyond those presented in Section F of the SM",
      "The paper will benefit from careful proofreading",
      "The paper discusses a novel algorithm, Cluster-Margin, for active learning, which can be applied to both large and small batch sizes.",
      "It also discusses the theoretical guarantees of the proposed algorithm under certain assumptions.",
      "The authors have conducted experiments to compare the performance of their algorithm with those of existing similar methods such as CoreSet and BADGE.",
      "The performance of the proposed algorithm is compared with that of existing methods using various metrics.",
      "The paper also discusses the limitations of the proposed algorithm.",
      "The authors have made a significant contribution to the field of active learning with their novel algorithm, Cluster-Margin.",
      "The paper presents an empirical evaluation of the algorithm and its comparison with existing methods.",
      "However, the theoretical analysis of the algorithm is limited to very specific settings and does not provide a complete understanding of the algorithm's behavior.",
      "The authors' experimental results demonstrate the effectiveness of the Cluster-Margin algorithm, particularly in large-batch-size settings.",
      "However, a more detailed analysis of the algorithm's performance in small-batch-size settings would be helpful.",
      "The paper presents a new approach to solving the multi-class problem.",
      "The main idea is to use the k-nearest neighbors method to find the most representative samples for each class.",
      "It is shown that this approach outperforms the traditional methods in terms of both accuracy and computational efficiency.",
      "In contrast to previous methods, this approach does not require a priori knowledge of the class distribution.",
      "This is particularly useful in real-world applications where the class distribution may change over time or is unknown.",
      "The authors' methodology is well-motivated and well-designed, and I appreciate how they have clearly presented the key components of their model.",
      "The authors have provided a thorough analysis of their results, both quantitative and qualitative.",
      "The paper is a relatively short and dense, with little background context for those outside the field.",
      "Additionally, some of the notation and mathematical derivations could benefit from clarification for non-experts.",
      "The paper provides a detailed analysis of the impact of the number of training samples on the performance of a machine learning model.",
      "The results are clear and the authors have presented a convincing argument for the relevance of this problem.",
      "However, the paper is limited in its scope, as it only considers a specific type of machine learning models and does not provide insights into the general applicability of the findings.",
      "I appreciate the effort put into providing a comprehensive overview of the existing methods for solving a specific problem.",
      "The authors have done an excellent job of explaining the background and motivation for this research.",
      "However, the paper could benefit from a deeper analysis of the strengths and weaknesses of each method, and how they compare to each other."
    ]
  },
  {
    "paper_id": "2107.03190v2",
    "submission_id": "z3tlL2MeTK2",
    "submission_title": "Nested Counterfactual Identification from Arbitrary Surrogate Experiments",
    "review_id": "1ptj-zc5iyL",
    "input": {
      "title": "Nested Counterfactual Identification from Arbitrary Surrogate Experiments",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is very difficult to follow, as written.\n- The paper would definitely benefit from worked examples of the operation of the algorithms, and at least an outline of the proof strategy for soundness and completeness.\n- The proofs are very difficult to follow otherwise.\n- It appears to generalize results in [10].\n- The paper completely fails to mention ('Complete Identification Methods for the Causal Hierarchy', Shpitser and Pearl, 2008),\n- Many of the concepts the authors introduce, e.g. counterfactual factors, eliminating redundancy, and detecting inconsistency of events, and the problem of identifying a joint probabilities of counterfactual events and conditional probabilities of counterfactual events (at the third level of the ladder of causation) in terms of interventions distributions (at the second level) first appeared in the above reference.\n- Specifically, identification of counterfactual joints and conditionals is given by the ID* and IDC* algorithms, respectively.\n- In addition, the above reference gives a graphical view of the problem based on counterfactual graphs (a generalization of Balke and Pearl's twin network graphs) that shed light on many concepts the authors use that are typically graphical (e.g. ancestors of counterfactuals -- in what graph?, counterfactual factors -- corresponding to districts in what graph?, ancestral set factorization -- with respect to what graph?) but appear not to be in the authors' paper.\n- Given that the omitted paper deals with exactly the same problem, the omission is quite disappointing, and leads to serious worries regarding novelty, and the true relationship of the authors' work to prior work.\n- Are the authors' algorithms effectively the same as ID* or IDC*?  Did these algorithm 'miss something' that the authors caught?\n- Theorem 1: this appears to be definition of notation, rather than a theorem.\n- In other words, the semantics the authors use give the definition of the joint distribution over counterfactuals using the structural model (via equation (1)), while Theorem 1 is a definition of the 'capital letters in the subscript' notation, which is otherwise undefined via (1).\n- Further, there are also result on the identification of path-specific effects, which correspond to counterfactuals that isolate specific paths in the graph.\n- In particular, [1] provides a complete algorithm for identification from observational data.\n- Unlike other results the authors cite, [1] appears to only apply to fully observed models.\n- The extensions to hidden variable models appear in ('Identification of Personalized Effects Associated With Causal Pathways' Shpitser and Sherman, 2018).\n- the composition axiom [13, 7.3.1]\n- To most readers, this is probably known as consistency.\n- It might be worth pointing this out to improve readability.",
    "review_points_list": [
      "The paper is very difficult to follow, as written.",
      "The paper would definitely benefit from worked examples of the operation of the algorithms, and at least an outline of the proof strategy for soundness and completeness.",
      "The proofs are very difficult to follow otherwise.",
      "It appears to generalize results in [10].",
      "The paper completely fails to mention ('Complete Identification Methods for the Causal Hierarchy', Shpitser and Pearl, 2008),",
      "Many of the concepts the authors introduce, e.g. counterfactual factors, eliminating redundancy, and detecting inconsistency of events, and the problem of identifying a joint probabilities of counterfactual events and conditional probabilities of counterfactual events (at the third level of the ladder of causation) in terms of interventions distributions (at the second level) first appeared in the above reference.",
      "Specifically, identification of counterfactual joints and conditionals is given by the ID* and IDC* algorithms, respectively.",
      "In addition, the above reference gives a graphical view of the problem based on counterfactual graphs (a generalization of Balke and Pearl's twin network graphs) that shed light on many concepts the authors use that are typically graphical (e.g. ancestors of counterfactuals -- in what graph?, counterfactual factors -- corresponding to districts in what graph?, ancestral set factorization -- with respect to what graph?) but appear not to be in the authors' paper.",
      "Given that the omitted paper deals with exactly the same problem, the omission is quite disappointing, and leads to serious worries regarding novelty, and the true relationship of the authors' work to prior work.",
      "Are the authors' algorithms effectively the same as ID* or IDC*?  Did these algorithm 'miss something' that the authors caught?",
      "Theorem 1: this appears to be definition of notation, rather than a theorem.",
      "In other words, the semantics the authors use give the definition of the joint distribution over counterfactuals using the structural model (via equation (1)), while Theorem 1 is a definition of the 'capital letters in the subscript' notation, which is otherwise undefined via (1).",
      "Further, there are also result on the identification of path-specific effects, which correspond to counterfactuals that isolate specific paths in the graph.",
      "In particular, [1] provides a complete algorithm for identification from observational data.",
      "Unlike other results the authors cite, [1] appears to only apply to fully observed models.",
      "The extensions to hidden variable models appear in ('Identification of Personalized Effects Associated With Causal Pathways' Shpitser and Sherman, 2018).",
      "the composition axiom [13, 7.3.1]",
      "To most readers, this is probably known as consistency.",
      "It might be worth pointing this out to improve readability."
    ]
  },
  {
    "paper_id": "2107.03190v2",
    "submission_id": "z3tlL2MeTK2",
    "submission_title": "Nested Counterfactual Identification from Arbitrary Surrogate Experiments",
    "review_id": "MnE4ImnHvHg",
    "input": {
      "title": "Nested Counterfactual Identification from Arbitrary Surrogate Experiments",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This is a potentially strong paper but I would not like to see it published in the current form because I see that the presentation could be improved in many ways.\n- I am afraid that publishing the paper in the current form would create confusion. On the other hand, I think it is relatively easy to fix the paper and resubmit.\n- The authors do not explain how their proposal differs from the current state-of-the-art.\n- For years I have believed that the algorithm published by Shpitser & Pearl (2007,2008) completely solves the counterfactual identification problem.\n- The manuscript implicitly indicates that this is not the case but do not present the novel contribution in clear and direct way.\n- It is should not be readers' task to find the subtle differences between the proposed algorithm and the algorithm published by Shpitser & Pearl.\n- I would like to see the differences explicitly stated and demonstrated in an identification problem that is solvable with the proposed algorithm but not with the existing algorithms.\n- The area chair has expressed a concern that a query could be identifiable from marginalization of some other form than the one considered (e.g. the last line of Algorithm 1).\n- I share this concern because I cannot see an immediate reason why some other marginalization could not be used.\n- The notation gets really heavy in some places like in line 9 of Algorithm 1.\n- I traced algorithm 2 in Fig. 5(a) and obtained the same result as in equation (23).\n- I ran a simulation to check the result numerically.\n- So I can confirm that the algorithm works correctly in this example.\n- Proofs are of course needed but these kind demonstrations could serve the average reader who does not have the perseverance to study the proofs in detail.",
    "review_points_list": [
      "This is a potentially strong paper but I would not like to see it published in the current form because I see that the presentation could be improved in many ways.",
      "I am afraid that publishing the paper in the current form would create confusion. On the other hand, I think it is relatively easy to fix the paper and resubmit.",
      "The authors do not explain how their proposal differs from the current state-of-the-art.",
      "For years I have believed that the algorithm published by Shpitser & Pearl (2007,2008) completely solves the counterfactual identification problem.",
      "The manuscript implicitly indicates that this is not the case but do not present the novel contribution in clear and direct way.",
      "It is should not be readers' task to find the subtle differences between the proposed algorithm and the algorithm published by Shpitser & Pearl.",
      "I would like to see the differences explicitly stated and demonstrated in an identification problem that is solvable with the proposed algorithm but not with the existing algorithms.",
      "The area chair has expressed a concern that a query could be identifiable from marginalization of some other form than the one considered (e.g. the last line of Algorithm 1).",
      "I share this concern because I cannot see an immediate reason why some other marginalization could not be used.",
      "The notation gets really heavy in some places like in line 9 of Algorithm 1.",
      "I traced algorithm 2 in Fig. 5(a) and obtained the same result as in equation (23).",
      "I ran a simulation to check the result numerically.",
      "So I can confirm that the algorithm works correctly in this example.",
      "Proofs are of course needed but these kind demonstrations could serve the average reader who does not have the perseverance to study the proofs in detail."
    ]
  },
  {
    "paper_id": "2105.14039v3",
    "submission_id": "wfiVgITyCC_",
    "submission_title": "Towards mental time travel: a hierarchical memory for reinforcement learning agents",
    "review_id": "bf_9TRW2Eqc",
    "input": {
      "title": "Towards mental time travel: a hierarchical memory for reinforcement learning agents",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The main strength of the paper is the sheer number of different environments that were used to benchmark the method.\n- It really is impressive and shows that the method can potentially handle different scenarios.\n- Taking it a step further and comparing the architecture to state-of-the-art results in other domains is also a big plus.\n- The approach is fairly intuitive - attending over chunks instead of over individual states makes intuitive sense.\n- Many ablations are provided in the appendix.\n- Tuning the chunk size for each environment feels a little hacky.\n- As mentioned by the authors \u2013 learning the chunk size would be an interesting avenue of future work.\n- From scanning the appendix \u2013 Figure 10 shows that the self-supervised loss seems to be crucial to obtain decent performance in the Ballet and Rapid word learning tasks.\n- The model performs close to chance without it.\n- I don\u2019t think this is emphasized nearly enough in the main text.\n- The method doesn\u2019t work without it\u2026\n- I find it hard to believe that the transformer XL performs so poorly on some of the simpler tasks.\n- I can\u2019t help but wonder if the baseline was properly tuned for these tasks.\n- I scanned the appendix, and it seems like the same sweep over hyper parameters was performed for the main method as well as the baselines but I wonder if something as simple as tuning the learning rate for the baseline (which to my understanding was not done) could have improved its performance.\n- For the most part the paper is well written and easy to follow.\n- I think the paper could have benefited from a background section where Transformers and RL could have been introduced.\n- As is, without any background, section 2 feels very dense.\n- In particular, lines 95-109 are extremely dense and should be handled with more care.\n- I also think that Figure 11 from the appendix should somehow make its way into figure 5 of the main paper.\n- It really feels strange to just show that the baselines are failing when in reality they do learn properly on the training task.\n- The relation to prior work is handled nicely in the discussion section.\n- UPDATE: Thanks for the replies to my questions. I leave my score as it stands.",
    "review_points_list": [
      "The main strength of the paper is the sheer number of different environments that were used to benchmark the method.",
      "It really is impressive and shows that the method can potentially handle different scenarios.",
      "Taking it a step further and comparing the architecture to state-of-the-art results in other domains is also a big plus.",
      "The approach is fairly intuitive - attending over chunks instead of over individual states makes intuitive sense.",
      "Many ablations are provided in the appendix.",
      "Tuning the chunk size for each environment feels a little hacky.",
      "As mentioned by the authors \u2013 learning the chunk size would be an interesting avenue of future work.",
      "From scanning the appendix \u2013 Figure 10 shows that the self-supervised loss seems to be crucial to obtain decent performance in the Ballet and Rapid word learning tasks.",
      "The model performs close to chance without it.",
      "I don\u2019t think this is emphasized nearly enough in the main text.",
      "The method doesn\u2019t work without it\u2026",
      "I find it hard to believe that the transformer XL performs so poorly on some of the simpler tasks.",
      "I can\u2019t help but wonder if the baseline was properly tuned for these tasks.",
      "I scanned the appendix, and it seems like the same sweep over hyper parameters was performed for the main method as well as the baselines but I wonder if something as simple as tuning the learning rate for the baseline (which to my understanding was not done) could have improved its performance.",
      "For the most part the paper is well written and easy to follow.",
      "I think the paper could have benefited from a background section where Transformers and RL could have been introduced.",
      "As is, without any background, section 2 feels very dense.",
      "In particular, lines 95-109 are extremely dense and should be handled with more care.",
      "I also think that Figure 11 from the appendix should somehow make its way into figure 5 of the main paper.",
      "It really feels strange to just show that the baselines are failing when in reality they do learn properly on the training task.",
      "The relation to prior work is handled nicely in the discussion section.",
      "UPDATE: Thanks for the replies to my questions. I leave my score as it stands."
    ]
  },
  {
    "paper_id": "2105.14039v3",
    "submission_id": "wfiVgITyCC_",
    "submission_title": "Towards mental time travel: a hierarchical memory for reinforcement learning agents",
    "review_id": "ToxqkQVsFr",
    "input": {
      "title": "Towards mental time travel: a hierarchical memory for reinforcement learning agents",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- At the high-level, the idea of storing memories in a tree structure may not be mind-blowing. It\u2019s still important to show that it can work in practice. And the range of tasks tested is rather impressive.\n- The quality of the work is high. The network architecture is intuitive and well-motivated. The empirical results are thorough and convincing.\n- The paper is clearly written.\n- This work provides a solid and significant improvement in the use of memory network for RL agents.",
    "review_points_list": [
      "At the high-level, the idea of storing memories in a tree structure may not be mind-blowing. It\u2019s still important to show that it can work in practice. And the range of tasks tested is rather impressive.",
      "The quality of the work is high. The network architecture is intuitive and well-motivated. The empirical results are thorough and convincing.",
      "The paper is clearly written.",
      "This work provides a solid and significant improvement in the use of memory network for RL agents."
    ]
  },
  {
    "paper_id": "2105.14039v3",
    "submission_id": "wfiVgITyCC_",
    "submission_title": "Towards mental time travel: a hierarchical memory for reinforcement learning agents",
    "review_id": "LXxBkakzVvQ",
    "input": {
      "title": "Towards mental time travel: a hierarchical memory for reinforcement learning agents",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed architecture is novel.\n- The acronym HTM is too easily confused with the HTM network (Hierarchical Temporal Memory) introduced by Jeff Hawkins in 2004, and still in development today.\n- The paper's central claim is that HTM's history-chunking mechanism improves its ability to retrieve information as needed.\n- HTM outperforms TrXL on four of six RL domains, but no TrXL results are reported for the other two tasks (Passive Visual Match and Paired Associative Inference).\n- HTM performs on par with SOTA models on those two tasks.\n- The case for HTM is undermined by the scarcity of hyperparameter tuning as reported.\n- Reliable experimental practice generally requires that hyperparameters for baseline models be tuned with as much care as those of the new model.\n- Four of those HPs pertain only to HTM, one pertains only to TrXL, and the other 23 apply to both models.\n- The paper discusses the tuning of only 6 HPs (in Table 2 and Appendix D.3).\n- How were the values of the other 22 HPs obtained?\n- Most of them vary by task, and so were presumably found through limited testing of HTM on short runs instead of full sweeps.\n- In no case are separate values reported, one for HTM and one for TrXL.\n- Since TrXL is essentially an ablation of HTM, one would be tempted to tune many or most of the shared HPs on HTM, then apply the best HP configuration to TrXL as well.\n- All of the reported experiments were run for billions of training steps, demonstrating that sufficient compute was available to tune HPs for HTM and TrXL independently, if only on shorter runs.\n- In the absence of separate tuning, it\u2019s hard to assess the benefit of history chunking.\n- In general, the paper is very clear and well-written.\n- Contrary to the answer on checklist item 3.b, section A.1 does not explain how most hyperparameters were chosen.\n- In Figures 3.a and 3.b, why does the HTM curve start at 100%?\n- In Figure 5, how could the LSTM do worse than random chance?\n- As noted in \u201cLimitations & future directions\u201d, HTM requires the permanent storage of data from each step.\n- The severity of this limitation strikes me as fundamental, and I don\u2019t expect the potential workarounds to make it a practical approach for most applications of interest in the future.\n- But this is a personal view, and I could be wrong.\n- The open questions regarding the choices of hyperparameters lead me to doubt the attribution of HTM\u2019s performance gains to its chunking mechanism.\n- If I have overlooked or misunderstood something, I look forward to being corrected.\n- I commend the authors for their helpful responses.\n- They have clarified several issues related to hyperparameters, and have performed supplementary hyperparameter sweeps that improve the work.\n- Regarding the prior use of the term HTM, I find no problem with any of the suggested alternatives.\n- HCAM seems the clearest to my mind.\n- I recommend replacing \u2018chance level performance\u2019 with a clearer term, as it can too easily be interpreted to mean the performance of a trivial agent that simply takes random actions.\n- I have raised my score by one point.",
    "review_points_list": [
      "The proposed architecture is novel.",
      "The acronym HTM is too easily confused with the HTM network (Hierarchical Temporal Memory) introduced by Jeff Hawkins in 2004, and still in development today.",
      "The paper's central claim is that HTM's history-chunking mechanism improves its ability to retrieve information as needed.",
      "HTM outperforms TrXL on four of six RL domains, but no TrXL results are reported for the other two tasks (Passive Visual Match and Paired Associative Inference).",
      "HTM performs on par with SOTA models on those two tasks.",
      "The case for HTM is undermined by the scarcity of hyperparameter tuning as reported.",
      "Reliable experimental practice generally requires that hyperparameters for baseline models be tuned with as much care as those of the new model.",
      "Four of those HPs pertain only to HTM, one pertains only to TrXL, and the other 23 apply to both models.",
      "The paper discusses the tuning of only 6 HPs (in Table 2 and Appendix D.3).",
      "How were the values of the other 22 HPs obtained?",
      "Most of them vary by task, and so were presumably found through limited testing of HTM on short runs instead of full sweeps.",
      "In no case are separate values reported, one for HTM and one for TrXL.",
      "Since TrXL is essentially an ablation of HTM, one would be tempted to tune many or most of the shared HPs on HTM, then apply the best HP configuration to TrXL as well.",
      "All of the reported experiments were run for billions of training steps, demonstrating that sufficient compute was available to tune HPs for HTM and TrXL independently, if only on shorter runs.",
      "In the absence of separate tuning, it\u2019s hard to assess the benefit of history chunking.",
      "In general, the paper is very clear and well-written.",
      "Contrary to the answer on checklist item 3.b, section A.1 does not explain how most hyperparameters were chosen.",
      "In Figures 3.a and 3.b, why does the HTM curve start at 100%?",
      "In Figure 5, how could the LSTM do worse than random chance?",
      "As noted in \u201cLimitations & future directions\u201d, HTM requires the permanent storage of data from each step.",
      "The severity of this limitation strikes me as fundamental, and I don\u2019t expect the potential workarounds to make it a practical approach for most applications of interest in the future.",
      "But this is a personal view, and I could be wrong.",
      "The open questions regarding the choices of hyperparameters lead me to doubt the attribution of HTM\u2019s performance gains to its chunking mechanism.",
      "If I have overlooked or misunderstood something, I look forward to being corrected.",
      "I commend the authors for their helpful responses.",
      "They have clarified several issues related to hyperparameters, and have performed supplementary hyperparameter sweeps that improve the work.",
      "Regarding the prior use of the term HTM, I find no problem with any of the suggested alternatives.",
      "HCAM seems the clearest to my mind.",
      "I recommend replacing \u2018chance level performance\u2019 with a clearer term, as it can too easily be interpreted to mean the performance of a trivial agent that simply takes random actions.",
      "I have raised my score by one point."
    ]
  },
  {
    "paper_id": "2110.13100v1",
    "submission_id": "vqHak8NLk25",
    "submission_title": "Parameter Prediction for Unseen Deep Architectures",
    "review_id": "repBJtrMeVX",
    "input": {
      "title": "Parameter Prediction for Unseen Deep Architectures",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper analyzes the interesting task of directly predicting trained parameters for diverse feed-forward networks.\n- It has been done previously in many NAS works for the purposes for creating performance predictors as well works on targeting a specific class of networks.\n- There is significant novelty in the scope of diverse network architectures that their method can predict reasonable weights for and this may be the first which does a focused analysis on accuracy performance of these predicted weights.\n- The analysis of results on in distribution and out of distribution architectures is quite novel.\n- Unfortunately, the practical use cases of using these weights to generate good initializations for fine tuning seems to currently significantly degrade performance.\n- That in itself is still an interesting finding to invite further analysis.\n- The paper provides thorough analysis of their methods against the baseline of training from scratch for a very diverse set of architectures.\n- The work also proposed three main improvements to improve performance: normalization of predicted parameters, enhanced long-range interactions in the GHN, and meta-batching of architectures.\n- They provide thorough experiments ablating the effect of these changes.\n- Some of the results could benefit from further analysis, such as the observation that CIFAR-10 trained networks seem to generalize significantly better to Resnet than the Imagenet-trained networks.\n- I believe that this paper's main weakness is that it would be very useful to be able to compare the performance of the GHN with some stronger competitors.\n- There has been significant NAS work on training supernets, which would provide a strong baseline to examine performance when directly deriving networks from those subnetworks.\n- This paper would greatly benefit from significant analysis of the weights that are generated.\n- How sparse are the weights generated? Is there a correlation between more weights or less weights and model accuracy?\n- For deep networks for example is it generating a few layers and a bunch of identity or skip layers? It would be interesting to visualize the activations.\n- It is also a bit difficult to judge the usability of this work since it lacks discussion of the training cost of the graph hypernetwork.",
    "review_points_list": [
      "This paper analyzes the interesting task of directly predicting trained parameters for diverse feed-forward networks.",
      "It has been done previously in many NAS works for the purposes for creating performance predictors as well works on targeting a specific class of networks.",
      "There is significant novelty in the scope of diverse network architectures that their method can predict reasonable weights for and this may be the first which does a focused analysis on accuracy performance of these predicted weights.",
      "The analysis of results on in distribution and out of distribution architectures is quite novel.",
      "Unfortunately, the practical use cases of using these weights to generate good initializations for fine tuning seems to currently significantly degrade performance.",
      "That in itself is still an interesting finding to invite further analysis.",
      "The paper provides thorough analysis of their methods against the baseline of training from scratch for a very diverse set of architectures.",
      "The work also proposed three main improvements to improve performance: normalization of predicted parameters, enhanced long-range interactions in the GHN, and meta-batching of architectures.",
      "They provide thorough experiments ablating the effect of these changes.",
      "Some of the results could benefit from further analysis, such as the observation that CIFAR-10 trained networks seem to generalize significantly better to Resnet than the Imagenet-trained networks.",
      "I believe that this paper's main weakness is that it would be very useful to be able to compare the performance of the GHN with some stronger competitors.",
      "There has been significant NAS work on training supernets, which would provide a strong baseline to examine performance when directly deriving networks from those subnetworks.",
      "This paper would greatly benefit from significant analysis of the weights that are generated.",
      "How sparse are the weights generated? Is there a correlation between more weights or less weights and model accuracy?",
      "For deep networks for example is it generating a few layers and a bunch of identity or skip layers? It would be interesting to visualize the activations.",
      "It is also a bit difficult to judge the usability of this work since it lacks discussion of the training cost of the graph hypernetwork."
    ]
  },
  {
    "paper_id": "2110.13100v1",
    "submission_id": "vqHak8NLk25",
    "submission_title": "Parameter Prediction for Unseen Deep Architectures",
    "review_id": "kBWZw-uneL",
    "input": {
      "title": "Parameter Prediction for Unseen Deep Architectures",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper proposes a way to predict/generate the parameters of an image based deep network instead of training it via SGD.\n- The idea is novel and very thought provoking and different than standard way of approaching learning.\n- The ability to accelerate learning is a great thing to do, given the time it takes to train large models.\n- The paper is well written and clear.\n- The authors have also shown the limitations of this approach which provides good context and discussion.\n- The results don't surpass He-initialization with finetuning, which would've be nice and strong suggestions in favor of this approach.\n- The authors suggested that it was 'natural' to be able to predict parameters from architecture. I think this isn't quite clear and it would be good for the author to outline more benefits to predicting the parameters.\n- Given that the weights are good but not near SoTA, it's naturally to ask why predict the parameters?\n- The proposed method predicts parameters given architecture. How does this fit in with NAS?\n- How sensitive are the changes of the parameters to network architecture (of the same parameter dimension), is it possible that the good weights are 'stored' in the GHN?\n- Overall, I think the paper is well written and novel and interesting, even though the results are not SoTA.\n- The authors are advised to address the comments above for the next version of the paper.",
    "review_points_list": [
      "This paper proposes a way to predict/generate the parameters of an image based deep network instead of training it via SGD.",
      "The idea is novel and very thought provoking and different than standard way of approaching learning.",
      "The ability to accelerate learning is a great thing to do, given the time it takes to train large models.",
      "The paper is well written and clear.",
      "The authors have also shown the limitations of this approach which provides good context and discussion.",
      "The results don't surpass He-initialization with finetuning, which would've be nice and strong suggestions in favor of this approach.",
      "The authors suggested that it was 'natural' to be able to predict parameters from architecture. I think this isn't quite clear and it would be good for the author to outline more benefits to predicting the parameters.",
      "Given that the weights are good but not near SoTA, it's naturally to ask why predict the parameters?",
      "The proposed method predicts parameters given architecture. How does this fit in with NAS?",
      "How sensitive are the changes of the parameters to network architecture (of the same parameter dimension), is it possible that the good weights are 'stored' in the GHN?",
      "Overall, I think the paper is well written and novel and interesting, even though the results are not SoTA.",
      "The authors are advised to address the comments above for the next version of the paper."
    ]
  },
  {
    "paper_id": "2110.13100v1",
    "submission_id": "vqHak8NLk25",
    "submission_title": "Parameter Prediction for Unseen Deep Architectures",
    "review_id": "Aeq4qJ0cmv4",
    "input": {
      "title": "Parameter Prediction for Unseen Deep Architectures",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The three components proposed by this paper significantly improve the original GHN performance.\n- The authors also provide rich ablation studies to show the effectiveness of their modifications.\n- The authors extend the network design space to include a lot of different ops.\n- The proposed GHN-2 shows good generalization ability on OOD architectures.\n- The neural architecture representation learned by GHN seems to be more powerful than previous works.",
    "review_points_list": [
      "The three components proposed by this paper significantly improve the original GHN performance.",
      "The authors also provide rich ablation studies to show the effectiveness of their modifications.",
      "The authors extend the network design space to include a lot of different ops.",
      "The proposed GHN-2 shows good generalization ability on OOD architectures.",
      "The neural architecture representation learned by GHN seems to be more powerful than previous works."
    ]
  },
  {
    "paper_id": "2110.13100v1",
    "submission_id": "vqHak8NLk25",
    "submission_title": "Parameter Prediction for Unseen Deep Architectures",
    "review_id": "inYtvK7T6vi",
    "input": {
      "title": "Parameter Prediction for Unseen Deep Architectures",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The task of predicting the parameter of diverse architectures with a single hyper-network is novel and important.\n- Though iterative optimization is the mainstream for learning deep networks, it should be encouraged to explore different directions.\n- The method is based on the existing work Graph-hypernetworks, while there are three key elements introduced to gain superior improvement.\n- The modification is certainly well motivated which also provides impressive empirical performance.\n- The evaluation part of this paper is strict and extensive.\n- I appreciate the efforts in providing the benchmarks for evaluating the generalization ability of the different methods which will certainly benefit the research in this area.\n- The ablation study on different components is detailed and clear which makes the results convincing.\n- One appealing property of the proposed method is the decreased computation burden.\n- To this end, I suggest the authors provide some statistics about the learning procedure of the Graph-hypernetworks.\n- The experiments is conducted mainly in the image classification settings.\n- I wonder whether the proposed method could apply to different data type, such as language and graph, or different architectures such as transformers.",
    "review_points_list": [
      "The task of predicting the parameter of diverse architectures with a single hyper-network is novel and important.",
      "Though iterative optimization is the mainstream for learning deep networks, it should be encouraged to explore different directions.",
      "The method is based on the existing work Graph-hypernetworks, while there are three key elements introduced to gain superior improvement.",
      "The modification is certainly well motivated which also provides impressive empirical performance.",
      "The evaluation part of this paper is strict and extensive.",
      "I appreciate the efforts in providing the benchmarks for evaluating the generalization ability of the different methods which will certainly benefit the research in this area.",
      "The ablation study on different components is detailed and clear which makes the results convincing.",
      "One appealing property of the proposed method is the decreased computation burden.",
      "To this end, I suggest the authors provide some statistics about the learning procedure of the Graph-hypernetworks.",
      "The experiments is conducted mainly in the image classification settings.",
      "I wonder whether the proposed method could apply to different data type, such as language and graph, or different architectures such as transformers."
    ]
  },
  {
    "paper_id": "2106.09524v3",
    "submission_id": "vvi7KqHQiA",
    "submission_title": "Implicit Bias of SGD for Diagonal Linear Networks: a Provable Benefit of Stochasticity",
    "review_id": "Co5wObEugJv",
    "input": {
      "title": "Implicit Bias of SGD for Diagonal Linear Networks: a Provable Benefit of Stochasticity",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Please paste the Review here. Type your review here. I will assist you in splitting it into individual review points.\n- Please paste the Review you want to split into individual review points.\n- Please paste the Review you want to split into individual review points.",
    "review_points_list": [
      "Please paste the Review here. Type your review here. I will assist you in splitting it into individual review points.",
      "Please paste the Review you want to split into individual review points.",
      "Please paste the Review you want to split into individual review points."
    ]
  },
  {
    "paper_id": "2106.09524v3",
    "submission_id": "vvi7KqHQiA",
    "submission_title": "Implicit Bias of SGD for Diagonal Linear Networks: a Provable Benefit of Stochasticity",
    "review_id": "kMSDRc_iVQY",
    "input": {
      "title": "Implicit Bias of SGD for Diagonal Linear Networks: a Provable Benefit of Stochasticity",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The key qualitative assumption discussed in this paper is 'the effect of the implicit bias is controlled by the convergence speed of the loss: the slower it converges, the sparser the selected solution will be.' As far as I am aware, this is a very novel statement and quite significant (even if only made for a constrained class of models).\n- Overall, this work was very well done, however I think more emphasis could have been on experiments (such as some of the suggestions I give below) and discussing the qualitative takeaways that might apply to the general class of nonlinear networks.\n- I agree with the authors, the most interesting direction for future work would be 'whether the integral of the loss also controls the difference of implicit regularisation for more general architectures.' A longer discussion at the end on the connections of this analysis to nonlinear networks (where the benefits of SGD really shine compared to GD) would be very helpful.\n- The writing and mathematics in this paper are incredibly clear and well done. I found the flow very natural and the discussion of related work very helpful for grounding their analysis.\n- The experiments were well documented and explained.\n- Throughout the work (such as in abstract) you say 'better the bias', but its not clear what 'better' means. Is there another description that might be more specific you can use as your tag line? Such as 'sparse'?\n- This analysis is done assuming a batch size of 1? Can this be extended to mini-batches? A discussion about this assumption/limitation should be given.\n- In the buildup to the SDEs you never explicitly assume the noise term is Gaussian, as done in many of the 'SDE for SGD' papers. Yet implicitly it seems like you are, as the Euler-Maruyama discretization of equation (3) would lead to gaussian noise with the same covariance as your noise term. I think its worth having a discussion about this, as the Gaussian assumption has been one of the major sources for complaint on the 'SDE for SGD' literature?\n- The statement on line 206/207 'the recovered solution minimizes the same potential as for gradient flow but with an effective parameter which is strictly smaller' makes me want to see an experiment where you run SGD with $\beta$ and compute $\beta_\text{inf}$ from trajectory then run GD with $\beta_\text{inf}$ and compare overall optimization time and final solution. An experiment like this would definitely help convince me of the statement 'However it is clear experimentally that SGD systematically largely wins the trade-off over GD'.\n- All your experiments used features generated from an isotropic gaussian. I would have been very curious to see how dynamics change with features from an anisotropic gaussian. Intuitively, I would assume that anisotropy would have a large effect on the SGD dynamics...and maybe even the final solution reached.\n- The section 'Doping the implicit bias with label noise' is interesting. I would devote more space to this discussion in revision and pull experiments up from appendix.\n- Consider citing the recent work 'ON THE ORIGIN OF IMPLICIT REGULARIZATION IN STOCHASTIC GRADIENT DESCENT'\n- Consider replacing [line 105-106] 'All inequalities between vectors should be understood value by value' with 'All inequalities between vectors should be understood element-wise'\n- In the section 'Implicit bias and hyperbolic entropy' the analysis in [32] you are referencing is for the same quadratic parametrization correct? If so, can you make this clear?",
    "review_points_list": [
      "The key qualitative assumption discussed in this paper is 'the effect of the implicit bias is controlled by the convergence speed of the loss: the slower it converges, the sparser the selected solution will be.' As far as I am aware, this is a very novel statement and quite significant (even if only made for a constrained class of models).",
      "Overall, this work was very well done, however I think more emphasis could have been on experiments (such as some of the suggestions I give below) and discussing the qualitative takeaways that might apply to the general class of nonlinear networks.",
      "I agree with the authors, the most interesting direction for future work would be 'whether the integral of the loss also controls the difference of implicit regularisation for more general architectures.' A longer discussion at the end on the connections of this analysis to nonlinear networks (where the benefits of SGD really shine compared to GD) would be very helpful.",
      "The writing and mathematics in this paper are incredibly clear and well done. I found the flow very natural and the discussion of related work very helpful for grounding their analysis.",
      "The experiments were well documented and explained.",
      "Throughout the work (such as in abstract) you say 'better the bias', but its not clear what 'better' means. Is there another description that might be more specific you can use as your tag line? Such as 'sparse'?",
      "This analysis is done assuming a batch size of 1? Can this be extended to mini-batches? A discussion about this assumption/limitation should be given.",
      "In the buildup to the SDEs you never explicitly assume the noise term is Gaussian, as done in many of the 'SDE for SGD' papers. Yet implicitly it seems like you are, as the Euler-Maruyama discretization of equation (3) would lead to gaussian noise with the same covariance as your noise term. I think its worth having a discussion about this, as the Gaussian assumption has been one of the major sources for complaint on the 'SDE for SGD' literature?",
      "The statement on line 206/207 'the recovered solution minimizes the same potential as for gradient flow but with an effective parameter which is strictly smaller' makes me want to see an experiment where you run SGD with $\beta$ and compute $\beta_\text{inf}$ from trajectory then run GD with $\beta_\text{inf}$ and compare overall optimization time and final solution. An experiment like this would definitely help convince me of the statement 'However it is clear experimentally that SGD systematically largely wins the trade-off over GD'.",
      "All your experiments used features generated from an isotropic gaussian. I would have been very curious to see how dynamics change with features from an anisotropic gaussian. Intuitively, I would assume that anisotropy would have a large effect on the SGD dynamics...and maybe even the final solution reached.",
      "The section 'Doping the implicit bias with label noise' is interesting. I would devote more space to this discussion in revision and pull experiments up from appendix.",
      "Consider citing the recent work 'ON THE ORIGIN OF IMPLICIT REGULARIZATION IN STOCHASTIC GRADIENT DESCENT'",
      "Consider replacing [line 105-106] 'All inequalities between vectors should be understood value by value' with 'All inequalities between vectors should be understood element-wise'",
      "In the section 'Implicit bias and hyperbolic entropy' the analysis in [32] you are referencing is for the same quadratic parametrization correct? If so, can you make this clear?"
    ]
  },
  {
    "paper_id": "2106.00719v2",
    "submission_id": "ykN3tbJ0qmX",
    "submission_title": "Collapsed Variational Bounds for Bayesian Neural Networks",
    "review_id": "rDB448UR5Ho",
    "input": {
      "title": "Collapsed Variational Bounds for Bayesian Neural Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think the proposed method is interesting and is backed up by extensive experiments.\n- This could be the answer to the difficulty of training VB due to hyperparameter selection.\n- Nevertheless, I think the experiments can be expanded more, esp. regarding uncertainty quantification, OOD detection.\n- Currently, the authors only show MNIST-FMNIST OOD detection with MLP.\n- I think this is inadequate and the authors should use the standard OOD detection suites (MNIST, FMNIST, SVHN, CIFAR10, CIFAR100 in-distributions against 3+ OOD test sets) with a more commonly used network instead (ResNets, Wide-ResNets).\n- With that being said, the major issue with this paper is that it is *not* well-written.\n- There is no paragraph break *at all* in this paper, making it a continuous blob of text.\n- Maybe this due to some \n- LaTex hacks\n- that the authors used to make the text fit the page limit.\n- If this is so, I suggest the authors not use them.\n- All in all, the presentation of this paper needs to be improved significantly and I urge the authors to do so meticulously.\n- Based on the discussion in L.80-84: How does the collapsed bound compare to EM?\n- Use paragraph break and use whitespace judiciously\n- Use display math judiciously, instead of putting long formulas inline\n- Put L.120-123 inside LaTex's algorithm env. Inline, it is very confusing to read\n- Figures are very hard to read. I suggest the author to use tikz\n- L.46: ... *the* ELBO lowers bound ...\n- Fig. 3: Add y-label to the second row\n- Tab. 1: What is 'test ER'? (It's discussed in the next page, but it should be much closer to Tab. 1)\n- Tab. 2, 3: Unclear which one is test-NLL, which one is test-ER.\n- While I like the idea, I still think that it would be beneficial for the paper to be given more careful treatment in its writing and presentation---this will ultimately change the paper substantially and thus, I believe, is more suitable for resubmission.\n- My updated score (weak reject) reflects this ambivalence.",
    "review_points_list": [
      "I think the proposed method is interesting and is backed up by extensive experiments.",
      "This could be the answer to the difficulty of training VB due to hyperparameter selection.",
      "Nevertheless, I think the experiments can be expanded more, esp. regarding uncertainty quantification, OOD detection.",
      "Currently, the authors only show MNIST-FMNIST OOD detection with MLP.",
      "I think this is inadequate and the authors should use the standard OOD detection suites (MNIST, FMNIST, SVHN, CIFAR10, CIFAR100 in-distributions against 3+ OOD test sets) with a more commonly used network instead (ResNets, Wide-ResNets).",
      "With that being said, the major issue with this paper is that it is *not* well-written.",
      "There is no paragraph break *at all* in this paper, making it a continuous blob of text.",
      "Maybe this due to some ",
      "LaTex hacks",
      "that the authors used to make the text fit the page limit.",
      "If this is so, I suggest the authors not use them.",
      "All in all, the presentation of this paper needs to be improved significantly and I urge the authors to do so meticulously.",
      "Based on the discussion in L.80-84: How does the collapsed bound compare to EM?",
      "Use paragraph break and use whitespace judiciously",
      "Use display math judiciously, instead of putting long formulas inline",
      "Put L.120-123 inside LaTex's algorithm env. Inline, it is very confusing to read",
      "Figures are very hard to read. I suggest the author to use tikz",
      "L.46: ... *the* ELBO lowers bound ...",
      "Fig. 3: Add y-label to the second row",
      "Tab. 1: What is 'test ER'? (It's discussed in the next page, but it should be much closer to Tab. 1)",
      "Tab. 2, 3: Unclear which one is test-NLL, which one is test-ER.",
      "While I like the idea, I still think that it would be beneficial for the paper to be given more careful treatment in its writing and presentation---this will ultimately change the paper substantially and thus, I believe, is more suitable for resubmission.",
      "My updated score (weak reject) reflects this ambivalence."
    ]
  },
  {
    "paper_id": "2106.00719v2",
    "submission_id": "ykN3tbJ0qmX",
    "submission_title": "Collapsed Variational Bounds for Bayesian Neural Networks",
    "review_id": "sr-HRdpKVi",
    "input": {
      "title": "Collapsed Variational Bounds for Bayesian Neural Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I found this paper difficult to assign a score to, and I remain quite uncertain.\n- On the one hand, I believe that you have proposed a sensible approach which fixes a moderately important problem.\n- You have also provided extensive experimental support for your hypotheses.\n- On the other hand, I found the paper quite hard to read and somewhat poorly organized.\n- I feel that it would benefit a lot from being redrafted in a way that makes it clearer what its contributions are and how they are being examined.\n- For that reason I am currently recommending borderline rejection, but I could easily be persuaded upwards if other reviewers think particularly highly of the significance of the work.\n- There is a lot of redundancy.\n- The abstract could probably be pruned by a third.\n- Much of the introduction is relatively boiler-plate and does not focus on the specific contribution that *you* are making.\n- I did not quite understand what the role of the 'Preliminaries' section was.\n- Probably you could take a small part of this and place it at the start of what is now S3.\n- Similarly, I would reserve a discussion of over-pruning until the experiments section and make a note in the introduction that your method resolves an over-pruning issue in VI.\n- When I read it I had no idea why this was being mentioned and Figure 1 is somewhat a distraction at this stage.\n- I think some of the details of the derivations in S3 could be moved to an appendix, with more space devoted to an explanation of why you are doing things and what the intuitive purpose is and less on the details.\n- The captions on many figures seem incomplete, with only some subfigures discussed explicitly.\n- The figures are all far too small and difficult to read.\n- I would be inclined to pick your experiments more carefully for the main body so that you can devote more time/space to explaining and interpreting each thoroughly.\n- They feel rushed and crowded.\n- Regarding the introduction: I'm easily persuaded that a tighter bound to the marginal likelihood would be good, so a lot of this background isn't super necessary.\n- I would have liked more of a sketch of what your approach is going to be.\n- Please make your references hyperlinks.\n- Especially when you use a numerical citation style it is almost impossible to figure out what you are citing otherwise.\n- The spacing of the paper is very tight, perhaps some of the style-sheet was accidentally overridden?\n- This makes it much harder to read.",
    "review_points_list": [
      "I found this paper difficult to assign a score to, and I remain quite uncertain.",
      "On the one hand, I believe that you have proposed a sensible approach which fixes a moderately important problem.",
      "You have also provided extensive experimental support for your hypotheses.",
      "On the other hand, I found the paper quite hard to read and somewhat poorly organized.",
      "I feel that it would benefit a lot from being redrafted in a way that makes it clearer what its contributions are and how they are being examined.",
      "For that reason I am currently recommending borderline rejection, but I could easily be persuaded upwards if other reviewers think particularly highly of the significance of the work.",
      "There is a lot of redundancy.",
      "The abstract could probably be pruned by a third.",
      "Much of the introduction is relatively boiler-plate and does not focus on the specific contribution that *you* are making.",
      "I did not quite understand what the role of the 'Preliminaries' section was.",
      "Probably you could take a small part of this and place it at the start of what is now S3.",
      "Similarly, I would reserve a discussion of over-pruning until the experiments section and make a note in the introduction that your method resolves an over-pruning issue in VI.",
      "When I read it I had no idea why this was being mentioned and Figure 1 is somewhat a distraction at this stage.",
      "I think some of the details of the derivations in S3 could be moved to an appendix, with more space devoted to an explanation of why you are doing things and what the intuitive purpose is and less on the details.",
      "The captions on many figures seem incomplete, with only some subfigures discussed explicitly.",
      "The figures are all far too small and difficult to read.",
      "I would be inclined to pick your experiments more carefully for the main body so that you can devote more time/space to explaining and interpreting each thoroughly.",
      "They feel rushed and crowded.",
      "Regarding the introduction: I'm easily persuaded that a tighter bound to the marginal likelihood would be good, so a lot of this background isn't super necessary.",
      "I would have liked more of a sketch of what your approach is going to be.",
      "Please make your references hyperlinks.",
      "Especially when you use a numerical citation style it is almost impossible to figure out what you are citing otherwise.",
      "The spacing of the paper is very tight, perhaps some of the style-sheet was accidentally overridden?",
      "This makes it much harder to read."
    ]
  },
  {
    "paper_id": "2106.00719v2",
    "submission_id": "ykN3tbJ0qmX",
    "submission_title": "Collapsed Variational Bounds for Bayesian Neural Networks",
    "review_id": "TMNX0x3m_9Z",
    "input": {
      "title": "Collapsed Variational Bounds for Bayesian Neural Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Other work in this area has largely centered on improvements on gradients of the ELBO this work focuses on an improvement on the bound of the log marginal likelihood.\n- These improved bounds are shown mathematically with sufficient detail.\n- This work builds on existing ideas from Bayesian hierarchical models.\n- The idea of learning hyperparameters seems to be related in spirit to empirical Bayes applied to neural networks.\n- It is hard to read the algorithm as it is currently written in paragraph form; breaking this into its own section/some sort of indentation would help.\n- The provided example right after this was illustrative and helpful.\n- Just above equation (2) there is a missing period \u2018.\u2019: \u20180, ELBO lower bounds log marginal likelihood $\backslash log p(D|\backslash mu_p,\backslash sigma^2_p) \backslashgeq L(\backslash mu_q,\backslash sigma^2_q;\backslash mu_p,\backslash sigma^2_p)$ Replacing\u2019 \u2192 \u20180, ELBO lower bounds log marginal likelihood $\backslash log p(D|\backslash mu_p,\backslash sigma^2 p) \backslashgeq L(\backslash mu_q,\backslash sigma^2_q;\backslash mu_p,\backslash sigma^2_p) \backslash Replacing\u2019\n- Thanks for the reply. After further discussion and thought I have lowered my rating to marginally above the acceptance threshold. The idea is good but the structure and writing is weak.",
    "review_points_list": [
      "Other work in this area has largely centered on improvements on gradients of the ELBO this work focuses on an improvement on the bound of the log marginal likelihood.",
      "These improved bounds are shown mathematically with sufficient detail.",
      "This work builds on existing ideas from Bayesian hierarchical models.",
      "The idea of learning hyperparameters seems to be related in spirit to empirical Bayes applied to neural networks.",
      "It is hard to read the algorithm as it is currently written in paragraph form; breaking this into its own section/some sort of indentation would help.",
      "The provided example right after this was illustrative and helpful.",
      "Just above equation (2) there is a missing period \u2018.\u2019: \u20180, ELBO lower bounds log marginal likelihood $\backslash log p(D|\backslash mu_p,\backslash sigma^2_p) \backslashgeq L(\backslash mu_q,\backslash sigma^2_q;\backslash mu_p,\backslash sigma^2_p)$ Replacing\u2019 \u2192 \u20180, ELBO lower bounds log marginal likelihood $\backslash log p(D|\backslash mu_p,\backslash sigma^2 p) \backslashgeq L(\backslash mu_q,\backslash sigma^2_q;\backslash mu_p,\backslash sigma^2_p) \backslash Replacing\u2019",
      "Thanks for the reply. After further discussion and thought I have lowered my rating to marginally above the acceptance threshold. The idea is good but the structure and writing is weak."
    ]
  },
  {
    "paper_id": "2106.00719v2",
    "submission_id": "ykN3tbJ0qmX",
    "submission_title": "Collapsed Variational Bounds for Bayesian Neural Networks",
    "review_id": "47c_5bVYRXf",
    "input": {
      "title": "Collapsed Variational Bounds for Bayesian Neural Networks",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I found this paper to be a very interesting read, and a solid contribution to the fundamental research question on how to best model uncertainty in deep neural networks.\n- Using hyperpriors makes a lot of sense to me, since as it is also shown in the experiments, fixing the values of the hyperparameters as normally done is not a robust solution.\n- To the best of my knowledge, this is the first work that extends MF-VI for bayesian deep learning using ideas on collapsed bounds previously introduced for hierarchical bayesian models.\n- By using distribution from the exponential family the authors show a scalable and effective way to learn such models.\n- Because of its nature, the paper is quite dense from the theoretical point of view. In most parts derivations are well explained, but there are some places that require clarification:\n- line 87: 'where for clarity we omit. the parameterization..' this actually caused me some confusion since I did not know why you would do this. You should say that you do it since it will be implicitly defined.\n- line 107: 'straightforward to derive...' missing a reference for readers not familiar with MF-VI (Bishop's PRML book could be a good one for example)\n- line 146: why are there 2 different priors over W?\n- line 148: distribution G in p($\\tau$) is not defined, i assume it is a Gamma distribution?\n- line 215: what is p? is it the dropout probability?\n- Overall, I believe this paper can have a big impact on the area of bayesian deep learning, so I vote for accepting it.\n- Thanks for your reply, I will leave the score unchanged and argue for acceptance.",
    "review_points_list": [
      "I found this paper to be a very interesting read, and a solid contribution to the fundamental research question on how to best model uncertainty in deep neural networks.",
      "Using hyperpriors makes a lot of sense to me, since as it is also shown in the experiments, fixing the values of the hyperparameters as normally done is not a robust solution.",
      "To the best of my knowledge, this is the first work that extends MF-VI for bayesian deep learning using ideas on collapsed bounds previously introduced for hierarchical bayesian models.",
      "By using distribution from the exponential family the authors show a scalable and effective way to learn such models.",
      "Because of its nature, the paper is quite dense from the theoretical point of view. In most parts derivations are well explained, but there are some places that require clarification:",
      "line 87: 'where for clarity we omit. the parameterization..' this actually caused me some confusion since I did not know why you would do this. You should say that you do it since it will be implicitly defined.",
      "line 107: 'straightforward to derive...' missing a reference for readers not familiar with MF-VI (Bishop's PRML book could be a good one for example)",
      "line 146: why are there 2 different priors over W?",
      "line 148: distribution G in p($\\tau$) is not defined, i assume it is a Gamma distribution?",
      "line 215: what is p? is it the dropout probability?",
      "Overall, I believe this paper can have a big impact on the area of bayesian deep learning, so I vote for accepting it.",
      "Thanks for your reply, I will leave the score unchanged and argue for acceptance."
    ]
  },
  {
    "paper_id": "2110.15781v1",
    "submission_id": "uPWdkoZHgba",
    "submission_title": "Two-sided fairness in rankings via Lorenz dominance",
    "review_id": "mFDagfdnZLQ",
    "input": {
      "title": "Two-sided fairness in rankings via Lorenz dominance",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors study a natural consideration in matching problems where you must balance fairness on the part of both the users and advertisers simultaneously.\n- The definition of fairness introduced by the authors makes sense in a two-sided market, and they bring up a good parallel to Pareto efficiency.\n- Pareto efficiency (and Lorenz domination) can be a relatively weak property in the sense that a Pareto or Lorenz curve with one small 'good part' may not ever be dominated by any other curve even though those curves are better 'overall'.\n- I found the paper to be quite dense and notationally heavy, and some results were hard to interpret without the appendix.\n- Around line 103, the analogies explaining why mu_{ij} = mu_{ji} in two-sided preferences don't exactly fit (at least not to me).\n- Prospective employers and prospective employees derive different utilities from an interview; in general, people in relationships can derive different utilities as well.\n- Around line 160, could you please explain the alphas a bit better?\n- It seems like each alpha should be between 0 and 1 in order to get a strictly concave function, and the experiments show a range of alphas -- how did you choose them in asymmetric settings?\n- I also found the figures in the experimental section a bit hard to interpret.\n- Would it be helpful / informative to plot 'perfectly equitable' Lorenz curves where applicable to more clearly illustrate domination?\n- Minor comments: 44 and 46: either 'can lead to a decrease in the utility' or 'can decrease the utility'.\n- 47: worst-off.\n- 89: users.\n- 91: cardinality.\n- 92: the (i,j)-th.\n- 97: either? stress that this 'either' is based on previous lines of work; it'll be clear in this paper depending on context.\n- 103: don't understand the analogies. different utilities to each side...suggest something like.\n- 201: of the most satisfied users.\n- 224: qualitatively.",
    "review_points_list": [
      "The authors study a natural consideration in matching problems where you must balance fairness on the part of both the users and advertisers simultaneously.",
      "The definition of fairness introduced by the authors makes sense in a two-sided market, and they bring up a good parallel to Pareto efficiency.",
      "Pareto efficiency (and Lorenz domination) can be a relatively weak property in the sense that a Pareto or Lorenz curve with one small 'good part' may not ever be dominated by any other curve even though those curves are better 'overall'.",
      "I found the paper to be quite dense and notationally heavy, and some results were hard to interpret without the appendix.",
      "Around line 103, the analogies explaining why mu_{ij} = mu_{ji} in two-sided preferences don't exactly fit (at least not to me).",
      "Prospective employers and prospective employees derive different utilities from an interview; in general, people in relationships can derive different utilities as well.",
      "Around line 160, could you please explain the alphas a bit better?",
      "It seems like each alpha should be between 0 and 1 in order to get a strictly concave function, and the experiments show a range of alphas -- how did you choose them in asymmetric settings?",
      "I also found the figures in the experimental section a bit hard to interpret.",
      "Would it be helpful / informative to plot 'perfectly equitable' Lorenz curves where applicable to more clearly illustrate domination?",
      "Minor comments: 44 and 46: either 'can lead to a decrease in the utility' or 'can decrease the utility'.",
      "47: worst-off.",
      "89: users.",
      "91: cardinality.",
      "92: the (i,j)-th.",
      "97: either? stress that this 'either' is based on previous lines of work; it'll be clear in this paper depending on context.",
      "103: don't understand the analogies. different utilities to each side...suggest something like.",
      "201: of the most satisfied users.",
      "224: qualitatively."
    ]
  },
  {
    "paper_id": "2110.15781v1",
    "submission_id": "uPWdkoZHgba",
    "submission_title": "Two-sided fairness in rankings via Lorenz dominance",
    "review_id": "EKQDIEIH3oG",
    "input": {
      "title": "Two-sided fairness in rankings via Lorenz dominance",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The algorithm is well-defined\n- The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.\n- The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset.\n- Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.\n- The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.\n- The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.\n- This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.\n- The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.\n- log(k) is an upper bound on the improvement of query complexity for any sampler.\n- The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.\n- The paper is very clear and well organized.\n- The authors detail the hyper-parameters and compute details used for the experiments.\n- The Cluster-Margin algorithm is also explained in detail.\n- The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods.\n- The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.\n- S1: The main idea (of employing Lorenz dominance to implement fair utility) is insightful.\n- S2: The proposed formulation is elegant: it covers both one-sided and reciprocal recommendation systems.\n- S3: Theoretical guarantees of the considered algorithm are provided in Theorems 1 and 2.\n- W1: Improvement over the considered baselines (particularly for equal_expo and equal_util) seems marginal.\n- W2: Comparison with prior two-sided fairness algorithms (such as [41]) are missing.\n- W3: Tradeoffs are unclear in Figure 2 and Figure 3.\n- The technical content of this paper appears to be correct.\n- The paper was overall well-written yet would benefit from more proofreading.",
    "review_points_list": [
      "The algorithm is well-defined",
      "The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.",
      "The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset.",
      "Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.",
      "The authors establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.",
      "The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.",
      "This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.",
      "The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.",
      "log(k) is an upper bound on the improvement of query complexity for any sampler.",
      "The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.",
      "The paper is very clear and well organized.",
      "The authors detail the hyper-parameters and compute details used for the experiments.",
      "The Cluster-Margin algorithm is also explained in detail.",
      "The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods.",
      "The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.",
      "S1: The main idea (of employing Lorenz dominance to implement fair utility) is insightful.",
      "S2: The proposed formulation is elegant: it covers both one-sided and reciprocal recommendation systems.",
      "S3: Theoretical guarantees of the considered algorithm are provided in Theorems 1 and 2.",
      "W1: Improvement over the considered baselines (particularly for equal_expo and equal_util) seems marginal.",
      "W2: Comparison with prior two-sided fairness algorithms (such as [41]) are missing.",
      "W3: Tradeoffs are unclear in Figure 2 and Figure 3.",
      "The technical content of this paper appears to be correct.",
      "The paper was overall well-written yet would benefit from more proofreading."
    ]
  },
  {
    "paper_id": "2110.15781v1",
    "submission_id": "uPWdkoZHgba",
    "submission_title": "Two-sided fairness in rankings via Lorenz dominance",
    "review_id": "IgwUyZ79r9",
    "input": {
      "title": "Two-sided fairness in rankings via Lorenz dominance",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The main contribution of this paper is the development of a novel algorithm for active learning.\n- The paper is well-written and easy to follow.\n- However, I would suggest rephrasing a few sentences for increased clarity.\n- The algorithm appears to be novel and innovative, and the authors provide a good comparison to existing methods (BADGE, CoreSet).\n- The results are impressive, particularly the experiments on CIFAR10 and CIFAR100, which demonstrate the algorithm's effectiveness.\n- The paper contributes to the active learning literature and may have practical implications for certain applications.\n- The introduction could be improved by providing more background on the current state of the field.\n- The authors responded to this comment by stating that they agree that the introduction could be improved but that it would require more space.\n- The authors are planning to address this in a future paper.\n- The authors rephrased a few sentences as suggested.\n- This helped improve the understandability of the paper.\n- I believe that it may significantly benefit for practice if it (at least) discusses how the results can be used in paid scenarios.\n- Many ranking (recomm) systems are paid. So, how are these results related to such systems that are quite popular? Usually, every large system needs a monetization implying sponsored ranking / recommendations / suggestions / etc.: e.g., sponsored search, social networks, ecom, crowdsourcing platforms,\n- Minor comments: - Line 130: I did not get 'true' applied to 'user'",
    "review_points_list": [
      "The main contribution of this paper is the development of a novel algorithm for active learning.",
      "The paper is well-written and easy to follow.",
      "However, I would suggest rephrasing a few sentences for increased clarity.",
      "The algorithm appears to be novel and innovative, and the authors provide a good comparison to existing methods (BADGE, CoreSet).",
      "The results are impressive, particularly the experiments on CIFAR10 and CIFAR100, which demonstrate the algorithm's effectiveness.",
      "The paper contributes to the active learning literature and may have practical implications for certain applications.",
      "The introduction could be improved by providing more background on the current state of the field.",
      "The authors responded to this comment by stating that they agree that the introduction could be improved but that it would require more space.",
      "The authors are planning to address this in a future paper.",
      "The authors rephrased a few sentences as suggested.",
      "This helped improve the understandability of the paper.",
      "I believe that it may significantly benefit for practice if it (at least) discusses how the results can be used in paid scenarios.",
      "Many ranking (recomm) systems are paid. So, how are these results related to such systems that are quite popular? Usually, every large system needs a monetization implying sponsored ranking / recommendations / suggestions / etc.: e.g., sponsored search, social networks, ecom, crowdsourcing platforms,",
      "Minor comments: - Line 130: I did not get 'true' applied to 'user'"
    ]
  },
  {
    "paper_id": "2305.07892v1",
    "submission_id": "wKf9iSu_TEm",
    "submission_title": "Multi-Objective Meta Learning",
    "review_id": "azKSPvSRcfe",
    "input": {
      "title": "Multi-Objective Meta Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This work is well-written, and for the most part, lucid.\n- Certain sections are quite dense, which I attribute to the author's desire to include a comprehensive explanation of their methods/proofs/experiments, but I would recommend further elaboration in Section 3 and 4 to elucidate the proposed method.\n- For instance, clearly defining $\textbackslash alpha$, clearly defining $w$, and elaborating on how the MOPSolver combines LL gradients would likely help readers better grasp the scope of the proposed method, especially if they are unfamiliar with multi-objective optimization.\n- The theoretical analysis on convergence supports the authors' proposal, and strong empirical results on a diverse range of applications further bolster the utility of MOML.\n- Given this is a general purpose augmentation that can be applied to many Meta Learning problems to improve performance, I believe it is a significant contribution to the field.\n- However, one well-known detriment associated with Multi-Objective Optimization methods relates to its slow runtime.\n- It would be beneficial for the authors to provide comparison to SOML (single objective, weighted combination in the outer optimization) to be transparent on the limitations of Desideri's algorithm.\n- In summary, I believe this paper is well-written, incorporates prior work to make a novel contribution, provides theoretical analysis, offers comprehensive empirical results, and makes a meaningful contribution to the meta learning domain.\n- In many ways, it feels like the Meta Learning analog of Sener and Koltun's Multi-Task Learning as Multi-Objective Optimization, which itself was a seminal work.",
    "review_points_list": [
      "This work is well-written, and for the most part, lucid.",
      "Certain sections are quite dense, which I attribute to the author's desire to include a comprehensive explanation of their methods/proofs/experiments, but I would recommend further elaboration in Section 3 and 4 to elucidate the proposed method.",
      "For instance, clearly defining $\textbackslash alpha$, clearly defining $w$, and elaborating on how the MOPSolver combines LL gradients would likely help readers better grasp the scope of the proposed method, especially if they are unfamiliar with multi-objective optimization.",
      "The theoretical analysis on convergence supports the authors' proposal, and strong empirical results on a diverse range of applications further bolster the utility of MOML.",
      "Given this is a general purpose augmentation that can be applied to many Meta Learning problems to improve performance, I believe it is a significant contribution to the field.",
      "However, one well-known detriment associated with Multi-Objective Optimization methods relates to its slow runtime.",
      "It would be beneficial for the authors to provide comparison to SOML (single objective, weighted combination in the outer optimization) to be transparent on the limitations of Desideri's algorithm.",
      "In summary, I believe this paper is well-written, incorporates prior work to make a novel contribution, provides theoretical analysis, offers comprehensive empirical results, and makes a meaningful contribution to the meta learning domain.",
      "In many ways, it feels like the Meta Learning analog of Sener and Koltun's Multi-Task Learning as Multi-Objective Optimization, which itself was a seminal work."
    ]
  },
  {
    "paper_id": "2305.07892v1",
    "submission_id": "wKf9iSu_TEm",
    "submission_title": "Multi-Objective Meta Learning",
    "review_id": "x4LhfUl0IH",
    "input": {
      "title": "Multi-Objective Meta Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors consider a multi-objective perspective for meta-learning in which one desires optimizing multiple objectives simultaneously at the meta-level.\n- The necessity of considering a multiple-objective perspective in Meta-Learning is not enough motivated.\n- It would be nice to give an example of the multi-meta-objective F, immediately after Eq. 1.\n- Since usually there is no closed-form solution to the lower-level problem, the authors solve such a problem approximately by applying Stochastic Gradient Descent...\n- The approximation error introduced by this substitution is not enough analyzed in my opinion.\n- Is it possible to formally quantify such an approximation error as done in [1] below?\n- The authors need to consider optimization tools for vector-valued functions and to make standard assumptions in literature, such as the existence and the uniqueness of the solution of the lower-level problem.\n- About the convergence result presented in Thm. 2: it would be nice to have a non-asymptotic convergence rate.\n- What about the step in which the authors compute the meta-subgradients by a routine?\n- The authors say that, for MAML, one may need to consider not only the performance but also the robustness which can help adapt to new tasks with the learned initialization.\n- If one motivation supporting the necessity of considering multiple-objective is controlling the robustness of the learned initialization, what about the connection to the conditional Meta-Learning approach introduced in [2,3] below?\n- f in Eq. 2 is the within-task objective. Clarify this.\n- In Eq. 1, w depends on \u03b1: indicate this dependency by denoting it with w_\u03b1.\n- Lines 181-182: 'How to obtain multiple nearly optimal solutions for MOBLPs is beyond the scope of this paper and we will study it in our future work.' What do you mean? Why?\n- The experiments seem to be exhaustive and show the advantage of applying their multi-objective meta-learning method in comparison to state-of-the-art methods on problems of few-shot learning, semi-supervised domain adaptation, multi-task learning, and neural architecture search.",
    "review_points_list": [
      "The authors consider a multi-objective perspective for meta-learning in which one desires optimizing multiple objectives simultaneously at the meta-level.",
      "The necessity of considering a multiple-objective perspective in Meta-Learning is not enough motivated.",
      "It would be nice to give an example of the multi-meta-objective F, immediately after Eq. 1.",
      "Since usually there is no closed-form solution to the lower-level problem, the authors solve such a problem approximately by applying Stochastic Gradient Descent...",
      "The approximation error introduced by this substitution is not enough analyzed in my opinion.",
      "Is it possible to formally quantify such an approximation error as done in [1] below?",
      "The authors need to consider optimization tools for vector-valued functions and to make standard assumptions in literature, such as the existence and the uniqueness of the solution of the lower-level problem.",
      "About the convergence result presented in Thm. 2: it would be nice to have a non-asymptotic convergence rate.",
      "What about the step in which the authors compute the meta-subgradients by a routine?",
      "The authors say that, for MAML, one may need to consider not only the performance but also the robustness which can help adapt to new tasks with the learned initialization.",
      "If one motivation supporting the necessity of considering multiple-objective is controlling the robustness of the learned initialization, what about the connection to the conditional Meta-Learning approach introduced in [2,3] below?",
      "f in Eq. 2 is the within-task objective. Clarify this.",
      "In Eq. 1, w depends on \u03b1: indicate this dependency by denoting it with w_\u03b1.",
      "Lines 181-182: 'How to obtain multiple nearly optimal solutions for MOBLPs is beyond the scope of this paper and we will study it in our future work.' What do you mean? Why?",
      "The experiments seem to be exhaustive and show the advantage of applying their multi-objective meta-learning method in comparison to state-of-the-art methods on problems of few-shot learning, semi-supervised domain adaptation, multi-task learning, and neural architecture search."
    ]
  },
  {
    "paper_id": "2305.07892v1",
    "submission_id": "wKf9iSu_TEm",
    "submission_title": "Multi-Objective Meta Learning",
    "review_id": "woiC7gRAXDB",
    "input": {
      "title": "Multi-Objective Meta Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The review seems to be about multiple objective meta learning problems\n- There have been many meta learning problems that optimize multiple objective functions\n- the proposed multi-objective meta learning (MOML) framework is trying to make it easier by avoiding the hyper-parameter tuning for combing those objective functions\n- Multiple Gradient Descent Algorithm (MGDA) seamlessly fits into gradient-based meta-learning frameworks\n- this proposed method is straight forward\n- it is good to have convergence analysis to properly understand the method\n- The right applications have been shown in the experimental section\n- it is interesting to see how this can be applied\n- The single-objective meta learning (SOML) is used as a baseline\n- where the weighting parameters for objective functions have to be tuned\n- However, it is unclear, how this SOML was trained or how the performance varies by randomly choosing the weighting parameters?\n- When we have multiple objective functions, we would like to emphasize particular objective function rather than others\n- for SOML, we have chance to manually emphasize it\n- but could this kind of situation can be handled with the proposed MOML?",
    "review_points_list": [
      "The review seems to be about multiple objective meta learning problems",
      "There have been many meta learning problems that optimize multiple objective functions",
      "the proposed multi-objective meta learning (MOML) framework is trying to make it easier by avoiding the hyper-parameter tuning for combing those objective functions",
      "Multiple Gradient Descent Algorithm (MGDA) seamlessly fits into gradient-based meta-learning frameworks",
      "this proposed method is straight forward",
      "it is good to have convergence analysis to properly understand the method",
      "The right applications have been shown in the experimental section",
      "it is interesting to see how this can be applied",
      "The single-objective meta learning (SOML) is used as a baseline",
      "where the weighting parameters for objective functions have to be tuned",
      "However, it is unclear, how this SOML was trained or how the performance varies by randomly choosing the weighting parameters?",
      "When we have multiple objective functions, we would like to emphasize particular objective function rather than others",
      "for SOML, we have chance to manually emphasize it",
      "but could this kind of situation can be handled with the proposed MOML?"
    ]
  },
  {
    "paper_id": "2305.07892v1",
    "submission_id": "wKf9iSu_TEm",
    "submission_title": "Multi-Objective Meta Learning",
    "review_id": "r3b3xeOl44T",
    "input": {
      "title": "Multi-Objective Meta Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The title of this paper excites me in the first place, but the idea of this method quickly disappoints me as the method is a simple learning extension to the current method.\n- Unfortunately, I did not learn any new insight from this paper, so I decide to reject it.\n- easy to understand\n- many experiments with good results\n- I suggest authors taking a broader investigation of literature in Multi-objective Optimization.\n- The authors should conduct an in-depth literature review in this field.\n- Frankly, even Wikipedia covers a few methods.\n- The idea is boring.\n- Correct me if I'm wrong; I believe the method only parameterizes the weights for each objective at the upper level and learns these weights.\n- That's the main contribution of this method.\n- If this is the case, I can easily come up with thousands of variants of proposed methods, e.g., by learning the scalarization, by learning the construction of hyper-volume.\n- I understand you have a good result, but why is this better than others?\n- The idea should be a few lines (< 5) of changes to DARTS.\n- The evaluation seems to cover quite different tasks, but the improvement seems very limited (e.g. Table.2).\n- Overall it cannot convince me that this method solves some problems that other methods cannot solve.\n- I understand a few points of improvement in these tables, but these numbers are not significantly different.\n- To other reviewers who are not familiar with DARTS, I highly recommend taking a look at it here (https://arxiv.org/abs/1806.09055).\n- The proposed method simply combines multiple objectives of DARTS, and performs the experiments on different downstream tasks.\n- Therefore, this novelty and contribution of this paper is very limited.\n- I read the authors' comments, but the authors did not address my novelty concerns, especially on its difference to DARTS.\n- This work is clearly a trivial version of DARTS applied to a different domain.\n- Here the trivial part is that 1) the formulation of bi-level optimization is exactly same as DARTS.\n- 2) Darts goes to single objective optimization, which optimizes min o1\n- The proposed method in this paper is simply: min o1*w1+o2*w2+o3*w3.....\n- where w1, w2, w3 are learnable weights.\n- The inner loop of both methods is exactly same.\n- So I really don't think this is a valid contribution to the research community, especially to a top conference like ICLR.",
    "review_points_list": [
      "The title of this paper excites me in the first place, but the idea of this method quickly disappoints me as the method is a simple learning extension to the current method.",
      "Unfortunately, I did not learn any new insight from this paper, so I decide to reject it.",
      "easy to understand",
      "many experiments with good results",
      "I suggest authors taking a broader investigation of literature in Multi-objective Optimization.",
      "The authors should conduct an in-depth literature review in this field.",
      "Frankly, even Wikipedia covers a few methods.",
      "The idea is boring.",
      "Correct me if I'm wrong; I believe the method only parameterizes the weights for each objective at the upper level and learns these weights.",
      "That's the main contribution of this method.",
      "If this is the case, I can easily come up with thousands of variants of proposed methods, e.g., by learning the scalarization, by learning the construction of hyper-volume.",
      "I understand you have a good result, but why is this better than others?",
      "The idea should be a few lines (< 5) of changes to DARTS.",
      "The evaluation seems to cover quite different tasks, but the improvement seems very limited (e.g. Table.2).",
      "Overall it cannot convince me that this method solves some problems that other methods cannot solve.",
      "I understand a few points of improvement in these tables, but these numbers are not significantly different.",
      "To other reviewers who are not familiar with DARTS, I highly recommend taking a look at it here (https://arxiv.org/abs/1806.09055).",
      "The proposed method simply combines multiple objectives of DARTS, and performs the experiments on different downstream tasks.",
      "Therefore, this novelty and contribution of this paper is very limited.",
      "I read the authors' comments, but the authors did not address my novelty concerns, especially on its difference to DARTS.",
      "This work is clearly a trivial version of DARTS applied to a different domain.",
      "Here the trivial part is that 1) the formulation of bi-level optimization is exactly same as DARTS.",
      "2) Darts goes to single objective optimization, which optimizes min o1",
      "The proposed method in this paper is simply: min o1*w1+o2*w2+o3*w3.....",
      "where w1, w2, w3 are learnable weights.",
      "The inner loop of both methods is exactly same.",
      "So I really don't think this is a valid contribution to the research community, especially to a top conference like ICLR."
    ]
  },
  {
    "paper_id": "2411.01115v3",
    "submission_id": "yAIYc7YjGbd",
    "submission_title": "Solving Soft Clustering Ensemble via $k$-Sparse Discrete Wasserstein Barycenter",
    "review_id": "eAmPyHofze6",
    "input": {
      "title": "Solving Soft Clustering Ensemble via $k$-Sparse Discrete Wasserstein Barycenter",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- + The connection of Wasserstein barycenters and soft clustering ensemble\n- + Solid the mathematical derivation seems; claims in the paper seem to be supported by either proofs or reference.\n- - Theorem 2 seems a straightforward result of connecting the objectives of DWB and SCE.\n- - Algorithm 1 is not practical ($k!$ in step 3) and not used in the experiments. Please correct me if I am wrong but I found in the code that alternative optimization for DWB was actually adopted instead.\n- - The results don't show much improvement for a smaller sampling rate. And in Figure 2, (a-f) I wonder if x-ticks are wrong because they suggest a large rate leads to shorter time but the largest rate AM-1 took the longest time.",
    "review_points_list": [
      "+ The connection of Wasserstein barycenters and soft clustering ensemble",
      "+ Solid the mathematical derivation seems; claims in the paper seem to be supported by either proofs or reference.",
      "- Theorem 2 seems a straightforward result of connecting the objectives of DWB and SCE.",
      "- Algorithm 1 is not practical ($k!$ in step 3) and not used in the experiments. Please correct me if I am wrong but I found in the code that alternative optimization for DWB was actually adopted instead.",
      "- The results don't show much improvement for a smaller sampling rate. And in Figure 2, (a-f) I wonder if x-ticks are wrong because they suggest a large rate leads to shorter time but the largest rate AM-1 took the longest time."
    ]
  },
  {
    "paper_id": "2411.01115v3",
    "submission_id": "yAIYc7YjGbd",
    "submission_title": "Solving Soft Clustering Ensemble via $k$-Sparse Discrete Wasserstein Barycenter",
    "review_id": "K_jJP4109Wd",
    "input": {
      "title": "Solving Soft Clustering Ensemble via $k$-Sparse Discrete Wasserstein Barycenter",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is original and clearly written.\n- The new connection between soft clustering ensemble and $k$-sparse discrete Wasserstein barycenter is interesting, which allows using techniques in DWB literature to solve the SCE problem.\n- Building a bridge between seemingly different tasks is always a good thing, as it may introduce new tools for both problems.\n- Leveraging the new equivalence, the hardness and consensus analysis are reported for the SCE problem by studying the equivalence DWB problem.\n- Approximation algorithms are also provided, though these results are mostly working in theory due to the efficiency issue (see complexity in Theorem 3).\n- So new efficient algorithms for $k$-sparse DWB might be interesting for further research.\n- Overall, considering the new connection brings fruitful results for the SCE problem, I tend to vote yes for its acceptance.",
    "review_points_list": [
      "The paper is original and clearly written.",
      "The new connection between soft clustering ensemble and $k$-sparse discrete Wasserstein barycenter is interesting, which allows using techniques in DWB literature to solve the SCE problem.",
      "Building a bridge between seemingly different tasks is always a good thing, as it may introduce new tools for both problems.",
      "Leveraging the new equivalence, the hardness and consensus analysis are reported for the SCE problem by studying the equivalence DWB problem.",
      "Approximation algorithms are also provided, though these results are mostly working in theory due to the efficiency issue (see complexity in Theorem 3).",
      "So new efficient algorithms for $k$-sparse DWB might be interesting for further research.",
      "Overall, considering the new connection brings fruitful results for the SCE problem, I tend to vote yes for its acceptance."
    ]
  },
  {
    "paper_id": "2411.01115v3",
    "submission_id": "yAIYc7YjGbd",
    "submission_title": "Solving Soft Clustering Ensemble via $k$-Sparse Discrete Wasserstein Barycenter",
    "review_id": "iXGYNggwWTY",
    "input": {
      "title": "Solving Soft Clustering Ensemble via $k$-Sparse Discrete Wasserstein Barycenter",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is generally clear and well organized.\n- Occasionally, the writing should be improved, and some small mistakes should be corrected.\n- The problem is well described and motivated.\n- However, some claims lack adequate reference, as for instance in lines 128-129, lines 138-139; and Lemma 1 and 2.\n- The main results appear to be an improvement on an existing algorithm, and the proof of the convergence of the solution with m clustering to the ground truth under weaker assumptions and with a quantitative analysis.\n- The experimental results are good when compared to the baselines.\n- The Discrete Barycenter Problem is NP-hard when the support points of the barycenter are not given or they are not in polynomial size.\n- If the support points of the barycenter are given, problem (6) is not NP-hard, but it is polynomially solvable by Linear Programming, and it can be efficiently solved to optimality also in practice by the barrier algorithm of commercial solvers such as Gurobi (at least for dataset of the size you\u2019re considering), as shown, for example, in ...\n- Auricchio, G., Bassetti, F., Gualandi, S. and Veneroni, M., 2019. Computing Wasserstein Barycenters via Linear Programming. In CPAIOR-2019, 355-363. Springer.\n- Questions for the authors: are the baselines method selected for the comparison really the state of the art for the (small) datasets you have used in your experiments?\n- Do you have any test where you have the \u201creal\u201d ground truth, and you can really check that with your approach you are able to recover the true optimal clustering?\n- Evaluating the clustering only in terms of the objective function value can be misleading if the objective function is not the best possible to recover the ground truth.\n- Equation (5) is wrong: it misses a \u201c^1/s\u201d for the minimal value.\n- If you use s for the norm, maybe is better to use the index p for the power of the norm, and \u201c1/p\u201d for the minimum distance.\n- Line 63: that whether;\n- Line 68: infinity -> infinite.\n- Line 108: C subset of [0,1]^n is not correct (actually S_j is a subset of [0,1]^n).\n- Line 153: formal definition of F is not correct: the conditions on f_ij should be inside the braces.\n- Line 170: covert -> convert.\n- Section 4.1: the letter of the dimension of the space changes from d to n.\n- Algorithm 1: \u03b4, \u03b5 >; 0 (instead of \u2265).\n- Line 262: that;\n- Line 264: since \u03c1 is a density, \u03c1(C) is not the probability of obtaining C.\n- Line 279: what;\n- Line 284: necessary to be -> necessarily.\n- Assumption 2, as it is formulated, is weaker than Assumption 1: it can be easily seen by taking \u03be = L. Can it just be removed?\n- Line 326: the",
    "review_points_list": [
      "The paper is generally clear and well organized.",
      "Occasionally, the writing should be improved, and some small mistakes should be corrected.",
      "The problem is well described and motivated.",
      "However, some claims lack adequate reference, as for instance in lines 128-129, lines 138-139; and Lemma 1 and 2.",
      "The main results appear to be an improvement on an existing algorithm, and the proof of the convergence of the solution with m clustering to the ground truth under weaker assumptions and with a quantitative analysis.",
      "The experimental results are good when compared to the baselines.",
      "The Discrete Barycenter Problem is NP-hard when the support points of the barycenter are not given or they are not in polynomial size.",
      "If the support points of the barycenter are given, problem (6) is not NP-hard, but it is polynomially solvable by Linear Programming, and it can be efficiently solved to optimality also in practice by the barrier algorithm of commercial solvers such as Gurobi (at least for dataset of the size you\u2019re considering), as shown, for example, in ...",
      "Auricchio, G., Bassetti, F., Gualandi, S. and Veneroni, M., 2019. Computing Wasserstein Barycenters via Linear Programming. In CPAIOR-2019, 355-363. Springer.",
      "Questions for the authors: are the baselines method selected for the comparison really the state of the art for the (small) datasets you have used in your experiments?",
      "Do you have any test where you have the \u201creal\u201d ground truth, and you can really check that with your approach you are able to recover the true optimal clustering?",
      "Evaluating the clustering only in terms of the objective function value can be misleading if the objective function is not the best possible to recover the ground truth.",
      "Equation (5) is wrong: it misses a \u201c^1/s\u201d for the minimal value.",
      "If you use s for the norm, maybe is better to use the index p for the power of the norm, and \u201c1/p\u201d for the minimum distance.",
      "Line 63: that whether;",
      "Line 68: infinity -> infinite.",
      "Line 108: C subset of [0,1]^n is not correct (actually S_j is a subset of [0,1]^n).",
      "Line 153: formal definition of F is not correct: the conditions on f_ij should be inside the braces.",
      "Line 170: covert -> convert.",
      "Section 4.1: the letter of the dimension of the space changes from d to n.",
      "Algorithm 1: \u03b4, \u03b5 >; 0 (instead of \u2265).",
      "Line 262: that;",
      "Line 264: since \u03c1 is a density, \u03c1(C) is not the probability of obtaining C.",
      "Line 279: what;",
      "Line 284: necessary to be -> necessarily.",
      "Assumption 2, as it is formulated, is weaker than Assumption 1: it can be easily seen by taking \u03be = L. Can it just be removed?",
      "Line 326: the"
    ]
  },
  {
    "paper_id": "2411.01115v3",
    "submission_id": "yAIYc7YjGbd",
    "submission_title": "Solving Soft Clustering Ensemble via $k$-Sparse Discrete Wasserstein Barycenter",
    "review_id": "_5Np9rtuPAN",
    "input": {
      "title": "Solving Soft Clustering Ensemble via $k$-Sparse Discrete Wasserstein Barycenter",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This manuscript shows theoretical analyses of soft clustering ensemble problems.\n- It has been known that clustering ensemble can be formulated as a geometric prototype problem.\n- The main contribution of this manuscript is to show that the geometric prototype is actually equivalent with an instance of discrete Wasserstein barycenter (DWB).\n- The explanations about this point and intuitions are well described in the manuscript.\n- A sampling-based algorithm is proposed with provable quality guarantees based on the connection between the soft clustering ensemble and the discrete Wasserstein barycenter.\n- It has been shown that the obtained DWB can be close to the ground-truth clustering if the number of given clustering solutions is large enough.\n- I did not check all the details about the proofs, but the high-level intuition seems reasonable.\n- I wonder how the proposed method compares to the following paper if the assignment is assumed to be a hard clustering.\n- Spectral ensemble clustering (KDD 2015) by H. Liu et al.\n- I might have missed something, but I wonder how the proposed method can achieve better runtime than the other methods in the experiments for k=10 (USPS and CIFAR-10 datasets) even though in Algorithm 1, the third step includes computing k! permutations for pi_i.\n- In the experiments, it is stated that we apply random projections to generate the clustering solutions (in each random subspace, we use k-means to cluster the data). More details should be provided to understand this experimental setting clearly.\n- How are the base soft clustering results generated?",
    "review_points_list": [
      "This manuscript shows theoretical analyses of soft clustering ensemble problems.",
      "It has been known that clustering ensemble can be formulated as a geometric prototype problem.",
      "The main contribution of this manuscript is to show that the geometric prototype is actually equivalent with an instance of discrete Wasserstein barycenter (DWB).",
      "The explanations about this point and intuitions are well described in the manuscript.",
      "A sampling-based algorithm is proposed with provable quality guarantees based on the connection between the soft clustering ensemble and the discrete Wasserstein barycenter.",
      "It has been shown that the obtained DWB can be close to the ground-truth clustering if the number of given clustering solutions is large enough.",
      "I did not check all the details about the proofs, but the high-level intuition seems reasonable.",
      "I wonder how the proposed method compares to the following paper if the assignment is assumed to be a hard clustering.",
      "Spectral ensemble clustering (KDD 2015) by H. Liu et al.",
      "I might have missed something, but I wonder how the proposed method can achieve better runtime than the other methods in the experiments for k=10 (USPS and CIFAR-10 datasets) even though in Algorithm 1, the third step includes computing k! permutations for pi_i.",
      "In the experiments, it is stated that we apply random projections to generate the clustering solutions (in each random subspace, we use k-means to cluster the data). More details should be provided to understand this experimental setting clearly.",
      "How are the base soft clustering results generated?"
    ]
  },
  {
    "paper_id": "1705.10528v1",
    "submission_id": "vERYhbX_6Y",
    "submission_title": "Constrained Optimization to Train Neural Networks on Critical and Under-Represented Classes",
    "review_id": "zftWnMCo6sr",
    "input": {
      "title": "Constrained Optimization to Train Neural Networks on Critical and Under-Represented Classes",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed approach is definitely very novel and interesting. I am not aware of other work in this area that pose AUC optimization as a constrained optimization problem.\n- The authors provided a very comprehensive and well organized related work section, and its clear how this approach distinguishes itself from the others.\n- The related work is broadly split into 3 groups: the first proposes variants of common loss functions with added emphasis on minority classes, the second focuses on different sampling strategies to improve the occurrences of the minority class samples in the batches, and the third focuses on scaling and thresholding model outputs post training.\n- This paper falls in that subgroup, but differs from the other papers by proposing an approach that's scalable to large datasets and model architectures, and that can be used along with other loss functions.\n- The paper overall is very well written. Its clear, understandable, and very well organized.\n- Its clear that the authors included a toy example in section 4.2 to explain intuitively how their approach works.\n- One minor comment is, in Figure 1, the axis labels should be False Positive Rate and True Positive Rate instead.\n- The paper is technically very sound.\n- The proposed constraint was given ample intuitive and mathematical explanation, and using a toy example in section 4.2 and detailed theoretical explanations in the appendix section A.8 is very helpful.\n- The authors conducted very comprehensive experiments (including the results presented in the appendix) and provided compelling evidence for the improvements obtained by their approach by comparing directly with the results of several approaches from the related work.\n- This approach improved the results considerably in most of the cases.\n- The authors also extended their work to the multiclass domain and provided the relevant results.\n- The proposed approach produced considerable improvements in empirical results over several state of the art methods.\n- The main appeal of this approach is that it can be integrated with any other approach very easily.\n- I think this will make it very easy for other authors to include it as a baseline in their works.\n- This is a complete piece of work with a several important details provided in the appendix, and code required to reproduce the results provided in the supplementary material.\n- The proposed approach provides a unique way to reduce the FPRs of classifiers operating at a high TPR.\n- This is a very wide spread problem faced especially in the medical domain, and a lot of approaches do lead to a high FPR which impacts their practical usability adversely.\n- This approach is definitely a very welcome addition in tackling that problem.\n- It would have been helpful if the authors provided results in another public medical dataset like ADNI, etc.\n- It would be helpful if the authors include some discussion on how they plan to extend this work in the conclusion section.",
    "review_points_list": [
      "The proposed approach is definitely very novel and interesting. I am not aware of other work in this area that pose AUC optimization as a constrained optimization problem.",
      "The authors provided a very comprehensive and well organized related work section, and its clear how this approach distinguishes itself from the others.",
      "The related work is broadly split into 3 groups: the first proposes variants of common loss functions with added emphasis on minority classes, the second focuses on different sampling strategies to improve the occurrences of the minority class samples in the batches, and the third focuses on scaling and thresholding model outputs post training.",
      "This paper falls in that subgroup, but differs from the other papers by proposing an approach that's scalable to large datasets and model architectures, and that can be used along with other loss functions.",
      "The paper overall is very well written. Its clear, understandable, and very well organized.",
      "Its clear that the authors included a toy example in section 4.2 to explain intuitively how their approach works.",
      "One minor comment is, in Figure 1, the axis labels should be False Positive Rate and True Positive Rate instead.",
      "The paper is technically very sound.",
      "The proposed constraint was given ample intuitive and mathematical explanation, and using a toy example in section 4.2 and detailed theoretical explanations in the appendix section A.8 is very helpful.",
      "The authors conducted very comprehensive experiments (including the results presented in the appendix) and provided compelling evidence for the improvements obtained by their approach by comparing directly with the results of several approaches from the related work.",
      "This approach improved the results considerably in most of the cases.",
      "The authors also extended their work to the multiclass domain and provided the relevant results.",
      "The proposed approach produced considerable improvements in empirical results over several state of the art methods.",
      "The main appeal of this approach is that it can be integrated with any other approach very easily.",
      "I think this will make it very easy for other authors to include it as a baseline in their works.",
      "This is a complete piece of work with a several important details provided in the appendix, and code required to reproduce the results provided in the supplementary material.",
      "The proposed approach provides a unique way to reduce the FPRs of classifiers operating at a high TPR.",
      "This is a very wide spread problem faced especially in the medical domain, and a lot of approaches do lead to a high FPR which impacts their practical usability adversely.",
      "This approach is definitely a very welcome addition in tackling that problem.",
      "It would have been helpful if the authors provided results in another public medical dataset like ADNI, etc.",
      "It would be helpful if the authors include some discussion on how they plan to extend this work in the conclusion section."
    ]
  },
  {
    "paper_id": "1705.10528v1",
    "submission_id": "vERYhbX_6Y",
    "submission_title": "Constrained Optimization to Train Neural Networks on Critical and Under-Represented Classes",
    "review_id": "59aMZdwBjbW",
    "input": {
      "title": "Constrained Optimization to Train Neural Networks on Critical and Under-Represented Classes",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Why not compare against any of these approaches? Or is it not just that the performance is unknown, but that their application to DNNs is nontrivial?\n- Statistical significance is not included in Table 1 and Table 2. Multiple replicates should be used to test the significance.\n- Avg AUCs in table 3 have large standard deviation, which might not indicate significant improvement.\n- Instead of using selected thresholds 98%, 95% and 90%, it is more informative to show a TPR- FPR curve plot.\n- How to predefine critical and non-critical classes? In binary classification, it seems that the minority class is always the critical class.\n- Is this always the case in real-world applications? In the multi-class setting with many classes, classifying each class into critical and non-critical seems to be difficult and needs domain knowledge.\n- If a critical class is misdefined as a non-critical class, this might be problematic for many applications.\n- The setting of class ratios in CIFAR experiments seems unrealistic (e.g., a clinical dataset with 200 healthy patients and 1 sick patient).\n- Is it because the method can only have good improvement on such a very imbalanced ratio?\n- I suggest the author to either show improvement on CIFAR with smaller ratios (e.g., 1:5, 1:10) or find a real-world medical application that has such a class ratio close to 1:100.\n- A slightly longer description of MBAUC, such as the framework it uses or other ways in which it differs from the proposed method, would be useful.\n- I think you mean non-convergence?\n- It would be useful to include a citation for the claim in Section 4.1 that \u2018Satisfying the constraint would directly ensure maximal AUC.\u2019\n- Given the precise setup of the line plot I think that it would be useful for the grid axes to go from [0, 5], rather than [0, 1].\n- What is the justification for CIFAR10 and CIFAR100 to use validation sets that have 100 samples per class?\n- Why is this not also class-imbalanced?\n- I find the tables difficult to read.\n- First, when the original loss function achieves a lower FPR / higher test AUC than the ALM-optimization version, I think those results should be bolded for clarity.\n- Given the quantity of bolded results, it is also difficult to distinguish the underlines of \u201cbest result\u201d, particularly when it is not one of the bolded entries.\n- Avg AUCs in table 3 have large standard deviation, which might not indicate significant improvement.\n- I didn\u2019t understand why the entry for ALM_{m, 1} + LDAM [Acc. Critical Class 1] was not bolded in table A5.\n- The details of the multi-class classification experiment were not fully explained in the paper.\n- Specifically, I was not fully clear that there was only one critical class (and multiple non-critical classes) in this problem formulation until Section A.4.\n- I wish the authors provided slightly more discussion about the actual results, including why the ALM helped more with some methods than others.\n- This wasn\u2019t the case on the MRI dataset -- is this due to an easier problem (lower FPR/higher TPR to begin with)? Weaker requirements on TPR? Less extreme class imbalances?\n- I would appreciate some kind of study on the impact of class imbalance ratios to the improvement attributed to the ALM optimization.\n- Showing the % improvement by incorporating ALM would also be a useful plot to include somewhere, and might be more readable than the tables.\n- Tables A",
    "review_points_list": [
      "Why not compare against any of these approaches? Or is it not just that the performance is unknown, but that their application to DNNs is nontrivial?",
      "Statistical significance is not included in Table 1 and Table 2. Multiple replicates should be used to test the significance.",
      "Avg AUCs in table 3 have large standard deviation, which might not indicate significant improvement.",
      "Instead of using selected thresholds 98%, 95% and 90%, it is more informative to show a TPR- FPR curve plot.",
      "How to predefine critical and non-critical classes? In binary classification, it seems that the minority class is always the critical class.",
      "Is this always the case in real-world applications? In the multi-class setting with many classes, classifying each class into critical and non-critical seems to be difficult and needs domain knowledge.",
      "If a critical class is misdefined as a non-critical class, this might be problematic for many applications.",
      "The setting of class ratios in CIFAR experiments seems unrealistic (e.g., a clinical dataset with 200 healthy patients and 1 sick patient).",
      "Is it because the method can only have good improvement on such a very imbalanced ratio?",
      "I suggest the author to either show improvement on CIFAR with smaller ratios (e.g., 1:5, 1:10) or find a real-world medical application that has such a class ratio close to 1:100.",
      "A slightly longer description of MBAUC, such as the framework it uses or other ways in which it differs from the proposed method, would be useful.",
      "I think you mean non-convergence?",
      "It would be useful to include a citation for the claim in Section 4.1 that \u2018Satisfying the constraint would directly ensure maximal AUC.\u2019",
      "Given the precise setup of the line plot I think that it would be useful for the grid axes to go from [0, 5], rather than [0, 1].",
      "What is the justification for CIFAR10 and CIFAR100 to use validation sets that have 100 samples per class?",
      "Why is this not also class-imbalanced?",
      "I find the tables difficult to read.",
      "First, when the original loss function achieves a lower FPR / higher test AUC than the ALM-optimization version, I think those results should be bolded for clarity.",
      "Given the quantity of bolded results, it is also difficult to distinguish the underlines of \u201cbest result\u201d, particularly when it is not one of the bolded entries.",
      "Avg AUCs in table 3 have large standard deviation, which might not indicate significant improvement.",
      "I didn\u2019t understand why the entry for ALM_{m, 1} + LDAM [Acc. Critical Class 1] was not bolded in table A5.",
      "The details of the multi-class classification experiment were not fully explained in the paper.",
      "Specifically, I was not fully clear that there was only one critical class (and multiple non-critical classes) in this problem formulation until Section A.4.",
      "I wish the authors provided slightly more discussion about the actual results, including why the ALM helped more with some methods than others.",
      "This wasn\u2019t the case on the MRI dataset -- is this due to an easier problem (lower FPR/higher TPR to begin with)? Weaker requirements on TPR? Less extreme class imbalances?",
      "I would appreciate some kind of study on the impact of class imbalance ratios to the improvement attributed to the ALM optimization.",
      "Showing the % improvement by incorporating ALM would also be a useful plot to include somewhere, and might be more readable than the tables.",
      "Tables A"
    ]
  },
  {
    "paper_id": "2106.12915v4",
    "submission_id": "urrcVI-_jRm",
    "submission_title": "Numerical influence of ReLU\u2019(0) on backpropagation",
    "review_id": "_iDjFadQl7V",
    "input": {
      "title": "Numerical influence of ReLU\u2019(0) on backpropagation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors empirically prove that the numerical choice of the non-smooth activation function's gradient can affect the training behavior.\n- I guess this is not surprising for half-precision training since 16 bit has a much smaller representation range than single-precision values.\n- The paper is well-organized and well-written with a clear structure.\n- The topic of this paper is quite interesting and can inspire more fellow research.\n- The experiments evaluate relevant aspects, e.g. precision bit-width, optimizer, BN, etc.\n- Paper is neat and well-written.\n- No large-scale experiments like ImageNet are conducted.\n- I'd like to see the impact of network architectures. For example, will ResNet outperform VGG-Net in terms of this stability of the non-smooth activation function?\n- Can the authors provide more examples of non-smooth activation and compare the results.",
    "review_points_list": [
      "The authors empirically prove that the numerical choice of the non-smooth activation function's gradient can affect the training behavior.",
      "I guess this is not surprising for half-precision training since 16 bit has a much smaller representation range than single-precision values.",
      "The paper is well-organized and well-written with a clear structure.",
      "The topic of this paper is quite interesting and can inspire more fellow research.",
      "The experiments evaluate relevant aspects, e.g. precision bit-width, optimizer, BN, etc.",
      "Paper is neat and well-written.",
      "No large-scale experiments like ImageNet are conducted.",
      "I'd like to see the impact of network architectures. For example, will ResNet outperform VGG-Net in terms of this stability of the non-smooth activation function?",
      "Can the authors provide more examples of non-smooth activation and compare the results."
    ]
  },
  {
    "paper_id": "2106.12915v4",
    "submission_id": "urrcVI-_jRm",
    "submission_title": "Numerical influence of ReLU\u2019(0) on backpropagation",
    "review_id": "pvDQF4pts9",
    "input": {
      "title": "Numerical influence of ReLU\u2019(0) on backpropagation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think this is a good paper and such a study has been overdue.\n- The authors may considering the paper https://arxiv.org/pdf/1905.04992.pdf which performs a mathematical analysis of related issues.",
    "review_points_list": [
      "I think this is a good paper and such a study has been overdue.",
      "The authors may considering the paper https://arxiv.org/pdf/1905.04992.pdf which performs a mathematical analysis of related issues."
    ]
  },
  {
    "paper_id": "2106.12915v4",
    "submission_id": "urrcVI-_jRm",
    "submission_title": "Numerical influence of ReLU\u2019(0) on backpropagation",
    "review_id": "Nj110P1DY-i",
    "input": {
      "title": "Numerical influence of ReLU\u2019(0) on backpropagation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors have addressed my main concern on significance, namely that learning rate was not tuned for non-zero derivative settings. Conditioned on having the learning rate and number of training epochs tuned for each setting in section 4 (and other changes discussed in the rebuttal, e.g. the one on expected number of evaluations), I have raised the score from 5 to 7 and recommend accept, since I find it novel and potentially impactful that this setting has a strong influence not only on trainability, but also on generalization.\n- Overall, I found this to be an interesting investigation with a surprising result. However, I am leaning to reject this paper due to (1) minimal qualitative / theoretical analysis or explanations of the observed phenomena (see section \"Quality\"), and (2) potentially flawed experimental setting to evaluate the impact of ReLU'(0) on training and test performance (see section \"Significance\"). I can see how the former",
    "review_points_list": [
      "The authors have addressed my main concern on significance, namely that learning rate was not tuned for non-zero derivative settings. Conditioned on having the learning rate and number of training epochs tuned for each setting in section 4 (and other changes discussed in the rebuttal, e.g. the one on expected number of evaluations), I have raised the score from 5 to 7 and recommend accept, since I find it novel and potentially impactful that this setting has a strong influence not only on trainability, but also on generalization.",
      "Overall, I found this to be an interesting investigation with a surprising result. However, I am leaning to reject this paper due to (1) minimal qualitative / theoretical analysis or explanations of the observed phenomena (see section \"Quality\"), and (2) potentially flawed experimental setting to evaluate the impact of ReLU'(0) on training and test performance (see section \"Significance\"). I can see how the former"
    ]
  },
  {
    "paper_id": "2106.12915v4",
    "submission_id": "urrcVI-_jRm",
    "submission_title": "Numerical influence of ReLU\u2019(0) on backpropagation",
    "review_id": "5haw4F5RPSD",
    "input": {
      "title": "Numerical influence of ReLU\u2019(0) on backpropagation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The author does a good job explaining the theory and experiments associated with the study of the impact of ReLU'[0].\n- The challenge in my view is the following:\n- The studies seemed to indicate that the default values of ReLU'[0] = 0 seem to yield the best accuracy results! Therefore, its hard to see how the outcome of this work would be in general useful to neural network (and framework) designers.\n- The authors describe the proportion difference % between the different precisions. Can the authors comment on the final model accuracy difference for the different precisions for the different datasets. If there is no substantial difference in accuracy between the different precisions (as is indeed expected), then can the authors comment on why this result is important?\n- In general, it'd be good to study this effect on larger models and datasets (e.g. ResNet50 or EfficientNetBx on ImageNet) - to see if this effect results in any noticeable difference in accuracy and to see if there are better optimal values for ReLU'[0]?\n- Do the authors have results on other discontinuities besides ReLU'[0]? For e.g. one would expect ReLU[6] (used in MobileNets) to have a discontinuity at 0 and 6?",
    "review_points_list": [
      "The author does a good job explaining the theory and experiments associated with the study of the impact of ReLU'[0].",
      "The challenge in my view is the following:",
      "The studies seemed to indicate that the default values of ReLU'[0] = 0 seem to yield the best accuracy results! Therefore, its hard to see how the outcome of this work would be in general useful to neural network (and framework) designers.",
      "The authors describe the proportion difference % between the different precisions. Can the authors comment on the final model accuracy difference for the different precisions for the different datasets. If there is no substantial difference in accuracy between the different precisions (as is indeed expected), then can the authors comment on why this result is important?",
      "In general, it'd be good to study this effect on larger models and datasets (e.g. ResNet50 or EfficientNetBx on ImageNet) - to see if this effect results in any noticeable difference in accuracy and to see if there are better optimal values for ReLU'[0]?",
      "Do the authors have results on other discontinuities besides ReLU'[0]? For e.g. one would expect ReLU[6] (used in MobileNets) to have a discontinuity at 0 and 6?"
    ]
  },
  {
    "paper_id": "2111.01177v2",
    "submission_id": "waWmZSw0mn",
    "submission_title": "Don\u2019t Generate Me: Training Differentially Private Generative Models with Sinkhorn Divergence",
    "review_id": "FEZPH76Ynof",
    "input": {
      "title": "Don\u2019t Generate Me: Training Differentially Private Generative Models with Sinkhorn Divergence",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The choice of optimizing semi-debiased Sinkhorn loss is, to the best of my knowledge, novel.\n- The task itself (differentially private generative models) and techniques (gradient clipping + adding Gaussian noise) are well-known in the literature.\n- The authors do an adequate job of surveying related work, their exposition as to other methods could be significantly improved in the experiments section (Table 1).\n- It's not clear exactly how the objectives and training procedures differ between these methods and those proposed by the authors.\n- A quick summary of how these other algorithms work would be beneficial so as to better understand the contributions of their paper.\n- The submission is technically sound.\n- The proofs appear to be correct, although I was not able to verify them in precise detail.\n- The methods used in evaluation seem appropriate, although it would be helpful to the reader if the author's provided confidence intervals for the results in table 1 to get a better sense of the variance in these methods.\n- The paper is for the most part well written.\n- While their methods do appear to provide some improvement on MNIST and CelebA, these datasets are relatively low dimensional and it would be valuable to understand how the procedures introduced in this paper perform in more complicated settings.\n- Given that the theoretical contributions are based on standard applications of DP tools, the overall impact of the work seems to me like it hinges on the quality of the empirical results.\n- To this end, I would have liked to see experiments in a wider variety of domains to be better convinced of the impact that these ideas will have in practice.",
    "review_points_list": [
      "The choice of optimizing semi-debiased Sinkhorn loss is, to the best of my knowledge, novel.",
      "The task itself (differentially private generative models) and techniques (gradient clipping + adding Gaussian noise) are well-known in the literature.",
      "The authors do an adequate job of surveying related work, their exposition as to other methods could be significantly improved in the experiments section (Table 1).",
      "It's not clear exactly how the objectives and training procedures differ between these methods and those proposed by the authors.",
      "A quick summary of how these other algorithms work would be beneficial so as to better understand the contributions of their paper.",
      "The submission is technically sound.",
      "The proofs appear to be correct, although I was not able to verify them in precise detail.",
      "The methods used in evaluation seem appropriate, although it would be helpful to the reader if the author's provided confidence intervals for the results in table 1 to get a better sense of the variance in these methods.",
      "The paper is for the most part well written.",
      "While their methods do appear to provide some improvement on MNIST and CelebA, these datasets are relatively low dimensional and it would be valuable to understand how the procedures introduced in this paper perform in more complicated settings.",
      "Given that the theoretical contributions are based on standard applications of DP tools, the overall impact of the work seems to me like it hinges on the quality of the empirical results.",
      "To this end, I would have liked to see experiments in a wider variety of domains to be better convinced of the impact that these ideas will have in practice."
    ]
  },
  {
    "paper_id": "2111.01177v2",
    "submission_id": "waWmZSw0mn",
    "submission_title": "Don\u2019t Generate Me: Training Differentially Private Generative Models with Sinkhorn Divergence",
    "review_id": "a7EqVmVlQC",
    "input": {
      "title": "Don\u2019t Generate Me: Training Differentially Private Generative Models with Sinkhorn Divergence",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The experimental results are strong (improving over existing DP strategies for synthetic data), although evaluated on small datasets.\n- I'm a bit surprised that the classifier performance on MNIST is so bad, when even at somewhat small epsilon values, just because of how easy MNIST is.\n- Being able to avoid noising G' is nice.\n- The authors put a solid amount of effort into ablation to justify their strategy.\n- Epsilon is really large - the typical way of justifying this is showing that privacy attacks are not effective - could you do this here?\n- I have seen, for example, membership inference being run on discriminators to test the privacy of generative models.\n- The l_1 and l_2 losses are pretty simple for image data; I have seen perceptual distance used in place of these for image generation.\n- I'd be interested in seeing results on non-ML images, e.g. medical image datasets or medical records. This seems to be fairly standard in the DP synthetic data literature.\n- Overall, I am happy with the paper.\n- I'm not super familiar with the generative model literature, but it seems to take a known nonprivate technique and apply it, overcoming challenges that pop up.",
    "review_points_list": [
      "The experimental results are strong (improving over existing DP strategies for synthetic data), although evaluated on small datasets.",
      "I'm a bit surprised that the classifier performance on MNIST is so bad, when even at somewhat small epsilon values, just because of how easy MNIST is.",
      "Being able to avoid noising G' is nice.",
      "The authors put a solid amount of effort into ablation to justify their strategy.",
      "Epsilon is really large - the typical way of justifying this is showing that privacy attacks are not effective - could you do this here?",
      "I have seen, for example, membership inference being run on discriminators to test the privacy of generative models.",
      "The l_1 and l_2 losses are pretty simple for image data; I have seen perceptual distance used in place of these for image generation.",
      "I'd be interested in seeing results on non-ML images, e.g. medical image datasets or medical records. This seems to be fairly standard in the DP synthetic data literature.",
      "Overall, I am happy with the paper.",
      "I'm not super familiar with the generative model literature, but it seems to take a known nonprivate technique and apply it, overcoming challenges that pop up."
    ]
  },
  {
    "paper_id": "2111.01177v2",
    "submission_id": "waWmZSw0mn",
    "submission_title": "Don\u2019t Generate Me: Training Differentially Private Generative Models with Sinkhorn Divergence",
    "review_id": "_KDIInkMvoD",
    "input": {
      "title": "Don\u2019t Generate Me: Training Differentially Private Generative Models with Sinkhorn Divergence",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think this is a potentially interesting idea, and I believe there is a lot of value to pursuing non-adversarial techniques for DP generative models.\n- The idea of using sinkhorn divergence to (non-adversarially) train a generative model appears to be new, to the best of my knowledge.\n- My main concern is that the proposed generative model simply doesn\u2019t work very well in the non-private setting, as evidenced by its poor FID scores.\n- This seems to suggest that there is no hope of making this approach ever have \u201cgood enough\u201d fidelity to compete with non-DP data.\n- That being said, Sinkhorn-DP does seem to have slightly better FID and prediction accuracy than the many competing baselines, so that is an interesting observation.\n- Though the difference is not large compared to, say, GS-WGAN. So when we\u2019re talking about FID scores that in the hundreds, I would have ideally liked to see a more substantial improvement over the state-of-the-art scores.\n- Technically, I found the ideas in this paper to be a bit limited.\n- The approach is heuristic, and there is no fundamental reason this approach should work better, other than getting rid of adversarial training.\n- The Sinkhorn-DP approach seems to be very sensitive to hyperparameters as shown in the evaluation, and it is only evaluated on small-scale datasets.\n- The theoretical claims are limited to proving DP of the scheme, which follows trivially from the construction.\n- So in terms of contribution, I am not sure this paper deepens our understanding of how to improve DP generative models.\n- That being said, it does appear to give (modest) gains over SOTA.\n- I was not able to understand a few details of the approach from the paper:\n- Def. 4.1 \u2013 how is the cost matrix C_AB defined, and what is its intuitive meaning?\n- What is the Sinkhorn Algorithm used to compute P_AB, and why isn\u2019t W_\u03bb(X, X)=0?\n- Algorithm 1: Why do you clip grad(X[n:n+n\u2019]) if you are not adding DP noise?\n- What is the meaning of the categories 0,\u2026, L?\n- Are you assuming labelled data and conditional generation?\n- If so, this isn\u2019t described in the problem setup\u2026\n- In contrast, only a single generator network is trained in DP-Sinkhorn, making our approach more amenable to various hardware configurations -> do you mean a single discriminator?",
    "review_points_list": [
      "I think this is a potentially interesting idea, and I believe there is a lot of value to pursuing non-adversarial techniques for DP generative models.",
      "The idea of using sinkhorn divergence to (non-adversarially) train a generative model appears to be new, to the best of my knowledge.",
      "My main concern is that the proposed generative model simply doesn\u2019t work very well in the non-private setting, as evidenced by its poor FID scores.",
      "This seems to suggest that there is no hope of making this approach ever have \u201cgood enough\u201d fidelity to compete with non-DP data.",
      "That being said, Sinkhorn-DP does seem to have slightly better FID and prediction accuracy than the many competing baselines, so that is an interesting observation.",
      "Though the difference is not large compared to, say, GS-WGAN. So when we\u2019re talking about FID scores that in the hundreds, I would have ideally liked to see a more substantial improvement over the state-of-the-art scores.",
      "Technically, I found the ideas in this paper to be a bit limited.",
      "The approach is heuristic, and there is no fundamental reason this approach should work better, other than getting rid of adversarial training.",
      "The Sinkhorn-DP approach seems to be very sensitive to hyperparameters as shown in the evaluation, and it is only evaluated on small-scale datasets.",
      "The theoretical claims are limited to proving DP of the scheme, which follows trivially from the construction.",
      "So in terms of contribution, I am not sure this paper deepens our understanding of how to improve DP generative models.",
      "That being said, it does appear to give (modest) gains over SOTA.",
      "I was not able to understand a few details of the approach from the paper:",
      "Def. 4.1 \u2013 how is the cost matrix C_AB defined, and what is its intuitive meaning?",
      "What is the Sinkhorn Algorithm used to compute P_AB, and why isn\u2019t W_\u03bb(X, X)=0?",
      "Algorithm 1: Why do you clip grad(X[n:n+n\u2019]) if you are not adding DP noise?",
      "What is the meaning of the categories 0,\u2026, L?",
      "Are you assuming labelled data and conditional generation?",
      "If so, this isn\u2019t described in the problem setup\u2026",
      "In contrast, only a single generator network is trained in DP-Sinkhorn, making our approach more amenable to various hardware configurations -> do you mean a single discriminator?"
    ]
  },
  {
    "paper_id": "2111.01177v2",
    "submission_id": "waWmZSw0mn",
    "submission_title": "Don\u2019t Generate Me: Training Differentially Private Generative Models with Sinkhorn Divergence",
    "review_id": "I4fu7V9OIu5",
    "input": {
      "title": "Don\u2019t Generate Me: Training Differentially Private Generative Models with Sinkhorn Divergence",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I found the paper to be confusing in terms of what it is arguing its main contributions are.\n- The paper casts itself as a contribution in privacy-preserving generative models, but there is not really any novelty in the DP domain as existing privacy mechanisms are used to achieve DP in the same way they are used for existing DP GANs and related models.\n- Rather, the primary novelty is that the authors have proposed the \"semi-debiased\" Sinkhorn loss, compared to the debiased Sinkhorn loss, but it's not clear what this has to do with privacy - and if this does represent a significant improvement, the paper does not dedicate much theory or experiments in attempting to understand its improvement (why the semi-debiased version is better in a general, non-private context).\n- This same confusion extends to the experimental results. While the results appear strong, the only included baselines are other DP generative models so it's unclear why the performance is better (is the underlying model just better in a non-private context so it remains better even after DP is added?). This confusion makes it difficult to judge the novelty and significance.\n- It seems there are 3 possibilities: 1) the paper is arguing OT-based generative models are better in general than GANs so they remain better when coupled with standard DP mechanisms; 2) the paper is arguing that the \"semi-debiased\" Sinkhorn loss significantly improves over the debiased Sinkhorn loss and that's what's responsible for the gains (making privacy a secondary thought); 3) the paper is arguing there is something specific about the semd-debiased Sinkhorn related to privacy that causes it to perform better (compared to other Sinkhorn losses) when coupled with DP mechanisms. I'm not sure which the paper is intending to argue and what the primary support would be for the claim.\n- I also found the claim that DP-Sinkhorn \"avoids the need for early stopping\" strange since this does not appear to be something specific to adversarial learning.\n- Finally, the writing in section 4.2 should be more clear and explicit since it's describing the main contribution, e.g. X' is never defined. It still remains unclear to me why the performance should be that different by simply splitting the batch rather than sample from the generator twice.",
    "review_points_list": [
      "I found the paper to be confusing in terms of what it is arguing its main contributions are.",
      "The paper casts itself as a contribution in privacy-preserving generative models, but there is not really any novelty in the DP domain as existing privacy mechanisms are used to achieve DP in the same way they are used for existing DP GANs and related models.",
      "Rather, the primary novelty is that the authors have proposed the \"semi-debiased\" Sinkhorn loss, compared to the debiased Sinkhorn loss, but it's not clear what this has to do with privacy - and if this does represent a significant improvement, the paper does not dedicate much theory or experiments in attempting to understand its improvement (why the semi-debiased version is better in a general, non-private context).",
      "This same confusion extends to the experimental results. While the results appear strong, the only included baselines are other DP generative models so it's unclear why the performance is better (is the underlying model just better in a non-private context so it remains better even after DP is added?). This confusion makes it difficult to judge the novelty and significance.",
      "It seems there are 3 possibilities: 1) the paper is arguing OT-based generative models are better in general than GANs so they remain better when coupled with standard DP mechanisms; 2) the paper is arguing that the \"semi-debiased\" Sinkhorn loss significantly improves over the debiased Sinkhorn loss and that's what's responsible for the gains (making privacy a secondary thought); 3) the paper is arguing there is something specific about the semd-debiased Sinkhorn related to privacy that causes it to perform better (compared to other Sinkhorn losses) when coupled with DP mechanisms. I'm not sure which the paper is intending to argue and what the primary support would be for the claim.",
      "I also found the claim that DP-Sinkhorn \"avoids the need for early stopping\" strange since this does not appear to be something specific to adversarial learning.",
      "Finally, the writing in section 4.2 should be more clear and explicit since it's describing the main contribution, e.g. X' is never defined. It still remains unclear to me why the performance should be that different by simply splitting the batch rather than sample from the generator twice."
    ]
  },
  {
    "paper_id": "2111.01177v2",
    "submission_id": "waWmZSw0mn",
    "submission_title": "Don\u2019t Generate Me: Training Differentially Private Generative Models with Sinkhorn Divergence",
    "review_id": "jPw-WlDQU6g",
    "input": {
      "title": "Don\u2019t Generate Me: Training Differentially Private Generative Models with Sinkhorn Divergence",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- In Section 2, the authors briefly mentioned some of the existing DP-GAN methods based on DP-SGD or PATE. Many these techniques or new developed version of them are already applied noised on the gradient of the Wasserstein distance and handled instability of traditional GANs.\n- It is not clear how the proposed method is different from the state-of-the-art techniques. Maybe a good comparison between DP-Sinkhorn and DP-WGAN can better address this issue.\n- Please explain how DP-Sinkhorn can be applied on non-image data (e.g., tabular data) where both continues and categorical features exist. For GANs, there are several techniques that handle tabular data (e.g., CTGAN.)\n- Please provide more information about cross group and debiasing group and why noise is only added to the cross group?\n- One of the disadvantage of GAN models are the long training time. It would be great if the authors show the training time comparison between the proposed model and DP-GAN models.\n- In experimental results, why CelebA data is missing in table 1 (comparison results)?\n- Why for this dataset, the image size is reduced to 32*32?\n- How the model can handle large scale datasets (images with high resolution)?\n- Why Figure 3 does not include other benchmarks?\n- Please explain how the proposed model performs on imbalanced datasets and if it suffers from mode collapse similar to some traditional GAN models?",
    "review_points_list": [
      "In Section 2, the authors briefly mentioned some of the existing DP-GAN methods based on DP-SGD or PATE. Many these techniques or new developed version of them are already applied noised on the gradient of the Wasserstein distance and handled instability of traditional GANs.",
      "It is not clear how the proposed method is different from the state-of-the-art techniques. Maybe a good comparison between DP-Sinkhorn and DP-WGAN can better address this issue.",
      "Please explain how DP-Sinkhorn can be applied on non-image data (e.g., tabular data) where both continues and categorical features exist. For GANs, there are several techniques that handle tabular data (e.g., CTGAN.)",
      "Please provide more information about cross group and debiasing group and why noise is only added to the cross group?",
      "One of the disadvantage of GAN models are the long training time. It would be great if the authors show the training time comparison between the proposed model and DP-GAN models.",
      "In experimental results, why CelebA data is missing in table 1 (comparison results)?",
      "Why for this dataset, the image size is reduced to 32*32?",
      "How the model can handle large scale datasets (images with high resolution)?",
      "Why Figure 3 does not include other benchmarks?",
      "Please explain how the proposed model performs on imbalanced datasets and if it suffers from mode collapse similar to some traditional GAN models?"
    ]
  },
  {
    "paper_id": "2106.01429v2",
    "submission_id": "vnHjsF7NSMw",
    "submission_title": "Smooth Bilevel Programming for Sparse Regularization",
    "review_id": "LoGQLRTYpBr",
    "input": {
      "title": "Smooth Bilevel Programming for Sparse Regularization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- In general, the paper is well-written and easy to read (although there are some typos, see below).\n- The authors propose a new algorithm and demonstrate in experiments its versatility for a diverse set of problems.\n- I clearly see the strengths of the paper on the empirical side.\n- As the algorithm is new and appears to work well compared to a large class of existing algorithms on a wide set of problems (as it has been examined thoroughly in the paper), I would recommend acceptance.\n- I feel that the results on the theoretical side are a bit weaker.\n- The authors cite Lee et al., which guarantees convergence from almost every starting point.\n- However, it is known this convergence guarantee does not give any rates.\n- (In particular, the convergence might take exponentially long in the accuracy.)\n- Hence, it is not so clear what the impact is of the theoretical results\n- I feel that this should be pointed out by the authors.\n- Of course, it might be interesting to have some bounds on the computational complexity of the presented algorithm (or on the convergence rate), but I feel that it might be difficult to derive those (especially in the very general setting as presented in this paper).\n- Can one derive such bounds in the setting where for example $R (\beta) = \beta_{\text{l}_1} $?\n- It could be interesting if the authors could comment on these issues in their paper.\n- Questions: - In l. 238 the authors define Non-cvx-LBFGS. How is this algorithm different to Noncvx-Pro. Is it not exactly the same? What am I missing?\n- The authors motivate their algorithm by IRLS. It is known that IRLS works especially well in the non-convex case, i.e. one consider the $\beta_{\text{l}_p} $-norm with $p<1$. Have the authors compared their algorithm to the non-convex IRLS formulation?\n- Nitpicks: - l. 11: minima->minimum\n- l. 66 detail->detailed\n- l. 180 approach(es)\n- l. 185 global minimums->minima",
    "review_points_list": [
      "In general, the paper is well-written and easy to read (although there are some typos, see below).",
      "The authors propose a new algorithm and demonstrate in experiments its versatility for a diverse set of problems.",
      "I clearly see the strengths of the paper on the empirical side.",
      "As the algorithm is new and appears to work well compared to a large class of existing algorithms on a wide set of problems (as it has been examined thoroughly in the paper), I would recommend acceptance.",
      "I feel that the results on the theoretical side are a bit weaker.",
      "The authors cite Lee et al., which guarantees convergence from almost every starting point.",
      "However, it is known this convergence guarantee does not give any rates.",
      "(In particular, the convergence might take exponentially long in the accuracy.)",
      "Hence, it is not so clear what the impact is of the theoretical results",
      "I feel that this should be pointed out by the authors.",
      "Of course, it might be interesting to have some bounds on the computational complexity of the presented algorithm (or on the convergence rate), but I feel that it might be difficult to derive those (especially in the very general setting as presented in this paper).",
      "Can one derive such bounds in the setting where for example $R (\beta) = \beta_{\text{l}_1} $?",
      "It could be interesting if the authors could comment on these issues in their paper.",
      "Questions: - In l. 238 the authors define Non-cvx-LBFGS. How is this algorithm different to Noncvx-Pro. Is it not exactly the same? What am I missing?",
      "The authors motivate their algorithm by IRLS. It is known that IRLS works especially well in the non-convex case, i.e. one consider the $\beta_{\text{l}_p} $-norm with $p<1$. Have the authors compared their algorithm to the non-convex IRLS formulation?",
      "Nitpicks: - l. 11: minima->minimum",
      "l. 66 detail->detailed",
      "l. 180 approach(es)",
      "l. 185 global minimums->minima"
    ]
  },
  {
    "paper_id": "2106.01429v2",
    "submission_id": "vnHjsF7NSMw",
    "submission_title": "Smooth Bilevel Programming for Sparse Regularization",
    "review_id": "RY28rVM6R9Y",
    "input": {
      "title": "Smooth Bilevel Programming for Sparse Regularization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- To the best of my knowledge, the described approach to reformulate and reparametrize the regularized objective is novel.\n- I find the presented idea interesting because the smoothed objective allows for applying efficient algorithms like L-BFGS.\n- The reported numerical results indicate that the method is competitive and especially robust with respect to the choice of the regularization parameter.\n- The manuscript is technically correct.\n- The authors provide extensive supplementary material.\n- I think that the scope of the paper is limited to linear models and a few specific (although common) regularizers,\n- There exist a variety of solvers that can handle these kind of problems.\n- Although I think that this is basically a good paper, I am not sure whether it will gain high significance.",
    "review_points_list": [
      "To the best of my knowledge, the described approach to reformulate and reparametrize the regularized objective is novel.",
      "I find the presented idea interesting because the smoothed objective allows for applying efficient algorithms like L-BFGS.",
      "The reported numerical results indicate that the method is competitive and especially robust with respect to the choice of the regularization parameter.",
      "The manuscript is technically correct.",
      "The authors provide extensive supplementary material.",
      "I think that the scope of the paper is limited to linear models and a few specific (although common) regularizers,",
      "There exist a variety of solvers that can handle these kind of problems.",
      "Although I think that this is basically a good paper, I am not sure whether it will gain high significance."
    ]
  },
  {
    "paper_id": "2106.01429v2",
    "submission_id": "vnHjsF7NSMw",
    "submission_title": "Smooth Bilevel Programming for Sparse Regularization",
    "review_id": "MNFxUcnFPmX",
    "input": {
      "title": "Smooth Bilevel Programming for Sparse Regularization",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well written and clear.\n- It showcases impressive speedups thanks to the proposed reparametrization for a variety of problems.\n- It takes an unusual route, by examining how a non-smooth convex problem can be written as a smooth, non-convex problem without spurious saddles.\n- The proposed method shows strong results, in particular ones which are robust across different problems.\n- The proposed reparametrization is elegant and seems efficient.\n- It is directly applicable to sparse linear models which are very much used in practice.\n- It is easy to implement, since it relies on readily available smooth optimizers + linear solvers.\n- The method would also directly benefit from improvement in these types of solvers.",
    "review_points_list": [
      "The paper is well written and clear.",
      "It showcases impressive speedups thanks to the proposed reparametrization for a variety of problems.",
      "It takes an unusual route, by examining how a non-smooth convex problem can be written as a smooth, non-convex problem without spurious saddles.",
      "The proposed method shows strong results, in particular ones which are robust across different problems.",
      "The proposed reparametrization is elegant and seems efficient.",
      "It is directly applicable to sparse linear models which are very much used in practice.",
      "It is easy to implement, since it relies on readily available smooth optimizers + linear solvers.",
      "The method would also directly benefit from improvement in these types of solvers."
    ]
  },
  {
    "paper_id": "2110.15497v4",
    "submission_id": "tu5Wg41hWl_",
    "submission_title": "Unsupervised Foreground Extraction via Deep Region Competition",
    "review_id": "8aOyBrLuiVk",
    "input": {
      "title": "Unsupervised Foreground Extraction via Deep Region Competition",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think the proposed method is of some novelty and may be insightful for the community.\n- It has also shown superior performance on 5 challenging datasets.\n- My major concern on this paper is clarity.\n- It is hard for me to fully understand the description.\n- Instead of directly going into the technical details, I suggest the authors first provide a high-level overview of the task as well as the proposed method,\n- and explain what are the important components of this method, what are their functions, how are they incorporated and learned?\n- By doing so, the authors can further claim which part of the method is their unique design, and what are the advantages or differences to prior methods.\n- In the methodology sections, I do not understand how to achieve pixel re-assignment,\n- and what is its relationship to the proposed method.\n- In the experiment section, it is not clear what is the input resolution and how long does it take to train/test the proposed method.\n- The authors claim to provide limitations in section 4.1. I cannot find detailed discussions.\n- Please provide in-depth discussions on the limitation of this work and potential solutions.",
    "review_points_list": [
      "I think the proposed method is of some novelty and may be insightful for the community.",
      "It has also shown superior performance on 5 challenging datasets.",
      "My major concern on this paper is clarity.",
      "It is hard for me to fully understand the description.",
      "Instead of directly going into the technical details, I suggest the authors first provide a high-level overview of the task as well as the proposed method,",
      "and explain what are the important components of this method, what are their functions, how are they incorporated and learned?",
      "By doing so, the authors can further claim which part of the method is their unique design, and what are the advantages or differences to prior methods.",
      "In the methodology sections, I do not understand how to achieve pixel re-assignment,",
      "and what is its relationship to the proposed method.",
      "In the experiment section, it is not clear what is the input resolution and how long does it take to train/test the proposed method.",
      "The authors claim to provide limitations in section 4.1. I cannot find detailed discussions.",
      "Please provide in-depth discussions on the limitation of this work and potential solutions."
    ]
  },
  {
    "paper_id": "2110.15497v4",
    "submission_id": "tu5Wg41hWl_",
    "submission_title": "Unsupervised Foreground Extraction via Deep Region Competition",
    "review_id": "dXSyzBD8g5L",
    "input": {
      "title": "Unsupervised Foreground Extraction via Deep Region Competition",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This work is an application of an existing modeling technique (LEBM) to an existing task (unsupervised foreground segmentation). To my knowledge, the combination however is novel.\n- It is made clear in the paper, to which degree the approach is adapted from previous work and which components are contributed with this work.\n- The paper does not contain a related work section. Instead, some relations to previous work are discussed in the introduction, and some in the method section (L184-191). In my view, discussing previous works to provide context for the current work is an integral part of every scientific article and deserves to be discussed in a separate section with greater detail.\n- The derivation of the model and its training procedure is described in great detail, and technically sound to me.\n- The information given in the main paper is sufficient to comprehend the model and experiments, further details about the datasets, hyperparameters and model training are provided in-depth in the supplemental information.\n- The model is compared with previous approaches on five datasets, including datasets with natural images.\n- An ablation study is performed to judge the contribution of every modeling component.\n- In the main results on the segmentation performance (Table 1), the models are however evaluated on the training set.\n- Only in Table 3 when evaluating the generalizability, a subset of the models is evaluated on a separate test set for a subset of the datasets.\n- Testing on held out samples should also be the norm for unsupervised methods, since overfitting might also happen in this case.\n- Ideally, the same information would be given in Table 1, but using separate test sets.\n- If evaluating on the training set is required for comparing to previous methods, this should be made explicit and featured less prominently.\n- The paper only shows and evaluates reconstructions (including the segmentation mask) of images, but no samples from the model.\n- While not strictly necessary for the target task of foreground-background segmentation, in my view this is still necessary to fully understand the modelling approach in this setting.\n- The authors propose a generative model, which is derived with the goal of fitting the data distribution, but do not directly evaluate to which degree the model succeeds in that respect.\n- Evaluating and/or showing samples from the model would be a means to obtain more insights into this.\n- The paper and supplement are very well written.\n- The derivation of the model and the experiments are well described, and the necessary concepts from previous works briefly introduced.\n- My main criticism is about the missing related work section (see above).\n- Foreground-background segmentation is a classical task in computer vision with several applications, and using unsupervised models has many practical advantages.\n- This model is therefore relevant to both researchers and practitioners in that field.\n- Compared to more general segmentation approaches as, e.g. semantic or instance segmentation, the applicability of the model is limited in practice.\n- From the perspective of applying this method, the paper would profit from a discussion of the real world relevance of unsupervised foreground-background segmentation in the introduction.\n- Interest in unsupervised methods in computer vision has increased in recent years.\n- Structured latent-space models are one particular area with much recent interest, often under the umbrella term 'object-centric representation learning'.\n- Mostly this is approached by using GAN or VAE-based models.\n- The successful demonstration of a different generative method for foreground-background modelling is very interesting and might well inspire further research in that field.\n- From the perspective of this field, the present work however has two important limitations:\n- As shown in the supplemental material, the modelling approach in its current form is not able to model multiple objects well, which is one of the core challenges in that field.\n- The model is not able to handle appearances well, as opposed to the masks.\n- Overall my concerns have been addressed, especially regarding the related work.\n- Therefore I improve my rating of this paper accordingly.\n- In summary I think this is a good paper, however I still see some minor points where this paper could be improved further.\n- This decision is justified to be able to compare to previous methods, and the proposed model is additionally tested on held-out data.\n- In my view the paper could however be improved further by restructuring the result presentation to push more towards proper evaluation.",
    "review_points_list": [
      "This work is an application of an existing modeling technique (LEBM) to an existing task (unsupervised foreground segmentation). To my knowledge, the combination however is novel.",
      "It is made clear in the paper, to which degree the approach is adapted from previous work and which components are contributed with this work.",
      "The paper does not contain a related work section. Instead, some relations to previous work are discussed in the introduction, and some in the method section (L184-191). In my view, discussing previous works to provide context for the current work is an integral part of every scientific article and deserves to be discussed in a separate section with greater detail.",
      "The derivation of the model and its training procedure is described in great detail, and technically sound to me.",
      "The information given in the main paper is sufficient to comprehend the model and experiments, further details about the datasets, hyperparameters and model training are provided in-depth in the supplemental information.",
      "The model is compared with previous approaches on five datasets, including datasets with natural images.",
      "An ablation study is performed to judge the contribution of every modeling component.",
      "In the main results on the segmentation performance (Table 1), the models are however evaluated on the training set.",
      "Only in Table 3 when evaluating the generalizability, a subset of the models is evaluated on a separate test set for a subset of the datasets.",
      "Testing on held out samples should also be the norm for unsupervised methods, since overfitting might also happen in this case.",
      "Ideally, the same information would be given in Table 1, but using separate test sets.",
      "If evaluating on the training set is required for comparing to previous methods, this should be made explicit and featured less prominently.",
      "The paper only shows and evaluates reconstructions (including the segmentation mask) of images, but no samples from the model.",
      "While not strictly necessary for the target task of foreground-background segmentation, in my view this is still necessary to fully understand the modelling approach in this setting.",
      "The authors propose a generative model, which is derived with the goal of fitting the data distribution, but do not directly evaluate to which degree the model succeeds in that respect.",
      "Evaluating and/or showing samples from the model would be a means to obtain more insights into this.",
      "The paper and supplement are very well written.",
      "The derivation of the model and the experiments are well described, and the necessary concepts from previous works briefly introduced.",
      "My main criticism is about the missing related work section (see above).",
      "Foreground-background segmentation is a classical task in computer vision with several applications, and using unsupervised models has many practical advantages.",
      "This model is therefore relevant to both researchers and practitioners in that field.",
      "Compared to more general segmentation approaches as, e.g. semantic or instance segmentation, the applicability of the model is limited in practice.",
      "From the perspective of applying this method, the paper would profit from a discussion of the real world relevance of unsupervised foreground-background segmentation in the introduction.",
      "Interest in unsupervised methods in computer vision has increased in recent years.",
      "Structured latent-space models are one particular area with much recent interest, often under the umbrella term 'object-centric representation learning'.",
      "Mostly this is approached by using GAN or VAE-based models.",
      "The successful demonstration of a different generative method for foreground-background modelling is very interesting and might well inspire further research in that field.",
      "From the perspective of this field, the present work however has two important limitations:",
      "As shown in the supplemental material, the modelling approach in its current form is not able to model multiple objects well, which is one of the core challenges in that field.",
      "The model is not able to handle appearances well, as opposed to the masks.",
      "Overall my concerns have been addressed, especially regarding the related work.",
      "Therefore I improve my rating of this paper accordingly.",
      "In summary I think this is a good paper, however I still see some minor points where this paper could be improved further.",
      "This decision is justified to be able to compare to previous methods, and the proposed model is additionally tested on held-out data.",
      "In my view the paper could however be improved further by restructuring the result presentation to push more towards proper evaluation."
    ]
  },
  {
    "paper_id": "2502.10050v1",
    "submission_id": "zO6Q8q2AmbV",
    "submission_title": "On Component Interactions in Two-Stage Recommender Systems",
    "review_id": "C6w-ZXzG9g",
    "input": {
      "title": "On Component Interactions in Two-Stage Recommender Systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This work targets at looking for two-stage specific properties, an interesting topic for the audience in the area of online large scale information system.\n- Empirical and theoretical observations well motivate its research problem.\n- Literature review is well embedded in the body of this submission.\n- Since this work focus on recommender system. My main concern is what are the differences between RS and others.\n- The mentioned ranker and nominator are also existed in some information systems like Q&A, Web search, sentence matching, and so on.\n- Without clearly addressing those differences, readers may feel that the current version can be applied mechanically to other IS.\n- Back to RS, there are various benchmark datasets. The reason of selecting \u201cAmazonCat-13K\u201d is not known.\n- Experiments are conducted on review texts, so if only using rating scores, does it have different effects on the current findings?\n- The way to define two-stage RS is based on the bandit based approach. The reason and its advantages should be further addressed.",
    "review_points_list": [
      "This work targets at looking for two-stage specific properties, an interesting topic for the audience in the area of online large scale information system.",
      "Empirical and theoretical observations well motivate its research problem.",
      "Literature review is well embedded in the body of this submission.",
      "Since this work focus on recommender system. My main concern is what are the differences between RS and others.",
      "The mentioned ranker and nominator are also existed in some information systems like Q&A, Web search, sentence matching, and so on.",
      "Without clearly addressing those differences, readers may feel that the current version can be applied mechanically to other IS.",
      "Back to RS, there are various benchmark datasets. The reason of selecting \u201cAmazonCat-13K\u201d is not known.",
      "Experiments are conducted on review texts, so if only using rating scores, does it have different effects on the current findings?",
      "The way to define two-stage RS is based on the bandit based approach. The reason and its advantages should be further addressed."
    ]
  },
  {
    "paper_id": "2502.10050v1",
    "submission_id": "zO6Q8q2AmbV",
    "submission_title": "On Component Interactions in Two-Stage Recommender Systems",
    "review_id": "Hcs0lVTkZJK",
    "input": {
      "title": "On Component Interactions in Two-Stage Recommender Systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The idea of being able to do combined optimization on the rankers and candidate generators together is extremely useful.\n- The authors proposed solution to use MOE model to create multiple candidate/item pool (nominators) specialized on different sub-tasks and final ranker to select the best candidate can find a lot of applications.\n- The authors have given extensive explanation with solid theoretical proof for their proposed solution.\n- They have presented a thorough study of different components in their system and how it effects the final stage performance of the ranker.\n- The evaluations presented in the paper support the author\u2019s claims and observations.\n- However, the paper is not extremely easy to read especially the experimental setup could have been better explained,\n- and I have listed down some opportunities the authors could have presented better.\n- There is no evaluation against any Learning to rank models, extremely popular with the two stage recommendation systems.\n- Their main performance comparison is against single stage performance, but the setup for that evaluation/theoretical justification remains the same (EE based system).\n- The related work section can be better explored.",
    "review_points_list": [
      "The idea of being able to do combined optimization on the rankers and candidate generators together is extremely useful.",
      "The authors proposed solution to use MOE model to create multiple candidate/item pool (nominators) specialized on different sub-tasks and final ranker to select the best candidate can find a lot of applications.",
      "The authors have given extensive explanation with solid theoretical proof for their proposed solution.",
      "They have presented a thorough study of different components in their system and how it effects the final stage performance of the ranker.",
      "The evaluations presented in the paper support the author\u2019s claims and observations.",
      "However, the paper is not extremely easy to read especially the experimental setup could have been better explained,",
      "and I have listed down some opportunities the authors could have presented better.",
      "There is no evaluation against any Learning to rank models, extremely popular with the two stage recommendation systems.",
      "Their main performance comparison is against single stage performance, but the setup for that evaluation/theoretical justification remains the same (EE based system).",
      "The related work section can be better explored."
    ]
  },
  {
    "paper_id": "2502.10050v1",
    "submission_id": "zO6Q8q2AmbV",
    "submission_title": "On Component Interactions in Two-Stage Recommender Systems",
    "review_id": "yIRfYAwuK6t",
    "input": {
      "title": "On Component Interactions in Two-Stage Recommender Systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper studies on the properties of the two-stage recommendation architecture.\n- It is an interesting and under-explored topic.\n- Both empirical and theoretical analyses are conducted to validate the importance of pool allocation on recommendation performance.\n- The authors further propose to learn pool allocation with MOE strategy, which yields empirical improvement over the random pool allocation.\n- The analyses are based on some strong assumptions, which may not be consistent with the setting of real-world two-stage recommendation system.\n- In real-world RS, we usually use complex model (e.g. MF, FM, DeepFM) instead of simple linear model;\n- Also, each nominator may return a list of items rather than single item;\n- What\u2019s more serious, the assigned pool of nominators in real-world RS usually covers all items (ie. A_n=A). I do not understand why we need pool allocation in this scenario.\n- The proof of Proposition 2 is not complete.\n- The proof is on the specific case with two nominators and three items, which lacks generalization.\n- Some important concepts lack clear interpretation, making the paper hard to follow.\n- For example, what does \u2018context distribution\u2019 mean? Does it mean \\pi(x), or mean the distribution of x over the items in the pool?\n- Also, in figure 2, what does \u2018 G\u2019 or \u2018U\u2019 mean? Does it mean one-stage recommender?\n- Insufficient motivation of using MOE.\n- We do agree that learning pool allocation is promising.\n- But whether MOE can learn a proper allocation is questionable.\n- More concretely, we do not understand why the weights returned by the MOE is a useful signal for pool allocation.\n- The authors should give more deep analyses on MOE and explain why MOE is so special for pool allocation.\n- In summary, although this paper studies an interesting and important problem, it has some serious limitations in terms of presentation and theoretical soundness.\n- As such, I think this paper is potential but this version is not touch the bar of NIPS.",
    "review_points_list": [
      "This paper studies on the properties of the two-stage recommendation architecture.",
      "It is an interesting and under-explored topic.",
      "Both empirical and theoretical analyses are conducted to validate the importance of pool allocation on recommendation performance.",
      "The authors further propose to learn pool allocation with MOE strategy, which yields empirical improvement over the random pool allocation.",
      "The analyses are based on some strong assumptions, which may not be consistent with the setting of real-world two-stage recommendation system.",
      "In real-world RS, we usually use complex model (e.g. MF, FM, DeepFM) instead of simple linear model;",
      "Also, each nominator may return a list of items rather than single item;",
      "What\u2019s more serious, the assigned pool of nominators in real-world RS usually covers all items (ie. A_n=A). I do not understand why we need pool allocation in this scenario.",
      "The proof of Proposition 2 is not complete.",
      "The proof is on the specific case with two nominators and three items, which lacks generalization.",
      "Some important concepts lack clear interpretation, making the paper hard to follow.",
      "For example, what does \u2018context distribution\u2019 mean? Does it mean \\pi(x), or mean the distribution of x over the items in the pool?",
      "Also, in figure 2, what does \u2018 G\u2019 or \u2018U\u2019 mean? Does it mean one-stage recommender?",
      "Insufficient motivation of using MOE.",
      "We do agree that learning pool allocation is promising.",
      "But whether MOE can learn a proper allocation is questionable.",
      "More concretely, we do not understand why the weights returned by the MOE is a useful signal for pool allocation.",
      "The authors should give more deep analyses on MOE and explain why MOE is so special for pool allocation.",
      "In summary, although this paper studies an interesting and important problem, it has some serious limitations in terms of presentation and theoretical soundness.",
      "As such, I think this paper is potential but this version is not touch the bar of NIPS."
    ]
  },
  {
    "paper_id": "2502.10050v1",
    "submission_id": "zO6Q8q2AmbV",
    "submission_title": "On Component Interactions in Two-Stage Recommender Systems",
    "review_id": "cDw_zAHTqs8",
    "input": {
      "title": "On Component Interactions in Two-Stage Recommender Systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors agree that there's a lack of research devoted to two-stage recommenders.\n- There are many reports from different companies on the use-cases where two-stage systems provide more advantages over standalone monolithic solutions.\n- This observation is also supported by various recsys challenges where two-stage solutions are demonstrated to provide highly competitive results.\n- Hence, attempts to better understand their internals and working mechanics are more than welcomed.\n- The work provides good theoretical grounds for the considered cases within the specified constraints and nicely connects it to experimental part.\n- It would be great to see (at least at high level) some connections to other approaches, e.g. when ranker is based on Decision Trees and nominator is based on matrix factorization, which is a very popular setup.\n- An abstract creates an impression of a general solution, while only the case of bandits is considered.\n- The work should be modified to be more clearly positioned and define its boundaries.\n- In Section 3.1, the synthetic dataset is generated under the assumption that context follows normal distribution.\n- In almost all practical cases, items in recommender systems follow power law or zipf-like distributions, which, I believe, would contradict to the described assumption.\n- It's not clear how this would affect further derivations and provided intuitions.\n- Describing how different assumptions on the nature of contexts may affect the theoretical and/or experimental results of this work would help to better understand its practicality.\n- The data preprocessing part also seems to deviate from real scenarios.\n- E.g., in Section 4 (lines 273-275): why sampling based on label frequency is performed?\n- How does it affect distribution of data?\n- How it relates to the assumptions on data used in theoretical part?\n- What is the connection to real world datasets?\n- Please, add more details on the reasons for the described preprocessing.",
    "review_points_list": [
      "The authors agree that there's a lack of research devoted to two-stage recommenders.",
      "There are many reports from different companies on the use-cases where two-stage systems provide more advantages over standalone monolithic solutions.",
      "This observation is also supported by various recsys challenges where two-stage solutions are demonstrated to provide highly competitive results.",
      "Hence, attempts to better understand their internals and working mechanics are more than welcomed.",
      "The work provides good theoretical grounds for the considered cases within the specified constraints and nicely connects it to experimental part.",
      "It would be great to see (at least at high level) some connections to other approaches, e.g. when ranker is based on Decision Trees and nominator is based on matrix factorization, which is a very popular setup.",
      "An abstract creates an impression of a general solution, while only the case of bandits is considered.",
      "The work should be modified to be more clearly positioned and define its boundaries.",
      "In Section 3.1, the synthetic dataset is generated under the assumption that context follows normal distribution.",
      "In almost all practical cases, items in recommender systems follow power law or zipf-like distributions, which, I believe, would contradict to the described assumption.",
      "It's not clear how this would affect further derivations and provided intuitions.",
      "Describing how different assumptions on the nature of contexts may affect the theoretical and/or experimental results of this work would help to better understand its practicality.",
      "The data preprocessing part also seems to deviate from real scenarios.",
      "E.g., in Section 4 (lines 273-275): why sampling based on label frequency is performed?",
      "How does it affect distribution of data?",
      "How it relates to the assumptions on data used in theoretical part?",
      "What is the connection to real world datasets?",
      "Please, add more details on the reasons for the described preprocessing."
    ]
  },
  {
    "paper_id": "2104.05418v2",
    "submission_id": "txWfwhc6gi",
    "submission_title": "Contrastive Learning of Global and Local Video Representations",
    "review_id": "YDzWOvQav6",
    "input": {
      "title": "Contrastive Learning of Global and Local Video Representations",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Please go ahead and provide the review!",
    "review_points_list": [
      "Please go ahead and provide the review!"
    ]
  },
  {
    "paper_id": "2104.05418v2",
    "submission_id": "txWfwhc6gi",
    "submission_title": "Contrastive Learning of Global and Local Video Representations",
    "review_id": "Dx8de9lZD4",
    "input": {
      "title": "Contrastive Learning of Global and Local Video Representations",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is clear and well written. The different parts of the model are well motivated and it is easy for follow and understand the reason behind the design decisions.\n- The idea of introducing explicitly the notion of fine-grained spatiotemporal information in contrastive learning is interesting and novel.\n- Authors execution of the idea is simple but effective, building the two losses consistently with their goals.\n- In my opinion, new methods for self-supervised learning will start considering more granular information, following the direction of this paper.\n- Authors ablate all the relevant decisions, which to me is interesting and shows the importance and effect of the two losses used in the model.\n- I like how looking at Table 5 you can extract the main conclusions in the paper.\n- Authors also present qualitative results of the attention between the audio and the video modality.\n- The results are consistent with the goal of the attention layer (highlight the areas in the video with relevant audio-visual correlation).\n- The model is evaluated for very different tasks (lip reading, deepfake detection and classification) which is good for the reader to understand better the properties of the model.\n- I am missing linear evaluation for some of the video classification tasks.\n- It is hard to evaluate the quality of the features by only looking at the fine-tuning performance where all the network is updated on the downstream task.\n- I am missing larger action classification datasets such as Kinetics-400.\n- I believe having additional evaluation performances in this datasets would help the readers understand a bit better the strengths of the features.\n- I would be curious to know how this model would scale using larger scale dataset such as AudioSet.\n- One question to answer would be if this performance improvement is only present for smaller datasets but goes away when using more data.\n- I think it would be good if authors can answer this question.\n- Although I understand that some papers cannot be directly comparable, I think it would be worth for the authors to at least report performances for some of the models trained on different architectures or datasets.\n- I think it is important for the reader to put the quantitative performance on perspective to all the works on the topic.\n- Some examples of this would be reporting XDC or GDT when trained in AudioSet or reporting performance of MMV.\n- Authors ablate very well all the design decisions.\n- However, I am curious about whether it is necessary to have such a large negative pool for the S-Global / T-local loss.\n- I wonder if authors can evaluate that by just sampling some of the negatives at each iteration.",
    "review_points_list": [
      "The paper is clear and well written. The different parts of the model are well motivated and it is easy for follow and understand the reason behind the design decisions.",
      "The idea of introducing explicitly the notion of fine-grained spatiotemporal information in contrastive learning is interesting and novel.",
      "Authors execution of the idea is simple but effective, building the two losses consistently with their goals.",
      "In my opinion, new methods for self-supervised learning will start considering more granular information, following the direction of this paper.",
      "Authors ablate all the relevant decisions, which to me is interesting and shows the importance and effect of the two losses used in the model.",
      "I like how looking at Table 5 you can extract the main conclusions in the paper.",
      "Authors also present qualitative results of the attention between the audio and the video modality.",
      "The results are consistent with the goal of the attention layer (highlight the areas in the video with relevant audio-visual correlation).",
      "The model is evaluated for very different tasks (lip reading, deepfake detection and classification) which is good for the reader to understand better the properties of the model.",
      "I am missing linear evaluation for some of the video classification tasks.",
      "It is hard to evaluate the quality of the features by only looking at the fine-tuning performance where all the network is updated on the downstream task.",
      "I am missing larger action classification datasets such as Kinetics-400.",
      "I believe having additional evaluation performances in this datasets would help the readers understand a bit better the strengths of the features.",
      "I would be curious to know how this model would scale using larger scale dataset such as AudioSet.",
      "One question to answer would be if this performance improvement is only present for smaller datasets but goes away when using more data.",
      "I think it would be good if authors can answer this question.",
      "Although I understand that some papers cannot be directly comparable, I think it would be worth for the authors to at least report performances for some of the models trained on different architectures or datasets.",
      "I think it is important for the reader to put the quantitative performance on perspective to all the works on the topic.",
      "Some examples of this would be reporting XDC or GDT when trained in AudioSet or reporting performance of MMV.",
      "Authors ablate very well all the design decisions.",
      "However, I am curious about whether it is necessary to have such a large negative pool for the S-Global / T-local loss.",
      "I wonder if authors can evaluate that by just sampling some of the negatives at each iteration."
    ]
  },
  {
    "paper_id": "2104.05418v2",
    "submission_id": "txWfwhc6gi",
    "submission_title": "Contrastive Learning of Global and Local Video Representations",
    "review_id": "50xF4E9VQ_z",
    "input": {
      "title": "Contrastive Learning of Global and Local Video Representations",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well motivated.\n- The authors recognise an important problem and present an effective way of solving it.\n- However, the key training method (e.g. sampling method for negatives) overlap strongly with Nagrani et al.[1] which is not cited in the paper.\n- The authors should give a clear summary of the different between this paper and theirs.\n- I may change my rating based on this.\n- The experiments are very thorough and convincing.\n- The ablation studies are good.\n- The paper is well written.",
    "review_points_list": [
      "The paper is well motivated.",
      "The authors recognise an important problem and present an effective way of solving it.",
      "However, the key training method (e.g. sampling method for negatives) overlap strongly with Nagrani et al.[1] which is not cited in the paper.",
      "The authors should give a clear summary of the different between this paper and theirs.",
      "I may change my rating based on this.",
      "The experiments are very thorough and convincing.",
      "The ablation studies are good.",
      "The paper is well written."
    ]
  },
  {
    "paper_id": "2405.20380v1",
    "submission_id": "x9jS8pX3dkx",
    "submission_title": "Gradient Inversion with Generative Image Prior",
    "review_id": "EcVi90VepzF",
    "input": {
      "title": "Gradient Inversion with Generative Image Prior",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper proposes GIAS and GIML with improvements from baseline methods, while it might be better to provide more support on their effectiveness.\n- This paper compares the proposed GIAS with several other methods thoroughly via experiments.\n- While I wonder if there are more theoretical justifications behind the effectiveness of the proposed searching mechanism in the latent and model parameter spaces.\n- On the other hand, how is the generalizability of GIML for more complex tasks?\n- As 32x32 qualitative examples shown in Figure 4, there are substantial gaps between the reconstructions and the ground truths.",
    "review_points_list": [
      "This paper proposes GIAS and GIML with improvements from baseline methods, while it might be better to provide more support on their effectiveness.",
      "This paper compares the proposed GIAS with several other methods thoroughly via experiments.",
      "While I wonder if there are more theoretical justifications behind the effectiveness of the proposed searching mechanism in the latent and model parameter spaces.",
      "On the other hand, how is the generalizability of GIML for more complex tasks?",
      "As 32x32 qualitative examples shown in Figure 4, there are substantial gaps between the reconstructions and the ground truths."
    ]
  },
  {
    "paper_id": "2405.20380v1",
    "submission_id": "x9jS8pX3dkx",
    "submission_title": "Gradient Inversion with Generative Image Prior",
    "review_id": "FVEQRqRmIDz",
    "input": {
      "title": "Gradient Inversion with Generative Image Prior",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think this work is a reasonable improvement of gradient inversion attacks against federated learning.\n- The idea to utilize prior knowledge via generative models is good and executed well.\n- I would like to see a larger discussion of [23] (Wang et al., Beyond Inferring Class Representatives) in the related work section, which is an older work in the gradient inversion literature, but also involves training a GAN to aid in the reconstruction (although not quite in the way the authors describe here, but it would be good to delineate the differences of both approaches explicitly)\n- To a lesser degree this comment also applies to works such as [Hitaj et al, Deep Models Under the GAN: Information Leakage from Collaborative Deep Learning]\n- In [9] (Geiping et al, Inverting Gradients), small prior effects are noticed when considering GI-x reconstruction from the gradients of trained models\n- For the given submission I am not quite clear whether the authors consider a randomly initialized ResNet-18 model are a trained model\n- In any case, does the beneficial effect of the generative model increase or decrease when switching from random to trained parameters?\n- Feedback from practitioners of federated learning about gradient attacks has often focussed on the perceived security of larger image batches (via e.g secure aggregation) and gradient noise (as main component of differential privacy)\n- It would be great if the authors could plot the success of the proposed reconstruction approach (possibly in the best-PSNR case) over a large range of batch sizes (up to 48 or even 128?) and gradient noise levels\n- This would be an extension of Fig.3",
    "review_points_list": [
      "I think this work is a reasonable improvement of gradient inversion attacks against federated learning.",
      "The idea to utilize prior knowledge via generative models is good and executed well.",
      "I would like to see a larger discussion of [23] (Wang et al., Beyond Inferring Class Representatives) in the related work section, which is an older work in the gradient inversion literature, but also involves training a GAN to aid in the reconstruction (although not quite in the way the authors describe here, but it would be good to delineate the differences of both approaches explicitly)",
      "To a lesser degree this comment also applies to works such as [Hitaj et al, Deep Models Under the GAN: Information Leakage from Collaborative Deep Learning]",
      "In [9] (Geiping et al, Inverting Gradients), small prior effects are noticed when considering GI-x reconstruction from the gradients of trained models",
      "For the given submission I am not quite clear whether the authors consider a randomly initialized ResNet-18 model are a trained model",
      "In any case, does the beneficial effect of the generative model increase or decrease when switching from random to trained parameters?",
      "Feedback from practitioners of federated learning about gradient attacks has often focussed on the perceived security of larger image batches (via e.g secure aggregation) and gradient noise (as main component of differential privacy)",
      "It would be great if the authors could plot the success of the proposed reconstruction approach (possibly in the best-PSNR case) over a large range of batch sizes (up to 48 or even 128?) and gradient noise levels",
      "This would be an extension of Fig.3"
    ]
  },
  {
    "paper_id": "2405.20380v1",
    "submission_id": "x9jS8pX3dkx",
    "submission_title": "Gradient Inversion with Generative Image Prior",
    "review_id": "DnUPoNSL-rs",
    "input": {
      "title": "Gradient Inversion with Generative Image Prior",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors seem to decompose (3) into (6) and (8). With algorithm 1, only (8) is satisfied.\n- The z_i's solved by (6) no longer minimize (3) given the solutions in (8).\n- Clarification of why algorithm 1 is the desired method should be stated here.\n- What is used as the real image data here?\n- Who is doing the gradient inversion in the scenario of federated learning?\n- If the server is inverting the gradient, does that mean the server need to store a public dataset?\n- Moreover, if the public dataset distribution is highly heterogeneous with the local data distribution, what would the performance be?\n- The experiment results would significantly improve if the relation between performance and heterogeneity level is presented.",
    "review_points_list": [
      "The authors seem to decompose (3) into (6) and (8). With algorithm 1, only (8) is satisfied.",
      "The z_i's solved by (6) no longer minimize (3) given the solutions in (8).",
      "Clarification of why algorithm 1 is the desired method should be stated here.",
      "What is used as the real image data here?",
      "Who is doing the gradient inversion in the scenario of federated learning?",
      "If the server is inverting the gradient, does that mean the server need to store a public dataset?",
      "Moreover, if the public dataset distribution is highly heterogeneous with the local data distribution, what would the performance be?",
      "The experiment results would significantly improve if the relation between performance and heterogeneity level is presented."
    ]
  },
  {
    "paper_id": "2405.20380v1",
    "submission_id": "x9jS8pX3dkx",
    "submission_title": "Gradient Inversion with Generative Image Prior",
    "review_id": "H0kGzOMDsYS",
    "input": {
      "title": "Gradient Inversion with Generative Image Prior",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper provides a sufficient description of prior work.\n- Some sentences used in the paper are not clear or have errors.\n- Lines 53-55\n- Line 66: propose should be proposed\n- Is BN in Line 73 Batch Norm? This needs to be made clear.\n- Lines 75-77\n- Lines 94-96\n- Lines 265-266\n- To my knowledge, the paper assumes that the classifier $f_\theta$ is known (or at least the architecture on $f_\theta$ is known). Is this a valid and reasonable assumption in practice?\n- Is there anything we can say about the number of gradients we need to accurately recover/estimate the dataset. For the case when the generative model is not known, is it in the order of $k$ (the latent code dimension)? What about when the generative model is known? A discussion would be helpful.\n- What is the motivation for line 11 in Algorithm 2.\n- In practice, how does one assume the architecture of the generative model if such a model is not known a prior?",
    "review_points_list": [
      "The paper provides a sufficient description of prior work.",
      "Some sentences used in the paper are not clear or have errors.",
      "Lines 53-55",
      "Line 66: propose should be proposed",
      "Is BN in Line 73 Batch Norm? This needs to be made clear.",
      "Lines 75-77",
      "Lines 94-96",
      "Lines 265-266",
      "To my knowledge, the paper assumes that the classifier $f_\theta$ is known (or at least the architecture on $f_\theta$ is known). Is this a valid and reasonable assumption in practice?",
      "Is there anything we can say about the number of gradients we need to accurately recover/estimate the dataset. For the case when the generative model is not known, is it in the order of $k$ (the latent code dimension)? What about when the generative model is known? A discussion would be helpful.",
      "What is the motivation for line 11 in Algorithm 2.",
      "In practice, how does one assume the architecture of the generative model if such a model is not known a prior?"
    ]
  },
  {
    "paper_id": "2106.03894v3",
    "submission_id": "uJGObgFU0lU",
    "submission_title": "Differentiable Quality Diversity",
    "review_id": "YYfuRuVfy3",
    "input": {
      "title": "Differentiable Quality Diversity",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- You've revised your score from 7 to 8, following the author response.\n- The idea of DQD proposed by the paper is an intuitive and natural development combining ideas from QD with modern ML driven by first-order optimization.\n- The paper is extremely well-written, with a brief but useful explanation of the background, and the algorithms are carefully described in detail.\n- The DQD benchmark with StyleGAN-CLIP is quite intuitive and is bound to inspire some follow-up work.\n- The experimental evaluation is convincing, with the proposed algorithms demonstrating clear wins in high dimensional parameter spaces.\n- The experimental results are presented with a statistical significance analysis -- I commend the authors for this.\n- My first instinct upon looking at the problem would be to write down an optimization problem which trades-off the objective for diversity, e.g., maintain a catalog $\\theta_1, \\cdots, \\theta_N$ and iteratively update $\\theta_j$ with an approximate solution to $\\max_\\theta f(\\theta) + \\lambda \\sum_{i \\neq j} \\Vert m(\\theta) - m(\\theta_i)\\Vert^2$ where $\\lambda$ is a trade-off parameter.\n- How is the proposed approach better than this baseline?\n- MEGA takes one gradient step in Eq. (3).\n- What are the pros and cons of taking multiple gradient steps?\n- Would this help experimentally?\n- The proposed strategy to tune the learning rate in Appendix A does not seem scalable.\n- Could the authors suggest some heuristics to choose the learning rate?\n- How would a grid search work in this case?\n- How do you choose the noise variance $\\sigma_g^2$?\n- What happens if it is too large or too small?\n- It would be helpful if the authors could show plots with QD score and coverage percentage versus the learning rate and $\\sigma_g^2$\n- (minor) $w_i$ is undefined in Algorithm 1.",
    "review_points_list": [
      "You've revised your score from 7 to 8, following the author response.",
      "The idea of DQD proposed by the paper is an intuitive and natural development combining ideas from QD with modern ML driven by first-order optimization.",
      "The paper is extremely well-written, with a brief but useful explanation of the background, and the algorithms are carefully described in detail.",
      "The DQD benchmark with StyleGAN-CLIP is quite intuitive and is bound to inspire some follow-up work.",
      "The experimental evaluation is convincing, with the proposed algorithms demonstrating clear wins in high dimensional parameter spaces.",
      "The experimental results are presented with a statistical significance analysis -- I commend the authors for this.",
      "My first instinct upon looking at the problem would be to write down an optimization problem which trades-off the objective for diversity, e.g., maintain a catalog $\\theta_1, \\cdots, \\theta_N$ and iteratively update $\\theta_j$ with an approximate solution to $\\max_\\theta f(\\theta) + \\lambda \\sum_{i \\neq j} \\Vert m(\\theta) - m(\\theta_i)\\Vert^2$ where $\\lambda$ is a trade-off parameter.",
      "How is the proposed approach better than this baseline?",
      "MEGA takes one gradient step in Eq. (3).",
      "What are the pros and cons of taking multiple gradient steps?",
      "Would this help experimentally?",
      "The proposed strategy to tune the learning rate in Appendix A does not seem scalable.",
      "Could the authors suggest some heuristics to choose the learning rate?",
      "How would a grid search work in this case?",
      "How do you choose the noise variance $\\sigma_g^2$?",
      "What happens if it is too large or too small?",
      "It would be helpful if the authors could show plots with QD score and coverage percentage versus the learning rate and $\\sigma_g^2$",
      "(minor) $w_i$ is undefined in Algorithm 1."
    ]
  },
  {
    "paper_id": "2106.03894v3",
    "submission_id": "uJGObgFU0lU",
    "submission_title": "Differentiable Quality Diversity",
    "review_id": "nXPkVp3EaD",
    "input": {
      "title": "Differentiable Quality Diversity",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Both the problem setup and the proposed solutions are novel.\n- The setup itself is a non-trivial important special case of the previously studied Quality Diversity problem, eg, the use case in generative modeling has potential implications beyond just diverse face generation in other scientific fields as well.\n- The methods proposed in the work are sound, simple, and easy to implement.\n- I also liked their descriptions, which was sufficiently clear in text and aptly formalized mathematically.\n- In CMA-MEGA, could the authors study the effect of the ranking strategy on downstream performance? In particular, it is not obvious to me that prioritizing all exploration candidates over the delta improvements is a good defacto strategy.\n- If the delta improvement is very large, then deprioritizing it to explore a new cell is not ideal.\n- Similar to explore-exploit strategies in BayesOpt, RL algorithms, an acquisition function style approach to scalarize the exploration score and the delta improvement score seems like a better strategy.\n- In general, for the QD problem, we expect a Pareto optimal frontier of (max or top-m) QD score vs. coverage.\n- The results in Table 1 focus on a specific point on this frontier.\n- Can we tailor the algorithms to target a specific frontier?\n- i.e., for x% coverage, what is the best QD score we can obtain?\n- Or vice versa\n- Empirical trends of model performance as a function of number of cells would be interesting to include for testing the scalability of the approaches and also for monitoring the divergence in performance from a baseline gradient-only approach (at the extreme, when number of cells is 1, we only care about the target based objective and the gradient based approach is expected to dominate).\n- Latent space illumination is a very important problem and a very convincing motivation for this work.\n- But the empirical investigations seemed lacking.\n- While the authors acknowledge that the results are not very robust to hyperparameters, a further investigation as to analyzing the causes of instability and tricks to alleviate them would make the work more extendable by other practitioners.\n- The current set of results based on 1 Elon Musk prompt are too limited and potentially subject to cherry-picking.",
    "review_points_list": [
      "Both the problem setup and the proposed solutions are novel.",
      "The setup itself is a non-trivial important special case of the previously studied Quality Diversity problem, eg, the use case in generative modeling has potential implications beyond just diverse face generation in other scientific fields as well.",
      "The methods proposed in the work are sound, simple, and easy to implement.",
      "I also liked their descriptions, which was sufficiently clear in text and aptly formalized mathematically.",
      "In CMA-MEGA, could the authors study the effect of the ranking strategy on downstream performance? In particular, it is not obvious to me that prioritizing all exploration candidates over the delta improvements is a good defacto strategy.",
      "If the delta improvement is very large, then deprioritizing it to explore a new cell is not ideal.",
      "Similar to explore-exploit strategies in BayesOpt, RL algorithms, an acquisition function style approach to scalarize the exploration score and the delta improvement score seems like a better strategy.",
      "In general, for the QD problem, we expect a Pareto optimal frontier of (max or top-m) QD score vs. coverage.",
      "The results in Table 1 focus on a specific point on this frontier.",
      "Can we tailor the algorithms to target a specific frontier?",
      "i.e., for x% coverage, what is the best QD score we can obtain?",
      "Or vice versa",
      "Empirical trends of model performance as a function of number of cells would be interesting to include for testing the scalability of the approaches and also for monitoring the divergence in performance from a baseline gradient-only approach (at the extreme, when number of cells is 1, we only care about the target based objective and the gradient based approach is expected to dominate).",
      "Latent space illumination is a very important problem and a very convincing motivation for this work.",
      "But the empirical investigations seemed lacking.",
      "While the authors acknowledge that the results are not very robust to hyperparameters, a further investigation as to analyzing the causes of instability and tricks to alleviate them would make the work more extendable by other practitioners.",
      "The current set of results based on 1 Elon Musk prompt are too limited and potentially subject to cherry-picking."
    ]
  },
  {
    "paper_id": "2110.13752v1",
    "submission_id": "vLvsnP64VC0",
    "submission_title": "Dynamic Trace Estimation",
    "review_id": "dNYr16jozAd",
    "input": {
      "title": "Dynamic Trace Estimation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well-organized\n- I don't see any major flaws in the proofs\n- The idea of damped variance reduction is quite good\n- But I worry that setting of this paper is too specific\n- And is not very important for other types of problems",
    "review_points_list": [
      "The paper is well-organized",
      "I don't see any major flaws in the proofs",
      "The idea of damped variance reduction is quite good",
      "But I worry that setting of this paper is too specific",
      "And is not very important for other types of problems"
    ]
  },
  {
    "paper_id": "2110.13752v1",
    "submission_id": "vLvsnP64VC0",
    "submission_title": "Dynamic Trace Estimation",
    "review_id": "qlhrOYonj_H",
    "input": {
      "title": "Dynamic Trace Estimation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors' approach is innovative and provides a new perspective on this problem.\n- The paper is well-written and easy to follow.\n- The authors could improve the clarity of the",
    "review_points_list": [
      "The authors' approach is innovative and provides a new perspective on this problem.",
      "The paper is well-written and easy to follow.",
      "The authors could improve the clarity of the"
    ]
  },
  {
    "paper_id": "2110.13752v1",
    "submission_id": "vLvsnP64VC0",
    "submission_title": "Dynamic Trace Estimation",
    "review_id": "9mcUOPC7C6p",
    "input": {
      "title": "Dynamic Trace Estimation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This work proposes an efficient method for the dynamic trace estimation problem by utilizing well-known Hutchinson trace estimation and variance reduction technique (aka control variate).\n- The problem is quite fundamental so that it can be applied to various of practical tasks, e.g., triangle counting, Hessian spectral density estimation and so on.\n- The idea of Hutchinson estimator and variance reduction is not new and widely used in many problems involving computational issues, but the authors analyze with concrete theoretical results.\n- I think that dynamic trace estimation is somewhat related to greedy algorithm of the determinant maximization problem (aka MAP inference of Determinantal Point Processes).\n- Indeed, [1] tried to dynamically estimate log-determinant (polynomial version of Hutchinson estimator) and analyzed the variance of two distinct Hutchinson estimations when randomness is shared (see Theorem 2 in [1]).\n- More generally, it seems that the proposed method can combine with a polynomial to extend to more various essential problems.\n- [1] Han, Insu, et al. \"Faster greedy MAP inference for determinantal point processes.\" ICML, 2017.",
    "review_points_list": [
      "This work proposes an efficient method for the dynamic trace estimation problem by utilizing well-known Hutchinson trace estimation and variance reduction technique (aka control variate).",
      "The problem is quite fundamental so that it can be applied to various of practical tasks, e.g., triangle counting, Hessian spectral density estimation and so on.",
      "The idea of Hutchinson estimator and variance reduction is not new and widely used in many problems involving computational issues, but the authors analyze with concrete theoretical results.",
      "I think that dynamic trace estimation is somewhat related to greedy algorithm of the determinant maximization problem (aka MAP inference of Determinantal Point Processes).",
      "Indeed, [1] tried to dynamically estimate log-determinant (polynomial version of Hutchinson estimator) and analyzed the variance of two distinct Hutchinson estimations when randomness is shared (see Theorem 2 in [1]).",
      "More generally, it seems that the proposed method can combine with a polynomial to extend to more various essential problems.",
      "[1] Han, Insu, et al. \"Faster greedy MAP inference for determinantal point processes.\" ICML, 2017."
    ]
  },
  {
    "paper_id": "2110.13752v1",
    "submission_id": "vLvsnP64VC0",
    "submission_title": "Dynamic Trace Estimation",
    "review_id": "kprcik18Ryu",
    "input": {
      "title": "Dynamic Trace Estimation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think this is a nice algorithm based on a clean and simple idea that could lead to direct gains in some settings, e.g. estimating the trace of the hessian while training a neural network.\n- The key idea is to maintain a trace estimate of a moving (exponentially) weighted average of the matrices, and to estimate the trace of the difference at each step using the Hutchinston estimator.\n- A nicer baseline to compare against is a Hutchinston estimator that is restarted every $1/\\alpha$ iterations.\n- A few comments:\n- 1. ... \n- 2. ... \n- 3. ... ",
    "review_points_list": [
      "I think this is a nice algorithm based on a clean and simple idea that could lead to direct gains in some settings, e.g. estimating the trace of the hessian while training a neural network.",
      "The key idea is to maintain a trace estimate of a moving (exponentially) weighted average of the matrices, and to estimate the trace of the difference at each step using the Hutchinston estimator.",
      "A nicer baseline to compare against is a Hutchinston estimator that is restarted every $1/\\alpha$ iterations.",
      "A few comments:",
      "1. ... ",
      "2. ... ",
      "3. ... "
    ]
  },
  {
    "paper_id": "2102.09086v3",
    "submission_id": "vAMh-dcNMcR",
    "submission_title": "Consistent Non-Parametric Methods for Maximizing Robustness",
    "review_id": "uIov7f1jQJ5",
    "input": {
      "title": "Consistent Non-Parametric Methods for Maximizing Robustness",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors propose an alternative formulation of robust classification that ensures that in the large sample limit, there is no robustness-accuracy tradeoff, and that regions of space with higher separation are classified more robustly.\n- To this end, the authors introduce a new large-sample limit, the neighborhood preserving Bayes optimal (NPBO) classifier.\n- For an input x, it outputs the prediction of the Bayes Optimal on the nearest neighbor (including itself) in the support of the data distribution D.\n- They show that k_n-nearest neighbors converge to the NPBO provided k_n = \u03c9(log n), and kernel classifiers converge to the NPBO provided certain conditions\n- certain types of histogram classifiers do not converge to the NPBO, even if they do converge to the Bayes optimal.\n- They also provide experiments to validate their claims.\n- I feel this work is novel in motivation and solid in theory.\n- In Section 1, 'astuteness' is used without any citation in the first paragraph.\n- In Section 2, there are many conceptions that are existed in previous papers, but the authors did not mention or give references, for instance, Definition 1 'astute and astuteness', weight functions, histogram classfiers, etc.\n- Line 259: Conditions 2. and 3. are ..., conditions 2. and 3. of ... .  I think the period '.' is not needed after 2 and 3.\n- Line 144: We call this the the neighborhood preserving ...",
    "review_points_list": [
      "The authors propose an alternative formulation of robust classification that ensures that in the large sample limit, there is no robustness-accuracy tradeoff, and that regions of space with higher separation are classified more robustly.",
      "To this end, the authors introduce a new large-sample limit, the neighborhood preserving Bayes optimal (NPBO) classifier.",
      "For an input x, it outputs the prediction of the Bayes Optimal on the nearest neighbor (including itself) in the support of the data distribution D.",
      "They show that k_n-nearest neighbors converge to the NPBO provided k_n = \u03c9(log n), and kernel classifiers converge to the NPBO provided certain conditions",
      "certain types of histogram classifiers do not converge to the NPBO, even if they do converge to the Bayes optimal.",
      "They also provide experiments to validate their claims.",
      "I feel this work is novel in motivation and solid in theory.",
      "In Section 1, 'astuteness' is used without any citation in the first paragraph.",
      "In Section 2, there are many conceptions that are existed in previous papers, but the authors did not mention or give references, for instance, Definition 1 'astute and astuteness', weight functions, histogram classfiers, etc.",
      "Line 259: Conditions 2. and 3. are ..., conditions 2. and 3. of ... .  I think the period '.' is not needed after 2 and 3.",
      "Line 144: We call this the the neighborhood preserving ..."
    ]
  },
  {
    "paper_id": "2102.09086v3",
    "submission_id": "vAMh-dcNMcR",
    "submission_title": "Consistent Non-Parametric Methods for Maximizing Robustness",
    "review_id": "ZZ0dRd6XqKf",
    "input": {
      "title": "Consistent Non-Parametric Methods for Maximizing Robustness",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The main contribution of this paper is when the number of samples n goes toward infinity and consequently the true data distribution becomes known to the learner.\n- The most robust classifier which coincides with the Bayes optimal classifier inside the support would be trivial and easy to achieve\n- The paper gives a methodical approach so that some classes of non-paramteric classifiers (like k-nearest neighbor) can be computed for finite n, while are also guaranteed to converge to the trivial robust classifiers of n=infinity\n- The guarantees are all asymptotic in this work\n- There are some other contributions in proving the consistency of certain non-parametric classes of learners, which I assume to be additional results\n- The Introduction section needs improvement, especially with regard to the definition of terms like 'accuracy and astuteness'\n- Some motivations in the beginning of the paper have become lost and buried under tones of theorems and definitions inside the manuscript\n- The results do not seem to be aligned with the abstract's motif regarding varying radius of attacks r for different regions of the distribution\n- The paper lacks real-world justification for its main idea: Having robustness to out-of-distribution samples (for example, off-manifold data points which are usually the result of adversarial attacks) is interesting, but the discussions around this issue in the paper is slim to none\n- Why should any reader be concerned with samples like x which are not in the support of data distribution, i.e., xnotin supp(\u03bc)?\n- No non-asymptotic bounds have been proposed to guarantee any type of performance measure when the number of samples n is finite.\n- Any type of guarantees on the adversarial robustness when n is infinite and the true underlying data distribution (or at least the true data manifold) is revealed are not that much interesting\n- Would it be nice if authors can give some certificate for robustness when n is finite\n- Some of the cited works in this paper (Sinha et al., for example) have already done that for distributionally robust scenarios\n- The paper would benefit from a rewritten abstract and parts of the introduction section to better align with the paper's contents\n- The 'the' word has been repeated in Line 144",
    "review_points_list": [
      "The main contribution of this paper is when the number of samples n goes toward infinity and consequently the true data distribution becomes known to the learner.",
      "The most robust classifier which coincides with the Bayes optimal classifier inside the support would be trivial and easy to achieve",
      "The paper gives a methodical approach so that some classes of non-paramteric classifiers (like k-nearest neighbor) can be computed for finite n, while are also guaranteed to converge to the trivial robust classifiers of n=infinity",
      "The guarantees are all asymptotic in this work",
      "There are some other contributions in proving the consistency of certain non-parametric classes of learners, which I assume to be additional results",
      "The Introduction section needs improvement, especially with regard to the definition of terms like 'accuracy and astuteness'",
      "Some motivations in the beginning of the paper have become lost and buried under tones of theorems and definitions inside the manuscript",
      "The results do not seem to be aligned with the abstract's motif regarding varying radius of attacks r for different regions of the distribution",
      "The paper lacks real-world justification for its main idea: Having robustness to out-of-distribution samples (for example, off-manifold data points which are usually the result of adversarial attacks) is interesting, but the discussions around this issue in the paper is slim to none",
      "Why should any reader be concerned with samples like x which are not in the support of data distribution, i.e., xnotin supp(\u03bc)?",
      "No non-asymptotic bounds have been proposed to guarantee any type of performance measure when the number of samples n is finite.",
      "Any type of guarantees on the adversarial robustness when n is infinite and the true underlying data distribution (or at least the true data manifold) is revealed are not that much interesting",
      "Would it be nice if authors can give some certificate for robustness when n is finite",
      "Some of the cited works in this paper (Sinha et al., for example) have already done that for distributionally robust scenarios",
      "The paper would benefit from a rewritten abstract and parts of the introduction section to better align with the paper's contents",
      "The 'the' word has been repeated in Line 144"
    ]
  },
  {
    "paper_id": "2102.09086v3",
    "submission_id": "vAMh-dcNMcR",
    "submission_title": "Consistent Non-Parametric Methods for Maximizing Robustness",
    "review_id": "Bc3Yh5HPeKJ",
    "input": {
      "title": "Consistent Non-Parametric Methods for Maximizing Robustness",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper is very interesting, and a pleasure to read.\n- The limitation of current approaches to study adversarial robustness is clear from the presented concepts, and the proposed solutions are intuitive and elegant.\n- Can the authors comment, at least briefly, on the potential of extending the analysis of convergence rates of non-parametric classifiers (such as those in Doring et al, 2018) to the setting presented here?\n- In the paragraph on line 154, the authors motivate their definition of 'neighborhood preserving robustness regions'. To do so, they explain that they seek for regions U_x so that the astute accuracy of g_max equals the accuracy of the Bayes classifier. However, it's not totally clear what g_max is. Is it the one that maximizes the measure of U_x? A clarification would be appreciated.\n- On the paragraph following Theorem 5, the authors comment that g_neighbor can be thought of a local maximum to a constrained optimization problem. However, it is not clear why this is not a global maximum - how could one obtain a classifier with larger robustness constrained to having equal accuracy as the Bayes?\n- Lines 57: space missing on 'Instead [3]'\n- The paragraphs on line 71 and 78 feel a bit repetitive, given that the preceding paragraphs just gave a summary of the presented contributions.\n- Line 96: coma instead of semicolon?\n- Line 137: principal -> principle\n- Line 144: 'the the' -> ?\n- Line 171: the authors write 'max-margin Bayes' classifier, but I believe they mean the neighborhood preserving Bayes classifier? This might be equivalent, but has not been defined as 'max-margin' explicitely.\n- The notation of algorithm (A_S) and Accuracy is slightly confusing.\n- Line 222 'consistnecy' -> consistency\n- Line 222: 'needed accuracy' -> 'needed for accuracy'\n- On Corollary 12, the authors use the notation k_n^\\infty_1. There's a parenthesis that seems out of place. But also, this notation has not been defined?\n- On Corollary 13, the authors use h_n, but this seems undefined. Do they simply refer to the rule k_nn on the computed features?\n- Line 293: 'The answer this' -> the answer to this\n- Figure 3 seems to have some strange gray edges on its bottom and left sides.",
    "review_points_list": [
      "This paper is very interesting, and a pleasure to read.",
      "The limitation of current approaches to study adversarial robustness is clear from the presented concepts, and the proposed solutions are intuitive and elegant.",
      "Can the authors comment, at least briefly, on the potential of extending the analysis of convergence rates of non-parametric classifiers (such as those in Doring et al, 2018) to the setting presented here?",
      "In the paragraph on line 154, the authors motivate their definition of 'neighborhood preserving robustness regions'. To do so, they explain that they seek for regions U_x so that the astute accuracy of g_max equals the accuracy of the Bayes classifier. However, it's not totally clear what g_max is. Is it the one that maximizes the measure of U_x? A clarification would be appreciated.",
      "On the paragraph following Theorem 5, the authors comment that g_neighbor can be thought of a local maximum to a constrained optimization problem. However, it is not clear why this is not a global maximum - how could one obtain a classifier with larger robustness constrained to having equal accuracy as the Bayes?",
      "Lines 57: space missing on 'Instead [3]'",
      "The paragraphs on line 71 and 78 feel a bit repetitive, given that the preceding paragraphs just gave a summary of the presented contributions.",
      "Line 96: coma instead of semicolon?",
      "Line 137: principal -> principle",
      "Line 144: 'the the' -> ?",
      "Line 171: the authors write 'max-margin Bayes' classifier, but I believe they mean the neighborhood preserving Bayes classifier? This might be equivalent, but has not been defined as 'max-margin' explicitely.",
      "The notation of algorithm (A_S) and Accuracy is slightly confusing.",
      "Line 222 'consistnecy' -> consistency",
      "Line 222: 'needed accuracy' -> 'needed for accuracy'",
      "On Corollary 12, the authors use the notation k_n^\\infty_1. There's a parenthesis that seems out of place. But also, this notation has not been defined?",
      "On Corollary 13, the authors use h_n, but this seems undefined. Do they simply refer to the rule k_nn on the computed features?",
      "Line 293: 'The answer this' -> the answer to this",
      "Figure 3 seems to have some strange gray edges on its bottom and left sides."
    ]
  },
  {
    "paper_id": "2010.01279v3",
    "submission_id": "wxjtOI_8jO",
    "submission_title": "Do Wider Neural Networks Really Help Adversarial Robustness?",
    "review_id": "vilRlhisyc1",
    "input": {
      "title": "Do Wider Neural Networks Really Help Adversarial Robustness?",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- To the best of my knowledge, the contributions of this submission are original. Prior works have indicated that adversarial training performs better with models of larger capacity, but the authors explore the impact of increasing the model width and empirically and theoretically show that this is not necessarily the case.\n- The authors do a good job of citing related works.\n- The quality of the submission is good.\n- The authors provide theory as well as rigorous experiments to show that higher model width leads to lower perturbation stability and the need for a higher robust regularization value.\n- The scope of these experiments is good, the authors experiment with multiple architectures (WideResNet, DenseNet-BC) as well as different adversarial training techniques (TRADES, Adversarial Training), datasets (CIFAR-10, CIFAR-100, Imagenet), and different attack methods.\n- For the section where the authors introduce WAR, I can only see experiments on WideResNet and what I think is the CIFAR-10 dataset.\n- I think the authors can benefit by also extending these experiments to different architectures and datasets as well.\n- Overall the paper is clear, but the paper can be proofread for grammar.\n- try to use in text citations (\\citet{}) when using the citation as a subject or object in a sentence\n- I think the first paragraph under section 3.1 can be placed with related works\n- line 163: 'unlearned model' --> 'untrained model'\n- last sentence of 1: ... such that the learned models cannot be easily perturbed for the sake of model robustness --> this wording is awkward.\n- I think what is meant is that the models aren't fooled by small perturbations which in turn improves model robustness\n- 171-173: 'Works including [49] and [43] also challenged this robust-natural trade-off [59] does not hold for some cases' --> awkward wording and 'does not hold for some cases' is very vague and can be elaborated on\n- 173-174: 'Therefore, we argue ... of this trade-off'--> these 2 sentences should be 1 sentence joined by a comma\n- 179-180: 'Do they only help natural risk, to robust regularization, or maybe both of them.' --> should be combined with the previous sentence and should be a question\n- line 182: 'explains why the' --> 'illustrates how'\n- line 183: 'it still remains unclear what the underlying reasons are ...'\n- The results lead to a better understanding of how width impacts the robustness of neural networks.\n- The authors also propose WAR to finetune the robust regularization hyperparameter for models of larger width which maintains the same tuning time that is used in practice while improving robustness for these larger models.",
    "review_points_list": [
      "To the best of my knowledge, the contributions of this submission are original. Prior works have indicated that adversarial training performs better with models of larger capacity, but the authors explore the impact of increasing the model width and empirically and theoretically show that this is not necessarily the case.",
      "The authors do a good job of citing related works.",
      "The quality of the submission is good.",
      "The authors provide theory as well as rigorous experiments to show that higher model width leads to lower perturbation stability and the need for a higher robust regularization value.",
      "The scope of these experiments is good, the authors experiment with multiple architectures (WideResNet, DenseNet-BC) as well as different adversarial training techniques (TRADES, Adversarial Training), datasets (CIFAR-10, CIFAR-100, Imagenet), and different attack methods.",
      "For the section where the authors introduce WAR, I can only see experiments on WideResNet and what I think is the CIFAR-10 dataset.",
      "I think the authors can benefit by also extending these experiments to different architectures and datasets as well.",
      "Overall the paper is clear, but the paper can be proofread for grammar.",
      "try to use in text citations (\\citet{}) when using the citation as a subject or object in a sentence",
      "I think the first paragraph under section 3.1 can be placed with related works",
      "line 163: 'unlearned model' --> 'untrained model'",
      "last sentence of 1: ... such that the learned models cannot be easily perturbed for the sake of model robustness --> this wording is awkward.",
      "I think what is meant is that the models aren't fooled by small perturbations which in turn improves model robustness",
      "171-173: 'Works including [49] and [43] also challenged this robust-natural trade-off [59] does not hold for some cases' --> awkward wording and 'does not hold for some cases' is very vague and can be elaborated on",
      "173-174: 'Therefore, we argue ... of this trade-off'--> these 2 sentences should be 1 sentence joined by a comma",
      "179-180: 'Do they only help natural risk, to robust regularization, or maybe both of them.' --> should be combined with the previous sentence and should be a question",
      "line 182: 'explains why the' --> 'illustrates how'",
      "line 183: 'it still remains unclear what the underlying reasons are ...'",
      "The results lead to a better understanding of how width impacts the robustness of neural networks.",
      "The authors also propose WAR to finetune the robust regularization hyperparameter for models of larger width which maintains the same tuning time that is used in practice while improving robustness for these larger models."
    ]
  },
  {
    "paper_id": "2010.01279v3",
    "submission_id": "wxjtOI_8jO",
    "submission_title": "Do Wider Neural Networks Really Help Adversarial Robustness?",
    "review_id": "Bcx7B2zMANg",
    "input": {
      "title": "Do Wider Neural Networks Really Help Adversarial Robustness?",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think the paper is well written and gives a new perspective on adversarial training of wide networks.\n- The authors do a good job of exploring the topic from different directions.\n- Given a motivation why they suspect better tuned $lambda$ on wider models would help improve robustness.\n- Providing analytical insight through the Lipschitz constants.\n- Showing the improvement in robust accuracy through empirical results.\n- Proposing a method to automatically tune $lambda$ for wider models while training.\n- Some things that could be improved:\n- In line 64 and at later points the authors say that increasing the width of models while keeping $lambda$ constant would decrease the overall robustness.\n- I find this a bit inaccurate as robustness is usually looked at in terms of the robust accuracy and it (as the authors show in figure 3) usually increase with the width.\n- I think the authors should clarify that they mean the perturbation stability.\n- The authors in their analysis in section 4 show that $lambda$ should grow with $\root{mH}$ but don't use that later on.\n- Could this be an easier way to optimize $lambda$?\n- Some minor typos/nits:\n- Line 3 'it remains elusive how does neural network width affect model' should be 'it remains elusive how neural network width affects model'.\n- Line 45 same as above.\n- The notation in line 81-82 seems unnecessary.\n- The defined notation is very standard and other similarly standard notation isn't explained.\n- Line 84 'tremendous work' instead of 'tremendous works'.\n- Line 216 'increases with' instead of 'increases as'.\n- Line 264 '90-th epoch as in' instead of '90-th epoch in'.\n- This paper makes a valuable contribution to the field and I believe it's suitable for Neurips.",
    "review_points_list": [
      "I think the paper is well written and gives a new perspective on adversarial training of wide networks.",
      "The authors do a good job of exploring the topic from different directions.",
      "Given a motivation why they suspect better tuned $lambda$ on wider models would help improve robustness.",
      "Providing analytical insight through the Lipschitz constants.",
      "Showing the improvement in robust accuracy through empirical results.",
      "Proposing a method to automatically tune $lambda$ for wider models while training.",
      "Some things that could be improved:",
      "In line 64 and at later points the authors say that increasing the width of models while keeping $lambda$ constant would decrease the overall robustness.",
      "I find this a bit inaccurate as robustness is usually looked at in terms of the robust accuracy and it (as the authors show in figure 3) usually increase with the width.",
      "I think the authors should clarify that they mean the perturbation stability.",
      "The authors in their analysis in section 4 show that $lambda$ should grow with $\root{mH}$ but don't use that later on.",
      "Could this be an easier way to optimize $lambda$?",
      "Some minor typos/nits:",
      "Line 3 'it remains elusive how does neural network width affect model' should be 'it remains elusive how neural network width affects model'.",
      "Line 45 same as above.",
      "The notation in line 81-82 seems unnecessary.",
      "The defined notation is very standard and other similarly standard notation isn't explained.",
      "Line 84 'tremendous work' instead of 'tremendous works'.",
      "Line 216 'increases with' instead of 'increases as'.",
      "Line 264 '90-th epoch as in' instead of '90-th epoch in'.",
      "This paper makes a valuable contribution to the field and I believe it's suitable for Neurips."
    ]
  },
  {
    "paper_id": "2010.01279v3",
    "submission_id": "wxjtOI_8jO",
    "submission_title": "Do Wider Neural Networks Really Help Adversarial Robustness?",
    "review_id": "VYua3JWLo8",
    "input": {
      "title": "Do Wider Neural Networks Really Help Adversarial Robustness?",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Overall, this paper makes a significant contribution on an important topic---we still do not fully understand the connection between capacity and robustness.\n- The perspective proposed is simple and intuitive but at the same time appears to be quite useful for reasoning about the empirical behavior of wide models.\n- I believe that these results will be of interest to anyone who cares about robustness.\n- Figure 1 and 3: What is epsilon/norm used for training and eval?\n- Did you perform additional experiments with different norms and values of epsilon? Were the results consistent?\n- L167 (and similar discussion in other places): In all three works mentioned [68,59,50], the underlying trade-off actually manifests as a stability-accuracy trade-off.\n- Specifically, in [68, 59] the trade-off manifests because robust models cannot rely on predictive but unstable features, while in [50] the trade-off is a precisely a result of the requirement that the model's prediction needs to be stable around training points.\n- Thus, while this discussion appears to be contradicting these prior works, it actually doesn't.",
    "review_points_list": [
      "Overall, this paper makes a significant contribution on an important topic---we still do not fully understand the connection between capacity and robustness.",
      "The perspective proposed is simple and intuitive but at the same time appears to be quite useful for reasoning about the empirical behavior of wide models.",
      "I believe that these results will be of interest to anyone who cares about robustness.",
      "Figure 1 and 3: What is epsilon/norm used for training and eval?",
      "Did you perform additional experiments with different norms and values of epsilon? Were the results consistent?",
      "L167 (and similar discussion in other places): In all three works mentioned [68,59,50], the underlying trade-off actually manifests as a stability-accuracy trade-off.",
      "Specifically, in [68, 59] the trade-off manifests because robust models cannot rely on predictive but unstable features, while in [50] the trade-off is a precisely a result of the requirement that the model's prediction needs to be stable around training points.",
      "Thus, while this discussion appears to be contradicting these prior works, it actually doesn't."
    ]
  },
  {
    "paper_id": "2010.01279v3",
    "submission_id": "wxjtOI_8jO",
    "submission_title": "Do Wider Neural Networks Really Help Adversarial Robustness?",
    "review_id": "pGV-2YMNSMW",
    "input": {
      "title": "Do Wider Neural Networks Really Help Adversarial Robustness?",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The main problem I find with the current paper is that the main message is not clear.\n- There are some empirical comparisons based on the width of neural networks in relation to adversarial robustness, and some theorems based on previous results on Lipschitz bounds on neural networks.\n- But the main novelty or contribution of the paper is not clear.\n- Increasing the width does not necessarily add to the adversarial robustness, contrary to the claims of some of the previous works.\n- But this alone is not a very significant contribution.\n- There is a problem with analyzing the relation between natural accuracy and robust accuracy using equation 3.1.\n- Equation 3.1 is based on accuracy, whereas in practice we always optimize a surrogate loss function such as the cross-entropy loss.\n- The tradeoff in the optimization is not the direct tradeoff of accuracies, but tradeoff of their respective loss functions.\n- Given the cross-entropy loss can be unbounded, the actual tradeoff might not be similar to equation 3.1.\n- The analysis of perturbation stability using Lipschitz constant in section 4 is not particularly new.\n- And apart from stating the bounds, there is little insight on how the bounds affect the tradeoffs and relate to the empirical results.\n- The rest of the paper is on empirical comparison of width vs adversarial robustness.\n- But without better connections to other parts of the paper they seem like standalone empirical results.\n- I believe the authors need to improve on the clarity of presentation of their paper, and state more clearly what their actual contributions are.",
    "review_points_list": [
      "The main problem I find with the current paper is that the main message is not clear.",
      "There are some empirical comparisons based on the width of neural networks in relation to adversarial robustness, and some theorems based on previous results on Lipschitz bounds on neural networks.",
      "But the main novelty or contribution of the paper is not clear.",
      "Increasing the width does not necessarily add to the adversarial robustness, contrary to the claims of some of the previous works.",
      "But this alone is not a very significant contribution.",
      "There is a problem with analyzing the relation between natural accuracy and robust accuracy using equation 3.1.",
      "Equation 3.1 is based on accuracy, whereas in practice we always optimize a surrogate loss function such as the cross-entropy loss.",
      "The tradeoff in the optimization is not the direct tradeoff of accuracies, but tradeoff of their respective loss functions.",
      "Given the cross-entropy loss can be unbounded, the actual tradeoff might not be similar to equation 3.1.",
      "The analysis of perturbation stability using Lipschitz constant in section 4 is not particularly new.",
      "And apart from stating the bounds, there is little insight on how the bounds affect the tradeoffs and relate to the empirical results.",
      "The rest of the paper is on empirical comparison of width vs adversarial robustness.",
      "But without better connections to other parts of the paper they seem like standalone empirical results.",
      "I believe the authors need to improve on the clarity of presentation of their paper, and state more clearly what their actual contributions are."
    ]
  },
  {
    "paper_id": "2109.03622v2",
    "submission_id": "vQTYEUtSUr",
    "submission_title": "Learning Local-Global Contextual Adaptation for Fully End-to-End Bottom-Up Human Pose Estimation",
    "review_id": "98569tsbgzz",
    "input": {
      "title": "Learning Local-Global Contextual Adaptation for Fully End-to-End Bottom-Up Human Pose Estimation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The method proposed by this paper is novel and technically sound.\n- The idea of combining keypoint features that belong to the same person to obtain the convolution kernel of a single keypoint is interesting.\n- Extracting a 97x97 pose-guided heatmap for each keypoint introduces high resolution to the bottom-up architecture, what is exactly the bottom-up architecture needed.\n- Of course, this paper also has some problems.\n- First, the 'Fast Keypointer' and 'Slow Keypointer' mentioned at the beginning of this paper do not actually relate to speed.\n- The 'Slow Keypointer' proposed is actually a refinement of the coarse estimated pose.\n- This statement affects readers' understanding to a certain extent.\n- Second, there are many tricks used in this paper, such as Attention Normalization, reweigh heatmaps using Gaussian kernel and OKS loss.\n- But ablation study has not been carried out in the experiment to show the influence of these tricks.\n- Adding an experiment like this would be more convincing.\n- Last, since each keypoint of each person has to be dealt with separately, the speed of the method proposed in this paper should be greatly affected by the number of people in an image, and the memory usage should also be large, but this paper does not mention it.\n- I don\u2019t know if some techniques are used to alleviate these two problems.\n- All in all, the conclusions of this paper are significant.\n- After DEKR, it proves again that the center-offset architecture can perform high-precision pose estimation.",
    "review_points_list": [
      "The method proposed by this paper is novel and technically sound.",
      "The idea of combining keypoint features that belong to the same person to obtain the convolution kernel of a single keypoint is interesting.",
      "Extracting a 97x97 pose-guided heatmap for each keypoint introduces high resolution to the bottom-up architecture, what is exactly the bottom-up architecture needed.",
      "Of course, this paper also has some problems.",
      "First, the 'Fast Keypointer' and 'Slow Keypointer' mentioned at the beginning of this paper do not actually relate to speed.",
      "The 'Slow Keypointer' proposed is actually a refinement of the coarse estimated pose.",
      "This statement affects readers' understanding to a certain extent.",
      "Second, there are many tricks used in this paper, such as Attention Normalization, reweigh heatmaps using Gaussian kernel and OKS loss.",
      "But ablation study has not been carried out in the experiment to show the influence of these tricks.",
      "Adding an experiment like this would be more convincing.",
      "Last, since each keypoint of each person has to be dealt with separately, the speed of the method proposed in this paper should be greatly affected by the number of people in an image, and the memory usage should also be large, but this paper does not mention it.",
      "I don\u2019t know if some techniques are used to alleviate these two problems.",
      "All in all, the conclusions of this paper are significant.",
      "After DEKR, it proves again that the center-offset architecture can perform high-precision pose estimation."
    ]
  },
  {
    "paper_id": "2109.03622v2",
    "submission_id": "vQTYEUtSUr",
    "submission_title": "Learning Local-Global Contextual Adaptation for Fully End-to-End Bottom-Up Human Pose Estimation",
    "review_id": "5x7LUvEQQI-",
    "input": {
      "title": "Learning Local-Global Contextual Adaptation for Fully End-to-End Bottom-Up Human Pose Estimation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This work proposes a novel local-global contextual adaptation formation for accurate pose estimation.\n- Comparing with bottom-up center-offset methods, LOGO-CAP achieves a better trade-off between accuracy and efficiency, which is important in the task of human pose estimation.\n- This paper argues that \u201cit is the first fully end-to-end trainable method that achieves state-of-the-art performance\u201d, which is over-claimed.\n- There are several end-to-end methods for human pose estimation (e.g., Mask RCNN, bottom-up methods [35, 20] and bottom-up regression methods [28, 11]); LOGO-CAP does not achieve the state-of-the-art performance (SimpleBaseline[32], HRNet[27]).\n- 'Slow' keypointer, which introduces KAMs and the global KEMs to refine the poses estimated by center-offset formulation, is applied at person instance level (or even at joint level).\n- It is more like a top-down approach rather than a bottom-up approach.\n- The center-offset formulation only provides the coarse position of persons or joints, then they are processed individually.\n- Their inference time increases with the number of people.\n- Both top-down approaches and bottom-up approaches should be compared in Table2.\n- This paper lacks of ablation study to show the effect of proposed modules.\n- It should clearly introduce where the improvement over the baseline come from.\n- The following experiment results should be given: a) the effect of local-global contextual adaptation; b) the effect of Gaussian reweighting; c) the effect of convolution message passing module; d) The result of applying the local window search (the argmax) on the KAMs, which is similar to Table.1 Emp. Bound.\n- The inference time of the proposed method increases with the number of persons.\n- The details of how to test the inference speed for multi-person images and the reasons why LGO-CAP show superiority over the bottom up methods (DEKR[11]) on inference speed should be given.\n- The inaccuracy of global KEMs comes from the global keypoint heatmaps, while the KAMs measure the error of center-offset results.\n- Here is the mismatch between heatmaps and center-offsets.\n- How can KAMs help refine global KEMs?\n- The writing can be improved. Notations in this paper are not well defined.\n- There are also too many similar concepts with different names, e.g. Local heatmaps, local KEMs, KAMs.\n- It would be better if they use a consistent name throughout the paper.\n- Some important details of the proposed approach are missing (e.g., how to compute the geometric mesh of the global KEMs).",
    "review_points_list": [
      "This work proposes a novel local-global contextual adaptation formation for accurate pose estimation.",
      "Comparing with bottom-up center-offset methods, LOGO-CAP achieves a better trade-off between accuracy and efficiency, which is important in the task of human pose estimation.",
      "This paper argues that \u201cit is the first fully end-to-end trainable method that achieves state-of-the-art performance\u201d, which is over-claimed.",
      "There are several end-to-end methods for human pose estimation (e.g., Mask RCNN, bottom-up methods [35, 20] and bottom-up regression methods [28, 11]); LOGO-CAP does not achieve the state-of-the-art performance (SimpleBaseline[32], HRNet[27]).",
      "'Slow' keypointer, which introduces KAMs and the global KEMs to refine the poses estimated by center-offset formulation, is applied at person instance level (or even at joint level).",
      "It is more like a top-down approach rather than a bottom-up approach.",
      "The center-offset formulation only provides the coarse position of persons or joints, then they are processed individually.",
      "Their inference time increases with the number of people.",
      "Both top-down approaches and bottom-up approaches should be compared in Table2.",
      "This paper lacks of ablation study to show the effect of proposed modules.",
      "It should clearly introduce where the improvement over the baseline come from.",
      "The following experiment results should be given: a) the effect of local-global contextual adaptation; b) the effect of Gaussian reweighting; c) the effect of convolution message passing module; d) The result of applying the local window search (the argmax) on the KAMs, which is similar to Table.1 Emp. Bound.",
      "The inference time of the proposed method increases with the number of persons.",
      "The details of how to test the inference speed for multi-person images and the reasons why LGO-CAP show superiority over the bottom up methods (DEKR[11]) on inference speed should be given.",
      "The inaccuracy of global KEMs comes from the global keypoint heatmaps, while the KAMs measure the error of center-offset results.",
      "Here is the mismatch between heatmaps and center-offsets.",
      "How can KAMs help refine global KEMs?",
      "The writing can be improved. Notations in this paper are not well defined.",
      "There are also too many similar concepts with different names, e.g. Local heatmaps, local KEMs, KAMs.",
      "It would be better if they use a consistent name throughout the paper.",
      "Some important details of the proposed approach are missing (e.g., how to compute the geometric mesh of the global KEMs)."
    ]
  },
  {
    "paper_id": "2109.03622v2",
    "submission_id": "vQTYEUtSUr",
    "submission_title": "Learning Local-Global Contextual Adaptation for Fully End-to-End Bottom-Up Human Pose Estimation",
    "review_id": "_dD9bAWWdIv",
    "input": {
      "title": "Learning Local-Global Contextual Adaptation for Fully End-to-End Bottom-Up Human Pose Estimation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper proposed an interesting way to refine the results of center-offset-based pose estimation.\n- The proposed method outperforms the state of the art on COCO and OCHuman datasets.\n- The details of the proposed method are well described.\n- The experiment is not sufficient to prove the effectiveness of the proposed method. More ablation studies and analyses should be provided.\n- Different ways for KAM generation should be investigated, for example, different sizes of local KEMs, different designs of convolutional message passing module, use or do not use KAM to refine the global KAMs.\n- Some proposed modules should be evaluated in the ablation studies, e.g. the CMP, the attention normalization and the effectiveness of performing KAM to global KEMs, etc.\n- It is important to show the inference speed comparison between the baseline and the proposed LOGO-CAP.\n- Further analysis should be provided, what kinds of KAMs kernels are generated adaptively and how do the KAMs refine the global maps? What kind of hard cases are refined by the proposed method.\n- This paper claims that 'this is the first fully end-to-end trainable method that achieves the state-of-the-art performance' (in L. 161), but many end-to-end trainable pose estimation methods have been proposed before.\n- The paper should be further polished before being published.\n- More explanations should be presented in the caption of each figure, e.g. Figure 1, 3, 4.\n- The major difference between the initial offsets and the refined pose should be highlighted in Figure 4.\n- Typos need to be corrected, in L.45, 'approach is' -> 'approaches are', in L. 280, the citation is missed, in L. 319, 321, 328, 'points' should be '%'.",
    "review_points_list": [
      "The paper proposed an interesting way to refine the results of center-offset-based pose estimation.",
      "The proposed method outperforms the state of the art on COCO and OCHuman datasets.",
      "The details of the proposed method are well described.",
      "The experiment is not sufficient to prove the effectiveness of the proposed method. More ablation studies and analyses should be provided.",
      "Different ways for KAM generation should be investigated, for example, different sizes of local KEMs, different designs of convolutional message passing module, use or do not use KAM to refine the global KAMs.",
      "Some proposed modules should be evaluated in the ablation studies, e.g. the CMP, the attention normalization and the effectiveness of performing KAM to global KEMs, etc.",
      "It is important to show the inference speed comparison between the baseline and the proposed LOGO-CAP.",
      "Further analysis should be provided, what kinds of KAMs kernels are generated adaptively and how do the KAMs refine the global maps? What kind of hard cases are refined by the proposed method.",
      "This paper claims that 'this is the first fully end-to-end trainable method that achieves the state-of-the-art performance' (in L. 161), but many end-to-end trainable pose estimation methods have been proposed before.",
      "The paper should be further polished before being published.",
      "More explanations should be presented in the caption of each figure, e.g. Figure 1, 3, 4.",
      "The major difference between the initial offsets and the refined pose should be highlighted in Figure 4.",
      "Typos need to be corrected, in L.45, 'approach is' -> 'approaches are', in L. 280, the citation is missed, in L. 319, 321, 328, 'points' should be '%'."
    ]
  },
  {
    "paper_id": "2406.11888v1",
    "submission_id": "wHkKTW2wrmm",
    "submission_title": "Neural Additive Models: Interpretable Machine Learning with Neural Nets",
    "review_id": "1Rx3qCNraw",
    "input": {
      "title": "Neural Additive Models: Interpretable Machine Learning with Neural Nets",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper is incredibly well written, easy to follow, and has some of the best visualizations I have seen.\n- The motivation and core method are clear and the analysis was quite thorough and seems like it could be easily reproduced.\n- Furthermore, the applications to things like covid-19 and COMPAS are well thought out and have impressive results.\n- Overall a very fun read and seems particularly well suited to the NeurIPS audience.\n- My only concerns are relatively small:\n- (1) In section 2.1 the authors mention that they altered the weight initialization to better fit jagged curves;\n- I would love to see a plot showing the difference in curves with this new initialization as well as the traditional weight initialization (similar to figure 2).\n- I looked in A.3 but that section seems to be empty.\n- (2) While the plots in section 2.1 are convincing that these ExU networks are better for jagged curves,\n- it would be nice to add them as another benchmark in section 3\n- Other small nits: units of median income are missing in Fig 6\n- line 327 I believe should be 'the public has different...'\n- a period needs to be added at the end of the conclusion",
    "review_points_list": [
      "This paper is incredibly well written, easy to follow, and has some of the best visualizations I have seen.",
      "The motivation and core method are clear and the analysis was quite thorough and seems like it could be easily reproduced.",
      "Furthermore, the applications to things like covid-19 and COMPAS are well thought out and have impressive results.",
      "Overall a very fun read and seems particularly well suited to the NeurIPS audience.",
      "My only concerns are relatively small:",
      "(1) In section 2.1 the authors mention that they altered the weight initialization to better fit jagged curves;",
      "I would love to see a plot showing the difference in curves with this new initialization as well as the traditional weight initialization (similar to figure 2).",
      "I looked in A.3 but that section seems to be empty.",
      "(2) While the plots in section 2.1 are convincing that these ExU networks are better for jagged curves,",
      "it would be nice to add them as another benchmark in section 3",
      "Other small nits: units of median income are missing in Fig 6",
      "line 327 I believe should be 'the public has different...'",
      "a period needs to be added at the end of the conclusion"
    ]
  },
  {
    "paper_id": "2406.11888v1",
    "submission_id": "wHkKTW2wrmm",
    "submission_title": "Neural Additive Models: Interpretable Machine Learning with Neural Nets",
    "review_id": "bEXNkDvjvZE",
    "input": {
      "title": "Neural Additive Models: Interpretable Machine Learning with Neural Nets",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Each point should be a distinct comment, observation, strength, weakness, or question.",
    "review_points_list": [
      "Each point should be a distinct comment, observation, strength, weakness, or question."
    ]
  },
  {
    "paper_id": "2406.11888v1",
    "submission_id": "wHkKTW2wrmm",
    "submission_title": "Neural Additive Models: Interpretable Machine Learning with Neural Nets",
    "review_id": "1oqmnoO1aU3",
    "input": {
      "title": "Neural Additive Models: Interpretable Machine Learning with Neural Nets",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors propose neural additive models, a linear combination of multiple small networks, which are trained jointly and can learn complex functions such as jagged shape functions.\n- The claim is that because the models are modular, the predictions can be propagated back to the individual network functions and easily visualized.\n- They show the explainability of the networks in applications like fraud detection and recidivism risk prediction.\n- The authors have explained the proposed structure reasonably well but its readability could be improved with a better presentation of the notations and the model structure.\n- The experimental section is detailed and covers various single-task and multi-task learning applications.\n- They have compared their solution with other explainable ML algorithms and shown comparable prediction accuracy.\n- My only concern is that their analysis results on interpretability is very heuristic and subjective, rather than a formal validation.\n- Overall, the paper is a good contribution and I recommend acceptance.\n- The authors have addressed my main concerns.\n- I recommend acceptance with the changes proposed in the author response.",
    "review_points_list": [
      "The authors propose neural additive models, a linear combination of multiple small networks, which are trained jointly and can learn complex functions such as jagged shape functions.",
      "The claim is that because the models are modular, the predictions can be propagated back to the individual network functions and easily visualized.",
      "They show the explainability of the networks in applications like fraud detection and recidivism risk prediction.",
      "The authors have explained the proposed structure reasonably well but its readability could be improved with a better presentation of the notations and the model structure.",
      "The experimental section is detailed and covers various single-task and multi-task learning applications.",
      "They have compared their solution with other explainable ML algorithms and shown comparable prediction accuracy.",
      "My only concern is that their analysis results on interpretability is very heuristic and subjective, rather than a formal validation.",
      "Overall, the paper is a good contribution and I recommend acceptance.",
      "The authors have addressed my main concerns.",
      "I recommend acceptance with the changes proposed in the author response."
    ]
  },
  {
    "paper_id": "2202.02296v2",
    "submission_id": "vRwnHlAgK5x",
    "submission_title": "Coupled Segmentation and Edge Learning via Dynamic Graph Propagation",
    "review_id": "vRpr1ZtoUOG",
    "input": {
      "title": "Coupled Segmentation and Edge Learning via Dynamic Graph Propagation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper addresses the problem of joint predicting the segmentation results and the edge.\n- By the proposed DGP layer, they achieve good results among several benchmarks.\n- They also show robustness by experimenting on Cityscapes-C.\n- There are some minor concerns, which need more clarification:\n- Do the PASCAL VOC and SBD train together? Are the method in Table 5 and Table 6 also trained under multi-task settings?\n- I am wondering about the efficiency of the proposed DGP. It will be better if the computational cost and inference speed could be compared and discussed.\n- Will edge detection help the semantic segmentation? It will be better if the single edge detection and single segmentation results could be reported in Table 2.\n- There are some typos, for example, Line 78...",
    "review_points_list": [
      "This paper addresses the problem of joint predicting the segmentation results and the edge.",
      "By the proposed DGP layer, they achieve good results among several benchmarks.",
      "They also show robustness by experimenting on Cityscapes-C.",
      "There are some minor concerns, which need more clarification:",
      "Do the PASCAL VOC and SBD train together? Are the method in Table 5 and Table 6 also trained under multi-task settings?",
      "I am wondering about the efficiency of the proposed DGP. It will be better if the computational cost and inference speed could be compared and discussed.",
      "Will edge detection help the semantic segmentation? It will be better if the single edge detection and single segmentation results could be reported in Table 2.",
      "There are some typos, for example, Line 78..."
    ]
  },
  {
    "paper_id": "2202.02296v2",
    "submission_id": "vRwnHlAgK5x",
    "submission_title": "Coupled Segmentation and Edge Learning via Dynamic Graph Propagation",
    "review_id": "2eyf40xfKB_",
    "input": {
      "title": "Coupled Segmentation and Edge Learning via Dynamic Graph Propagation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors' approach is intuitive and clearly explained, as is the logic for why information about edges should be useful for recurrently refining a feedforward feature map.\n- They thoroughly test their model and ablations on Cityscapes,\n- I buy that adding their module yields an improvement.\n- The performance improvements on some types of image corruptions are especially interesting.\n- I wish the authors had included a bunch of qualitative examples and tried to analyze why their module is helpful in dealing with some types of corruption but not others.\n- Indeed, the results in this section are strong enough that it's arguably their most important contribution, since the Cityscapes semantic segmentation task is so close to performance ceiling anyway (and adding a few percentage points to mIoU may not mean detecting new objects that were being missed before, etc.)\n- Other than this, my main suggestion is that the authors evaluate their model on at least one, and ideally several other datasets and tasks.\n- Cityscapes semantic segmentation is peculiar in that there are not too many categories and the images are pretty homogeneous.\n- If their module significantly improved results on a more diverse dataset (e.g. COCO) I'd be more inclined to think that they had really identified a very useful novel computation for the segmentation task.\n- Likewise, it seems that their approach could be adopted for performing or improving instance segmentation (rather than semantic segmentation),\n- which is a task in much greater need of algorithmic improvement than the latter.\n- If the authors could offer more than this one example (Cityscapes semantic segmentation) of how Dynamic Graph Propagation with joint edge learning improves results,\n- it would much more strongly support their initial motivation for introducing this architecture.",
    "review_points_list": [
      "The authors' approach is intuitive and clearly explained, as is the logic for why information about edges should be useful for recurrently refining a feedforward feature map.",
      "They thoroughly test their model and ablations on Cityscapes,",
      "I buy that adding their module yields an improvement.",
      "The performance improvements on some types of image corruptions are especially interesting.",
      "I wish the authors had included a bunch of qualitative examples and tried to analyze why their module is helpful in dealing with some types of corruption but not others.",
      "Indeed, the results in this section are strong enough that it's arguably their most important contribution, since the Cityscapes semantic segmentation task is so close to performance ceiling anyway (and adding a few percentage points to mIoU may not mean detecting new objects that were being missed before, etc.)",
      "Other than this, my main suggestion is that the authors evaluate their model on at least one, and ideally several other datasets and tasks.",
      "Cityscapes semantic segmentation is peculiar in that there are not too many categories and the images are pretty homogeneous.",
      "If their module significantly improved results on a more diverse dataset (e.g. COCO) I'd be more inclined to think that they had really identified a very useful novel computation for the segmentation task.",
      "Likewise, it seems that their approach could be adopted for performing or improving instance segmentation (rather than semantic segmentation),",
      "which is a task in much greater need of algorithmic improvement than the latter.",
      "If the authors could offer more than this one example (Cityscapes semantic segmentation) of how Dynamic Graph Propagation with joint edge learning improves results,",
      "it would much more strongly support their initial motivation for introducing this architecture."
    ]
  },
  {
    "paper_id": "2102.06648v5",
    "submission_id": "vU96vWPrWL",
    "submission_title": "A Critical Look at the Consistency of Causal Estimation with Deep Latent Variable Models",
    "review_id": "dE72Qbwbkp",
    "input": {
      "title": "A Critical Look at the Consistency of Causal Estimation with Deep Latent Variable Models",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Although the observations of CEVAE are quite interesting, I am not sure whether this paper is beneficial to the broad audience since the analysis is only narrowed to one method (CEVAE) that is specific to the causal graph with unobserved confounder.\n- Besides, some observations are not new, such as that the CEVAE can fail to recover the true causal effect with the incorrect specification of the distribution of the latent variables, which is not surprising given the non-identifiability of the VAE model for the latent variables.\n- That is, whether \\\n- int p(z)p(y|t,z) dz\\\n-  is determined by the p(y,t,x) that can be recovered by the generative model like VAE.\n- The observations with correlated proxies, and especially the scale factor analysis are interesting.\n- I believe this result can benefit other works that implement VAE to learn representations.\n- However, as I mentioned earlier, overall the perspective of this paper is somewhat narrow and not novel enough for publication.\n- Change my score from 5 to 6. This is nice work.",
    "review_points_list": [
      "Although the observations of CEVAE are quite interesting, I am not sure whether this paper is beneficial to the broad audience since the analysis is only narrowed to one method (CEVAE) that is specific to the causal graph with unobserved confounder.",
      "Besides, some observations are not new, such as that the CEVAE can fail to recover the true causal effect with the incorrect specification of the distribution of the latent variables, which is not surprising given the non-identifiability of the VAE model for the latent variables.",
      "That is, whether \\",
      "int p(z)p(y|t,z) dz\\",
      " is determined by the p(y,t,x) that can be recovered by the generative model like VAE.",
      "The observations with correlated proxies, and especially the scale factor analysis are interesting.",
      "I believe this result can benefit other works that implement VAE to learn representations.",
      "However, as I mentioned earlier, overall the perspective of this paper is somewhat narrow and not novel enough for publication.",
      "Change my score from 5 to 6. This is nice work."
    ]
  },
  {
    "paper_id": "2102.06648v5",
    "submission_id": "vU96vWPrWL",
    "submission_title": "A Critical Look at the Consistency of Causal Estimation with Deep Latent Variable Models",
    "review_id": "dyOMPc9b-hB",
    "input": {
      "title": "A Critical Look at the Consistency of Causal Estimation with Deep Latent Variable Models",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper contributes valuable insights to the understanding of the limitations of CEVAE methods, especially what can go wrong in real-world usage.\n- I found one of the key insights being that the scaling of the losses of CEVAE determines whether the right solution is found or not.\n- However, this insight was only discovered by post-mortem analysis.\n- Would it be possible to propose a guideline or an algorithm how the scaling of the CEVAE loss can be accomplished?\n- Would use of cross-validation solve this? Or some kind of normalization of the losses in the ELBO.\n- Found the paper easy to read and having a clear structure.",
    "review_points_list": [
      "The paper contributes valuable insights to the understanding of the limitations of CEVAE methods, especially what can go wrong in real-world usage.",
      "I found one of the key insights being that the scaling of the losses of CEVAE determines whether the right solution is found or not.",
      "However, this insight was only discovered by post-mortem analysis.",
      "Would it be possible to propose a guideline or an algorithm how the scaling of the CEVAE loss can be accomplished?",
      "Would use of cross-validation solve this? Or some kind of normalization of the losses in the ELBO.",
      "Found the paper easy to read and having a clear structure."
    ]
  },
  {
    "paper_id": "2101.09545v4",
    "submission_id": "xAFm5knU7Nc",
    "submission_title": "Accelerating Quadratic Optimization with Reinforcement Learning",
    "review_id": "MzGn6gAyquQ",
    "input": {
      "title": "Accelerating Quadratic Optimization with Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- using RL to adapt QP solver parameters is novel to me.\n- approach seems to be effective across various benchmarks.\n- detailed ablation on generalization to problem sizes, problem classes and warm start problems.\n- code provided.\n- The choice of state space might need more discussion, more on this in questions.\n- The state spaces of the RLQP(scalar) and RLQP(vector) are very different, as RLQP(scalar) only has the primal/dual residual while RLQP(vector) has other stuff.\n- If one provide the additional information of RLQP(vector) to RLQP(scalar), will performance of RLQP(scalar) improve?\n- Why not just use a big policy that takes all the state and output all the action for RLQP?\n- My understanding is that the setup in the current paper allows for solving QP with different sizes, but suppose I only want to solve problem of particular size, will the 'big policy' approach generate more efficient policy?",
    "review_points_list": [
      "using RL to adapt QP solver parameters is novel to me.",
      "approach seems to be effective across various benchmarks.",
      "detailed ablation on generalization to problem sizes, problem classes and warm start problems.",
      "code provided.",
      "The choice of state space might need more discussion, more on this in questions.",
      "The state spaces of the RLQP(scalar) and RLQP(vector) are very different, as RLQP(scalar) only has the primal/dual residual while RLQP(vector) has other stuff.",
      "If one provide the additional information of RLQP(vector) to RLQP(scalar), will performance of RLQP(scalar) improve?",
      "Why not just use a big policy that takes all the state and output all the action for RLQP?",
      "My understanding is that the setup in the current paper allows for solving QP with different sizes, but suppose I only want to solve problem of particular size, will the 'big policy' approach generate more efficient policy?"
    ]
  },
  {
    "paper_id": "2101.09545v4",
    "submission_id": "xAFm5knU7Nc",
    "submission_title": "Accelerating Quadratic Optimization with Reinforcement Learning",
    "review_id": "-XOcVrNV3Aa",
    "input": {
      "title": "Accelerating Quadratic Optimization with Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is rather light in terms of novelty.\n- Indeed, the idea of using RL to tune ADMM algorithms is not new and has been introduced in [44].\n- The difference w.r.t. [44] is marginal, if any at all.\n- The paper is not well written;\n- The convex optimization section is rather amateurish\n- The RL part is same to be said for the amateurish\n- As far as the general idea goes, I am not convinced that this line of work brings much to the optimization algorithmic area\n- since to tune the ADMM algorithm, or any algorithm, the authors are solving yet another optimization problem, much more complex, since non-convex and potentially large-scale, with many other hyper-parameters which need to be tuned !!!\n- so what's the gain really ?\n- do you use another RL algorithm to tune the optimization algorithm (e.g. ADAM) that is used to solve the first RL algorithm, etc. ?\n- This line of research is merely transferring the problem of tuning one optimization algorithm to another optimization algorithm, and so, in my opinion, not useful as it is proposed in this paper.",
    "review_points_list": [
      "The paper is rather light in terms of novelty.",
      "Indeed, the idea of using RL to tune ADMM algorithms is not new and has been introduced in [44].",
      "The difference w.r.t. [44] is marginal, if any at all.",
      "The paper is not well written;",
      "The convex optimization section is rather amateurish",
      "The RL part is same to be said for the amateurish",
      "As far as the general idea goes, I am not convinced that this line of work brings much to the optimization algorithmic area",
      "since to tune the ADMM algorithm, or any algorithm, the authors are solving yet another optimization problem, much more complex, since non-convex and potentially large-scale, with many other hyper-parameters which need to be tuned !!!",
      "so what's the gain really ?",
      "do you use another RL algorithm to tune the optimization algorithm (e.g. ADAM) that is used to solve the first RL algorithm, etc. ?",
      "This line of research is merely transferring the problem of tuning one optimization algorithm to another optimization algorithm, and so, in my opinion, not useful as it is proposed in this paper."
    ]
  },
  {
    "paper_id": "2106.12447v3",
    "submission_id": "vLPqnPf9k0",
    "submission_title": "How Well do Feature Visualizations Support Causal Understanding of CNN Activations?",
    "review_id": "39XZrhBi0vE",
    "input": {
      "title": "How Well do Feature Visualizations Support Causal Understanding of CNN Activations?",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Low. This work is similar to Borowski et al. 2021, but it does a more thorough evaluation encompassing more types of feature visualizations and more baselines.\n- It also uses an experimental design that is likely to be more powerful, as it compares two images that are obtained by occluding the same original image.\n- However it is not entirely clear that this methodological change is a strict improvement on Borowski et al. 2021 because such occluded distributions lie outside of the support of the natural image distribution and hence could fail to be representative of neural network activity for natural images, unless the network has been shown to be robust to occlusions.\n- A lot of thought was put into the experimental design and the analysis of the conclusions.\n- In particular, decomposing the variation in accuracy by not only visualization method but also unit and contrast in activation helps build the case that the visualizations do not differ by much.\n- The details of collecting data on MTurk also build confidence in data quality.\n- The paper is clear and details of the methods are well-motivated and explained.\n- The paper adds to the findings of Borowski et al. which pose serious questions for the feature visualization field.\n- Why are human rankings of feature activations so close to chance, and why don't visualizations (natural or synthetic) help more?",
    "review_points_list": [
      "Low. This work is similar to Borowski et al. 2021, but it does a more thorough evaluation encompassing more types of feature visualizations and more baselines.",
      "It also uses an experimental design that is likely to be more powerful, as it compares two images that are obtained by occluding the same original image.",
      "However it is not entirely clear that this methodological change is a strict improvement on Borowski et al. 2021 because such occluded distributions lie outside of the support of the natural image distribution and hence could fail to be representative of neural network activity for natural images, unless the network has been shown to be robust to occlusions.",
      "A lot of thought was put into the experimental design and the analysis of the conclusions.",
      "In particular, decomposing the variation in accuracy by not only visualization method but also unit and contrast in activation helps build the case that the visualizations do not differ by much.",
      "The details of collecting data on MTurk also build confidence in data quality.",
      "The paper is clear and details of the methods are well-motivated and explained.",
      "The paper adds to the findings of Borowski et al. which pose serious questions for the feature visualization field.",
      "Why are human rankings of feature activations so close to chance, and why don't visualizations (natural or synthetic) help more?"
    ]
  },
  {
    "paper_id": "2106.12447v3",
    "submission_id": "vLPqnPf9k0",
    "submission_title": "How Well do Feature Visualizations Support Causal Understanding of CNN Activations?",
    "review_id": "iHOZOm25QFs",
    "input": {
      "title": "How Well do Feature Visualizations Support Causal Understanding of CNN Activations?",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This is a brand-new idea that evaluates the performance of feature visualization totally with psychophysical experiments.\n- However, it is more like a social science document rather than a research paper target for NeurIPS.\n- This paper overflowed with design details, such as 3.1 Psychophysical Task, 3.3 Structure of the Psychophysical Experiment, and 3.4 Ensuring High-Quality Data in an Online Experiment, which could be paced in the supplement.\n- What's more, the results of the experiment also are trivial.\n- Besides the task accuracy in experiment 1, all other experiments are hard to understand the purpose.",
    "review_points_list": [
      "This is a brand-new idea that evaluates the performance of feature visualization totally with psychophysical experiments.",
      "However, it is more like a social science document rather than a research paper target for NeurIPS.",
      "This paper overflowed with design details, such as 3.1 Psychophysical Task, 3.3 Structure of the Psychophysical Experiment, and 3.4 Ensuring High-Quality Data in an Online Experiment, which could be paced in the supplement.",
      "What's more, the results of the experiment also are trivial.",
      "Besides the task accuracy in experiment 1, all other experiments are hard to understand the purpose."
    ]
  },
  {
    "paper_id": "2106.12447v3",
    "submission_id": "vLPqnPf9k0",
    "submission_title": "How Well do Feature Visualizations Support Causal Understanding of CNN Activations?",
    "review_id": "erwhW_0q-fS",
    "input": {
      "title": "How Well do Feature Visualizations Support Causal Understanding of CNN Activations?",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The psychophysical experiment design is novel and to my knowledge it is the first study that answers questions about unit interpretability in CNN with actual human behavioral data.\n- The amount of controls that are designed into the experiment is very impressive. It is able to rule out most of the competing hypothesis related to this problem.\n- Analysis of the decision patterns, reaction time, as well as comparison to expert evaluator are also very informative.\n- The paper is extremely well-written and organized.\n- The behavioral results in this paper has a lot of insights and is important in guiding the field for the next interpretability methods. It would also encourage more validating experiments to be done on other visualization methods in general.",
    "review_points_list": [
      "The psychophysical experiment design is novel and to my knowledge it is the first study that answers questions about unit interpretability in CNN with actual human behavioral data.",
      "The amount of controls that are designed into the experiment is very impressive. It is able to rule out most of the competing hypothesis related to this problem.",
      "Analysis of the decision patterns, reaction time, as well as comparison to expert evaluator are also very informative.",
      "The paper is extremely well-written and organized.",
      "The behavioral results in this paper has a lot of insights and is important in guiding the field for the next interpretability methods. It would also encourage more validating experiments to be done on other visualization methods in general."
    ]
  },
  {
    "paper_id": "2007.03760v2",
    "submission_id": "yMf3SLah5-y",
    "submission_title": "Optimal Uniform OPE and Model-based Offline Reinforcement Learning in Time-Homogeneous, Reward-Free and Task-Agnostic Settings ",
    "review_id": "0k6fY9dzwXG",
    "input": {
      "title": "Optimal Uniform OPE and Model-based Offline Reinforcement Learning in Time-Homogeneous, Reward-Free and Task-Agnostic Settings ",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The motivation for considering uniform OPE is insufficient, since it is not suitable to studying offline learning.\n- The bound established based on (local) uniform OPE is too loose compared with existing results for offline learning (both model based approach and model free approach, also known as asynchronous Q-learning).\n- Hence, I think this work is of limited importance.\n- In addition, the proof is based on Agarwal et al. 2020.\n- It is not evident to me what new challenges are in the proof.\n- A. Agarwal, S. Kakade, and L. F. Yang. Model-based reinforcement learning with a generative model is minimax optimal. Conference on Learning Theory, 2020.",
    "review_points_list": [
      "The motivation for considering uniform OPE is insufficient, since it is not suitable to studying offline learning.",
      "The bound established based on (local) uniform OPE is too loose compared with existing results for offline learning (both model based approach and model free approach, also known as asynchronous Q-learning).",
      "Hence, I think this work is of limited importance.",
      "In addition, the proof is based on Agarwal et al. 2020.",
      "It is not evident to me what new challenges are in the proof.",
      "A. Agarwal, S. Kakade, and L. F. Yang. Model-based reinforcement learning with a generative model is minimax optimal. Conference on Learning Theory, 2020."
    ]
  },
  {
    "paper_id": "2007.03760v2",
    "submission_id": "yMf3SLah5-y",
    "submission_title": "Optimal Uniform OPE and Model-based Offline Reinforcement Learning in Time-Homogeneous, Reward-Free and Task-Agnostic Settings ",
    "review_id": "C7uCfs3d82",
    "input": {
      "title": "Optimal Uniform OPE and Model-based Offline Reinforcement Learning in Time-Homogeneous, Reward-Free and Task-Agnostic Settings ",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors consider uniform convergence in model-based offline reinforcement learning, and generalize the results to two slightly different settings, termed as task-agnostic and reward-free reinforcement learning. Central to the analysis is an absorbing MDP technique to decouple the statistical dependency on the empirical and the terms obtained from the empirical model, which is a generalization from the infinite horizon case and eventually lead to a sharp result on the leading term. The results are clearly presented. One minor issue is that, the higher order term are not very satisfactory, especially the results in Theorem 5.6, that need samples proportion to the number of states in linear MDP with anchor points, which should be avoided in the setting with function approximation (as we want to deal with the large state space with function approximation.)\n- The authors present a novel approach to the active learning of neural networks. They propose a novel algorithm, the Cluster-Margin algorithm, which is capable of actively learning a neural network model from a large dataset. The authors show empirically that their algorithm, Cluster-Margin, is both more efficient and effective than existing active learning methods on a wide range of datasets. The Cluster-Margin algorithm is also theoretically guaranteed to be efficient and effective. However, the authors could have strengthened the paper by providing more details on the algorithm, such as the specific neural network architecture used and the exact implementation of the algorithm. It is also unclear how the algorithm handles issues such as overfitting and class imbalance. Additionally, the paper could benefit from more discussion on the potential limitations and future research directions.",
    "review_points_list": [
      "The authors consider uniform convergence in model-based offline reinforcement learning, and generalize the results to two slightly different settings, termed as task-agnostic and reward-free reinforcement learning. Central to the analysis is an absorbing MDP technique to decouple the statistical dependency on the empirical and the terms obtained from the empirical model, which is a generalization from the infinite horizon case and eventually lead to a sharp result on the leading term. The results are clearly presented. One minor issue is that, the higher order term are not very satisfactory, especially the results in Theorem 5.6, that need samples proportion to the number of states in linear MDP with anchor points, which should be avoided in the setting with function approximation (as we want to deal with the large state space with function approximation.)",
      "The authors present a novel approach to the active learning of neural networks. They propose a novel algorithm, the Cluster-Margin algorithm, which is capable of actively learning a neural network model from a large dataset. The authors show empirically that their algorithm, Cluster-Margin, is both more efficient and effective than existing active learning methods on a wide range of datasets. The Cluster-Margin algorithm is also theoretically guaranteed to be efficient and effective. However, the authors could have strengthened the paper by providing more details on the algorithm, such as the specific neural network architecture used and the exact implementation of the algorithm. It is also unclear how the algorithm handles issues such as overfitting and class imbalance. Additionally, the paper could benefit from more discussion on the potential limitations and future research directions."
    ]
  },
  {
    "paper_id": "2111.00053v2",
    "submission_id": "tjwQaOI9tdy",
    "submission_title": "Symbolic Regression via Deep Reinforcement Learning Enhanced Genetic Programming Seeding",
    "review_id": "zkfyPQnftnp",
    "input": {
      "title": "Symbolic Regression via Deep Reinforcement Learning Enhanced Genetic Programming Seeding",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The overall approach is mainly a combination of existing methods. Thus, I regard the originality as limited.\n- I did not find obvious flaws or misleading statements in the manuscript.\n- It is interesting that GP alone performs so well (table 2).\n- Some part were not clear to me:\n- Are the individuals which violate the constraints removed (i.e., get lethal fitness) or repaired (e.g., ln(e^x) is simply replaced by x)?\n- lines 54-59:  The authors could elaborate what they exactly refer to with 'out-of-distribution', 'off-policy', and 'on-policy' in this context. What are the two policies? Would the authors regard the RNN to be on-policy and, if yes, why is this a problem?\n- lines 231-234: I am not fully sure that I understand the fundamental difference between PQT and RSPG: PQT takes the best from T_rl and T_gp combines while RSPG only removes the worst solutions from T_rl?\n- line 303: The entropy term comes out of the blue - where is it used?\n- Literature embedding: lines 87-89: the idea of combining GP and gradient-based optimization of the numerical values goes back to: C. Igel. M. Kreutz. Using Fitness Distributions to Improve the Evolution of Learning Structures. Congress on Evolutionary Computation (CEC 99), pp. 1902-1909, IEEE Press, 1999 [see section 5]\n- Minor comments:\n- line 27: ', is' -> 'is'\n- line 48: 'the problem' -> 'the general problem'?\n- line 419: first name abbreviations",
    "review_points_list": [
      "The overall approach is mainly a combination of existing methods. Thus, I regard the originality as limited.",
      "I did not find obvious flaws or misleading statements in the manuscript.",
      "It is interesting that GP alone performs so well (table 2).",
      "Some part were not clear to me:",
      "Are the individuals which violate the constraints removed (i.e., get lethal fitness) or repaired (e.g., ln(e^x) is simply replaced by x)?",
      "lines 54-59:  The authors could elaborate what they exactly refer to with 'out-of-distribution', 'off-policy', and 'on-policy' in this context. What are the two policies? Would the authors regard the RNN to be on-policy and, if yes, why is this a problem?",
      "lines 231-234: I am not fully sure that I understand the fundamental difference between PQT and RSPG: PQT takes the best from T_rl and T_gp combines while RSPG only removes the worst solutions from T_rl?",
      "line 303: The entropy term comes out of the blue - where is it used?",
      "Literature embedding: lines 87-89: the idea of combining GP and gradient-based optimization of the numerical values goes back to: C. Igel. M. Kreutz. Using Fitness Distributions to Improve the Evolution of Learning Structures. Congress on Evolutionary Computation (CEC 99), pp. 1902-1909, IEEE Press, 1999 [see section 5]",
      "Minor comments:",
      "line 27: ', is' -> 'is'",
      "line 48: 'the problem' -> 'the general problem'?",
      "line 419: first name abbreviations"
    ]
  },
  {
    "paper_id": "2111.00053v2",
    "submission_id": "tjwQaOI9tdy",
    "submission_title": "Symbolic Regression via Deep Reinforcement Learning Enhanced Genetic Programming Seeding",
    "review_id": "nH68YMPzsHJ",
    "input": {
      "title": "Symbolic Regression via Deep Reinforcement Learning Enhanced Genetic Programming Seeding",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This work is somehow a novel combination of 'Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients Petersen et al. 2021' and 'Guiding deep molecular optimization with genetic exploration Ahn et al. 2020'.\n- The related work section is sound.\n- The idea of combining reinforcement learning (RL) and genetic algorithm is quite simple.\n- Use the results computed by the RL policy to guide the genetic algorithm, and the improved results from the genetic algorithm can be used to improve the RL policy.\n- Several methods to improve this cycle are studied and explained.\n- In the merit of simple, the performance looks good.\n- It would be better if the authors can improve the writing. It is a little bit hard for me to follow the paper.\n- Too many details are mentioned in the main text and hard to capture the high-level idea.\n- For the experiment section, it would be better if the author can mark your results at least in bold.\n- The program this paper studies is significant.\n- What's the difference between DSR in Tabel1 and DSR (RL only) in Tabel 2?\n- If there are differences, why use two different baselines?\n- And why not run all the baselines on all the datasets?\n- It would be better if you set a time budget and let all the methods run under the budget.\n- It seems that Nguyen-10 and 11 are more complicated than 12. But all the methods fail on 12. Do you have some intuitions?",
    "review_points_list": [
      "This work is somehow a novel combination of 'Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients Petersen et al. 2021' and 'Guiding deep molecular optimization with genetic exploration Ahn et al. 2020'.",
      "The related work section is sound.",
      "The idea of combining reinforcement learning (RL) and genetic algorithm is quite simple.",
      "Use the results computed by the RL policy to guide the genetic algorithm, and the improved results from the genetic algorithm can be used to improve the RL policy.",
      "Several methods to improve this cycle are studied and explained.",
      "In the merit of simple, the performance looks good.",
      "It would be better if the authors can improve the writing. It is a little bit hard for me to follow the paper.",
      "Too many details are mentioned in the main text and hard to capture the high-level idea.",
      "For the experiment section, it would be better if the author can mark your results at least in bold.",
      "The program this paper studies is significant.",
      "What's the difference between DSR in Tabel1 and DSR (RL only) in Tabel 2?",
      "If there are differences, why use two different baselines?",
      "And why not run all the baselines on all the datasets?",
      "It would be better if you set a time budget and let all the methods run under the budget.",
      "It seems that Nguyen-10 and 11 are more complicated than 12. But all the methods fail on 12. Do you have some intuitions?"
    ]
  },
  {
    "paper_id": "2111.00053v2",
    "submission_id": "tjwQaOI9tdy",
    "submission_title": "Symbolic Regression via Deep Reinforcement Learning Enhanced Genetic Programming Seeding",
    "review_id": "bRLJxvejZ-0",
    "input": {
      "title": "Symbolic Regression via Deep Reinforcement Learning Enhanced Genetic Programming Seeding",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is very well written and structured.\n- Language is clear at all times; math is not overused.\n- The method is very well described and presented.\n- I really like the simplicity behind it, and the authors do a good work explaining the motivations and intuitions behind it.\n- The contribution can be arguably minor, because they are taking two solid methods and just gluing them together; nevertheless, it works, so I'm guessing authors will have to defend the relevance of their contribution to the other reviewers.\n- I personally consider it worthy for acceptance at NeurIPS; there are, however, some details that I consider that need attention, before I can give a higher evaluation for the paper:\n- I reviewed closely your experimental design, and I noticed that you use extremely small sample points sets (10~20 points); I wonder how results change if you provide more sample points, let's say, in the range of hundreds or thousands, to the different methods tested.\n- If I understood correctly, your 'primitives' (as called in GP literature) is {+,\u2212,\u00d7,\u00f7,sin,cos,exp,log,x} (from your appendix). So, there are certain problems, such as Nguyen-8 and Nguyen-11 where the GP has no chance to find the correct expression, because it would be simply too difficult, or even impossible, to build it given those primitives.... why or how did you expect the GP to find those expression?? For example, express to me x^y using only the set of functions mentioned above.\n- More importantly, how did your method manage to find such functions?\n- The most important element that I find missing in your draft, is a bit of discussion on how or why you think your method works, at a low level analysis.\n- I do understand the perks and capabilities of RL, but my question is... what exactly is doing the RL that enhances that much a vanilla GP. My bet is that is pruning the primitives set, such that the GP has a smaller and better defined search space, but I'd really like to hear your thoughts on this.\n- Notice how your method could help immensely to understand on why GP sometimes work, sometimes doesn't, i.e. what makes a problem difficult for GP, which has been the million dollar question in GP research, but you need to provide a bit of discussion in such regard.\n- The Authors properly addressed all my questions and concerns.\n- I've no doubt on the effectiveness and relevance of their method.\n- The paper is well written, and my main objection (lack of discussion on how the method works at a low level) has been attended.\n- Therefore, I see no real reason for this work for not being accepted.",
    "review_points_list": [
      "The paper is very well written and structured.",
      "Language is clear at all times; math is not overused.",
      "The method is very well described and presented.",
      "I really like the simplicity behind it, and the authors do a good work explaining the motivations and intuitions behind it.",
      "The contribution can be arguably minor, because they are taking two solid methods and just gluing them together; nevertheless, it works, so I'm guessing authors will have to defend the relevance of their contribution to the other reviewers.",
      "I personally consider it worthy for acceptance at NeurIPS; there are, however, some details that I consider that need attention, before I can give a higher evaluation for the paper:",
      "I reviewed closely your experimental design, and I noticed that you use extremely small sample points sets (10~20 points); I wonder how results change if you provide more sample points, let's say, in the range of hundreds or thousands, to the different methods tested.",
      "If I understood correctly, your 'primitives' (as called in GP literature) is {+,\u2212,\u00d7,\u00f7,sin,cos,exp,log,x} (from your appendix). So, there are certain problems, such as Nguyen-8 and Nguyen-11 where the GP has no chance to find the correct expression, because it would be simply too difficult, or even impossible, to build it given those primitives.... why or how did you expect the GP to find those expression?? For example, express to me x^y using only the set of functions mentioned above.",
      "More importantly, how did your method manage to find such functions?",
      "The most important element that I find missing in your draft, is a bit of discussion on how or why you think your method works, at a low level analysis.",
      "I do understand the perks and capabilities of RL, but my question is... what exactly is doing the RL that enhances that much a vanilla GP. My bet is that is pruning the primitives set, such that the GP has a smaller and better defined search space, but I'd really like to hear your thoughts on this.",
      "Notice how your method could help immensely to understand on why GP sometimes work, sometimes doesn't, i.e. what makes a problem difficult for GP, which has been the million dollar question in GP research, but you need to provide a bit of discussion in such regard.",
      "The Authors properly addressed all my questions and concerns.",
      "I've no doubt on the effectiveness and relevance of their method.",
      "The paper is well written, and my main objection (lack of discussion on how the method works at a low level) has been attended.",
      "Therefore, I see no real reason for this work for not being accepted."
    ]
  },
  {
    "paper_id": "2111.00053v2",
    "submission_id": "tjwQaOI9tdy",
    "submission_title": "Symbolic Regression via Deep Reinforcement Learning Enhanced Genetic Programming Seeding",
    "review_id": "gZZkYj_CByW",
    "input": {
      "title": "Symbolic Regression via Deep Reinforcement Learning Enhanced Genetic Programming Seeding",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The hybrid method of a policy gradient method and genetic programming (GP) is interesting. However, the combination method proposed in this paper seems to be simple.\n- In the proposed method, the sampled solutions from a deep neural network are used as the initial population of GP iterations.\n- In addition, the generated solutions by GP are injected into the samples used for updating the neural network weights via policy gradient.\n- The samples generated by GP iterations are used for updating neural network weights by policy gradient update.\n- The policy gradient formula shown in section 3 is the Monte-Carlo approximation of the true gradient under the current policy.\n- If we inject the samples generated by GP to calculate the policy gradient, the estimation of the policy gradient is biased.\n- It should be carefully noted the justification of the proposed method.\n- The reviewer cannot understand the reason for the performance improvement by the proposed method.\n- How does genetic programming contribute to improving the recovery rate?\n- The authors should elaborate on the reason for the performance improvement.\n- In [Petersen et al., 2021], other benchmark symbolic regression problems are also examined, such as Jin-X and Neat-X.\n- How about the performance of the proposed method on these benchmarks?\n- Does 'GP-Meld' mean 'DREGS' in Table 4?\n- The authors reply to my request properly.\n- I agree with the clear performance improvement by the proposed method as the strength of this paper.\n- SO, I would raise my score.\n- However, the novelty is limited because the proposed method is a simple heuristic combination of the existing methods.",
    "review_points_list": [
      "The hybrid method of a policy gradient method and genetic programming (GP) is interesting. However, the combination method proposed in this paper seems to be simple.",
      "In the proposed method, the sampled solutions from a deep neural network are used as the initial population of GP iterations.",
      "In addition, the generated solutions by GP are injected into the samples used for updating the neural network weights via policy gradient.",
      "The samples generated by GP iterations are used for updating neural network weights by policy gradient update.",
      "The policy gradient formula shown in section 3 is the Monte-Carlo approximation of the true gradient under the current policy.",
      "If we inject the samples generated by GP to calculate the policy gradient, the estimation of the policy gradient is biased.",
      "It should be carefully noted the justification of the proposed method.",
      "The reviewer cannot understand the reason for the performance improvement by the proposed method.",
      "How does genetic programming contribute to improving the recovery rate?",
      "The authors should elaborate on the reason for the performance improvement.",
      "In [Petersen et al., 2021], other benchmark symbolic regression problems are also examined, such as Jin-X and Neat-X.",
      "How about the performance of the proposed method on these benchmarks?",
      "Does 'GP-Meld' mean 'DREGS' in Table 4?",
      "The authors reply to my request properly.",
      "I agree with the clear performance improvement by the proposed method as the strength of this paper.",
      "SO, I would raise my score.",
      "However, the novelty is limited because the proposed method is a simple heuristic combination of the existing methods."
    ]
  },
  {
    "paper_id": "2110.14865v2",
    "submission_id": "vFKvKIwcHw9",
    "submission_title": "Counterbalancing Learning and Strategic Incentives in Allocation Markets",
    "review_id": "nnl0MZxefbD",
    "input": {
      "title": "Counterbalancing Learning and Strategic Incentives in Allocation Markets",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The problem is very well and clearly motivated.\n- From a practical point of view, the running example that the authors use is that of organ allocation. There, it is extremely important to ensure that organs are not discarded due to inefficiencies in online decision-making.\n- The aspect studied by the authors is interesting.\n- The point of view taken here is that agents learn from not only their private signals but also from past observations whether the organ is likely to be good or not, and base their willingness to get the item on this knowledge.\n- The na\u00efve sequential mechanism then does not work, because early agents believing the organ is bad lead all subsequent agents to believe the same, leading to the organ being discarded.\n- I like the characterization of Lemma 1 that i) shows exactly when this can happen and ii) shows that this reduces to the beliefs of only the first 2 agents.\n- The characterization of Theorem 1 is tight.\n- If the information received by the agents is precise enough, then the authors develop a voting mechanism that is incentive-compatible and improves outcomes (correctness) compared to the na\u00efve sequential mechanism.\n- When not the case, they show that there is no truthful mechanism that will improve on the sequential one.\n- The mechanism is relatively simple in principle and the idea behind it is natural (divide the population in increasing batch sizes and have them vote to decide on the allocation).\n- It should be not too hard to implement in practice (up to getting the problem parameters right).\n- The experiments complement the theoretical results well, showing that even just 2 batches already improve results significantly compared to the sequential algorithm.\n- the model is still simple and first-cut, as acknowledged by the authors.\n- The agents are fully symmetric (before they receive their signals), and all have the same utility/need for an organ.\n- the randomness in the allocation may be undesirable, in the sense that an agent that is first of the remaining list might be skipped.\n- What is the justification for agents having a private signal on the quality of the organ, versus there being a public signal?\n- Why would individuals get different information about the organ in practice?\n- It would be nice to talk about this a bit more.",
    "review_points_list": [
      "The problem is very well and clearly motivated.",
      "From a practical point of view, the running example that the authors use is that of organ allocation. There, it is extremely important to ensure that organs are not discarded due to inefficiencies in online decision-making.",
      "The aspect studied by the authors is interesting.",
      "The point of view taken here is that agents learn from not only their private signals but also from past observations whether the organ is likely to be good or not, and base their willingness to get the item on this knowledge.",
      "The na\u00efve sequential mechanism then does not work, because early agents believing the organ is bad lead all subsequent agents to believe the same, leading to the organ being discarded.",
      "I like the characterization of Lemma 1 that i) shows exactly when this can happen and ii) shows that this reduces to the beliefs of only the first 2 agents.",
      "The characterization of Theorem 1 is tight.",
      "If the information received by the agents is precise enough, then the authors develop a voting mechanism that is incentive-compatible and improves outcomes (correctness) compared to the na\u00efve sequential mechanism.",
      "When not the case, they show that there is no truthful mechanism that will improve on the sequential one.",
      "The mechanism is relatively simple in principle and the idea behind it is natural (divide the population in increasing batch sizes and have them vote to decide on the allocation).",
      "It should be not too hard to implement in practice (up to getting the problem parameters right).",
      "The experiments complement the theoretical results well, showing that even just 2 batches already improve results significantly compared to the sequential algorithm.",
      "the model is still simple and first-cut, as acknowledged by the authors.",
      "The agents are fully symmetric (before they receive their signals), and all have the same utility/need for an organ.",
      "the randomness in the allocation may be undesirable, in the sense that an agent that is first of the remaining list might be skipped.",
      "What is the justification for agents having a private signal on the quality of the organ, versus there being a public signal?",
      "Why would individuals get different information about the organ in practice?",
      "It would be nice to talk about this a bit more."
    ]
  },
  {
    "paper_id": "2110.14865v2",
    "submission_id": "vFKvKIwcHw9",
    "submission_title": "Counterbalancing Learning and Strategic Incentives in Allocation Markets",
    "review_id": "Nw91R56TvXN",
    "input": {
      "title": "Counterbalancing Learning and Strategic Incentives in Allocation Markets",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper is well-written, clear, and easy to follow.\n- The problem studied is nicely motivated by important real world applications.\n- The collection of theoretical results is novel and interesting, which also gives interesting and useful insights to understand the problem.\n- This work also opens many interesting follow-up questions to consider.\n- The reviewer did not check all the proofs but they all look plausible in hindsight.\n- It is surprising to see that two agents would determine the outcome in sequential offering mechanisms.\n- The reviewer wonders perhaps this result is mainly due to the i.i.d. assumption.\n- What would happen if the agents are not identical?\n- The reviewer really likes Lemma 2.\n- It is very interesting to see that in order to achieve IC, the batch size cannot be too large or too small.\n- Given that the quality of the object is a binary, possibly the only relevant voting rule is majority.\n- It would be interesting to see how to extend the results to an environment where the quality of the object is no longer a binary; and understand which voting rule could give the best outcome.\n- There is no theoretical guarantee on how the greedy voting mechanism performs.\n- It would be great to figure out whether the greedy voting mechanism is indeed optimal; if no, then understand what approximation does the mechanism give and also find out the optimal mechanism.\n- Figure 3 is confusing.\n- Is V_GREEDY and V_OPT the same?\n- Could we try V_GREEDY^K with K > 2?\n- Is it better than V_GREEDY^2?\n- After reading Lemma 2, the reviewer is curious to see a table or a plot of upper and lower bounds.\n- This is shown in Figure 2 but it might be better to provide a reference to the figure here so that the readers do not need to wonder about the bounds.",
    "review_points_list": [
      "This paper is well-written, clear, and easy to follow.",
      "The problem studied is nicely motivated by important real world applications.",
      "The collection of theoretical results is novel and interesting, which also gives interesting and useful insights to understand the problem.",
      "This work also opens many interesting follow-up questions to consider.",
      "The reviewer did not check all the proofs but they all look plausible in hindsight.",
      "It is surprising to see that two agents would determine the outcome in sequential offering mechanisms.",
      "The reviewer wonders perhaps this result is mainly due to the i.i.d. assumption.",
      "What would happen if the agents are not identical?",
      "The reviewer really likes Lemma 2.",
      "It is very interesting to see that in order to achieve IC, the batch size cannot be too large or too small.",
      "Given that the quality of the object is a binary, possibly the only relevant voting rule is majority.",
      "It would be interesting to see how to extend the results to an environment where the quality of the object is no longer a binary; and understand which voting rule could give the best outcome.",
      "There is no theoretical guarantee on how the greedy voting mechanism performs.",
      "It would be great to figure out whether the greedy voting mechanism is indeed optimal; if no, then understand what approximation does the mechanism give and also find out the optimal mechanism.",
      "Figure 3 is confusing.",
      "Is V_GREEDY and V_OPT the same?",
      "Could we try V_GREEDY^K with K > 2?",
      "Is it better than V_GREEDY^2?",
      "After reading Lemma 2, the reviewer is curious to see a table or a plot of upper and lower bounds.",
      "This is shown in Figure 2 but it might be better to provide a reference to the figure here so that the readers do not need to wonder about the bounds."
    ]
  },
  {
    "paper_id": "2110.14865v2",
    "submission_id": "vFKvKIwcHw9",
    "submission_title": "Counterbalancing Learning and Strategic Incentives in Allocation Markets",
    "review_id": "l7nXLgxya4Y",
    "input": {
      "title": "Counterbalancing Learning and Strategic Incentives in Allocation Markets",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper provides a clever algorithm to solve a stylized version of an interesting and realistic problem.\n- The authors do a fantastic job of providing explanations and intuition behind their proofs and math.\n- The algorithm is a satisfying solution.\n- The paper is a good illustration of how incentives and learning can collide to interfere with one another, and provides a natural solution that will probably generalize to less stylized cases.\n- I generally like the paper, but I have several quibbles.\n- Using organ donation as the primary motivator, highlighted in the first sentence of the abstract, seems like a stretch.\n- The stylized model does not really fit the organ donation example.\n- In organ donation, organs are not just 'good' and 'bad' for everyone.\n- The quality of an organ for an agent is highly personalized, according to the level of match with blood type as the highest-order bit and with many other factors.\n- If an organ is not good for one patient, it should mean little for the next patient.\n- Also, patients themselves don't have the best information about the quality of an organ: doctors and hospitals do.\n- Presumably, if the organ is 'bad', the hospital system will not offer it to anyone.\n- The organ application seems like it is thrown in just to draw interest: the authors make no attempt to use real data from organ exchanges in the paper and don't really discuss how their stylized model diverges from the application complexities.\n- The paper is a theory paper with simulations: I encourage the authors to be more clear about the strength of fit to applications.\n- Real estate might be a better application.\n- When a house is on the market for a long time without being sold, buyers may think, 'something must be wrong with the house'.\n- Agents do have information about the house.\n- It's still not perfect, since real estate values are also subjective, and since the real estate market involves prices.\n- In general, I suggest the authors not highlight an application in detail unless some real data is used or care is taken to discuss the fit of theory to reality.\n- Potential applications can be mentioned in the intro, but I wouldn't highlight one of them in the first sentence of the abstract.\n- Second, I'd like more discussion of how important key assumptions are to the analysis.\n- In particular, the fact that the true positive rate equals the true negative rate (line 97) seems like a strong and unrealistic assumption.\n- Third, the simulations don't add a whole lot, in part because the theory is strong.\n- Using some kind of real data would make the paper much stronger than running simulations.\n- Why isn't V_GREEDY one of the simulated algorithms?\n- Why are only the 1- and 2-batch algorithms simulated?\n- This seems strange.\n- The main algorithm in the paper is V_GREEDY.\n- I would expect this to be simulated if nothing else.\n- When defining incentive compatibility (line 127), I suggest the authors mention that agents will update u as they learn from other agents.\n- In Figure 3, how does V_ALL achieve perfect correctness?\n- Presumably, even V_ALL will allocate incorrectly with some small probability, if, for example, many agents receive an incorrect signal by random chance.\n- Some minor suggestions: thousand of future lives.",
    "review_points_list": [
      "The paper provides a clever algorithm to solve a stylized version of an interesting and realistic problem.",
      "The authors do a fantastic job of providing explanations and intuition behind their proofs and math.",
      "The algorithm is a satisfying solution.",
      "The paper is a good illustration of how incentives and learning can collide to interfere with one another, and provides a natural solution that will probably generalize to less stylized cases.",
      "I generally like the paper, but I have several quibbles.",
      "Using organ donation as the primary motivator, highlighted in the first sentence of the abstract, seems like a stretch.",
      "The stylized model does not really fit the organ donation example.",
      "In organ donation, organs are not just 'good' and 'bad' for everyone.",
      "The quality of an organ for an agent is highly personalized, according to the level of match with blood type as the highest-order bit and with many other factors.",
      "If an organ is not good for one patient, it should mean little for the next patient.",
      "Also, patients themselves don't have the best information about the quality of an organ: doctors and hospitals do.",
      "Presumably, if the organ is 'bad', the hospital system will not offer it to anyone.",
      "The organ application seems like it is thrown in just to draw interest: the authors make no attempt to use real data from organ exchanges in the paper and don't really discuss how their stylized model diverges from the application complexities.",
      "The paper is a theory paper with simulations: I encourage the authors to be more clear about the strength of fit to applications.",
      "Real estate might be a better application.",
      "When a house is on the market for a long time without being sold, buyers may think, 'something must be wrong with the house'.",
      "Agents do have information about the house.",
      "It's still not perfect, since real estate values are also subjective, and since the real estate market involves prices.",
      "In general, I suggest the authors not highlight an application in detail unless some real data is used or care is taken to discuss the fit of theory to reality.",
      "Potential applications can be mentioned in the intro, but I wouldn't highlight one of them in the first sentence of the abstract.",
      "Second, I'd like more discussion of how important key assumptions are to the analysis.",
      "In particular, the fact that the true positive rate equals the true negative rate (line 97) seems like a strong and unrealistic assumption.",
      "Third, the simulations don't add a whole lot, in part because the theory is strong.",
      "Using some kind of real data would make the paper much stronger than running simulations.",
      "Why isn't V_GREEDY one of the simulated algorithms?",
      "Why are only the 1- and 2-batch algorithms simulated?",
      "This seems strange.",
      "The main algorithm in the paper is V_GREEDY.",
      "I would expect this to be simulated if nothing else.",
      "When defining incentive compatibility (line 127), I suggest the authors mention that agents will update u as they learn from other agents.",
      "In Figure 3, how does V_ALL achieve perfect correctness?",
      "Presumably, even V_ALL will allocate incorrectly with some small probability, if, for example, many agents receive an incorrect signal by random chance.",
      "Some minor suggestions: thousand of future lives."
    ]
  },
  {
    "paper_id": "2110.06418v1",
    "submission_id": "yxg-i8DAHK",
    "submission_title": "Stabilizing Dynamical Systems via Policy Gradient Methods",
    "review_id": "V1SdqQc4sKh",
    "input": {
      "title": "Stabilizing Dynamical Systems via Policy Gradient Methods",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper is well-written and insightful.\n- The proofs appear to be rigorous.\n- However, as discussed below, the basic idea of using the discount factor for model-free stabilization has appeared independently in the literature.\n- The proofs appear to be very different from the existing work, and the similarities appear to be coincidental.\n- So, overall, this is nice work, the contribution feels a bit smaller as a result.\n- A very similar model-free methodology has already been devised for computing stabilizing controllers\n- and solving LQR in: Lamperski, Andrew.\n- Computing Stabilizing Linear Controllers via Policy Iteration.\n- 2020 59th IEEE Conference on Decision and Control (CDC). IEEE, 2020.\n- Both are model free, and both interleave policy improvement steps with increases in the discount factor.\n- Both give stabilizing controllers and converge to the LQR solution.\n- The prior work uses policy-iteration style updates in an off-policy manner.\n- In particular, it can be used on a single trajectory or an offline data set.\n- The current submission uses gradient evaluations, which effectively require restating the system for each new gradient.\n- The current submission does give more explicit convergence bounds and gives applications to nonlinear systems.\n- Edit based on Response: Based on the response, I can see greater merit and distinction in the work and I will raise my score appropriately.",
    "review_points_list": [
      "This paper is well-written and insightful.",
      "The proofs appear to be rigorous.",
      "However, as discussed below, the basic idea of using the discount factor for model-free stabilization has appeared independently in the literature.",
      "The proofs appear to be very different from the existing work, and the similarities appear to be coincidental.",
      "So, overall, this is nice work, the contribution feels a bit smaller as a result.",
      "A very similar model-free methodology has already been devised for computing stabilizing controllers",
      "and solving LQR in: Lamperski, Andrew.",
      "Computing Stabilizing Linear Controllers via Policy Iteration.",
      "2020 59th IEEE Conference on Decision and Control (CDC). IEEE, 2020.",
      "Both are model free, and both interleave policy improvement steps with increases in the discount factor.",
      "Both give stabilizing controllers and converge to the LQR solution.",
      "The prior work uses policy-iteration style updates in an off-policy manner.",
      "In particular, it can be used on a single trajectory or an offline data set.",
      "The current submission uses gradient evaluations, which effectively require restating the system for each new gradient.",
      "The current submission does give more explicit convergence bounds and gives applications to nonlinear systems.",
      "Edit based on Response: Based on the response, I can see greater merit and distinction in the work and I will raise my score appropriately."
    ]
  },
  {
    "paper_id": "2110.06418v1",
    "submission_id": "yxg-i8DAHK",
    "submission_title": "Stabilizing Dynamical Systems via Policy Gradient Methods",
    "review_id": "_Dh2VFZe-PS",
    "input": {
      "title": "Stabilizing Dynamical Systems via Policy Gradient Methods",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- In my opinion, this paper is quite original and considers an important question.\n- Stabilization is a fundamental question for control, and how to solve it via policy gradient is unclear.\n- This paper makes progress in answering such an important question, and I can see there is unique contribution in this paper.\n- This paper missed a large body of literature on policy optimization of linear control problems.\n- The following papers are relevant, and the authors should discuss them.\n- This is a solid paper, although it is unclear how the authors draw the conclusion that their method improves the H-infinity control method.\n- I have a few more questions here.\n- 1) How can the authors prove that gamma keeps increasing to 1 without approaching some limit point in the middle?\n- I guess the proof will require some lower bound on how much progress on gamma can be made at each iteration. Is that true?\n- Any uniform lower bound here?\n- 2) In the nonlinear setting, it seems that based on Lyapunov's indirect method, one can just linearize the dynamics and then stabilize the linear systems.\n- Right?\n- What is the point of developing new theory for 'local' stabilization of nonlinear systems?\n- 3) Any evidence supporting the claim that the proposed approach is competitive with established robust control procedures?\n- I mean, I can't find how the authors set up robust control baselines in their numerical study.\n- 4) For simulations, how does the proposed approach work on systems which have modes blowing up to infinity very quickly?\n- In this case, although the theory states that a very small discount factor can be used such that the zero control gain lead to a finite cost, practically the system states in the simulations can blow up quickly to cause numerical issues, right?\n- Can the authors provide an example on this?\n- The paper is well written.\n- The idea is quite clear.\n- I think the paper is significant in that it tries to answer a fundamental question with relatively simple ideas.\n- In my opinion, such a solution for stabilization is novel and interesting.\n- I am convinced to increase my score to 7.",
    "review_points_list": [
      "In my opinion, this paper is quite original and considers an important question.",
      "Stabilization is a fundamental question for control, and how to solve it via policy gradient is unclear.",
      "This paper makes progress in answering such an important question, and I can see there is unique contribution in this paper.",
      "This paper missed a large body of literature on policy optimization of linear control problems.",
      "The following papers are relevant, and the authors should discuss them.",
      "This is a solid paper, although it is unclear how the authors draw the conclusion that their method improves the H-infinity control method.",
      "I have a few more questions here.",
      "1) How can the authors prove that gamma keeps increasing to 1 without approaching some limit point in the middle?",
      "I guess the proof will require some lower bound on how much progress on gamma can be made at each iteration. Is that true?",
      "Any uniform lower bound here?",
      "2) In the nonlinear setting, it seems that based on Lyapunov's indirect method, one can just linearize the dynamics and then stabilize the linear systems.",
      "Right?",
      "What is the point of developing new theory for 'local' stabilization of nonlinear systems?",
      "3) Any evidence supporting the claim that the proposed approach is competitive with established robust control procedures?",
      "I mean, I can't find how the authors set up robust control baselines in their numerical study.",
      "4) For simulations, how does the proposed approach work on systems which have modes blowing up to infinity very quickly?",
      "In this case, although the theory states that a very small discount factor can be used such that the zero control gain lead to a finite cost, practically the system states in the simulations can blow up quickly to cause numerical issues, right?",
      "Can the authors provide an example on this?",
      "The paper is well written.",
      "The idea is quite clear.",
      "I think the paper is significant in that it tries to answer a fundamental question with relatively simple ideas.",
      "In my opinion, such a solution for stabilization is novel and interesting.",
      "I am convinced to increase my score to 7."
    ]
  },
  {
    "paper_id": "2110.06418v1",
    "submission_id": "yxg-i8DAHK",
    "submission_title": "Stabilizing Dynamical Systems via Policy Gradient Methods",
    "review_id": "uRPSVuxg10X",
    "input": {
      "title": "Stabilizing Dynamical Systems via Policy Gradient Methods",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper considers an important problem, since many control methods require a stabilizing controller even when the system is unknown.\n- The paper leverages existing techniques but uses new insights to overcome the limitations of said techniques.\n- The theoretical results appear to be correct but I wasn\u2019t able to check all the details.\n- The significance of the result can be strengthened by comparing with other stabilization methods for linear systems with similar access models.\n- For example, \u201cFinite-Time Adaptive Stabilization of Linear Systems\u201d and \u201cRandomized algorithms for data-driven stabilization of stochastic linear systems\u201d  give algorithms for stabilization.\n- How does this paper compare with the techniques used there?\n- I\u2019m also not completely convinced of model-free methods\u2019 advantages over mode-based methods for linear systems, since linear systems don\u2019t have arbitrary dynamics.\n- The setting for linear systems assumes there is no noise, which is restrictive.\n- Can the results be extended to accommodate stochastic noise?\n- The experimental section could be improved by including other, and possibly more difficult, tasks.\n- Post rebuttal: I have read the authors' response, and will increase my score.",
    "review_points_list": [
      "The paper considers an important problem, since many control methods require a stabilizing controller even when the system is unknown.",
      "The paper leverages existing techniques but uses new insights to overcome the limitations of said techniques.",
      "The theoretical results appear to be correct but I wasn\u2019t able to check all the details.",
      "The significance of the result can be strengthened by comparing with other stabilization methods for linear systems with similar access models.",
      "For example, \u201cFinite-Time Adaptive Stabilization of Linear Systems\u201d and \u201cRandomized algorithms for data-driven stabilization of stochastic linear systems\u201d  give algorithms for stabilization.",
      "How does this paper compare with the techniques used there?",
      "I\u2019m also not completely convinced of model-free methods\u2019 advantages over mode-based methods for linear systems, since linear systems don\u2019t have arbitrary dynamics.",
      "The setting for linear systems assumes there is no noise, which is restrictive.",
      "Can the results be extended to accommodate stochastic noise?",
      "The experimental section could be improved by including other, and possibly more difficult, tasks.",
      "Post rebuttal: I have read the authors' response, and will increase my score."
    ]
  },
  {
    "paper_id": "2106.13679v2",
    "submission_id": "ui4xChWcA4R",
    "submission_title": "Shape Registration in the Time of Transformers",
    "review_id": "YETvlApWCE",
    "input": {
      "title": "Shape Registration in the Time of Transformers",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- a) The use of the Transformer architecture for the task of non-rigid registration is new, and seems to be the first as claimed by the authors;\n- b) For complete shape scans, it makes sense to modify the attention mechanism to make it aware of the point cloud local density;\n- Overall, this paper is well-written, and easy to follow.\n- As noted by authors in line 109, the deep closest point [50] also use a transformer to register rigid shapes. In light of this, it is highly beneficial if the author can provide the following comparisons:\n- Trim the architecture of [50], add MLP to \u03a6_X or \u03a6_Y (Figure 2 in [50]) to estimate the deformed points.\n- Use the above baseline to compare with your proposed architecture.\n- This paper lacks experiments of partial--to-partial registration of non-rigid point clouds. Adding noise in experiment is good (Line 207).\n- I would expect this partial-to-partial registration are more realistic in many real-world applications. How will your method handle significant portion of non-matchable outliers?\n- Furthermore, the above experiment would also check the effectiveness and robustness of the proposed modified attention mechanism (Equation 1).\n- Giving qualitative comparisons in Figure 3 is good. However, I would like to see full quantitative comparisons besides the 50% claim on line 245.\n- Please specify the details of computation times, and compare them with respect to other methods (in Table 2).\n- As indicated on Line 301-302, the proposed method is computationally expensive/time consuming.\n- Why do you claim it is an 'efficient registration' method (c.f. Line 1)?",
    "review_points_list": [
      "a) The use of the Transformer architecture for the task of non-rigid registration is new, and seems to be the first as claimed by the authors;",
      "b) For complete shape scans, it makes sense to modify the attention mechanism to make it aware of the point cloud local density;",
      "Overall, this paper is well-written, and easy to follow.",
      "As noted by authors in line 109, the deep closest point [50] also use a transformer to register rigid shapes. In light of this, it is highly beneficial if the author can provide the following comparisons:",
      "Trim the architecture of [50], add MLP to \u03a6_X or \u03a6_Y (Figure 2 in [50]) to estimate the deformed points.",
      "Use the above baseline to compare with your proposed architecture.",
      "This paper lacks experiments of partial--to-partial registration of non-rigid point clouds. Adding noise in experiment is good (Line 207).",
      "I would expect this partial-to-partial registration are more realistic in many real-world applications. How will your method handle significant portion of non-matchable outliers?",
      "Furthermore, the above experiment would also check the effectiveness and robustness of the proposed modified attention mechanism (Equation 1).",
      "Giving qualitative comparisons in Figure 3 is good. However, I would like to see full quantitative comparisons besides the 50% claim on line 245.",
      "Please specify the details of computation times, and compare them with respect to other methods (in Table 2).",
      "As indicated on Line 301-302, the proposed method is computationally expensive/time consuming.",
      "Why do you claim it is an 'efficient registration' method (c.f. Line 1)?"
    ]
  },
  {
    "paper_id": "2106.13679v2",
    "submission_id": "ui4xChWcA4R",
    "submission_title": "Shape Registration in the Time of Transformers",
    "review_id": "rodpPsM13rg",
    "input": {
      "title": "Shape Registration in the Time of Transformers",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.\n- The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective. In particular, the algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset. The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP). Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.\n- The authors also establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings. In particular, they show that the Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta. They also show that this improvement is possible under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large. They also show that the optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm. They finally show that log(k) is an upper bound on the improvement of query complexity for any sampler.\n- The authors are aware and mention that their theoretical results are initial and that equating volume-based samplers and the Cluster-Margin algorithm is an open research question.\n- The paper is very clear and well organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.\n- The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.\n- The approach is technically sound and makes intuitive sense.\n- Quantitative results look good.\n- Authors will release their code and data, which is appreciated.\n- Why does the proposed method need explicit normalization for point density?\n- Why can't it be augmented such that network learns to generalise to different sampling strategies?\n- There is a performance gap between performance on SURREAL and FAUST, which authors attribute to different surface distributions.\n- Why is this not evaluated on the FAUST challenge?\n- Are the baselines trained on the same data as the proposed method?\n- How do the transformers perform with denser inputs?\n- Current limitations stated in the conclusion section are generic.\n- It would be good to also discuss other directions in 3D vision where transformer architectures would be beneficial.",
    "review_points_list": [
      "The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.",
      "The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective. In particular, the algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset. The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP). Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.",
      "The authors also establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings. In particular, they show that the Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta. They also show that this improvement is possible under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large. They also show that the optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm. They finally show that log(k) is an upper bound on the improvement of query complexity for any sampler.",
      "The authors are aware and mention that their theoretical results are initial and that equating volume-based samplers and the Cluster-Margin algorithm is an open research question.",
      "The paper is very clear and well organized. The authors detail the hyper-parameters and compute details used for the experiments. The Cluster-Margin algorithm is also explained in detail.",
      "The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods. The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.",
      "The approach is technically sound and makes intuitive sense.",
      "Quantitative results look good.",
      "Authors will release their code and data, which is appreciated.",
      "Why does the proposed method need explicit normalization for point density?",
      "Why can't it be augmented such that network learns to generalise to different sampling strategies?",
      "There is a performance gap between performance on SURREAL and FAUST, which authors attribute to different surface distributions.",
      "Why is this not evaluated on the FAUST challenge?",
      "Are the baselines trained on the same data as the proposed method?",
      "How do the transformers perform with denser inputs?",
      "Current limitations stated in the conclusion section are generic.",
      "It would be good to also discuss other directions in 3D vision where transformer architectures would be beneficial."
    ]
  },
  {
    "paper_id": "2106.13679v2",
    "submission_id": "ui4xChWcA4R",
    "submission_title": "Shape Registration in the Time of Transformers",
    "review_id": "shcf3Lutjxk",
    "input": {
      "title": "Shape Registration in the Time of Transformers",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Somewhat derivative, but appropriately designed: The main ideas of the paper are inspired by other works, such as the recently popular Transformer structures and especially the iterative cross attention structure [21].\n- one might say that the work is somewhat derivative from [21].\n- But at the same time, some additional effort (e.g., density-adaptive attention) is appropriately made to handle the problem effectively.\n- The method yields state-of-the-art performance, and sometimes, the gaps are quite large, which suggests that the proposed method is indeed effective.\n- Why the Transformer for cross-modality?: The iterative cross attention inspired by [21] is originally for cross-modality. Point clouds are rather homogeneous in this sense.\n- In my understanding, the authors are using this to easily pass on the latent feature (which can be smaller and contain essential information) from the target to the source.\n- This can be indeed an efficient way to handle the problem. But at the same time, I think that a regular Transformer-like structure could also be used and there is a chance that the performance can be better.\n- Why is the proposed method a better choice? More discussion is needed.\n- How is the initial latent feature (latent probe) handled?: One thing that is not clearly explained in the paper is how the latent probe, which is one of the inputs of the network, is handled.\n- The authors have provided a code as supplementary material, but providing this in the paper or in the supplementary document will be good for completeness.",
    "review_points_list": [
      "Somewhat derivative, but appropriately designed: The main ideas of the paper are inspired by other works, such as the recently popular Transformer structures and especially the iterative cross attention structure [21].",
      "one might say that the work is somewhat derivative from [21].",
      "But at the same time, some additional effort (e.g., density-adaptive attention) is appropriately made to handle the problem effectively.",
      "The method yields state-of-the-art performance, and sometimes, the gaps are quite large, which suggests that the proposed method is indeed effective.",
      "Why the Transformer for cross-modality?: The iterative cross attention inspired by [21] is originally for cross-modality. Point clouds are rather homogeneous in this sense.",
      "In my understanding, the authors are using this to easily pass on the latent feature (which can be smaller and contain essential information) from the target to the source.",
      "This can be indeed an efficient way to handle the problem. But at the same time, I think that a regular Transformer-like structure could also be used and there is a chance that the performance can be better.",
      "Why is the proposed method a better choice? More discussion is needed.",
      "How is the initial latent feature (latent probe) handled?: One thing that is not clearly explained in the paper is how the latent probe, which is one of the inputs of the network, is handled.",
      "The authors have provided a code as supplementary material, but providing this in the paper or in the supplementary document will be good for completeness."
    ]
  },
  {
    "paper_id": "2106.13679v2",
    "submission_id": "ui4xChWcA4R",
    "submission_title": "Shape Registration in the Time of Transformers",
    "review_id": "BA3LXsFbeKc",
    "input": {
      "title": "Shape Registration in the Time of Transformers",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- On the positive side, the proposed method seems to outperform state of the art methods in the field, although I am not an expert in this field.\n- The method does not require the use of a template which makes the method directly applicable.\n- My main concern is the writing style of the paper which is too loose and not accurate enough in my opinion.\n- The first two sections are nicely written overviews discussing common generalities on attention and shape registration.\n- Beginning of section 4 loosely describes the architecture with inaccuracies in formula (1). It is not possible to reimplement the method from reading out the main text.\n- The authors do not discuss the problem of long training time of transformers in their situation.\n- Is the surface attention a particular case of classic attention in a particular formulation? Is it an inductive bias that could be learnt from enough data?\n- How is the bottleneck of attention (quadratic in the input) dealt with in the context of hundreds of thousand of points ? it is not detailed enough.\n- It seems that there are multiple typos in formula 1. The index summation $t$ is not present elsewhere in the formula, and the notations $\\exp^{(x)}y$ and $\\exp^{xy}$ are quite unusual. I would suggest to replace it with more standard notations.\n- The running times and computational resources are difficult to find in the main text although the authors replied positively that it is stated in section 5. I have hard time to find it. It is not discussed in this section and only touched upon in the conclusion. It needs more discussion.\n- Chamfer loss is said to be defined in section 4, but it is a pointer to another publication.",
    "review_points_list": [
      "On the positive side, the proposed method seems to outperform state of the art methods in the field, although I am not an expert in this field.",
      "The method does not require the use of a template which makes the method directly applicable.",
      "My main concern is the writing style of the paper which is too loose and not accurate enough in my opinion.",
      "The first two sections are nicely written overviews discussing common generalities on attention and shape registration.",
      "Beginning of section 4 loosely describes the architecture with inaccuracies in formula (1). It is not possible to reimplement the method from reading out the main text.",
      "The authors do not discuss the problem of long training time of transformers in their situation.",
      "Is the surface attention a particular case of classic attention in a particular formulation? Is it an inductive bias that could be learnt from enough data?",
      "How is the bottleneck of attention (quadratic in the input) dealt with in the context of hundreds of thousand of points ? it is not detailed enough.",
      "It seems that there are multiple typos in formula 1. The index summation $t$ is not present elsewhere in the formula, and the notations $\\exp^{(x)}y$ and $\\exp^{xy}$ are quite unusual. I would suggest to replace it with more standard notations.",
      "The running times and computational resources are difficult to find in the main text although the authors replied positively that it is stated in section 5. I have hard time to find it. It is not discussed in this section and only touched upon in the conclusion. It needs more discussion.",
      "Chamfer loss is said to be defined in section 4, but it is a pointer to another publication."
    ]
  },
  {
    "paper_id": "2111.00056v1",
    "submission_id": "xRrdX_wV1JI",
    "submission_title": "Generalized DataWeighting via Class-Level Gradient Manipulation",
    "review_id": "1vzCgiAFoM5",
    "input": {
      "title": "Generalized DataWeighting via Class-Level Gradient Manipulation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed method is well-motivated and well-illustrated. The Zero-mean Constraint trick (Eq 4) is interesting.\n- The proposed class-level weighting is similar to soft label methods which reassign the ground-truth label for training. This paper lacks the discussion of the difference.\n- I am concerned about learning the weight predictor w(phi) on the clean meta set, which will be used for the noised training set. How can w(phi) learned on clean and balanced data work well on noisy and imbalanced data?\n- The proposed method has negligible improvements in most experiments. Therefore the effectiveness of the proposed method is limited.\n- Suggestion: The term \u201cclass-level weighting\u201d is a bit confusing. Perhaps the authors can find a more accurate name.",
    "review_points_list": [
      "The proposed method is well-motivated and well-illustrated. The Zero-mean Constraint trick (Eq 4) is interesting.",
      "The proposed class-level weighting is similar to soft label methods which reassign the ground-truth label for training. This paper lacks the discussion of the difference.",
      "I am concerned about learning the weight predictor w(phi) on the clean meta set, which will be used for the noised training set. How can w(phi) learned on clean and balanced data work well on noisy and imbalanced data?",
      "The proposed method has negligible improvements in most experiments. Therefore the effectiveness of the proposed method is limited.",
      "Suggestion: The term \u201cclass-level weighting\u201d is a bit confusing. Perhaps the authors can find a more accurate name."
    ]
  },
  {
    "paper_id": "2111.00056v1",
    "submission_id": "xRrdX_wV1JI",
    "submission_title": "Generalized DataWeighting via Class-Level Gradient Manipulation",
    "review_id": "PJ0LroomLN",
    "input": {
      "title": "Generalized DataWeighting via Class-Level Gradient Manipulation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- GDW is a well-motivated method and its proposed modifications to the training process are sound.\n- The paper lacks a strong theoretical foundation.\n- The authors should have explored more theoretical aspects, such as the convergence properties of the proposed algorithm.\n- The empirical results are mostly positive, but I have a few concerns about the robustness of the proposed method.\n- For example, how does the method perform when the amount of label noise is increased?\n- Furthermore, the authors do not provide any information about the computational complexity of their method.\n- I would also like to know more about the intuition behind the choice of the hyperparameters \u03bb and \u03b3.\n- The authors could have also included more details about the experimental setup and the choice of hyperparameters.\n- Lastly, I have a minor quibble about the title of the paper.",
    "review_points_list": [
      "GDW is a well-motivated method and its proposed modifications to the training process are sound.",
      "The paper lacks a strong theoretical foundation.",
      "The authors should have explored more theoretical aspects, such as the convergence properties of the proposed algorithm.",
      "The empirical results are mostly positive, but I have a few concerns about the robustness of the proposed method.",
      "For example, how does the method perform when the amount of label noise is increased?",
      "Furthermore, the authors do not provide any information about the computational complexity of their method.",
      "I would also like to know more about the intuition behind the choice of the hyperparameters \u03bb and \u03b3.",
      "The authors could have also included more details about the experimental setup and the choice of hyperparameters.",
      "Lastly, I have a minor quibble about the title of the paper."
    ]
  },
  {
    "paper_id": "2111.00056v1",
    "submission_id": "xRrdX_wV1JI",
    "submission_title": "Generalized DataWeighting via Class-Level Gradient Manipulation",
    "review_id": "K13cDk-lSbn",
    "input": {
      "title": "Generalized DataWeighting via Class-Level Gradient Manipulation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.\n- The authors show empirically that their algorithm is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.\n- The algorithm clearly outperforms CoreSet, BADGE, Margin, and Random on the Open Images dataset.\n- The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).\n- Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.\n- The authors also establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.\n- The authors are aware and mention that their theoretical results are initial and that equating volume-based samplers and the Cluster-Margin algorithm is an open research question.\n- The paper is very clear and well-organized.\n- The authors detail the hyper-parameters and compute details used for the experiments.\n- The Cluster-Margin algorithm is also explained in detail.\n- The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods.\n- The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.\n- However, the algorithm seems to have some limitations.",
    "review_points_list": [
      "The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE. Related work is adequately cited.",
      "The authors show empirically that their algorithm is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.",
      "The algorithm clearly outperforms CoreSet, BADGE, Margin, and Random on the Open Images dataset.",
      "The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).",
      "Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.",
      "The authors also establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.",
      "The authors are aware and mention that their theoretical results are initial and that equating volume-based samplers and the Cluster-Margin algorithm is an open research question.",
      "The paper is very clear and well-organized.",
      "The authors detail the hyper-parameters and compute details used for the experiments.",
      "The Cluster-Margin algorithm is also explained in detail.",
      "The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods.",
      "The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.",
      "However, the algorithm seems to have some limitations."
    ]
  },
  {
    "paper_id": "2107.10370v2",
    "submission_id": "wxBGz3ScBBo",
    "submission_title": "Analytic Study of Families of Spurious Minima in Two-Layer ReLU Neural Networks: A Tale of Symmetry II",
    "review_id": "EUbWN6eoKV",
    "input": {
      "title": "Analytic Study of Families of Spurious Minima in Two-Layer ReLU Neural Networks: A Tale of Symmetry II",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The direct analysis of the loss and the Hessian spectrum of local minima is an interesting direction to pursue.\n- The calculated Hessian spectrum of the spurious local minima matches the empirical observation that most eigenvalues concentrate near zero, which may be a good justification for practice.\n- The symmetry of the families of spectrum of local minima also seems interesting, and the mechanism behind this is definitely worth further exploration.\n- If I didn't miss something, the rigorous proof of the theorems seems to be missing.\n- It is possible that the proof applies from other works, but if that is the case please explicitly remark on this.\n- Currently I am not fully sure about the correctness of the proof.\n- Theorem 1 discusses some families of the local minima.\n- Are these all the local minima contained in the network?\n- If not, how to analyze other local minima, and will they possess the same property as claimed in this paper?\n- I'm wondering what the 'break' of the symmetry of spurious local minima implies.\n- Will it be observed in practice?\n- What if the activation function is not ReLU?\n- Will the analysis be totally different?\n- The paper needs to address some of the issues before being accepted (at least adding a complete proof).\n- It definitely has the potential of being a good paper, but perhaps not the current version.\n- After reading the author's response, I'm convinced of the rigorousness of the proof.\n- Therefore I'm happy to raise my score to 6.\n- I still recommend the authors to include the formal details from [41] in this paper (possibly in the appendix) to make it more self-complete.",
    "review_points_list": [
      "The direct analysis of the loss and the Hessian spectrum of local minima is an interesting direction to pursue.",
      "The calculated Hessian spectrum of the spurious local minima matches the empirical observation that most eigenvalues concentrate near zero, which may be a good justification for practice.",
      "The symmetry of the families of spectrum of local minima also seems interesting, and the mechanism behind this is definitely worth further exploration.",
      "If I didn't miss something, the rigorous proof of the theorems seems to be missing.",
      "It is possible that the proof applies from other works, but if that is the case please explicitly remark on this.",
      "Currently I am not fully sure about the correctness of the proof.",
      "Theorem 1 discusses some families of the local minima.",
      "Are these all the local minima contained in the network?",
      "If not, how to analyze other local minima, and will they possess the same property as claimed in this paper?",
      "I'm wondering what the 'break' of the symmetry of spurious local minima implies.",
      "Will it be observed in practice?",
      "What if the activation function is not ReLU?",
      "Will the analysis be totally different?",
      "The paper needs to address some of the issues before being accepted (at least adding a complete proof).",
      "It definitely has the potential of being a good paper, but perhaps not the current version.",
      "After reading the author's response, I'm convinced of the rigorousness of the proof.",
      "Therefore I'm happy to raise my score to 6.",
      "I still recommend the authors to include the formal details from [41] in this paper (possibly in the appendix) to make it more self-complete."
    ]
  },
  {
    "paper_id": "2107.10370v2",
    "submission_id": "wxBGz3ScBBo",
    "submission_title": "Analytic Study of Families of Spurious Minima in Two-Layer ReLU Neural Networks: A Tale of Symmetry II",
    "review_id": "W9urGLH6lDU",
    "input": {
      "title": "Analytic Study of Families of Spurious Minima in Two-Layer ReLU Neural Networks: A Tale of Symmetry II",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The model described in the paper aims to address the problem of interpreting black-box models, specifically deep neural networks.\n- A notable strength of this work is the explicit consideration of non-convexity in deep networks, which is often overlooked.\n- The paper provides a formal analysis of the optimization landscape of a simple neural network model.\n- The authors propose a useful metric called 'max-linear regions' for assessing how flat the optimization landscape is.\n- The experiments demonstrate the effectiveness of the 'max-linear regions' metric in comparing the landscape of different models.\n- One critique is that the experiments are limited to synthetic networks and might not fully capture real-world scenarios.\n- The work could benefit from exploring the performance of the metric on more complex and diverse datasets.\n- Overall, this paper makes a valuable contribution to the field of interpretability in deep learning.",
    "review_points_list": [
      "The model described in the paper aims to address the problem of interpreting black-box models, specifically deep neural networks.",
      "A notable strength of this work is the explicit consideration of non-convexity in deep networks, which is often overlooked.",
      "The paper provides a formal analysis of the optimization landscape of a simple neural network model.",
      "The authors propose a useful metric called 'max-linear regions' for assessing how flat the optimization landscape is.",
      "The experiments demonstrate the effectiveness of the 'max-linear regions' metric in comparing the landscape of different models.",
      "One critique is that the experiments are limited to synthetic networks and might not fully capture real-world scenarios.",
      "The work could benefit from exploring the performance of the metric on more complex and diverse datasets.",
      "Overall, this paper makes a valuable contribution to the field of interpretability in deep learning."
    ]
  },
  {
    "paper_id": "2107.10370v2",
    "submission_id": "wxBGz3ScBBo",
    "submission_title": "Analytic Study of Families of Spurious Minima in Two-Layer ReLU Neural Networks: A Tale of Symmetry II",
    "review_id": "lbJ-v-S_yMS",
    "input": {
      "title": "Analytic Study of Families of Spurious Minima in Two-Layer ReLU Neural Networks: A Tale of Symmetry II",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper studies an important problem in deep learning optimization.\n- the paper provides a currently less mainstream approach to study 2 layer ReLU network with the goal of deriving the form of local minima and spectrum of the Hessian at these minima.\n- the theoretical results are not properly motivated and their implications are discussed. More on this below.\n- some of the claims in the paper are misleading or not true. See below.\n- It is not explicitly mentioned anywhere but the dimensionality d of the input vector x is assumed to be the same as the dimensionality d of beta (number of neurons in the hidden layer) in the target network (Eq 2). What is the reasoning behind this and what are the implications of this assumption on the outcome of the analysis?\n- It would be nice to establish a connection between dimensionality d and the number of classes C in a classification task (at least intuitively). This would be particularly helpful because it has been shown in [1] that the eigenvalues of the Hessian tend to have C large eigenvalues while the others are nearly zeros. So the dependence on d in the submitted paper should clearly have some connection with C.\n- the main statement of section 1: 'Spurious minima break the symmetry of global minima' and figure 2, are not very clear. Perhaps a more intuitive explanation of this statement and describing the physical significance of this claim would help.\n- On line 117-120, the authors cite [48,49] while claiming that (specifically) local minima lie in fixed low-dimensional subspaces of the parameter space. However, the cited papers do not mention the minima found were local. In fact fig. 1 in [48] suggests the minimum is global.\n- section 2 derives the analytical form of the various classes of local minima and the difference in the decay of their Hessian spectrum is discussed. While this is a strong result, it would be informative to also discuss how these differences can impact gradient descent based optimization (e.g. in terms of the likelihood of discovering these minima) or other physical significance of this result. \n- One of the claims in the paper (e.g. line 323-329) is around the exposition of how the proposed theory explains why local minima are not major limitation in over-parameterized deep networks since over-parameterization turns local minima into saddle points. However, this claim is not novel and has been known at least since [2] if not before.\n- Because of the above concerns, I am giving a score of 6 to the paper. If addressed, I am willing to increase the score.",
    "review_points_list": [
      "The paper studies an important problem in deep learning optimization.",
      "the paper provides a currently less mainstream approach to study 2 layer ReLU network with the goal of deriving the form of local minima and spectrum of the Hessian at these minima.",
      "the theoretical results are not properly motivated and their implications are discussed. More on this below.",
      "some of the claims in the paper are misleading or not true. See below.",
      "It is not explicitly mentioned anywhere but the dimensionality d of the input vector x is assumed to be the same as the dimensionality d of beta (number of neurons in the hidden layer) in the target network (Eq 2). What is the reasoning behind this and what are the implications of this assumption on the outcome of the analysis?",
      "It would be nice to establish a connection between dimensionality d and the number of classes C in a classification task (at least intuitively). This would be particularly helpful because it has been shown in [1] that the eigenvalues of the Hessian tend to have C large eigenvalues while the others are nearly zeros. So the dependence on d in the submitted paper should clearly have some connection with C.",
      "the main statement of section 1: 'Spurious minima break the symmetry of global minima' and figure 2, are not very clear. Perhaps a more intuitive explanation of this statement and describing the physical significance of this claim would help.",
      "On line 117-120, the authors cite [48,49] while claiming that (specifically) local minima lie in fixed low-dimensional subspaces of the parameter space. However, the cited papers do not mention the minima found were local. In fact fig. 1 in [48] suggests the minimum is global.",
      "section 2 derives the analytical form of the various classes of local minima and the difference in the decay of their Hessian spectrum is discussed. While this is a strong result, it would be informative to also discuss how these differences can impact gradient descent based optimization (e.g. in terms of the likelihood of discovering these minima) or other physical significance of this result. ",
      "One of the claims in the paper (e.g. line 323-329) is around the exposition of how the proposed theory explains why local minima are not major limitation in over-parameterized deep networks since over-parameterization turns local minima into saddle points. However, this claim is not novel and has been known at least since [2] if not before.",
      "Because of the above concerns, I am giving a score of 6 to the paper. If addressed, I am willing to increase the score."
    ]
  },
  {
    "paper_id": "2010.11171v2",
    "submission_id": "wRFj6EKvpl",
    "submission_title": "How Data Augmentation affects Optimization for Linear Regression",
    "review_id": "Q6JEaxWyUOP",
    "input": {
      "title": "How Data Augmentation affects Optimization for Linear Regression",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper is novel based on my knowledge.\n- It provides a new theoretical framework to justify the convergence of optimization under changing learning rate and (either random or arbitrary) data augmentation.\n- The results not only cover the situations where data augmentation is independent to iteration t, but also include more general results when data augmentation is related to t.\n- The paper is well written and the main text is easy to understand.\n- The claims are well supported by the theoretical results.\n- The detailed examples for the general theorems are clearly written.\n- The authors are careful and mention both strengths and weaknesses (only for linear regression model) of this work.\n- Some minor issues: \n- (1) the current numerical experiments are weak to support the claims.\n- However, since this paper is already well supported by theories, please consider moving the experiments to appendix and emphasizing some other important things.\n- (2) the statements from line 120 to 128 are somewhat confusing.\n- Please specify why they cannot be obtained from Theorem 3.1/3.2.\n- If A_t is randomly generated and independent to iteration t, they can be viewed as some new data distribution, so they are supposed to converge in the optimization.\n- This paper provides detailed theories in the optimization of linear model, extending to other complicated algorithms is challenging, but it could potentially provide deeper understanding in data augmentation.",
    "review_points_list": [
      "This paper is novel based on my knowledge.",
      "It provides a new theoretical framework to justify the convergence of optimization under changing learning rate and (either random or arbitrary) data augmentation.",
      "The results not only cover the situations where data augmentation is independent to iteration t, but also include more general results when data augmentation is related to t.",
      "The paper is well written and the main text is easy to understand.",
      "The claims are well supported by the theoretical results.",
      "The detailed examples for the general theorems are clearly written.",
      "The authors are careful and mention both strengths and weaknesses (only for linear regression model) of this work.",
      "Some minor issues: ",
      "(1) the current numerical experiments are weak to support the claims.",
      "However, since this paper is already well supported by theories, please consider moving the experiments to appendix and emphasizing some other important things.",
      "(2) the statements from line 120 to 128 are somewhat confusing.",
      "Please specify why they cannot be obtained from Theorem 3.1/3.2.",
      "If A_t is randomly generated and independent to iteration t, they can be viewed as some new data distribution, so they are supposed to converge in the optimization.",
      "This paper provides detailed theories in the optimization of linear model, extending to other complicated algorithms is challenging, but it could potentially provide deeper understanding in data augmentation."
    ]
  },
  {
    "paper_id": "2010.11171v2",
    "submission_id": "wRFj6EKvpl",
    "submission_title": "How Data Augmentation affects Optimization for Linear Regression",
    "review_id": "U8w8-baqgvd",
    "input": {
      "title": "How Data Augmentation affects Optimization for Linear Regression",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proofs are technical and the overall problem studied is interesting.\n- It is important to study how data augmentation affects the optimization trajectory.\n- The model discussed here is limited to linear case, how can this case provide us insight for more general classes like kernels?\n- The problem formulation is general enough to include many types of augmentations, the detailed results are derived only for additive noise and random projects, which may not be what people mostly use nowadays.\n- It is unclear to me why studying the convergence to the min-norm solution is a good idea.\n- Augmenting with noise should make the learned minimizer more robust (at least to noise).\n- Training with random noise corresponds to training with l2 regularization (eq 3.2).\n- I'm not sure why the authors consider min-norm solution as the limiting classifier.\n- I'm also curious what if the condition eta_t->0 is relaxed (at least is allowed to decay much slower), the limiting behavior may be more interesting.",
    "review_points_list": [
      "The proofs are technical and the overall problem studied is interesting.",
      "It is important to study how data augmentation affects the optimization trajectory.",
      "The model discussed here is limited to linear case, how can this case provide us insight for more general classes like kernels?",
      "The problem formulation is general enough to include many types of augmentations, the detailed results are derived only for additive noise and random projects, which may not be what people mostly use nowadays.",
      "It is unclear to me why studying the convergence to the min-norm solution is a good idea.",
      "Augmenting with noise should make the learned minimizer more robust (at least to noise).",
      "Training with random noise corresponds to training with l2 regularization (eq 3.2).",
      "I'm not sure why the authors consider min-norm solution as the limiting classifier.",
      "I'm also curious what if the condition eta_t->0 is relaxed (at least is allowed to decay much slower), the limiting behavior may be more interesting."
    ]
  },
  {
    "paper_id": "2010.11171v2",
    "submission_id": "wRFj6EKvpl",
    "submission_title": "How Data Augmentation affects Optimization for Linear Regression",
    "review_id": "H9f3qp1HICk",
    "input": {
      "title": "How Data Augmentation affects Optimization for Linear Regression",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The convergence results of data augmentation algorithms are solid.\n- The analysis techniques seem non-trivial.\n- Some assumptions seem to strong.\n- How to justify the assumptions (3.10) (3.11) and (3.12) are reasonable?\n- Something for assumptions (3.7) (3.8) and (3.9).\n- Overall, the writing is clear to me.\n- First, I'm not convinced by the experimental results.\n- It only runs on simulated data for additive Gaussian noise case.\n- It would be better if the authors can provide the results for random projection case, and more importantly, if some real datasets can be used.\n- I think additional experiments would have made the paper much stronger.\n- Second, this paper only studies optimization of data augmentation.\n- However, I think the most interesting and important thing is about the generalization of data augmentation, since the key goal of using data augmentation is to avoid over-fitting.\n- Besides, it would also be better if the authors could provide some generalization results (such as testing error) in the experiments.",
    "review_points_list": [
      "The convergence results of data augmentation algorithms are solid.",
      "The analysis techniques seem non-trivial.",
      "Some assumptions seem to strong.",
      "How to justify the assumptions (3.10) (3.11) and (3.12) are reasonable?",
      "Something for assumptions (3.7) (3.8) and (3.9).",
      "Overall, the writing is clear to me.",
      "First, I'm not convinced by the experimental results.",
      "It only runs on simulated data for additive Gaussian noise case.",
      "It would be better if the authors can provide the results for random projection case, and more importantly, if some real datasets can be used.",
      "I think additional experiments would have made the paper much stronger.",
      "Second, this paper only studies optimization of data augmentation.",
      "However, I think the most interesting and important thing is about the generalization of data augmentation, since the key goal of using data augmentation is to avoid over-fitting.",
      "Besides, it would also be better if the authors could provide some generalization results (such as testing error) in the experiments."
    ]
  },
  {
    "paper_id": "2105.05115v2",
    "submission_id": "wLsA3nurh9W",
    "submission_title": "Analysis of one-hidden-layer neural networks via the resolvent method",
    "review_id": "PYuY9xhQ5W",
    "input": {
      "title": "Analysis of one-hidden-layer neural networks via the resolvent method",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think this is a nice contribution to this body of literature: To my knowledge, it is the first work to use this method of proof to study this type of non-linear matrix model.\n- The results of Theorems 2.1 and 2.2 are perhaps not so new in the context of existing work, but the authors illustrate how this method can be used to obtain a new result in the form of Theorem 2.5.\n- There is a high-level component of the proof that I don't understand---see below---but if this is a misunderstanding on my part and can be easily clarified or addressed, my opinion is that this work is above the bar for NeurIPS.\n- Major comment: In Propositions 3.2, 3.3, and Lemma A.3, what exactly is the claim that is being made on which mixed cumulants are 0 and which are non-zero, and how is this used on lines 371 and 456 in the proofs of the main results?\n- My confusion lies in e.g. the following example: Consider the 4th-order cumulant 1/n_0^2 kappa( (WX)_{1,2}, (WX)_{1,2}, (WX)_{1,2}, (WX)_{1,2} ) where all four entries of WX coincide.\n- Is this case treated in the discussion preceding Lemma A.3, and is Lemma A.3 claiming that this cumulant is 0? My understanding is that it's not 0, but since (WX)_{1,2}/sqrt(n_0) converges to a Gaussian, this is asymptotically 0.\n- However now consider kappa( Y_{1,2}, Y_{1,2}, Y_{1,2}, Y_{1,2} ) for the post-activations: Is Proposition 3.2 claiming that this is 0?\n- Since Y_{1,2} = f((WX)_{1,2}/sqrt(n_0)) converges to a non-Gaussian limit, I guess this is non-zero even in the asymptotic limit.\n- But then perhaps I don't understand how this mixed cumulant (and analogous terms for larger k) is treated in the second equality of line 371.\n- My confusion is related to the sentence 'Since the activation function f is applied component-wise, it follows from the previous results... that Y has cycle correlations' on lines 420-423; I'm not sure what is meant by this sentence.\n- A higher-level comment is that I feel a bit uneasy about the extent of casework that has been done---not only for Lemma A.3 as discussed above, but also in the 'Proof of (20)' starting on line 495, and the proofs of Lemmas A.4 and D.1 in appendix D.\n- (1) I don't know if it's fair to characterize the moment method as 'more commonly used' (in the abstract and conclusion). For example Refs. [19] and [9] also used the resolvent method, and I think an appendix of Ref. [9] derived also the quartic equation of Theorem 2.2 using a resolvent approach (although using a different method to analyze the resolvent).\n- (2) Line 51, is it common to call gamma here the learning rate?\n- (3) Can the authors state more precisely the moment conditions needed for nu_1 and nu_2 at the bottom of page 3, for their result to hold.\n- (4) In Eqs. (18) and (20) of Propositions 3.2 and 3.3 the pattern of indices and conjugations in '...' are not clear, and it would be helpful to write out a few more terms.\n- (5) Should the approximations of Proposition 3.2 and 3.3 be interpreted for each fixed k as n -> infinity? In the analysis of Eq. (16) one needs to consider the infinite series in k for each fixed n---can the authors elaborate on how the error terms are treated in this series?",
    "review_points_list": [
      "I think this is a nice contribution to this body of literature: To my knowledge, it is the first work to use this method of proof to study this type of non-linear matrix model.",
      "The results of Theorems 2.1 and 2.2 are perhaps not so new in the context of existing work, but the authors illustrate how this method can be used to obtain a new result in the form of Theorem 2.5.",
      "There is a high-level component of the proof that I don't understand---see below---but if this is a misunderstanding on my part and can be easily clarified or addressed, my opinion is that this work is above the bar for NeurIPS.",
      "Major comment: In Propositions 3.2, 3.3, and Lemma A.3, what exactly is the claim that is being made on which mixed cumulants are 0 and which are non-zero, and how is this used on lines 371 and 456 in the proofs of the main results?",
      "My confusion lies in e.g. the following example: Consider the 4th-order cumulant 1/n_0^2 kappa( (WX)_{1,2}, (WX)_{1,2}, (WX)_{1,2}, (WX)_{1,2} ) where all four entries of WX coincide.",
      "Is this case treated in the discussion preceding Lemma A.3, and is Lemma A.3 claiming that this cumulant is 0? My understanding is that it's not 0, but since (WX)_{1,2}/sqrt(n_0) converges to a Gaussian, this is asymptotically 0.",
      "However now consider kappa( Y_{1,2}, Y_{1,2}, Y_{1,2}, Y_{1,2} ) for the post-activations: Is Proposition 3.2 claiming that this is 0?",
      "Since Y_{1,2} = f((WX)_{1,2}/sqrt(n_0)) converges to a non-Gaussian limit, I guess this is non-zero even in the asymptotic limit.",
      "But then perhaps I don't understand how this mixed cumulant (and analogous terms for larger k) is treated in the second equality of line 371.",
      "My confusion is related to the sentence 'Since the activation function f is applied component-wise, it follows from the previous results... that Y has cycle correlations' on lines 420-423; I'm not sure what is meant by this sentence.",
      "A higher-level comment is that I feel a bit uneasy about the extent of casework that has been done---not only for Lemma A.3 as discussed above, but also in the 'Proof of (20)' starting on line 495, and the proofs of Lemmas A.4 and D.1 in appendix D.",
      "(1) I don't know if it's fair to characterize the moment method as 'more commonly used' (in the abstract and conclusion). For example Refs. [19] and [9] also used the resolvent method, and I think an appendix of Ref. [9] derived also the quartic equation of Theorem 2.2 using a resolvent approach (although using a different method to analyze the resolvent).",
      "(2) Line 51, is it common to call gamma here the learning rate?",
      "(3) Can the authors state more precisely the moment conditions needed for nu_1 and nu_2 at the bottom of page 3, for their result to hold.",
      "(4) In Eqs. (18) and (20) of Propositions 3.2 and 3.3 the pattern of indices and conjugations in '...' are not clear, and it would be helpful to write out a few more terms.",
      "(5) Should the approximations of Proposition 3.2 and 3.3 be interpreted for each fixed k as n -> infinity? In the analysis of Eq. (16) one needs to consider the infinite series in k for each fixed n---can the authors elaborate on how the error terms are treated in this series?"
    ]
  },
  {
    "paper_id": "2105.05115v2",
    "submission_id": "wLsA3nurh9W",
    "submission_title": "Analysis of one-hidden-layer neural networks via the resolvent method",
    "review_id": "3pL0u18EAi",
    "input": {
      "title": "Analysis of one-hidden-layer neural networks via the resolvent method",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The high level ideas of this paper are clearly explained.\n- The contribution of the paper is clear in the context of previous work.\n- The basic idea of the resolvent method itself it not new, this paper shows how it can be used to simplify and generalize the analysis of a problem of current interest.\n- I think this paper will be of interest to researchers working in this area.\n- I have some concerns about the lack of higher order moment assumptions on the entries of the matrices.\n- The author(s) require only the exists of finite second moments.\n- The nonexistence of moment conditions is also potentially problematic later.\n- I would not be surprised if the all of the analysis goes through under some tail conditions (such as the ones given in citation [6]).\n- There is room to improve the clarity of the technical results.\n- What does the notation less-than-approximately-equal-to mean?\n- What is the definition of \\(1_m\\)? (I assume identity matrix).\n- In line 146 - 147  there are some further statements about the limiting spectral measure (e.g., the nonzero part is continuous).\n- In line 148 , the function g(z) is the Stieltjes transform of the empirical measure, not the limit mu, and so the wording is a bit confusing.\n- In Remark 2.4 part (ii) says that Theorem 2.1 follows from Theorem 2.2.\n- One also needs to establish uniqueness of the solution (in the proper limiting sense)?\n- It would be useful to provide full details of the batch normalization used in Figure 3.",
    "review_points_list": [
      "The high level ideas of this paper are clearly explained.",
      "The contribution of the paper is clear in the context of previous work.",
      "The basic idea of the resolvent method itself it not new, this paper shows how it can be used to simplify and generalize the analysis of a problem of current interest.",
      "I think this paper will be of interest to researchers working in this area.",
      "I have some concerns about the lack of higher order moment assumptions on the entries of the matrices.",
      "The author(s) require only the exists of finite second moments.",
      "The nonexistence of moment conditions is also potentially problematic later.",
      "I would not be surprised if the all of the analysis goes through under some tail conditions (such as the ones given in citation [6]).",
      "There is room to improve the clarity of the technical results.",
      "What does the notation less-than-approximately-equal-to mean?",
      "What is the definition of \\(1_m\\)? (I assume identity matrix).",
      "In line 146 - 147  there are some further statements about the limiting spectral measure (e.g., the nonzero part is continuous).",
      "In line 148 , the function g(z) is the Stieltjes transform of the empirical measure, not the limit mu, and so the wording is a bit confusing.",
      "In Remark 2.4 part (ii) says that Theorem 2.1 follows from Theorem 2.2.",
      "One also needs to establish uniqueness of the solution (in the proper limiting sense)?",
      "It would be useful to provide full details of the batch normalization used in Figure 3."
    ]
  },
  {
    "paper_id": "2105.05115v2",
    "submission_id": "wLsA3nurh9W",
    "submission_title": "Analysis of one-hidden-layer neural networks via the resolvent method",
    "review_id": "SXN4QkKpdF",
    "input": {
      "title": "Analysis of one-hidden-layer neural networks via the resolvent method",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proof starts with the cumulant expansion in (16) and then applies Prop 3.2. But Prop 3.2 only deals with three special cases of cumulants.\n- Why the contribution of other configurations are negligible?\n- It seems it is assumed the only non-negligible contributions are those from even cycles. For example, it is claimed on p. 15 of the supplement 'Finally, we compute the cumulants of the entries of the random matrix Y. Since the activation function f is applied component-wise, it follows from the previous results that the only contribution comes from \u03ba(Yi1, Yi2i3^*, ..., Yi2ki1^*) for k \u2265 1 and i 1 ,...,i 2k distinct, thus proving that Y has cycle correlations.' This is not clear to me why this is the case and what the previous results being referred to are.\n- For example, it is clear that odd cycles can be ignored due to the zero-mean assumption. But how about four cycles with double edges, something like kappa(Y_12,Y_12,Y_23,Y_23,Y_34,Y_34,Y_41,Y_41)?\n- In (23), I cannot understand the second line. Note that here the kappa in the first line has k arguments and kappa in the second line has 2k arguments. So, this is not a matter of counting.\n- I presume at this point we are removing all other contributions except for even cycles. So this needs to be formally justified.\n- Also, from the writing, it seems in the second line of (23) the indices i_1,...,i_{2k} are required to be distinct. What about the first line and also those summations in Lemma 3.1 and in (16)? None of these are specified.\n- Another crucial step that is not justified is the last step of the proof of Prop 3.2, p16, which claims that the cumulant of the four-tuple \u2248 expectation of their product. Is this true for all other cumulants?\n- In fact, \u2248 is used throughout the paper without definition.\n- Line 106: The author should clarify \u03ba(Y_{i_1,i_2},Y_{i_2,i_3}^*,...,Y_{i_2k,i_1}^*). Do you mean \u03ba(Y_{i_1,i_2},Y_{i_2,i_3}^*,Y_{i_3,i_4}^*,Y_{i_4,i_5}^*,...,Y_{i_2k,i_1}^*) or \u03ba(Y_{i_1,i_2},Y_{i_2,i_3}^*,Y_{i_3,i_4},Y_{i_4,i_5}^*,...,Y_{i_2k,i_1}^*)?\n- I presume the latter.\n- Existence and uniqueness of the solution to the self-consistency equation (1) is not discussed. Perhaps this is in the previous work [21,6]?\n- In equation (1) the dummy variable m conflicts with the sample size m, which is also used everywhere. One should consider changing the notations.\n- It would be good to comment early on the meaning of the integral parameters. For example, \u03b8_1(f) is the variance of the entry of Y.\n- It is not very clear what 'invariance' means as mentioned in the abstract and also in the paper. Perhaps you meant the limiting spectral distributions of Y=f(WX) and X coincide?\n- Lemma A.1. What is \u210f? Is it only used for complex valued W/X?",
    "review_points_list": [
      "The proof starts with the cumulant expansion in (16) and then applies Prop 3.2. But Prop 3.2 only deals with three special cases of cumulants.",
      "Why the contribution of other configurations are negligible?",
      "It seems it is assumed the only non-negligible contributions are those from even cycles. For example, it is claimed on p. 15 of the supplement 'Finally, we compute the cumulants of the entries of the random matrix Y. Since the activation function f is applied component-wise, it follows from the previous results that the only contribution comes from \u03ba(Yi1, Yi2i3^*, ..., Yi2ki1^*) for k \u2265 1 and i 1 ,...,i 2k distinct, thus proving that Y has cycle correlations.' This is not clear to me why this is the case and what the previous results being referred to are.",
      "For example, it is clear that odd cycles can be ignored due to the zero-mean assumption. But how about four cycles with double edges, something like kappa(Y_12,Y_12,Y_23,Y_23,Y_34,Y_34,Y_41,Y_41)?",
      "In (23), I cannot understand the second line. Note that here the kappa in the first line has k arguments and kappa in the second line has 2k arguments. So, this is not a matter of counting.",
      "I presume at this point we are removing all other contributions except for even cycles. So this needs to be formally justified.",
      "Also, from the writing, it seems in the second line of (23) the indices i_1,...,i_{2k} are required to be distinct. What about the first line and also those summations in Lemma 3.1 and in (16)? None of these are specified.",
      "Another crucial step that is not justified is the last step of the proof of Prop 3.2, p16, which claims that the cumulant of the four-tuple \u2248 expectation of their product. Is this true for all other cumulants?",
      "In fact, \u2248 is used throughout the paper without definition.",
      "Line 106: The author should clarify \u03ba(Y_{i_1,i_2},Y_{i_2,i_3}^*,...,Y_{i_2k,i_1}^*). Do you mean \u03ba(Y_{i_1,i_2},Y_{i_2,i_3}^*,Y_{i_3,i_4}^*,Y_{i_4,i_5}^*,...,Y_{i_2k,i_1}^*) or \u03ba(Y_{i_1,i_2},Y_{i_2,i_3}^*,Y_{i_3,i_4},Y_{i_4,i_5}^*,...,Y_{i_2k,i_1}^*)?",
      "I presume the latter.",
      "Existence and uniqueness of the solution to the self-consistency equation (1) is not discussed. Perhaps this is in the previous work [21,6]?",
      "In equation (1) the dummy variable m conflicts with the sample size m, which is also used everywhere. One should consider changing the notations.",
      "It would be good to comment early on the meaning of the integral parameters. For example, \u03b8_1(f) is the variance of the entry of Y.",
      "It is not very clear what 'invariance' means as mentioned in the abstract and also in the paper. Perhaps you meant the limiting spectral distributions of Y=f(WX) and X coincide?",
      "Lemma A.1. What is \u210f? Is it only used for complex valued W/X?"
    ]
  },
  {
    "paper_id": "2105.05115v2",
    "submission_id": "wLsA3nurh9W",
    "submission_title": "Analysis of one-hidden-layer neural networks via the resolvent method",
    "review_id": "bGkCU_1mkWH",
    "input": {
      "title": "Analysis of one-hidden-layer neural networks via the resolvent method",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- A stark contrast between the bias-free case and the case with additive bias is shown: in the former case, the eigenvalue-distribution of $M$ converges almost-surely to a compactly supported deterministic probability distribution, whose Stieltjes transform satisfies a certain fourth order equation.\n- In the later case, there is no such convergence (if there is more than 1 hidden layer), irrespective the chose activation function.\n- The main technique used to prove the theorems is the so-called 'resolvent method'.\n- This is in contrast with the very combinatorial and cumbersome 'moment method' used in prior works.\n- The paper is well-written and easy to follow.\n- Related works are discussed in great detail, and the authors' contributions are well-situated.\n- Is this a conjecture, an empirical observation, or is this rigorously proved somewhere in the paper ?",
    "review_points_list": [
      "A stark contrast between the bias-free case and the case with additive bias is shown: in the former case, the eigenvalue-distribution of $M$ converges almost-surely to a compactly supported deterministic probability distribution, whose Stieltjes transform satisfies a certain fourth order equation.",
      "In the later case, there is no such convergence (if there is more than 1 hidden layer), irrespective the chose activation function.",
      "The main technique used to prove the theorems is the so-called 'resolvent method'.",
      "This is in contrast with the very combinatorial and cumbersome 'moment method' used in prior works.",
      "The paper is well-written and easy to follow.",
      "Related works are discussed in great detail, and the authors' contributions are well-situated.",
      "Is this a conjecture, an empirical observation, or is this rigorously proved somewhere in the paper ?"
    ]
  },
  {
    "paper_id": "2506.18883v1",
    "submission_id": "ybw2U70q_Vd",
    "submission_title": "End-to-end Multi-modal Video Temporal Grounding",
    "review_id": "WdutDJokR5",
    "input": {
      "title": "End-to-end Multi-modal Video Temporal Grounding",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed modules are straightforward use of existing techniques (transformers, contrastive learning).\n- Although the co-attention scheme is developed by modifying the self-attention scheme of the transformer, it has already been tried in various multi-modal methods.\n- Comprehensively, the novelty is weak.\n- Not enough analysis and studies are contained.\n- Several definitions/descriptions are unclear.\n- Although there is room for the amount of pages.\n- In table 1, does the single-stream DRFT mean replacing the inter-modal feature learning module with self-attention?\n- If not, the single-stream DRFT is just the method w/o any attention mechanism, and then it is not proper to verify the effect of the proposed co-attention.\n- Unclear description for REG module.\n- For example, how the start and end timing is obtained if there is multiple start-end in a video?\n- Why the definition/formulation of L_grn is not described?\n- In line 205-206, the authors mentioned that their LGI module is similar to LGI model [19]. Then, is the proposed method built on top of [19] by adding the proposed modules?\n- There is no analysis or studies for if the weight of dynamic fusion differs depending on videos or frames.\n- Without showing this point, the reviewer thinks that the gain of dynamic fusion results from merely using more computational cost.\n- Is there no previous multi-modal methods for this task?\n- As the multi-modal baseline, the authors use the simple combination of independently learned uni-modal models.\n- But, the lower performance of the baseline is not surprising at all.\n- To show the effectiveness of the proposed multi-modal fusion, it is required to compare the proposed fusion with other (even basic) intermediate fusion schemes.",
    "review_points_list": [
      "The proposed modules are straightforward use of existing techniques (transformers, contrastive learning).",
      "Although the co-attention scheme is developed by modifying the self-attention scheme of the transformer, it has already been tried in various multi-modal methods.",
      "Comprehensively, the novelty is weak.",
      "Not enough analysis and studies are contained.",
      "Several definitions/descriptions are unclear.",
      "Although there is room for the amount of pages.",
      "In table 1, does the single-stream DRFT mean replacing the inter-modal feature learning module with self-attention?",
      "If not, the single-stream DRFT is just the method w/o any attention mechanism, and then it is not proper to verify the effect of the proposed co-attention.",
      "Unclear description for REG module.",
      "For example, how the start and end timing is obtained if there is multiple start-end in a video?",
      "Why the definition/formulation of L_grn is not described?",
      "In line 205-206, the authors mentioned that their LGI module is similar to LGI model [19]. Then, is the proposed method built on top of [19] by adding the proposed modules?",
      "There is no analysis or studies for if the weight of dynamic fusion differs depending on videos or frames.",
      "Without showing this point, the reviewer thinks that the gain of dynamic fusion results from merely using more computational cost.",
      "Is there no previous multi-modal methods for this task?",
      "As the multi-modal baseline, the authors use the simple combination of independently learned uni-modal models.",
      "But, the lower performance of the baseline is not surprising at all.",
      "To show the effectiveness of the proposed multi-modal fusion, it is required to compare the proposed fusion with other (even basic) intermediate fusion schemes."
    ]
  },
  {
    "paper_id": "2506.18883v1",
    "submission_id": "ybw2U70q_Vd",
    "submission_title": "End-to-end Multi-modal Video Temporal Grounding",
    "review_id": "BwncHCg608x",
    "input": {
      "title": "End-to-end Multi-modal Video Temporal Grounding",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well-written and easy to follow.\n- Experimental results also justify the effectiveness of the proposed method.\n- The authors are expected to justify their design choices in the proposed method rather than just give a combination of existing techniques.\n- It would help further extension if the authors could elaborate more on the current design.\n- In DRFT, the authors only consider two kinds of fusion, namely RGB-depth and RGB-flow.\n- Is there any specific reason not to use other combinations, e.g., depth-flow?\n- The baseline models in Sec. 3.1 do not make sense to me.\n- It seems to me that the most straightforward would be to concatenate different modalities and learn a 1x1 conv to fuse those features.\n- Is there any reason that the authors adopt an average strategy? What\u2019s the gap between the concatenation and other models mentioned in the paper?\n- I am curious about the necessity of using a co-attentional transformer.\n- There have been a few lightweight attention modules, such as CBAM [1]. Can the authors briefly elaborate on this design choice?\n- Although the experiments suggest multi-modality does help, it is unclear how they help.\n- Maybe the authors could provide visualization showing what kind of information helps which activities more, by showing the attention weights and the corresponding activities.\n- The reason why intra-model feature learning works remains unclear to me.\n- It might be a novel point of view, but the authors are encouraged to provide more insights in the paper.",
    "review_points_list": [
      "The paper is well-written and easy to follow.",
      "Experimental results also justify the effectiveness of the proposed method.",
      "The authors are expected to justify their design choices in the proposed method rather than just give a combination of existing techniques.",
      "It would help further extension if the authors could elaborate more on the current design.",
      "In DRFT, the authors only consider two kinds of fusion, namely RGB-depth and RGB-flow.",
      "Is there any specific reason not to use other combinations, e.g., depth-flow?",
      "The baseline models in Sec. 3.1 do not make sense to me.",
      "It seems to me that the most straightforward would be to concatenate different modalities and learn a 1x1 conv to fuse those features.",
      "Is there any reason that the authors adopt an average strategy? What\u2019s the gap between the concatenation and other models mentioned in the paper?",
      "I am curious about the necessity of using a co-attentional transformer.",
      "There have been a few lightweight attention modules, such as CBAM [1]. Can the authors briefly elaborate on this design choice?",
      "Although the experiments suggest multi-modality does help, it is unclear how they help.",
      "Maybe the authors could provide visualization showing what kind of information helps which activities more, by showing the attention weights and the corresponding activities.",
      "The reason why intra-model feature learning works remains unclear to me.",
      "It might be a novel point of view, but the authors are encouraged to provide more insights in the paper."
    ]
  },
  {
    "paper_id": "2506.18883v1",
    "submission_id": "ybw2U70q_Vd",
    "submission_title": "End-to-end Multi-modal Video Temporal Grounding",
    "review_id": "0H5vI2Q9hXV",
    "input": {
      "title": "End-to-end Multi-modal Video Temporal Grounding",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well written and the approach is intuitive and easy to understand and follow.\n- Performance is also competitive and improves on state-of-the-art.\n- The technical novelty is somewhat incremental, with components effectively borrowed from other recent works.\n- That being said the choices are well motivated and work well together for the task at hand.\n- Overall, I feel the novelty is sufficient for a poster publication in NeurIPS.\n- The supervised loss (L_{and}) is not defined.\n- It should be defined in the paper, if for no other reason than completeness.\n- The extraction of video segment features (Lines 188-190) is unclear and should be clarified.\n- In addition, one of the more surprising aspects of the paper, for me, is that depth was helpful for the task.\n- I am not aware of any other works that use estimated depth for video tasks.\n- As such, I would be interested in seeing more analysis on the depth modality.\n- For example, how well would depth features work on their own (as one stream DRFT)?\n- How well would they perform in combination with RGB (as a two stream DRFT)? etc.",
    "review_points_list": [
      "The paper is well written and the approach is intuitive and easy to understand and follow.",
      "Performance is also competitive and improves on state-of-the-art.",
      "The technical novelty is somewhat incremental, with components effectively borrowed from other recent works.",
      "That being said the choices are well motivated and work well together for the task at hand.",
      "Overall, I feel the novelty is sufficient for a poster publication in NeurIPS.",
      "The supervised loss (L_{and}) is not defined.",
      "It should be defined in the paper, if for no other reason than completeness.",
      "The extraction of video segment features (Lines 188-190) is unclear and should be clarified.",
      "In addition, one of the more surprising aspects of the paper, for me, is that depth was helpful for the task.",
      "I am not aware of any other works that use estimated depth for video tasks.",
      "As such, I would be interested in seeing more analysis on the depth modality.",
      "For example, how well would depth features work on their own (as one stream DRFT)?",
      "How well would they perform in combination with RGB (as a two stream DRFT)? etc."
    ]
  },
  {
    "paper_id": "2506.18883v1",
    "submission_id": "ybw2U70q_Vd",
    "submission_title": "End-to-end Multi-modal Video Temporal Grounding",
    "review_id": "WP0QFHQBZdX",
    "input": {
      "title": "End-to-end Multi-modal Video Temporal Grounding",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Satisfactory paper writing. Clear technical presentation.\n- Good performances and thorough empirical studies.\n- My main concern is the novelty. All the proposed modules look natural but kind of straighforward to me.\n- There is no inspiring techniques or insightful technical conclusion.\n- For example, co-attentional transformer layers are adopted from [17] to model the interaction among different modalities;\n- Contrastive learning is adopted to model the intra-modal feature learning.\n- Why actions like 'sitting in a bed' require depth information? Can they be recognized by RGB information?\n- In the intra-modal feature learning, given only the sentence query, how to judge whether two videos are from the same action category?\n- I agree with other reviewers that depth information is interesting and properly leveraged for the multi-modality task.\n- From non-technical aspect, it is a novel idea.\n- The technical novelty might be limited but acceptable.\n- I increase my rating to 'Marginally above acceptence threshold'.",
    "review_points_list": [
      "Satisfactory paper writing. Clear technical presentation.",
      "Good performances and thorough empirical studies.",
      "My main concern is the novelty. All the proposed modules look natural but kind of straighforward to me.",
      "There is no inspiring techniques or insightful technical conclusion.",
      "For example, co-attentional transformer layers are adopted from [17] to model the interaction among different modalities;",
      "Contrastive learning is adopted to model the intra-modal feature learning.",
      "Why actions like 'sitting in a bed' require depth information? Can they be recognized by RGB information?",
      "In the intra-modal feature learning, given only the sentence query, how to judge whether two videos are from the same action category?",
      "I agree with other reviewers that depth information is interesting and properly leveraged for the multi-modality task.",
      "From non-technical aspect, it is a novel idea.",
      "The technical novelty might be limited but acceptable.",
      "I increase my rating to 'Marginally above acceptence threshold'."
    ]
  },
  {
    "paper_id": "2110.00959v2",
    "submission_id": "zaqGp90Od4y",
    "submission_title": "Boost Neural Networks by Checkpoints",
    "review_id": "RMbAyAwVkpC",
    "input": {
      "title": "Boost Neural Networks by Checkpoints",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper is well written and easy to follow.\n- The proposed method seems technically sound.\n- Sample reweighting is not a new idea in deep learning, but its connection to boosting and promoting model diversity among different checkpoints is interesting.\n- Most previous methods for 'checkpoints ensembling' still perform poorly due to low diversity.\n- The authors tackle low diversity by using sample reweighting.\n- The authors conduct sufficient experiments and ablation to demonstrate the effectiveness of the proposed method.\n- It would be valuable to compare the proposed method to an explicit ensemble.\n- A more detailed analysis is needed to understand why the proposed method outperforms previous methods.\n- It is unclear how relevant the theoretical analysis is to the main contributions of the paper.\n- There is no diversity analysis in the section.\n- Theoretical demonstrations of diversity would be more interesting.\n- The proposed method introduces additional hyper-parameters like the deviation rate.\n- It is unclear how sensitive the performance is to hyper-parameters and how easy they are to tune.\n- The paper is a good submission, and I recommend accepting it.",
    "review_points_list": [
      "This paper is well written and easy to follow.",
      "The proposed method seems technically sound.",
      "Sample reweighting is not a new idea in deep learning, but its connection to boosting and promoting model diversity among different checkpoints is interesting.",
      "Most previous methods for 'checkpoints ensembling' still perform poorly due to low diversity.",
      "The authors tackle low diversity by using sample reweighting.",
      "The authors conduct sufficient experiments and ablation to demonstrate the effectiveness of the proposed method.",
      "It would be valuable to compare the proposed method to an explicit ensemble.",
      "A more detailed analysis is needed to understand why the proposed method outperforms previous methods.",
      "It is unclear how relevant the theoretical analysis is to the main contributions of the paper.",
      "There is no diversity analysis in the section.",
      "Theoretical demonstrations of diversity would be more interesting.",
      "The proposed method introduces additional hyper-parameters like the deviation rate.",
      "It is unclear how sensitive the performance is to hyper-parameters and how easy they are to tune.",
      "The paper is a good submission, and I recommend accepting it."
    ]
  },
  {
    "paper_id": "2110.00959v2",
    "submission_id": "zaqGp90Od4y",
    "submission_title": "Boost Neural Networks by Checkpoints",
    "review_id": "Bn5RqI6zDyU",
    "input": {
      "title": "Boost Neural Networks by Checkpoints",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Snapshot Ensemble requires a modification to the learning rate scheme.\n- This limits its application when cylinder learning rate scheme is not desirable.\n- CBNN does not require any strange tweak to the current learning algorithm, so it has a much wider application.\n- The authors provide convergence analysis, leading to a theoretically grounded algorithm.\n- The baselines this paper compared to are competitive, including recent advances such as Snapshot Ensemble and FGE.\n- CBNN outperforms these competitive baselines on a variety of network architectures and vision datasets in terms of the accuracy measure.\n- Additionally, the diversity analysis section is also interesting as it provides more insights of the CBNN.\n- It also demonstrates that the proposed reweighting scheme is helpful.\n- Overall, the empirical evaluation is convincing and is consistent to the intuition of the proposed method.\n- I also have a number of concerns about this paper.\n- One of the major concern is that the paper is missing some ablation studies which are helpful to understand the proposed algorithm.\n- For example, under the fixed training budget, how does the accuracy and diversity change if we change the training iterations per checkpoint t / or M.\n- Another ablation study is dropping the sample reweighting during training but still keeping ensemble reweighting based on the error rate, how does this change the accuracy and diversity?\n- This demonstrates the importance of sample reweighting which is the core component in the CBNN.\n- There are some other minor concerns.\n- For example, it might be better to report the accuracy and diversity (Figure 2a) of fully independent ensembles, which can be used as an upper bound.\n- The gap also shows how much room left to improve CBNN.\n- It is also beneficial to report individual accuracy of each ensemble member (each checkpoint).\n- This helps understand the diversity, too.\n- One of the best advantages of this algorithm is its wide applicability.\n- The paper would be more convincing if the authors can demonstrate its effectiveness in the transformer models in the NLP domain.\n- Snapshot Ensemble and FGE are naturally short in these applications.\n- Another potential experiments are uncertainty estimation, deep ensembles are powerful not only because of its improved accuracy but only the improved calibration / uncertainty quantification.\n- The paper can be stronger if the authors can show CBNN has better calibration (expected calibration error, ECE) performance than the single model.\n- Overall, I consider this paper is slightly above the borderline at its current shape.",
    "review_points_list": [
      "Snapshot Ensemble requires a modification to the learning rate scheme.",
      "This limits its application when cylinder learning rate scheme is not desirable.",
      "CBNN does not require any strange tweak to the current learning algorithm, so it has a much wider application.",
      "The authors provide convergence analysis, leading to a theoretically grounded algorithm.",
      "The baselines this paper compared to are competitive, including recent advances such as Snapshot Ensemble and FGE.",
      "CBNN outperforms these competitive baselines on a variety of network architectures and vision datasets in terms of the accuracy measure.",
      "Additionally, the diversity analysis section is also interesting as it provides more insights of the CBNN.",
      "It also demonstrates that the proposed reweighting scheme is helpful.",
      "Overall, the empirical evaluation is convincing and is consistent to the intuition of the proposed method.",
      "I also have a number of concerns about this paper.",
      "One of the major concern is that the paper is missing some ablation studies which are helpful to understand the proposed algorithm.",
      "For example, under the fixed training budget, how does the accuracy and diversity change if we change the training iterations per checkpoint t / or M.",
      "Another ablation study is dropping the sample reweighting during training but still keeping ensemble reweighting based on the error rate, how does this change the accuracy and diversity?",
      "This demonstrates the importance of sample reweighting which is the core component in the CBNN.",
      "There are some other minor concerns.",
      "For example, it might be better to report the accuracy and diversity (Figure 2a) of fully independent ensembles, which can be used as an upper bound.",
      "The gap also shows how much room left to improve CBNN.",
      "It is also beneficial to report individual accuracy of each ensemble member (each checkpoint).",
      "This helps understand the diversity, too.",
      "One of the best advantages of this algorithm is its wide applicability.",
      "The paper would be more convincing if the authors can demonstrate its effectiveness in the transformer models in the NLP domain.",
      "Snapshot Ensemble and FGE are naturally short in these applications.",
      "Another potential experiments are uncertainty estimation, deep ensembles are powerful not only because of its improved accuracy but only the improved calibration / uncertainty quantification.",
      "The paper can be stronger if the authors can show CBNN has better calibration (expected calibration error, ECE) performance than the single model.",
      "Overall, I consider this paper is slightly above the borderline at its current shape."
    ]
  },
  {
    "paper_id": "2110.00959v2",
    "submission_id": "zaqGp90Od4y",
    "submission_title": "Boost Neural Networks by Checkpoints",
    "review_id": "tEZWN6N9a30",
    "input": {
      "title": "Boost Neural Networks by Checkpoints",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well-written and easy to follow.\n- The proposed method is straightforward and should be novel.\n- The experimental results look promising on both performance and training cost.\n- Is there a reason why ImageNet with Densenet and Resnet are omitted in Tab. 1?\n- As SSE is the second-best performance, I am wondering if the authors tried to adopt cyclic learning rate schedule as SSE does to improve CBNN?\n- The theoretical analysis Theorem 1 and Theorem 2 seem trivial and the conclusion is a little bit vacuous.\n- The conclusion is that an upper bound of the exponential loss is decreasing with more checkpoints.\n- The upper bound can be very loose, which can lead to a vacuous conclusion.\n- It would be better to calculate the tightness of the upper bound empirically.\n- Although random labeling has the error rate (k-1)/k, the worst-case error rate can be worse than this.\n- Therefore, $\\'m > 0$ needs to be assumed.\n- Overall, as the experimental results look promising, I think this paper would be interesting to the DL community.\n- However, due to the above concerns and lack of the limitation and societal impact discussion, I think the current version of the paper is not ready for publication.\n- I am open to change the score based on the authors' rebuttal.",
    "review_points_list": [
      "The paper is well-written and easy to follow.",
      "The proposed method is straightforward and should be novel.",
      "The experimental results look promising on both performance and training cost.",
      "Is there a reason why ImageNet with Densenet and Resnet are omitted in Tab. 1?",
      "As SSE is the second-best performance, I am wondering if the authors tried to adopt cyclic learning rate schedule as SSE does to improve CBNN?",
      "The theoretical analysis Theorem 1 and Theorem 2 seem trivial and the conclusion is a little bit vacuous.",
      "The conclusion is that an upper bound of the exponential loss is decreasing with more checkpoints.",
      "The upper bound can be very loose, which can lead to a vacuous conclusion.",
      "It would be better to calculate the tightness of the upper bound empirically.",
      "Although random labeling has the error rate (k-1)/k, the worst-case error rate can be worse than this.",
      "Therefore, $\\'m > 0$ needs to be assumed.",
      "Overall, as the experimental results look promising, I think this paper would be interesting to the DL community.",
      "However, due to the above concerns and lack of the limitation and societal impact discussion, I think the current version of the paper is not ready for publication.",
      "I am open to change the score based on the authors' rebuttal."
    ]
  },
  {
    "paper_id": "2108.07356v4",
    "submission_id": "w5j80GVGFsr",
    "submission_title": "Stochastic optimization under time drift: iterate averaging, step-decay schedules, and high probability guarantees",
    "review_id": "khzwoz6bmmt",
    "input": {
      "title": "Stochastic optimization under time drift: iterate averaging, step-decay schedules, and high probability guarantees",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The analysis is useful and interesting, and the writing was clear and precise throughout.\n- I could see it becoming a go-to reference for myself, and I can think of several colleagues who would be equally enthusiastic.\n- The results presented here actually relate to filtering --- the optimal choice of $\\eta$ depends on knowledge of $\\Delta$, which would amount to knowing the variance of the process noise driving the hidden state.\n- Concretely, in the classic least-squares setting, we'd have $x_{t}^*=F_{t} x_{t-1}^* +u_t$, $y_t = H_t x_t^* + v_t$ , where $u_t\\sim\\mathcal{N}(0, Q)$ and $v_t\\sim N(0, R)$, and we want to track $x_t^*$ through observations of $y_t$.\n- The results presented here seem to suggest we'd need to know both $R$ and $Q$ in order to set $\\eta=\\eta^*$, but given this information there's really nothing adaptive about the problem --- not knowing these variances is precisely the difficulty of adaptive filtering!\n- I would also be curious to see exactly how the iterates chosen when using the optimal fixed $\\eta^*$ relate to the steady-state solution of the Kalman filter, which *also* requires knowledge of the noise variances to set its step-size/gain matrix.\n- The connection to filtering could only hold in the 1d and/or time-invariant case without additional information?\n- In higher dimensions, even the squared loss $\\frac{1}{2}(y_t - F_tx_t)^2$ will only satisfy the strong-convexity assumption in a rather small subset of filtering problems.\n- Additional assumptions on the transition/measurement matrices (e.g. the observability matrix is invertible, etc) to say much of anything in higher dimensions\n- Rather than an appendix containing technical details, the supplementary materials are an extended version of the paper, also with its own appendix\n- It was also just generally annoying to navigate, and find what I was looking for, with some results now being mixed in alongside the things I already read in the main paper\n- The experiments were the weakest part of the paper to me; in my opinion these could be moved entirely to the appendix to make room for some of the other results",
    "review_points_list": [
      "The analysis is useful and interesting, and the writing was clear and precise throughout.",
      "I could see it becoming a go-to reference for myself, and I can think of several colleagues who would be equally enthusiastic.",
      "The results presented here actually relate to filtering --- the optimal choice of $\\eta$ depends on knowledge of $\\Delta$, which would amount to knowing the variance of the process noise driving the hidden state.",
      "Concretely, in the classic least-squares setting, we'd have $x_{t}^*=F_{t} x_{t-1}^* +u_t$, $y_t = H_t x_t^* + v_t$ , where $u_t\\sim\\mathcal{N}(0, Q)$ and $v_t\\sim N(0, R)$, and we want to track $x_t^*$ through observations of $y_t$.",
      "The results presented here seem to suggest we'd need to know both $R$ and $Q$ in order to set $\\eta=\\eta^*$, but given this information there's really nothing adaptive about the problem --- not knowing these variances is precisely the difficulty of adaptive filtering!",
      "I would also be curious to see exactly how the iterates chosen when using the optimal fixed $\\eta^*$ relate to the steady-state solution of the Kalman filter, which *also* requires knowledge of the noise variances to set its step-size/gain matrix.",
      "The connection to filtering could only hold in the 1d and/or time-invariant case without additional information?",
      "In higher dimensions, even the squared loss $\\frac{1}{2}(y_t - F_tx_t)^2$ will only satisfy the strong-convexity assumption in a rather small subset of filtering problems.",
      "Additional assumptions on the transition/measurement matrices (e.g. the observability matrix is invertible, etc) to say much of anything in higher dimensions",
      "Rather than an appendix containing technical details, the supplementary materials are an extended version of the paper, also with its own appendix",
      "It was also just generally annoying to navigate, and find what I was looking for, with some results now being mixed in alongside the things I already read in the main paper",
      "The experiments were the weakest part of the paper to me; in my opinion these could be moved entirely to the appendix to make room for some of the other results"
    ]
  },
  {
    "paper_id": "2108.07356v4",
    "submission_id": "w5j80GVGFsr",
    "submission_title": "Stochastic optimization under time drift: iterate averaging, step-decay schedules, and high probability guarantees",
    "review_id": "MyHrG8iEaMh",
    "input": {
      "title": "Stochastic optimization under time drift: iterate averaging, step-decay schedules, and high probability guarantees",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This is the first paper that deals with tracking in machine learning.\n- The study of tracking is very classical in system theory, but not in ML.\n- Most of the work in pursuit is devoted to the identification of linear systems.\n- The work on bounds in HP is also new.\n- The paper is well written and the main arguments are easy to follow.\n- The proofs are adapted from the classical arguments in the stationary case, so there are no really major surprises.\n- I would have liked a more detailed discussion of the assumptions.\n- The assumption of sub-Gaussianity of the gradient seems to me to be costly.\n- If the $f_t(x)= \\\\[ (y - \\\\[hi^x)^2]$ where \\\\[hi \\\\[sim N(0,\\\theta^2 Id) $ (the \"easy\" gaussian linear regression), and if $\\\tilde{\\\nabla} f_t(x)= \\\\[hi_t ( y_t - \\\\[hi_t x)$ (assuming for simplicity $\\{(y_t,\\\theta_t)\\}$ i.i.d. then this assumption is not satisfied.\n- Even if the regression vector is bounded, then the assumption is not satisfied (unless $x_t$ is bounded).\n- Therefore the assumption on the noise term seems strong.\n- It would be good to check the assumption whether the condition is satisfied for the $\\\theta_2^2$-regularized logistic regression (under which condition on the regressors ?).\n- When reading the example, it is not clear to understand what you mean by \"using a noisy gradient $g_t$ satisfying $\\left\\|g_{t}-\\\nabla f_{t}(x_{t})\\right\\|\\\theta\\sigma$ for each step $t$.\n- This is a essentially theoretical paper, a first step in analyzing the tracking ability of stochastic gradient algorithms.\n- Of course, this work opens many research directions and questions.\n- It is clear that all the results remain very theoretical\n- One would like to have algorithms able to adapt to different constants (lipschitz, strong convexity, non-stationarity).\n- The assumptions are very strong\n- In particular, it is very restrictive to assume a priori that the gradient noise is sub-gaussian, this precludes the use of this result even in very simple examples.",
    "review_points_list": [
      "This is the first paper that deals with tracking in machine learning.",
      "The study of tracking is very classical in system theory, but not in ML.",
      "Most of the work in pursuit is devoted to the identification of linear systems.",
      "The work on bounds in HP is also new.",
      "The paper is well written and the main arguments are easy to follow.",
      "The proofs are adapted from the classical arguments in the stationary case, so there are no really major surprises.",
      "I would have liked a more detailed discussion of the assumptions.",
      "The assumption of sub-Gaussianity of the gradient seems to me to be costly.",
      "If the $f_t(x)= \\\\[ (y - \\\\[hi^x)^2]$ where \\\\[hi \\\\[sim N(0,\\\theta^2 Id) $ (the \"easy\" gaussian linear regression), and if $\\\tilde{\\\nabla} f_t(x)= \\\\[hi_t ( y_t - \\\\[hi_t x)$ (assuming for simplicity $\\{(y_t,\\\theta_t)\\}$ i.i.d. then this assumption is not satisfied.",
      "Even if the regression vector is bounded, then the assumption is not satisfied (unless $x_t$ is bounded).",
      "Therefore the assumption on the noise term seems strong.",
      "It would be good to check the assumption whether the condition is satisfied for the $\\\theta_2^2$-regularized logistic regression (under which condition on the regressors ?).",
      "When reading the example, it is not clear to understand what you mean by \"using a noisy gradient $g_t$ satisfying $\\left\\|g_{t}-\\\nabla f_{t}(x_{t})\\right\\|\\\theta\\sigma$ for each step $t$.",
      "This is a essentially theoretical paper, a first step in analyzing the tracking ability of stochastic gradient algorithms.",
      "Of course, this work opens many research directions and questions.",
      "It is clear that all the results remain very theoretical",
      "One would like to have algorithms able to adapt to different constants (lipschitz, strong convexity, non-stationarity).",
      "The assumptions are very strong",
      "In particular, it is very restrictive to assume a priori that the gradient noise is sub-gaussian, this precludes the use of this result even in very simple examples."
    ]
  },
  {
    "paper_id": "2108.07356v4",
    "submission_id": "w5j80GVGFsr",
    "submission_title": "Stochastic optimization under time drift: iterate averaging, step-decay schedules, and high probability guarantees",
    "review_id": "uspblFfL3Gs",
    "input": {
      "title": "Stochastic optimization under time drift: iterate averaging, step-decay schedules, and high probability guarantees",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper presents a new way of looking at time varying optimization.\n- The proof techniques are not new, but the discovery of the two regimes is very interesting and this implication can be useful for real-world applications.\n- This paper is clearly written and well-organized.\n- The authors present a novel approach to time-variant optimization, which is an interesting area.\n- The novelty is mainly due to the combination of techniques, rather than a new underlying principle.\n- The introduction is clear and provides a good overview of the problem, but it lacks some specific details about the motivation behind the proposed method.\n- The experimental evaluation is well-structured and provides a good comparison with existing methods.\n- The results are generally positive, with the proposed method outperforming existing methods in most cases.\n- However, the discussion section could be improved by providing more insights into the limitations and potential applications of the proposed method.\n- The authors also provide a theoretical analysis of the proposed method, which is well-written and provides interesting insights.\n- However, the analysis is limited to a specific case, which may not generalize well to other scenarios.\n- In conclusion, the paper presents an interesting approach to time-variant optimization, but it requires further development and experimentation to validate its potential.\n- This paper presents a new technique for solving the NP-complete problem of the k-vertex connected subgraph problem.\n- The authors use a combination of integer programming and constraint programming to achieve this.\n- The novelty of the paper is that the authors provide a more efficient solution for this problem than previously known.\n- The authors also provide a theoretical guarantee for the proposed algorithm.\n- They prove that their algorithm is guaranteed to find the optimal solution in polynomial time, which is important for many applications in computer science.\n- However, the paper could be improved by providing more details about the implementation, including the choice of algorithms and data structures used.\n- The authors also assume that the input graph is undirected, which may not be the case in all applications.\n- In conclusion, the paper presents an interesting approach to solving the k-vertex connected subgraph problem, with potential applications in computer science.",
    "review_points_list": [
      "The paper presents a new way of looking at time varying optimization.",
      "The proof techniques are not new, but the discovery of the two regimes is very interesting and this implication can be useful for real-world applications.",
      "This paper is clearly written and well-organized.",
      "The authors present a novel approach to time-variant optimization, which is an interesting area.",
      "The novelty is mainly due to the combination of techniques, rather than a new underlying principle.",
      "The introduction is clear and provides a good overview of the problem, but it lacks some specific details about the motivation behind the proposed method.",
      "The experimental evaluation is well-structured and provides a good comparison with existing methods.",
      "The results are generally positive, with the proposed method outperforming existing methods in most cases.",
      "However, the discussion section could be improved by providing more insights into the limitations and potential applications of the proposed method.",
      "The authors also provide a theoretical analysis of the proposed method, which is well-written and provides interesting insights.",
      "However, the analysis is limited to a specific case, which may not generalize well to other scenarios.",
      "In conclusion, the paper presents an interesting approach to time-variant optimization, but it requires further development and experimentation to validate its potential.",
      "This paper presents a new technique for solving the NP-complete problem of the k-vertex connected subgraph problem.",
      "The authors use a combination of integer programming and constraint programming to achieve this.",
      "The novelty of the paper is that the authors provide a more efficient solution for this problem than previously known.",
      "The authors also provide a theoretical guarantee for the proposed algorithm.",
      "They prove that their algorithm is guaranteed to find the optimal solution in polynomial time, which is important for many applications in computer science.",
      "However, the paper could be improved by providing more details about the implementation, including the choice of algorithms and data structures used.",
      "The authors also assume that the input graph is undirected, which may not be the case in all applications.",
      "In conclusion, the paper presents an interesting approach to solving the k-vertex connected subgraph problem, with potential applications in computer science."
    ]
  },
  {
    "paper_id": "2108.07356v4",
    "submission_id": "w5j80GVGFsr",
    "submission_title": "Stochastic optimization under time drift: iterate averaging, step-decay schedules, and high probability guarantees",
    "review_id": "zjZq5Hlc-4A",
    "input": {
      "title": "Stochastic optimization under time drift: iterate averaging, step-decay schedules, and high probability guarantees",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors consider the problem of form $min f(x) + r_t(x)$, where $r_t$ is a drift term.\n- The author assumes that the stochastic gradient used for solving the problem is unbiased.\n- The author proves finite-time bounds.\n- The results seem to be correct but I have serious doubts about novelty.\n- The assumptions about bias and assumptions on drift term in my opinion make that such a bound are well known in the community.\n- This kind of result can be straightforwardly obtained from Athchade et al 2016 or Rossaco et al 2014.\n- I do not believe that the paper meets the standards of NIPS conference.\n- After reading the author response and other reviews, I agree that I underestimate the novelty of the paper.",
    "review_points_list": [
      "The authors consider the problem of form $min f(x) + r_t(x)$, where $r_t$ is a drift term.",
      "The author assumes that the stochastic gradient used for solving the problem is unbiased.",
      "The author proves finite-time bounds.",
      "The results seem to be correct but I have serious doubts about novelty.",
      "The assumptions about bias and assumptions on drift term in my opinion make that such a bound are well known in the community.",
      "This kind of result can be straightforwardly obtained from Athchade et al 2016 or Rossaco et al 2014.",
      "I do not believe that the paper meets the standards of NIPS conference.",
      "After reading the author response and other reviews, I agree that I underestimate the novelty of the paper."
    ]
  },
  {
    "paper_id": "2102.06857v2",
    "submission_id": "xRLT28nnlFV",
    "submission_title": "On Robust Optimal Transport: Computational Complexity and Barycenter Computation",
    "review_id": "03ZHTX4tN0N",
    "input": {
      "title": "On Robust Optimal Transport: Computational Complexity and Barycenter Computation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- For robust optimal transport and its corresponding barycenter problem, the authors develop Sinkhorn-based and IBP-based algorithms for solving them.\n- The proposed algorithms can achieve near-optimal complexity, which outperform state-of-the-art competitors.\n- The organization of this paper is satisfactory, and the motivation is very clear.\n- The experiments are implemented on various synthetic and real datasets; the experimental settings and results are well explained.\n- Some existing work considers the problem of robust optimal transport with similar idea, e.g.,\n- More discussion is needed to compare them with the proposed method.",
    "review_points_list": [
      "For robust optimal transport and its corresponding barycenter problem, the authors develop Sinkhorn-based and IBP-based algorithms for solving them.",
      "The proposed algorithms can achieve near-optimal complexity, which outperform state-of-the-art competitors.",
      "The organization of this paper is satisfactory, and the motivation is very clear.",
      "The experiments are implemented on various synthetic and real datasets; the experimental settings and results are well explained.",
      "Some existing work considers the problem of robust optimal transport with similar idea, e.g.,",
      "More discussion is needed to compare them with the proposed method."
    ]
  },
  {
    "paper_id": "2102.06857v2",
    "submission_id": "xRLT28nnlFV",
    "submission_title": "On Robust Optimal Transport: Computational Complexity and Barycenter Computation",
    "review_id": "GUVQhkLu8fO",
    "input": {
      "title": "On Robust Optimal Transport: Computational Complexity and Barycenter Computation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- It seems unfair to compare the proposed methods with the Sinkhorn algorithm, since the solution of the proposed method is even not in $\text{Pi}(P,Q)$.\n- Also, there is no comparison between the proposed methods and Sinkhorn, in terms of both accuracy and efficiency.\n- By further relaxing the equality constraints, the problem should be simpler and easier to compute. But what's the purpose of such a relaxing?\n- In Fig. 2, what's the meaning of different colors? Is there any way to enlarge the difference of different lines like plotting them in the log-domain? Currently they just mix together.\n- Similar relaxation about OT has been proposed in [Fast Unbalanced Optimal Transport on a Tree] and its cited works. Please see the first formula of this paper.\n- No comparison between the proposed methods and other similar ones, like the standard OT and UOT. Without such comparisons, it is hard to see the merits of the proposed ones.\n- Many missing references about partial optimal transport:\n- - Alessio Figalli. The optimal partial transport problem. Archive for rational mechanics and analysis, 195(2):533\u2013560, 2010\n- Luis A Caffarelli and Robert J McCann. Free boundaries in optimal transport and monge-ampere obstacle problems. Annals of mathematics, pages 673\u2013730, 2010.",
    "review_points_list": [
      "It seems unfair to compare the proposed methods with the Sinkhorn algorithm, since the solution of the proposed method is even not in $\text{Pi}(P,Q)$.",
      "Also, there is no comparison between the proposed methods and Sinkhorn, in terms of both accuracy and efficiency.",
      "By further relaxing the equality constraints, the problem should be simpler and easier to compute. But what's the purpose of such a relaxing?",
      "In Fig. 2, what's the meaning of different colors? Is there any way to enlarge the difference of different lines like plotting them in the log-domain? Currently they just mix together.",
      "Similar relaxation about OT has been proposed in [Fast Unbalanced Optimal Transport on a Tree] and its cited works. Please see the first formula of this paper.",
      "No comparison between the proposed methods and other similar ones, like the standard OT and UOT. Without such comparisons, it is hard to see the merits of the proposed ones.",
      "Many missing references about partial optimal transport:",
      "- Alessio Figalli. The optimal partial transport problem. Archive for rational mechanics and analysis, 195(2):533\u2013560, 2010",
      "Luis A Caffarelli and Robert J McCann. Free boundaries in optimal transport and monge-ampere obstacle problems. Annals of mathematics, pages 673\u2013730, 2010."
    ]
  },
  {
    "paper_id": "2102.06857v2",
    "submission_id": "xRLT28nnlFV",
    "submission_title": "On Robust Optimal Transport: Computational Complexity and Barycenter Computation",
    "review_id": "IkI8fHumTi",
    "input": {
      "title": "On Robust Optimal Transport: Computational Complexity and Barycenter Computation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed robust optimal transport is very similar the unbalanced optimal transport.\n- The algorithms proposed are largely inspired from existing method (UOT [9]).\n- The ROT algorithm follows the generalised Sinkhorn algorithm with a extra step that is the normalisation of the transport plan.\n- The complexity analysis of the proposed algorithms (solving ROT, RSOT and RobustIBP) are theoretically strong, as they in particular provide an \u03b5-approximation of the solutions.\n- A low-rank approximation improves the complexity of the algorithm solving ROT.\n- ROT is presented as a robust method but there are no theoretical or experimental results that truly support this claim (except for Figure 1, see Limitations).\n- This paper is well written and the different problems are clearly stated.\n- The improvements of the methods proposed in the article compared to the UOT is not clear.\n- Both problems have the same complexity.\n- The methods are compared with UOT in terms of complexity analysis but not in terms of behaviour.\n- How does an optimal transport plan move the mass under ROT or RSOT?\n- Does the normalising step significantly impact the results?\n- What are the key differences?",
    "review_points_list": [
      "The proposed robust optimal transport is very similar the unbalanced optimal transport.",
      "The algorithms proposed are largely inspired from existing method (UOT [9]).",
      "The ROT algorithm follows the generalised Sinkhorn algorithm with a extra step that is the normalisation of the transport plan.",
      "The complexity analysis of the proposed algorithms (solving ROT, RSOT and RobustIBP) are theoretically strong, as they in particular provide an \u03b5-approximation of the solutions.",
      "A low-rank approximation improves the complexity of the algorithm solving ROT.",
      "ROT is presented as a robust method but there are no theoretical or experimental results that truly support this claim (except for Figure 1, see Limitations).",
      "This paper is well written and the different problems are clearly stated.",
      "The improvements of the methods proposed in the article compared to the UOT is not clear.",
      "Both problems have the same complexity.",
      "The methods are compared with UOT in terms of complexity analysis but not in terms of behaviour.",
      "How does an optimal transport plan move the mass under ROT or RSOT?",
      "Does the normalising step significantly impact the results?",
      "What are the key differences?"
    ]
  },
  {
    "paper_id": "2102.06857v2",
    "submission_id": "xRLT28nnlFV",
    "submission_title": "On Robust Optimal Transport: Computational Complexity and Barycenter Computation",
    "review_id": "BiNbSfR_TAD",
    "input": {
      "title": "On Robust Optimal Transport: Computational Complexity and Barycenter Computation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The theoretical results derived in this work is new. The methods and proof techniques are essentially the same as [1].\n- The theoretical results and the associated proof seem to be solid.\n- The result on barycenter is restricted to the setting with only two marginals.\n- Though this is a pure theoretical work, the authors provided numerical examples to support their claims, which is a plus.\n- The paper is well-written.\n- The presentation is well-structured and clear.\n- The theoretical results in this paper are elegant, but I feel the contribution is incremental in view of [1].\n- Also, the barycenter result is a bit restricted.",
    "review_points_list": [
      "The theoretical results derived in this work is new. The methods and proof techniques are essentially the same as [1].",
      "The theoretical results and the associated proof seem to be solid.",
      "The result on barycenter is restricted to the setting with only two marginals.",
      "Though this is a pure theoretical work, the authors provided numerical examples to support their claims, which is a plus.",
      "The paper is well-written.",
      "The presentation is well-structured and clear.",
      "The theoretical results in this paper are elegant, but I feel the contribution is incremental in view of [1].",
      "Also, the barycenter result is a bit restricted."
    ]
  },
  {
    "paper_id": "2102.06857v2",
    "submission_id": "xRLT28nnlFV",
    "submission_title": "On Robust Optimal Transport: Computational Complexity and Barycenter Computation",
    "review_id": "yJySXhXg1xe",
    "input": {
      "title": "On Robust Optimal Transport: Computational Complexity and Barycenter Computation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- My main concern is that the paper is very similar to the analysis in [26] where the convergence proof of unbalanced Sinkhorn is provided.\n- This paper analyses a modification of unbalanced optimal transport in which the variable X is forced to be a transportation plan.\n- This modification also translates to a normalization step in the sinkhorn algorithm.\n- The authors show why this modification is important in Figure 1.\n- A difference due to the normalization step is seen in the convergence proof of Theorem 1.\n- There is a similarity with the analysis in [26].\n- The authors also analyze the robust barycenter problem, which is an extension of the robust OT problem.\n- This convergence analysis provides a O(n^2/\\epsilon) solution for the barycenter problem.\n- I did not go over the proofs in detail, but I am concerned about the similarity of the problem/analysis compared to [26] and not sure of the novelty.\n- I would like if the authors help clarify this.",
    "review_points_list": [
      "My main concern is that the paper is very similar to the analysis in [26] where the convergence proof of unbalanced Sinkhorn is provided.",
      "This paper analyses a modification of unbalanced optimal transport in which the variable X is forced to be a transportation plan.",
      "This modification also translates to a normalization step in the sinkhorn algorithm.",
      "The authors show why this modification is important in Figure 1.",
      "A difference due to the normalization step is seen in the convergence proof of Theorem 1.",
      "There is a similarity with the analysis in [26].",
      "The authors also analyze the robust barycenter problem, which is an extension of the robust OT problem.",
      "This convergence analysis provides a O(n^2/\\epsilon) solution for the barycenter problem.",
      "I did not go over the proofs in detail, but I am concerned about the similarity of the problem/analysis compared to [26] and not sure of the novelty.",
      "I would like if the authors help clarify this."
    ]
  },
  {
    "paper_id": "2008.09041v5",
    "submission_id": "xz80iPFIjvG",
    "submission_title": "On the Algorithmic Stability of Adversarial Training",
    "review_id": "F6tvrOuDZvm",
    "input": {
      "title": "On the Algorithmic Stability of Adversarial Training",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The problem of designing models that are robust against adversarial attacks is a burning issue both in academia and in the industry right now.\n- As adversarial training is one of the most efficient strategies against this problem, it is important to better understand this technique from a theoretical standpoint.\n- Hence, the main focus of this paper is completely relevant to the machine learning community.\n- I had some troubles following some parts of the paper.\n- I feel like the overall point could be much more convincing if the author were to reorganize and focus their contributions, at least in the main paper.\n- For example, Lemma 1 seems overcomplicated in its current form because the authors wanted to encapsulate several Lemmas at once (as explained in the appendix).\n- To clarify the contributions and to make the paper more readable, I would suggest that the authors focus on presenting results for the linear regression and leave similar findings with other models to the appendix.\n- Note that results are actually demonstrated in the appendix only for the regression case anyway, and extensions are left to the reader.\n- Similarly, Algorithm 1 (while it is quite straightforward) seemed a bit vague at first sight.\n- To my point of view, very generic statements such as \u2018\u2018Add noise with size $\neta$\u2019\u2019 do not convey a clear point.\n- I think the paper would benefit from focusing on the Gaussian noise injection, as it is the distribution that is used to demonstrate all the results.\n- I had some trouble evaluating the soundness of the technical results because of the clarity issues mentioned above.\n- Also, I am a bit uncomfortable with the way the authors demonstrate their statements.\n- Some results (Lemma 1, Propositions 1 and 2, Corollary 1) are not provided with any formal proof.\n- Some others (Theorems 2 and 3) are demonstrated only in the case of the linear regression.\n- Even though the results presented in Appendix and existing works in the domain might be sufficient to provide simple proofs for these results, I feel like this should not be the reviewer\u2019s (nor the reader\u2019s for that matter) job to check for the soundness of the statements by combinations of different (rather technical) results.\n- I think the authors should provide clear proofs for the results they state, even if those are very simple.\n- As in the clarity section, I suggest providing clear statements with proofs at least for the regression case in the main paper and provide some leads for generalizing the results in the appendix.\n- On the experimental part, I felt that the point was rather not very convincing and was not sufficiently correlated with the results.\n- This impression comes mostly from the fact that 1) the mean of the Lipschitz constants with and without noise injection do not seem to differ in a significant way and 2) low-dimensional intuitions are usually misleading when dealing with adversarial examples.\n- This problem on the experimental part is not my main concern because this is a theory paper, but I think it would be better to either present more convincing results or simply no experiments at all.\n- I am might not be fully aware of the literature but I think that studying adversarial training through the scope of algorithmic stability is a new idea.\n- The proposed solution of injecting noise is not very surprising (looking at the literature on algorithmic stability and specifically on the link between differential privacy and algorithmic stability) but the authors have the merit of using this solution in a new problem.\n- I think the overall idea has some merit and this paper could become an interesting first step toward a better analysis of adversarial training once the technical content is polished.\n- Some bibliographical notes: Here are some missing works that I think are worth mentioning.",
    "review_points_list": [
      "The problem of designing models that are robust against adversarial attacks is a burning issue both in academia and in the industry right now.",
      "As adversarial training is one of the most efficient strategies against this problem, it is important to better understand this technique from a theoretical standpoint.",
      "Hence, the main focus of this paper is completely relevant to the machine learning community.",
      "I had some troubles following some parts of the paper.",
      "I feel like the overall point could be much more convincing if the author were to reorganize and focus their contributions, at least in the main paper.",
      "For example, Lemma 1 seems overcomplicated in its current form because the authors wanted to encapsulate several Lemmas at once (as explained in the appendix).",
      "To clarify the contributions and to make the paper more readable, I would suggest that the authors focus on presenting results for the linear regression and leave similar findings with other models to the appendix.",
      "Note that results are actually demonstrated in the appendix only for the regression case anyway, and extensions are left to the reader.",
      "Similarly, Algorithm 1 (while it is quite straightforward) seemed a bit vague at first sight.",
      "To my point of view, very generic statements such as \u2018\u2018Add noise with size $\neta$\u2019\u2019 do not convey a clear point.",
      "I think the paper would benefit from focusing on the Gaussian noise injection, as it is the distribution that is used to demonstrate all the results.",
      "I had some trouble evaluating the soundness of the technical results because of the clarity issues mentioned above.",
      "Also, I am a bit uncomfortable with the way the authors demonstrate their statements.",
      "Some results (Lemma 1, Propositions 1 and 2, Corollary 1) are not provided with any formal proof.",
      "Some others (Theorems 2 and 3) are demonstrated only in the case of the linear regression.",
      "Even though the results presented in Appendix and existing works in the domain might be sufficient to provide simple proofs for these results, I feel like this should not be the reviewer\u2019s (nor the reader\u2019s for that matter) job to check for the soundness of the statements by combinations of different (rather technical) results.",
      "I think the authors should provide clear proofs for the results they state, even if those are very simple.",
      "As in the clarity section, I suggest providing clear statements with proofs at least for the regression case in the main paper and provide some leads for generalizing the results in the appendix.",
      "On the experimental part, I felt that the point was rather not very convincing and was not sufficiently correlated with the results.",
      "This impression comes mostly from the fact that 1) the mean of the Lipschitz constants with and without noise injection do not seem to differ in a significant way and 2) low-dimensional intuitions are usually misleading when dealing with adversarial examples.",
      "This problem on the experimental part is not my main concern because this is a theory paper, but I think it would be better to either present more convincing results or simply no experiments at all.",
      "I am might not be fully aware of the literature but I think that studying adversarial training through the scope of algorithmic stability is a new idea.",
      "The proposed solution of injecting noise is not very surprising (looking at the literature on algorithmic stability and specifically on the link between differential privacy and algorithmic stability) but the authors have the merit of using this solution in a new problem.",
      "I think the overall idea has some merit and this paper could become an interesting first step toward a better analysis of adversarial training once the technical content is polished.",
      "Some bibliographical notes: Here are some missing works that I think are worth mentioning."
    ]
  },
  {
    "paper_id": "2008.09041v5",
    "submission_id": "xz80iPFIjvG",
    "submission_title": "On the Algorithmic Stability of Adversarial Training",
    "review_id": "gRNM1v_eNuk",
    "input": {
      "title": "On the Algorithmic Stability of Adversarial Training",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The main contributions are on the theoretical side.\n- My main concerns are about originality/novelty.\n- The upper and lower bound on stability are adaptations of the claims of Bassily et al. (2020).\n- Methods of weight perturbation were already investigated empirically (see for example - Adversarial weight perturbation helps robust generalization, Neurips2020), and some theoretical justifications were also provided in follow-up papers.\n- There are glaring omissions in the literature review, especially on the theoretical side and regarding weights perturbation methods.\n- On the other hand, I think that the main research question is interesting and important.",
    "review_points_list": [
      "The main contributions are on the theoretical side.",
      "My main concerns are about originality/novelty.",
      "The upper and lower bound on stability are adaptations of the claims of Bassily et al. (2020).",
      "Methods of weight perturbation were already investigated empirically (see for example - Adversarial weight perturbation helps robust generalization, Neurips2020), and some theoretical justifications were also provided in follow-up papers.",
      "There are glaring omissions in the literature review, especially on the theoretical side and regarding weights perturbation methods.",
      "On the other hand, I think that the main research question is interesting and important."
    ]
  },
  {
    "paper_id": "2008.09041v5",
    "submission_id": "xz80iPFIjvG",
    "submission_title": "On the Algorithmic Stability of Adversarial Training",
    "review_id": "a61kcx2hY1",
    "input": {
      "title": "On the Algorithmic Stability of Adversarial Training",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Provides the first lower bound and upper bound for uniform argument stability (UAS) for AT.\n- Considers numerical attack error in inner maximization which better models the real scenario.\n- Theoretically analyzes how noise injection improves the stability.\n- The paper is well written and easy to follow.\n- The theoretical results are limited to linear models (linear/logistic regression, smooth hinge loss) and two-layer NNs.\n- The UAS bounds without noise injection seem to be limited to convex and L-Lipschitz loss.\n- Not sure whether it is a standard condition for UAS community.\n- The connection of UAS bound to generalization error bound seems not that direct.\n- What are the proper conditions for Eqn. (3)?\n- It seems that Eqn. (3) only relies on the argument stability but not any other properties of the model $f_\theta$ itself, which is a bit weird.\n- Are there any assumptions here, e.g., $f_\theta$ is a linear model, $f_\theta$ is convex or $L$-Lipschitz?\n- Can Theorem 1 and Corollary 1 be extended to provide generalization bound for GD/SGD trained models?\n- Do we need to further assume the tail distribution of $\textit{sup} \textbf{E} ||\theta_1^{(T)} - \theta_2^{(T)}||$?\n- Why do we have such generalization bound for noise injection (Proposition 2) regime but not for the normal regime?\n- What does $B$ stand for in Lemma 1?\n- It would be better if the $x$-axis scales in Figure 1 could be the same to allow for direct comparison.\n- I like the empirical evidence in C.2.1 that shows how noise injection shrinks the generalization gap in real-world data. Maybe move it to the main text?\n- I don't work in theory and didn't check the correctness of the proof.\n- While it appears to me that UAS bounds provide a new perspective on analyzing the generalization and stability for AT, and the UAS bounds in this paper are technically nontrivial.\n- I tend to support the acceptance but would adjust my evaluation based on theory reviewers.",
    "review_points_list": [
      "Provides the first lower bound and upper bound for uniform argument stability (UAS) for AT.",
      "Considers numerical attack error in inner maximization which better models the real scenario.",
      "Theoretically analyzes how noise injection improves the stability.",
      "The paper is well written and easy to follow.",
      "The theoretical results are limited to linear models (linear/logistic regression, smooth hinge loss) and two-layer NNs.",
      "The UAS bounds without noise injection seem to be limited to convex and L-Lipschitz loss.",
      "Not sure whether it is a standard condition for UAS community.",
      "The connection of UAS bound to generalization error bound seems not that direct.",
      "What are the proper conditions for Eqn. (3)?",
      "It seems that Eqn. (3) only relies on the argument stability but not any other properties of the model $f_\theta$ itself, which is a bit weird.",
      "Are there any assumptions here, e.g., $f_\theta$ is a linear model, $f_\theta$ is convex or $L$-Lipschitz?",
      "Can Theorem 1 and Corollary 1 be extended to provide generalization bound for GD/SGD trained models?",
      "Do we need to further assume the tail distribution of $\textit{sup} \textbf{E} ||\theta_1^{(T)} - \theta_2^{(T)}||$?",
      "Why do we have such generalization bound for noise injection (Proposition 2) regime but not for the normal regime?",
      "What does $B$ stand for in Lemma 1?",
      "It would be better if the $x$-axis scales in Figure 1 could be the same to allow for direct comparison.",
      "I like the empirical evidence in C.2.1 that shows how noise injection shrinks the generalization gap in real-world data. Maybe move it to the main text?",
      "I don't work in theory and didn't check the correctness of the proof.",
      "While it appears to me that UAS bounds provide a new perspective on analyzing the generalization and stability for AT, and the UAS bounds in this paper are technically nontrivial.",
      "I tend to support the acceptance but would adjust my evaluation based on theory reviewers."
    ]
  },
  {
    "paper_id": "2008.09041v5",
    "submission_id": "xz80iPFIjvG",
    "submission_title": "On the Algorithmic Stability of Adversarial Training",
    "review_id": "qieVKZCJ9wr",
    "input": {
      "title": "On the Algorithmic Stability of Adversarial Training",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE.\n- Related work is adequately cited.\n- The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.\n- The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset.\n- The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).\n- Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.\n- The authors also establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.\n- The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.\n- This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.\n- The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.\n- log(k) is an upper bound on the improvement of query complexity for any sampler.\n- The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.\n- The paper is very clear and well organized.\n- The authors detail the hyper-parameters and compute details used for the experiments.\n- The Cluster-Margin algorithm is also explained in detail.\n- The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods.\n- The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm.",
    "review_points_list": [
      "The algorithm seems to be novel and differs from previous comparable approaches like CoreSet or BADGE.",
      "Related work is adequately cited.",
      "The authors show empirically that their algorithm, Cluster-Margin, is both more efficient (O(nlog(n) vs O(n\u221a(n)) than CoreSet and BADGE in practice and more effective.",
      "The algorithm clearly outperforms CoreSet, BADGE, Margin and Random on the Open Images dataset.",
      "The algorithm requires 29% less labels than the second-best model in the 100k batch-size setting and 60% less labels in the 1M batch-size setting to achieve the same result (mAP).",
      "Cluster-Margin also outperforms all other methods on CIFAR10, CIFAR100 and obtains a similar performance on SVHN.",
      "The authors also establish a theoretical guarantee for the Cluster-MarginV algorithm and show that those results hold for the Cluster-Margin algorithm in specific settings.",
      "The Cluster-MarginV algorithm has a label complexity bound which improves over the Margin algorithm by a factor beta.",
      "This improvement is possible, under specific hypotheses like an optimal volume-based sampler, when the dimensionality of the embedding space is small or when the batch size k is large.",
      "The optimal volume-based sampler is approximately equivalent to the Cluster-Margin algorithm.",
      "log(k) is an upper bound on the improvement of query complexity for any sampler.",
      "The authors are aware and mention that their theoretical results are initial and that equating volume based samplers and the Cluster-Margin algorithm is an open research question.",
      "The paper is very clear and well organized.",
      "The authors detail the hyper-parameters and compute details used for the experiments.",
      "The Cluster-Margin algorithm is also explained in detail.",
      "The results are important as the algorithm allows for more efficient and effective large-batch-size active learning compared to existing methods.",
      "The authors also provide initial theoretical guarantees to explain the improvements obtained with the Cluster-Margin algorithm."
    ]
  },
  {
    "paper_id": "2009.12612v2",
    "submission_id": "u1XV9BPAB9",
    "submission_title": "Formalizing the Generalization-Forgetting Trade-off in Continual Learning",
    "review_id": "uZPG0anE8Ju",
    "input": {
      "title": "Formalizing the Generalization-Forgetting Trade-off in Continual Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Positives: - The paper is written very well and the generalization-forgetting trade-off is well-motivated. - There is a dearth of theory papers in continual learning and this presents a very nice theory for analyzing the trade-off between forgetting and generalization. - Empirical results are quite strong.\n- Negatives: While I don\u2019t have many problems with the paper, I do like to ask a couple of questions.  Modelling generalization: The paper argues that the degree of generalization depends on the discrepancy between the previous and new tasks. Hence in maximizing that discrepancy, and subsequently training your model to account for that discrepancy, we maximize the generalization. I could see why as an optimization objective such an adversarial training would encourage the model to adapt to possibly different tasks. But you can\u2019t say that a model would generalize better to more different tasks, in fact it is the opposite. If the two tasks are similar then the model has a better chance of generalizing (it's a test time concept). Maybe the authors would want to rephrase the lines 121-125 to correctly reflect this. Time constraints: It seems that the proposed approach BCL is quite time consuming. Could the authors please provide the timing comparison of their approach with the other baselines.",
    "review_points_list": [
      "Positives: - The paper is written very well and the generalization-forgetting trade-off is well-motivated. - There is a dearth of theory papers in continual learning and this presents a very nice theory for analyzing the trade-off between forgetting and generalization. - Empirical results are quite strong.",
      "Negatives: While I don\u2019t have many problems with the paper, I do like to ask a couple of questions.  Modelling generalization: The paper argues that the degree of generalization depends on the discrepancy between the previous and new tasks. Hence in maximizing that discrepancy, and subsequently training your model to account for that discrepancy, we maximize the generalization. I could see why as an optimization objective such an adversarial training would encourage the model to adapt to possibly different tasks. But you can\u2019t say that a model would generalize better to more different tasks, in fact it is the opposite. If the two tasks are similar then the model has a better chance of generalizing (it's a test time concept). Maybe the authors would want to rephrase the lines 121-125 to correctly reflect this. Time constraints: It seems that the proposed approach BCL is quite time consuming. Could the authors please provide the timing comparison of their approach with the other baselines."
    ]
  },
  {
    "paper_id": "2009.12612v2",
    "submission_id": "u1XV9BPAB9",
    "submission_title": "Formalizing the Generalization-Forgetting Trade-off in Continual Learning",
    "review_id": "FlFHemFgSG1",
    "input": {
      "title": "Formalizing the Generalization-Forgetting Trade-off in Continual Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The idea of formalizing continual learning problem as a two-player game is novel and interesting.\n- The theorems are interesting, but the flow of the paper is not quite clear, which makes the details hard to fully understand.\n- The paper has put a lot of emphasis on its theoretical contribution, however, it is not quite clear in their experiments.\n- Showing the average prediction accuracy in benchmark datasets, although necessary, could not fully support the theoretical side.\n- When talking about trade-off theoretically, authors should think about ways to reveal it experimentally also.\n- For example, several metrics such as average forgetting and learning curve area [1] could be leveraged to depict the actual trade-off between forgetting and generalization.\n- Also, in Table 2, showing more recent methods instead of earlier methods that are not particularly designed for incremental class learning might be a better choice.",
    "review_points_list": [
      "The idea of formalizing continual learning problem as a two-player game is novel and interesting.",
      "The theorems are interesting, but the flow of the paper is not quite clear, which makes the details hard to fully understand.",
      "The paper has put a lot of emphasis on its theoretical contribution, however, it is not quite clear in their experiments.",
      "Showing the average prediction accuracy in benchmark datasets, although necessary, could not fully support the theoretical side.",
      "When talking about trade-off theoretically, authors should think about ways to reveal it experimentally also.",
      "For example, several metrics such as average forgetting and learning curve area [1] could be leveraged to depict the actual trade-off between forgetting and generalization.",
      "Also, in Table 2, showing more recent methods instead of earlier methods that are not particularly designed for incremental class learning might be a better choice."
    ]
  },
  {
    "paper_id": "2009.12612v2",
    "submission_id": "u1XV9BPAB9",
    "submission_title": "Formalizing the Generalization-Forgetting Trade-off in Continual Learning",
    "review_id": "hOnefg5r2o",
    "input": {
      "title": "Formalizing the Generalization-Forgetting Trade-off in Continual Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- In my opinion, the paper is original and contains some very interesting ideas.\n- The generalization/forgetting trade-off is an interesting concept.\n- Using gradient ascent to improve generalization is also a useful idea.\n- I think the authors should try to simplify their mathematical notation, as it is very dense and very difficult to wrap your head around it.\n- The theoretical results and the algorithm presented in the paper are significant for non-task-free CL settings.\n- I feel that the experiments of the paper are insufficient.\n- Two-thirds of the experimental work are based on the MNIST dataset which is extremely simplistic and cannot be considered to give trustworthy benchmarks.\n- I recommend that the authors include at least one or two more split-type benchmarks in their experimental work.\n- I also recommend studying the effect of memory size on the behavior of the proposed algorithm using one of the 'harder' datasets.\n- I think that the paper will benefit a lot by if the authors were to describe some intuitive interpretations of the main theoretical results of their work.\n- Minor Issues: - Line 96: There is a 'Third' left there (probably after re-writing the paragraph) that needs to be removed.\n- - Line 134: In line 3 of Eq. (3), insert a large enough gap between the min and max operators so that their corresponding subscripts are clearly separated.\n- - Line 210: Regarding the expectation operator, you have used an italic E in the formula but a regular E in the text. In any case, I would recommend using a blackboard bold typeface for the expectation operator.\n- Questions: - What is the effect of memory size on the BCL game?\n- - Do you think BCL can be expanded for task-free CL?\n- - Do we really need to prioritize tasks? Why not use the expectation of all task losses (which will be bounded given the conditions stated in the paper)?\n- - Why define the loss function to be a weighted sum of H, where H is a weighted sum of task losses? Why not just use a weighted sum of task losses directly?\n- - What is the intuition behind the selected order of play (\u0394x first, \u03b8 afterwards)?\n- - Have you experimentally tried using the reverse order of play? I am curious if the results would be different as Theorem 2 only discusses the selected order of play but not the reverse.",
    "review_points_list": [
      "In my opinion, the paper is original and contains some very interesting ideas.",
      "The generalization/forgetting trade-off is an interesting concept.",
      "Using gradient ascent to improve generalization is also a useful idea.",
      "I think the authors should try to simplify their mathematical notation, as it is very dense and very difficult to wrap your head around it.",
      "The theoretical results and the algorithm presented in the paper are significant for non-task-free CL settings.",
      "I feel that the experiments of the paper are insufficient.",
      "Two-thirds of the experimental work are based on the MNIST dataset which is extremely simplistic and cannot be considered to give trustworthy benchmarks.",
      "I recommend that the authors include at least one or two more split-type benchmarks in their experimental work.",
      "I also recommend studying the effect of memory size on the behavior of the proposed algorithm using one of the 'harder' datasets.",
      "I think that the paper will benefit a lot by if the authors were to describe some intuitive interpretations of the main theoretical results of their work.",
      "Minor Issues: - Line 96: There is a 'Third' left there (probably after re-writing the paragraph) that needs to be removed.",
      "- Line 134: In line 3 of Eq. (3), insert a large enough gap between the min and max operators so that their corresponding subscripts are clearly separated.",
      "- Line 210: Regarding the expectation operator, you have used an italic E in the formula but a regular E in the text. In any case, I would recommend using a blackboard bold typeface for the expectation operator.",
      "Questions: - What is the effect of memory size on the BCL game?",
      "- Do you think BCL can be expanded for task-free CL?",
      "- Do we really need to prioritize tasks? Why not use the expectation of all task losses (which will be bounded given the conditions stated in the paper)?",
      "- Why define the loss function to be a weighted sum of H, where H is a weighted sum of task losses? Why not just use a weighted sum of task losses directly?",
      "- What is the intuition behind the selected order of play (\u0394x first, \u03b8 afterwards)?",
      "- Have you experimentally tried using the reverse order of play? I am curious if the results would be different as Theorem 2 only discusses the selected order of play but not the reverse."
    ]
  },
  {
    "paper_id": "2009.12612v2",
    "submission_id": "u1XV9BPAB9",
    "submission_title": "Formalizing the Generalization-Forgetting Trade-off in Continual Learning",
    "review_id": "l6FIfzj1xL",
    "input": {
      "title": "Formalizing the Generalization-Forgetting Trade-off in Continual Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- It was interesting for me to read the new CL cost function.\n- The analysis of the cost function and the proposed 2-player approach was also informative.\n- The experiments evaluate different CL settings (class-incremental, domain-incremental and task-incremental), which I think is useful for determining the overall worth of a proposed new method.\n- I'd be curious to see experiments with mixed datasets (e.g. CIFAR10 and MNIST), which would better illustrate whether your method can generate to diverse input domains\n- Note: I'm not sure that the baselines used in the experiments are state-of-the-art.\n- Note: It appears that Algorithm 1 has j=0 and i=0 swapped. Needs to be corrected.\n- When approximating H for player 2, you copy over the parameters in a new network \\theta_B and optimise them.\n- However, these(predictions are not differentiable wrt the original \\theta , are they?\n- If this is the case, why calculate it at all?\n- H includes J_k(\\theta) a number of times: H = \\beta * J_k(\\theta) + ... - J_k(\\theta) + ... -J_k(\\theta) = J_k(\\theta) *= (\\beta - 2) + ... .\n- If \\beta < 2, when player 2 is minising H, wouldn't it try to increase J_k(\\theta) in order to minimise H?\n- In this case, I find it a bit confusing why the method works so well?\n- I looked at your code as well to try to find the answers to the above questions, but it's not clear to me.\n- Looking at the code, it appears that you are using \\beta = 1.\n- How computationally intensive would",
    "review_points_list": [
      "It was interesting for me to read the new CL cost function.",
      "The analysis of the cost function and the proposed 2-player approach was also informative.",
      "The experiments evaluate different CL settings (class-incremental, domain-incremental and task-incremental), which I think is useful for determining the overall worth of a proposed new method.",
      "I'd be curious to see experiments with mixed datasets (e.g. CIFAR10 and MNIST), which would better illustrate whether your method can generate to diverse input domains",
      "Note: I'm not sure that the baselines used in the experiments are state-of-the-art.",
      "Note: It appears that Algorithm 1 has j=0 and i=0 swapped. Needs to be corrected.",
      "When approximating H for player 2, you copy over the parameters in a new network \\theta_B and optimise them.",
      "However, these(predictions are not differentiable wrt the original \\theta , are they?",
      "If this is the case, why calculate it at all?",
      "H includes J_k(\\theta) a number of times: H = \\beta * J_k(\\theta) + ... - J_k(\\theta) + ... -J_k(\\theta) = J_k(\\theta) *= (\\beta - 2) + ... .",
      "If \\beta < 2, when player 2 is minising H, wouldn't it try to increase J_k(\\theta) in order to minimise H?",
      "In this case, I find it a bit confusing why the method works so well?",
      "I looked at your code as well to try to find the answers to the above questions, but it's not clear to me.",
      "Looking at the code, it appears that you are using \\beta = 1.",
      "How computationally intensive would"
    ]
  },
  {
    "paper_id": "2110.01773v2",
    "submission_id": "umuW_b77q9A",
    "submission_title": "Differentiable Equilibrium Computation with Decision Diagrams for Stackelberg Models of Combinatorial Congestion Games",
    "review_id": "MjO6pdbCwHT",
    "input": {
      "title": "Differentiable Equilibrium Computation with Decision Diagrams for Stackelberg Models of Combinatorial Congestion Games",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The contribution of the paper falls mostly into the claim of making Nesterov\u2019s acceleration differentiable.\n- From the perspective of differentiable optimization, due to the complex constraints in this problem, the authors use the iterative Frank-Wolfe algorithm to optimize the potential function.\n- Thus the optimization operators involved in the algorithm are simply argmin/argmax only.\n- To my knowledge, there is no need to use KKT conditions and they also explained in the paper that they can\u2019t efficiently express the complex KKT conditions as well.\n- Thus the technique used in the problem is more about relaxing argmin to softmin in the Frank-Wolfe algorithm and Nesterov's acceleration, and less about generalizing differentiable optimization.\n- Overall, I still consider making Nesterov\u2019s acceleration algorithm differentiable a nice contribution in this paper.\n- I am familiar with differentiable optimization but less familiar with the recent literature on Nesterov\u2019s acceleration.\n- I agree that the main contribution is more on Nesterov's acceleration part.\n- Making Nesterov\u2019s acceleration differentiable is new to me from the perspective of differentiable optimization, but it is relatively a smaller modification compared to previous works in differentiable optimization using Frank-Wolfe algorithms, e.g., Wilder et al. [59] used KKT conditions as opposed to unrolling the entire Frank-Wolfe algorithm to achieve differentiability.\n- I would reserve my judgment on Nesterov\u2019s part to other reviewers, and I would appreciate it if the authors could elaborate more on some similar literature of relaxing argmin/argmax in Nesterov\u2019s acceleration.\n- Post-response: I am satisfied with the explanation and the additional elaboration of Nesterov\u2019s acceleration that the authors gave.\n- I agree that KTT conditions can sometimes be unnecessarily high-dimensional and complicated.\n- It makes sense to me to sometimes consider unrolling and relaxing argmin/argmax instead of differentiating through the KKT conditions.",
    "review_points_list": [
      "The contribution of the paper falls mostly into the claim of making Nesterov\u2019s acceleration differentiable.",
      "From the perspective of differentiable optimization, due to the complex constraints in this problem, the authors use the iterative Frank-Wolfe algorithm to optimize the potential function.",
      "Thus the optimization operators involved in the algorithm are simply argmin/argmax only.",
      "To my knowledge, there is no need to use KKT conditions and they also explained in the paper that they can\u2019t efficiently express the complex KKT conditions as well.",
      "Thus the technique used in the problem is more about relaxing argmin to softmin in the Frank-Wolfe algorithm and Nesterov's acceleration, and less about generalizing differentiable optimization.",
      "Overall, I still consider making Nesterov\u2019s acceleration algorithm differentiable a nice contribution in this paper.",
      "I am familiar with differentiable optimization but less familiar with the recent literature on Nesterov\u2019s acceleration.",
      "I agree that the main contribution is more on Nesterov's acceleration part.",
      "Making Nesterov\u2019s acceleration differentiable is new to me from the perspective of differentiable optimization, but it is relatively a smaller modification compared to previous works in differentiable optimization using Frank-Wolfe algorithms, e.g., Wilder et al. [59] used KKT conditions as opposed to unrolling the entire Frank-Wolfe algorithm to achieve differentiability.",
      "I would reserve my judgment on Nesterov\u2019s part to other reviewers, and I would appreciate it if the authors could elaborate more on some similar literature of relaxing argmin/argmax in Nesterov\u2019s acceleration.",
      "Post-response: I am satisfied with the explanation and the additional elaboration of Nesterov\u2019s acceleration that the authors gave.",
      "I agree that KTT conditions can sometimes be unnecessarily high-dimensional and complicated.",
      "It makes sense to me to sometimes consider unrolling and relaxing argmin/argmax instead of differentiating through the KKT conditions."
    ]
  },
  {
    "paper_id": "2110.01773v2",
    "submission_id": "umuW_b77q9A",
    "submission_title": "Differentiable Equilibrium Computation with Decision Diagrams for Stackelberg Models of Combinatorial Congestion Games",
    "review_id": "948bR7J-H_O",
    "input": {
      "title": "Differentiable Equilibrium Computation with Decision Diagrams for Stackelberg Models of Combinatorial Congestion Games",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well written, all concepts are rigorously explained, and the notation is clear.\n- I appreciate the examples described in the introduction that well illustrate the motivation of this paper.\n- Also, the authors explain well how their work fits into the existing literature on the topic.\n- As far as I can tell, the results are sound, the analyses and the proof of Theorem 1 seem correct to me.\n- The contributions of this paper may not be as strong since the approach is relatively similar to the method introduced in [42], i.e., a Frank\u2013Wolfe-type algorithm accelerated using the ZDDs.\n- Despite some similarities, this work makes the cut in my eyes because of the introduction of the Stackelberg setting, which required adapting the Frank\u2013Wolfe algorithm for computing the gradients.\n- While Theorem 1 establishes the convergence guarantee of solutions returned by the Frank\u2013Wolfe-type algorithm to the Wardrop equilibrium, the work does not offer any results on the optimality of the final parameters computed by the gradient descent.\n- If I interpret it correctly, there is no guarantee of how close to the global optimum the computed parameters are, given that the criterion F is non-convex in general.\n- Did the authors try to perform some experiments on very small settings when the globally optimal Stackelberg parameters can be found using, e.g., linearization into MILPs, to see how well the gradient descent can approximate the global solution in practice?\n- One minor note: the legends of all graphs in Figure 2 obstruct the view of the plots.\n- Since the legend is shared across all the graphs, it might be better to put one legend underneath them all.\n- Similarly also in Figure 3.\n- I would like to thank the authors for a very detailed response to my questions and the amount of effort they put into coming with examples and running the additional experiments.\n- I especially appreciate the example illustrating the difficulty of global optimization in this bilevel setting.\n- My impression of this work remains unchanged, I believe it is a good research that deserves publication.",
    "review_points_list": [
      "The paper is well written, all concepts are rigorously explained, and the notation is clear.",
      "I appreciate the examples described in the introduction that well illustrate the motivation of this paper.",
      "Also, the authors explain well how their work fits into the existing literature on the topic.",
      "As far as I can tell, the results are sound, the analyses and the proof of Theorem 1 seem correct to me.",
      "The contributions of this paper may not be as strong since the approach is relatively similar to the method introduced in [42], i.e., a Frank\u2013Wolfe-type algorithm accelerated using the ZDDs.",
      "Despite some similarities, this work makes the cut in my eyes because of the introduction of the Stackelberg setting, which required adapting the Frank\u2013Wolfe algorithm for computing the gradients.",
      "While Theorem 1 establishes the convergence guarantee of solutions returned by the Frank\u2013Wolfe-type algorithm to the Wardrop equilibrium, the work does not offer any results on the optimality of the final parameters computed by the gradient descent.",
      "If I interpret it correctly, there is no guarantee of how close to the global optimum the computed parameters are, given that the criterion F is non-convex in general.",
      "Did the authors try to perform some experiments on very small settings when the globally optimal Stackelberg parameters can be found using, e.g., linearization into MILPs, to see how well the gradient descent can approximate the global solution in practice?",
      "One minor note: the legends of all graphs in Figure 2 obstruct the view of the plots.",
      "Since the legend is shared across all the graphs, it might be better to put one legend underneath them all.",
      "Similarly also in Figure 3.",
      "I would like to thank the authors for a very detailed response to my questions and the amount of effort they put into coming with examples and running the additional experiments.",
      "I especially appreciate the example illustrating the difficulty of global optimization in this bilevel setting.",
      "My impression of this work remains unchanged, I believe it is a good research that deserves publication."
    ]
  },
  {
    "paper_id": "2110.01773v2",
    "submission_id": "umuW_b77q9A",
    "submission_title": "Differentiable Equilibrium Computation with Decision Diagrams for Stackelberg Models of Combinatorial Congestion Games",
    "review_id": "JOQliCOBnTH",
    "input": {
      "title": "Differentiable Equilibrium Computation with Decision Diagrams for Stackelberg Models of Combinatorial Congestion Games",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- A recent paper [42] proposed ZDDs method to tackle the combinatorial nature of CCGs. This paper moves one step forward to consider the Stackelberg models.\n- The submission is technically sound.\n- Clearly written.\n- The studied problem is not new, and the proposed method are mainly based on [42].\n- However, the Stackelberg model is very important, and the proposed technical novelties are very effective, thus I think the paper can be accepted.",
    "review_points_list": [
      "A recent paper [42] proposed ZDDs method to tackle the combinatorial nature of CCGs. This paper moves one step forward to consider the Stackelberg models.",
      "The submission is technically sound.",
      "Clearly written.",
      "The studied problem is not new, and the proposed method are mainly based on [42].",
      "However, the Stackelberg model is very important, and the proposed technical novelties are very effective, thus I think the paper can be accepted."
    ]
  },
  {
    "paper_id": "2110.01773v2",
    "submission_id": "umuW_b77q9A",
    "submission_title": "Differentiable Equilibrium Computation with Decision Diagrams for Stackelberg Models of Combinatorial Congestion Games",
    "review_id": "FrpE1Uce1o-",
    "input": {
      "title": "Differentiable Equilibrium Computation with Decision Diagrams for Stackelberg Models of Combinatorial Congestion Games",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The problem of computing equilibria in CGs is consider an easy task whenever the strategy space has a compact representation, since it turns out that the users minimize a convex function.\n- When having to decide on some parameters of the CG in order to optimize the performance at equilibrium we get a bi-level optimization problem, where in the upper level the designer sets the parameters and in the lower level the users optimize their function reaching an equilibrium.\n- Solving this bi-level problem is regarded to be far more difficult.\n- This work deals with the latter problem and combines optimization techniques to give an algorithm that performs well in practice.\n- The goal of the network designer is to minimize a function F that depends on the choice of the strategies of the players (let it be described by vector y) and a parameter vector \\theta.\n- The choice of \\theta is on the designer and users reach an equilibrium based on that choice, minimizing a different function f so that y=argmin f.\n- For the case of fixed \\theta we get a single level program computing an equilibrium of the CG.\n- A recent work (Nakamura et al. 20) used a data structure (zero-suppressed binary decision diagrams (ZDDs)) to get a compact strategy space representation for interesting cases and applied a Frank-Wolfe style algorithm that performs well whenever the representation using ZDDs is indeed compact.\n- Here, for the bi-level program, this technique does not work as is because of non differentiability wrt \\theta.\n- To get differentiability, the authors use softmin instead of argmin in the computation of y, while keeping the ZDDs representation for the strategy space, and provide an algorithm that seemingly performs well in practice.\n- The idea of using softmin (and making it work) in order to make the equilibrium differentiable wrt \\theta is interesting\n- Limited theoretical guarantees (although, in general this is difficult for bi-level programs)\n- If we fix \\theta, how does Algorithm 1 compare to the algorithm of Nakamura et al.?",
    "review_points_list": [
      "The problem of computing equilibria in CGs is consider an easy task whenever the strategy space has a compact representation, since it turns out that the users minimize a convex function.",
      "When having to decide on some parameters of the CG in order to optimize the performance at equilibrium we get a bi-level optimization problem, where in the upper level the designer sets the parameters and in the lower level the users optimize their function reaching an equilibrium.",
      "Solving this bi-level problem is regarded to be far more difficult.",
      "This work deals with the latter problem and combines optimization techniques to give an algorithm that performs well in practice.",
      "The goal of the network designer is to minimize a function F that depends on the choice of the strategies of the players (let it be described by vector y) and a parameter vector \\theta.",
      "The choice of \\theta is on the designer and users reach an equilibrium based on that choice, minimizing a different function f so that y=argmin f.",
      "For the case of fixed \\theta we get a single level program computing an equilibrium of the CG.",
      "A recent work (Nakamura et al. 20) used a data structure (zero-suppressed binary decision diagrams (ZDDs)) to get a compact strategy space representation for interesting cases and applied a Frank-Wolfe style algorithm that performs well whenever the representation using ZDDs is indeed compact.",
      "Here, for the bi-level program, this technique does not work as is because of non differentiability wrt \\theta.",
      "To get differentiability, the authors use softmin instead of argmin in the computation of y, while keeping the ZDDs representation for the strategy space, and provide an algorithm that seemingly performs well in practice.",
      "The idea of using softmin (and making it work) in order to make the equilibrium differentiable wrt \\theta is interesting",
      "Limited theoretical guarantees (although, in general this is difficult for bi-level programs)",
      "If we fix \\theta, how does Algorithm 1 compare to the algorithm of Nakamura et al.?"
    ]
  },
  {
    "paper_id": "2008.06043v3",
    "submission_id": "zdC5eXljMPy",
    "submission_title": "Weighted model estimation for offline model-based reinforcement learning",
    "review_id": "qe-w95SmNG",
    "input": {
      "title": "Weighted model estimation for offline model-based reinforcement learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The method applies to the case when a data set is collected from a real system by means of an exploration policy, and the new policy to be evaluated would result in a significantly different state occupancy distribution than that of the exploration policy.\n- The new policy is expensive to evaluate on the new system, and it is instead desired to be evaluated in simulation, using a model learned from the observed data that might have limited modeling capacity.\n- This difference in the state distributions, combined with the possibly incorrect model of the dynamics, would cause incorrect prediction of the system trajectory under the policy, and from there, and incorrect estimate of its expected return on the real system.\n- A weighting factor called artificial weight, expressed as a ratio of state-action occupancy probabilities, is used to iteratively tune the parameters encoding the dynamics of the learned system model to more accurately predict regions of state space where the policy being evaluated would bring the system to, and from there, the estimate of the expected return of the policy on the real system.\n- The model of the dynamics ends up focusing on the parts of state space that will actually be used by the evaluated policy, instead of trying to model the dynamics everywhere.\n- A parameter tuning algorithm with convergence guarantees is proposed, along with a simplified version that does not have such guarantees, but is computationally faster.\n- For stability reasons, only a scaled-down value of the weight is used.\n- Both versions of the algorithm are empirically evaluated on a pendulum stabilization problem and policy, and it is evident that the predicted trajectories and the estimate of the expected return of the policy are much closer to that of the real system that what a system model optimized by empirical risk minimization would produce.\n- The improved estimate of the policy's return can further be used for policy improvement, as customary for RL algorithms.\n- Empirical evaluation on the D4RL benchmark suite demonstrates improved performance with respect to the unweighted method.\n- The idea appears to be sound, and addresses a major issue with offline MBRL, which itself is a very important RL method for use cases that involve real physical equipment that is difficult, expensive, and slow to operate.\n- The proposed work builds upon a lot of related research in ML concerning covariate shift and offline MBRL that is well discussed and referenced by the authors, and the combination of these ideas into the proposed algorithms is the main contribution of this paper.\n- The paper is a solid contribution to a field of high practical importance and significance, and thus merits acceptance.\n- The presentation of the ideas and results could be improved.\n- The iterative improvement of the parameter \u03b8 representing the system's dynamics is not explained very well.\n- In Algorithm 1, there is an iteration over index i, but it is not clear how many iterations there are, and what i actually indexes.\n- Is it the successive estimates \u03b8i in lines 4, 5, and 6, respectively \u03b8i+1 in line 7?\n- If yes, Eq. 10 should probably be updated for consistency, too, replacing \u03b80 with \u03b8i and \u03b8 with \u03b8i+1.\n- It is also not entirely clear what the objective of the pendulum task is.\n- Is it the pendulum stabilization task around the vertical position (and if yes, which one - up or down), or the much harder problem of pendulum swing-up?\n- The goal state is angle 0 with 0 angular velocity, but does this angle correspond to the unstable up position, or the stable down position?\n- I assume it is the former, but please clarify.\n- It doesn't help that the starting state is not clearly shown, either.\n- The authors say that they are solving the pendulum stabilization task, which is normally defined for relatively small angles around the unstable equilibrium, typically +/-15 degrees.\n- However, Fig. 1 shows a trajectory in phase space (or is it two or more?) starting about pi radians away from the goal state (maybe in the stable equilibrium?) that pumps energy into the system, strongly suggesting a swing-up task with underactuated pendulum.\n- Please clarify the task that the evaluated policy is trying to solve.\n- Minor typos: Line 40: 'the both' -> 'both'.\n- Line 74: 'Preliminary' -> 'Preliminaries'.\n- Line 75: 'a action' -> 'an action'.\n- Line 193: 'with normalizing it' -> 'and normalizing it'.\n- Line 201: 'common logarithm' -> 'natural logarithm'?\n- Line 228: 'the' -> 'The'.\n- Line 236: 'averaged averaged' -> 'averaged'.\n- Line 237: 'stanrard' -> 'standard'.",
    "review_points_list": [
      "The method applies to the case when a data set is collected from a real system by means of an exploration policy, and the new policy to be evaluated would result in a significantly different state occupancy distribution than that of the exploration policy.",
      "The new policy is expensive to evaluate on the new system, and it is instead desired to be evaluated in simulation, using a model learned from the observed data that might have limited modeling capacity.",
      "This difference in the state distributions, combined with the possibly incorrect model of the dynamics, would cause incorrect prediction of the system trajectory under the policy, and from there, and incorrect estimate of its expected return on the real system.",
      "A weighting factor called artificial weight, expressed as a ratio of state-action occupancy probabilities, is used to iteratively tune the parameters encoding the dynamics of the learned system model to more accurately predict regions of state space where the policy being evaluated would bring the system to, and from there, the estimate of the expected return of the policy on the real system.",
      "The model of the dynamics ends up focusing on the parts of state space that will actually be used by the evaluated policy, instead of trying to model the dynamics everywhere.",
      "A parameter tuning algorithm with convergence guarantees is proposed, along with a simplified version that does not have such guarantees, but is computationally faster.",
      "For stability reasons, only a scaled-down value of the weight is used.",
      "Both versions of the algorithm are empirically evaluated on a pendulum stabilization problem and policy, and it is evident that the predicted trajectories and the estimate of the expected return of the policy are much closer to that of the real system that what a system model optimized by empirical risk minimization would produce.",
      "The improved estimate of the policy's return can further be used for policy improvement, as customary for RL algorithms.",
      "Empirical evaluation on the D4RL benchmark suite demonstrates improved performance with respect to the unweighted method.",
      "The idea appears to be sound, and addresses a major issue with offline MBRL, which itself is a very important RL method for use cases that involve real physical equipment that is difficult, expensive, and slow to operate.",
      "The proposed work builds upon a lot of related research in ML concerning covariate shift and offline MBRL that is well discussed and referenced by the authors, and the combination of these ideas into the proposed algorithms is the main contribution of this paper.",
      "The paper is a solid contribution to a field of high practical importance and significance, and thus merits acceptance.",
      "The presentation of the ideas and results could be improved.",
      "The iterative improvement of the parameter \u03b8 representing the system's dynamics is not explained very well.",
      "In Algorithm 1, there is an iteration over index i, but it is not clear how many iterations there are, and what i actually indexes.",
      "Is it the successive estimates \u03b8i in lines 4, 5, and 6, respectively \u03b8i+1 in line 7?",
      "If yes, Eq. 10 should probably be updated for consistency, too, replacing \u03b80 with \u03b8i and \u03b8 with \u03b8i+1.",
      "It is also not entirely clear what the objective of the pendulum task is.",
      "Is it the pendulum stabilization task around the vertical position (and if yes, which one - up or down), or the much harder problem of pendulum swing-up?",
      "The goal state is angle 0 with 0 angular velocity, but does this angle correspond to the unstable up position, or the stable down position?",
      "I assume it is the former, but please clarify.",
      "It doesn't help that the starting state is not clearly shown, either.",
      "The authors say that they are solving the pendulum stabilization task, which is normally defined for relatively small angles around the unstable equilibrium, typically +/-15 degrees.",
      "However, Fig. 1 shows a trajectory in phase space (or is it two or more?) starting about pi radians away from the goal state (maybe in the stable equilibrium?) that pumps energy into the system, strongly suggesting a swing-up task with underactuated pendulum.",
      "Please clarify the task that the evaluated policy is trying to solve.",
      "Minor typos: Line 40: 'the both' -> 'both'.",
      "Line 74: 'Preliminary' -> 'Preliminaries'.",
      "Line 75: 'a action' -> 'an action'.",
      "Line 193: 'with normalizing it' -> 'and normalizing it'.",
      "Line 201: 'common logarithm' -> 'natural logarithm'?",
      "Line 228: 'the' -> 'The'.",
      "Line 236: 'averaged averaged' -> 'averaged'.",
      "Line 237: 'stanrard' -> 'standard'."
    ]
  },
  {
    "paper_id": "2008.06043v3",
    "submission_id": "zdC5eXljMPy",
    "submission_title": "Weighted model estimation for offline model-based reinforcement learning",
    "review_id": "w3S_H827T0I",
    "input": {
      "title": "Weighted model estimation for offline model-based reinforcement learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The ideas presented in the paper are appealing:\n- by leveraging a known bound on the performance difference under two different models, a method for model learning based on density ratio estimation techniques can be derived.\n- Similarly, the same objective can be integrated into a policy optimization algorithm, which is reminiscent of recent model-based offline reinforcement learning approaches.\n- The derivation of the algorithm is generally sound, although the practical approximation used in the experiments looses most of the guarantees of the initial counterpart.\n- The method is, to be the best of my knowledge, a new use of importance ratio estimation for model learning in offline RL.\n- Nevertheless, some reference to relevant related work is missing.\n- The general quality of the work is mostly okay for the theoretical grounding, but less convincing for the experimental evaluation.\n- The clarity of the writing could be improved.\n- The presented method is a new approach at the intersection between two very active research areas, decision-aware model-based RL and offline RL.\n- For the experiment on the D4RL domain, given only 4 runs and largely overlapping error bars, I do not think there is enough experimental evidence to argue that one method is better than the other on this particular domain.\n- Even the explanation provided by the paper for the *Walker2d-medium dataset* is not very convincing for me:\n- the learning process can cause the agent to fall for many other, confounding, reasons (e.g., the random initialization of the function approximators in use) apart from fundamental differences in the two methods and I do not see enough nuances in the experimental design to discern whether that one is the specific cause or not.\n- Given the nice properties shown for the method in Section 6.1, I would have expected a clear difference in performance with respect to the baseline in Section 6.2.\n- How can the lack of it be explained?\n- Is the difference in performance in the first experiment due to the limited capacity of the model?\n- What happens if more hidden units are used for the model of the dynamics?\n- The exposition is often unclear for a generic reader.\n- To just give two examples, in line 19, it is written that the paper focuses on offline MBRL, without being explicit on the meaning of this expression;\n- in line 187, it is used the expression \"policy evaluation\", in a sense that is different from the one the typical RL researcher would expect (i.e., computing the value function for a policy).\n- As reported in the related works, the method presented in the paper is related to previous work in decision-aware model learning.\n- By contrast with what is written in the section, the use of a weighted log-likelihood objective for learning a model in the context of offline RL was already employed in (D'Oro, Pierluca, et al.\n- \"Gradient-aware model-based policy search.\" Proceedings of the AAAI Conference on Artificial Intelligence.\n- 2020.),\n- which incorporates a trajectory-based importance weight to handle the mismatch between behavior and target policies.\n- Can you elaborate again on the passage from Equation (3) to Equation (4)? This should not be so important for the paper overall, but is the importance weight (which is unbounded) missing from the second term?\n- Also, in the same derivation, is an absolute value missing from the first inequality?\n- At the current state, I tend to recommend to reject the paper.\n- I do not see enough experimental, nor theoretical, evidence about the advantages of the proposed method over existing baselines.\n- I am open to increase my score if the authors adequately address my points of concern.\n- I thank the authors for their response.\n- After reading it, I tend to recommend to accept the paper.\n- The bug disclosed and fixed by the authors does not change my general opinion, and my updated score.",
    "review_points_list": [
      "The ideas presented in the paper are appealing:",
      "by leveraging a known bound on the performance difference under two different models, a method for model learning based on density ratio estimation techniques can be derived.",
      "Similarly, the same objective can be integrated into a policy optimization algorithm, which is reminiscent of recent model-based offline reinforcement learning approaches.",
      "The derivation of the algorithm is generally sound, although the practical approximation used in the experiments looses most of the guarantees of the initial counterpart.",
      "The method is, to be the best of my knowledge, a new use of importance ratio estimation for model learning in offline RL.",
      "Nevertheless, some reference to relevant related work is missing.",
      "The general quality of the work is mostly okay for the theoretical grounding, but less convincing for the experimental evaluation.",
      "The clarity of the writing could be improved.",
      "The presented method is a new approach at the intersection between two very active research areas, decision-aware model-based RL and offline RL.",
      "For the experiment on the D4RL domain, given only 4 runs and largely overlapping error bars, I do not think there is enough experimental evidence to argue that one method is better than the other on this particular domain.",
      "Even the explanation provided by the paper for the *Walker2d-medium dataset* is not very convincing for me:",
      "the learning process can cause the agent to fall for many other, confounding, reasons (e.g., the random initialization of the function approximators in use) apart from fundamental differences in the two methods and I do not see enough nuances in the experimental design to discern whether that one is the specific cause or not.",
      "Given the nice properties shown for the method in Section 6.1, I would have expected a clear difference in performance with respect to the baseline in Section 6.2.",
      "How can the lack of it be explained?",
      "Is the difference in performance in the first experiment due to the limited capacity of the model?",
      "What happens if more hidden units are used for the model of the dynamics?",
      "The exposition is often unclear for a generic reader.",
      "To just give two examples, in line 19, it is written that the paper focuses on offline MBRL, without being explicit on the meaning of this expression;",
      "in line 187, it is used the expression \"policy evaluation\", in a sense that is different from the one the typical RL researcher would expect (i.e., computing the value function for a policy).",
      "As reported in the related works, the method presented in the paper is related to previous work in decision-aware model learning.",
      "By contrast with what is written in the section, the use of a weighted log-likelihood objective for learning a model in the context of offline RL was already employed in (D'Oro, Pierluca, et al.",
      "\"Gradient-aware model-based policy search.\" Proceedings of the AAAI Conference on Artificial Intelligence.",
      "2020.),",
      "which incorporates a trajectory-based importance weight to handle the mismatch between behavior and target policies.",
      "Can you elaborate again on the passage from Equation (3) to Equation (4)? This should not be so important for the paper overall, but is the importance weight (which is unbounded) missing from the second term?",
      "Also, in the same derivation, is an absolute value missing from the first inequality?",
      "At the current state, I tend to recommend to reject the paper.",
      "I do not see enough experimental, nor theoretical, evidence about the advantages of the proposed method over existing baselines.",
      "I am open to increase my score if the authors adequately address my points of concern.",
      "I thank the authors for their response.",
      "After reading it, I tend to recommend to accept the paper.",
      "The bug disclosed and fixed by the authors does not change my general opinion, and my updated score."
    ]
  },
  {
    "paper_id": "2008.06043v3",
    "submission_id": "zdC5eXljMPy",
    "submission_title": "Weighted model estimation for offline model-based reinforcement learning",
    "review_id": "m3crsqgiLLH",
    "input": {
      "title": "Weighted model estimation for offline model-based reinforcement learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors devise a new loss function for offline MBRL to alleviate the covariate shift issue. The core idea is weighting with the state-action distribution ratio of offline data and 'simulated' future data, which is interesting.\n- Nevertheless, the authors may want to conduct several additional experiments to demonstrate the effectiveness of the proposed approach.\n- The authors may want to compare the proposed approach with that using 'the natural weight'.\n- The author may want to provide a comparison with state-of-the-art offline algorithms, such as CQL and BEAR.\n- The results in Table 1 seem to show that using 'the artificial weight' does not improve the performance.\n- I wonder whether the proposed method reduces the error of the fictitious samples.\n- The authors may want to provide more details to explain the results in Table 1.\n- Is it possible the weight is so close to 1 that its effect on the learned model is negligible?\n- The authors may want to show how the hyperparameter $\\alpha$ affects the accuracy of the learned model.\n- For example, the authors may want to illustrate the K-step prediction error during the generation of fictitious samples when $\\alpha$ varies.",
    "review_points_list": [
      "The authors devise a new loss function for offline MBRL to alleviate the covariate shift issue. The core idea is weighting with the state-action distribution ratio of offline data and 'simulated' future data, which is interesting.",
      "Nevertheless, the authors may want to conduct several additional experiments to demonstrate the effectiveness of the proposed approach.",
      "The authors may want to compare the proposed approach with that using 'the natural weight'.",
      "The author may want to provide a comparison with state-of-the-art offline algorithms, such as CQL and BEAR.",
      "The results in Table 1 seem to show that using 'the artificial weight' does not improve the performance.",
      "I wonder whether the proposed method reduces the error of the fictitious samples.",
      "The authors may want to provide more details to explain the results in Table 1.",
      "Is it possible the weight is so close to 1 that its effect on the learned model is negligible?",
      "The authors may want to show how the hyperparameter $\\alpha$ affects the accuracy of the learned model.",
      "For example, the authors may want to illustrate the K-step prediction error during the generation of fictitious samples when $\\alpha$ varies."
    ]
  },
  {
    "paper_id": "2008.06043v3",
    "submission_id": "zdC5eXljMPy",
    "submission_title": "Weighted model estimation for offline model-based reinforcement learning",
    "review_id": "reC7BxsJhJ",
    "input": {
      "title": "Weighted model estimation for offline model-based reinforcement learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The algorithm in the paper is novel to my knowledge.\n- Despite some similarities to MOPO, it approaches the model estimation differently (using weighted losses and training jointly with the policy), leading to a more complicated algorithm but better results on D4RL tasks.\n- Considering that distribution shift is a major challenge in offline RL, this strikes me as a useful contribution.\n- Given that the algorithm requires a number of simplifications and tricks, it would be useful to ablate those design choices where possible.\n- For example, the authors take a majorization-minimization approach \u201cTo make each optimization step easier\u201d, but give no explanation as to what goes wrong if no MM surrogate is used.\n- Does it diverge? Or are the results just not as good?\n- The algorithm\u2019s claimed performance on the D4RL MuJoCo tasks is strong compared to previous algorithms.\n- However, I had to consult the D4RL paper to determine this.\n- I would recommend putting one or more of the baseline algorithms in the table for ease of comparison.\n- I found it odd that numerical results on D4RL were not presented for the simplified version of the algorithm.\n- It appears to work similarly to the full version on the pendulum environment as depicted in Figure 1(b), but it would be good to verify that it scales to more challenging environments, especially given that its primary motivation (relative to the full version) is to reduce the computational burden.\n- The writing of the paper is understandable, although the grammar could be improved in many places, and there are several typos.",
    "review_points_list": [
      "The algorithm in the paper is novel to my knowledge.",
      "Despite some similarities to MOPO, it approaches the model estimation differently (using weighted losses and training jointly with the policy), leading to a more complicated algorithm but better results on D4RL tasks.",
      "Considering that distribution shift is a major challenge in offline RL, this strikes me as a useful contribution.",
      "Given that the algorithm requires a number of simplifications and tricks, it would be useful to ablate those design choices where possible.",
      "For example, the authors take a majorization-minimization approach \u201cTo make each optimization step easier\u201d, but give no explanation as to what goes wrong if no MM surrogate is used.",
      "Does it diverge? Or are the results just not as good?",
      "The algorithm\u2019s claimed performance on the D4RL MuJoCo tasks is strong compared to previous algorithms.",
      "However, I had to consult the D4RL paper to determine this.",
      "I would recommend putting one or more of the baseline algorithms in the table for ease of comparison.",
      "I found it odd that numerical results on D4RL were not presented for the simplified version of the algorithm.",
      "It appears to work similarly to the full version on the pendulum environment as depicted in Figure 1(b), but it would be good to verify that it scales to more challenging environments, especially given that its primary motivation (relative to the full version) is to reduce the computational burden.",
      "The writing of the paper is understandable, although the grammar could be improved in many places, and there are several typos."
    ]
  },
  {
    "paper_id": "2110.14802v2",
    "submission_id": "xmx5rE9QP7R",
    "submission_title": "You Are the Best Reviewer of Your Own Papers: An Owner-Assisted Scoring Mechanism",
    "review_id": "oNouv4isMp0",
    "input": {
      "title": "You Are the Best Reviewer of Your Own Papers: An Owner-Assisted Scoring Mechanism",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I recognized the irony of peer reviewing a paper about improving noisy and bad peer review.\n- I think this is an important problem, as reviewing for conferences is a notoriously noisy process.\n- The author's proposed mechanism is very interesting.\n- Incentivizing authors to truthfully rank their papers (and perhaps other papers...?) could indeed be useful.\n- I found the paper interesting and well-presented.\n- I have some qualms about the rather strong assumptions made in the paper.\n- The convexity assumption throughout the paper is quite strong and perhaps unrealistic.\n- Some authors may indeed reap diminishing returns from more papers being accepted.\n- At least anecdotally, this seems to be a bigger driver than increasing visibility of more papers.\n- I would be interested to see an extension of the theory in the paper to non-convex (perhaps submodular?) functions.\n- With respect to the distribution of papers per author at conferences, it would also be very enlightening to see a complete distribution of the number of papers per author for large conferences like NeurIPS and ICML.\n- A full distribution of the number of papers per author could reveal a large fraction of papers with no additional information about them.\n- This could disadvantage the authors with fewer submissions.\n- One other suggestion that could be very interesting would be to allow authors to evaluate their own papers in comparison with other submissions.\n- To do this in a way such that their own paper's ranking is not affected by their report, a la notions of impartiality in the ranking literature.\n- Also, if all authors submit exactly two papers and there is a nice partition of the papers into pairs such that each paper is compared to exactly one other paper, how much does this help increase the accuracy of reviews?\n- Most of the theoretical results really kick in with noisy reviews and many papers per author.\n- It seems like the author is perhaps 'leaving some money on the table' with respect to multiple owners.\n- If instead of a partition, they allowed for an overlapping collection of subsets where each author with multiple papers was allowed to rank her own papers, this could yield much richer information across subsets.\n- This could help the mechanism considerably.\n- Have you considered this option?\n- I think that this mechanism could be readily abused by reviewing rings.\n- For instance, if an author has multiple submissions and knows that her strongest paper is being reviewed by people in her reviewing ring, then she can report that it is her weakest paper and presumably benefit from the highly positive reviews given to her now-'weakest' paper.\n- Minor comment: In Thm 3, it would be nice if you formally defined risk.\n- Minor comment: 224: Theorem 1, Theorem 2\n- Minor comment: 351-2 repeats 348-9.",
    "review_points_list": [
      "I recognized the irony of peer reviewing a paper about improving noisy and bad peer review.",
      "I think this is an important problem, as reviewing for conferences is a notoriously noisy process.",
      "The author's proposed mechanism is very interesting.",
      "Incentivizing authors to truthfully rank their papers (and perhaps other papers...?) could indeed be useful.",
      "I found the paper interesting and well-presented.",
      "I have some qualms about the rather strong assumptions made in the paper.",
      "The convexity assumption throughout the paper is quite strong and perhaps unrealistic.",
      "Some authors may indeed reap diminishing returns from more papers being accepted.",
      "At least anecdotally, this seems to be a bigger driver than increasing visibility of more papers.",
      "I would be interested to see an extension of the theory in the paper to non-convex (perhaps submodular?) functions.",
      "With respect to the distribution of papers per author at conferences, it would also be very enlightening to see a complete distribution of the number of papers per author for large conferences like NeurIPS and ICML.",
      "A full distribution of the number of papers per author could reveal a large fraction of papers with no additional information about them.",
      "This could disadvantage the authors with fewer submissions.",
      "One other suggestion that could be very interesting would be to allow authors to evaluate their own papers in comparison with other submissions.",
      "To do this in a way such that their own paper's ranking is not affected by their report, a la notions of impartiality in the ranking literature.",
      "Also, if all authors submit exactly two papers and there is a nice partition of the papers into pairs such that each paper is compared to exactly one other paper, how much does this help increase the accuracy of reviews?",
      "Most of the theoretical results really kick in with noisy reviews and many papers per author.",
      "It seems like the author is perhaps 'leaving some money on the table' with respect to multiple owners.",
      "If instead of a partition, they allowed for an overlapping collection of subsets where each author with multiple papers was allowed to rank her own papers, this could yield much richer information across subsets.",
      "This could help the mechanism considerably.",
      "Have you considered this option?",
      "I think that this mechanism could be readily abused by reviewing rings.",
      "For instance, if an author has multiple submissions and knows that her strongest paper is being reviewed by people in her reviewing ring, then she can report that it is her weakest paper and presumably benefit from the highly positive reviews given to her now-'weakest' paper.",
      "Minor comment: In Thm 3, it would be nice if you formally defined risk.",
      "Minor comment: 224: Theorem 1, Theorem 2",
      "Minor comment: 351-2 repeats 348-9."
    ]
  },
  {
    "paper_id": "2110.14802v2",
    "submission_id": "xmx5rE9QP7R",
    "submission_title": "You Are the Best Reviewer of Your Own Papers: An Owner-Assisted Scoring Mechanism",
    "review_id": "phA1lSzXIUX",
    "input": {
      "title": "You Are the Best Reviewer of Your Own Papers: An Owner-Assisted Scoring Mechanism",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed mechanism is interesting and seems very easy to be implemented.\n- The main theorem guarantees that the authors will truthfully report the ranking.\n- The presentation of this paper is also great.\n- The main message is easy to understand, and all theorems are followed with explanations.\n- The problem solved in this paper is indeed critical.\n- Sometimes I also got frustrated by the quality of some reviewers.\n- Theorem 3 is great! It says that the risk can be reduced significantly when $n$ is large.\n- I have three doubts about this paper.\n- The assumption about the utility function might be too strong.\n- For example, if I am the first author for an okay paper and the fourth author for a good paper.\n- The optimal strategy of mine might be ranking the okay paper on top of the good paper.\n- Not sure whether the idea of Isotonic Mechanism can also solve this problem if the author ranking is taken into account.\n- I am a bit doubtful about the performance of Algorithm 1 in real-world applications.\n- It might be possible that many owners only have one paper, which makes Isotonic Mechanism reduce to the standard mechanism.\n- I am not very familiar with the related works.\n- Is the author-wise ranking-based approach new in the review system?\n- I think the authors need to provide a clear answer to this question.",
    "review_points_list": [
      "The proposed mechanism is interesting and seems very easy to be implemented.",
      "The main theorem guarantees that the authors will truthfully report the ranking.",
      "The presentation of this paper is also great.",
      "The main message is easy to understand, and all theorems are followed with explanations.",
      "The problem solved in this paper is indeed critical.",
      "Sometimes I also got frustrated by the quality of some reviewers.",
      "Theorem 3 is great! It says that the risk can be reduced significantly when $n$ is large.",
      "I have three doubts about this paper.",
      "The assumption about the utility function might be too strong.",
      "For example, if I am the first author for an okay paper and the fourth author for a good paper.",
      "The optimal strategy of mine might be ranking the okay paper on top of the good paper.",
      "Not sure whether the idea of Isotonic Mechanism can also solve this problem if the author ranking is taken into account.",
      "I am a bit doubtful about the performance of Algorithm 1 in real-world applications.",
      "It might be possible that many owners only have one paper, which makes Isotonic Mechanism reduce to the standard mechanism.",
      "I am not very familiar with the related works.",
      "Is the author-wise ranking-based approach new in the review system?",
      "I think the authors need to provide a clear answer to this question."
    ]
  },
  {
    "paper_id": "2110.14802v2",
    "submission_id": "xmx5rE9QP7R",
    "submission_title": "You Are the Best Reviewer of Your Own Papers: An Owner-Assisted Scoring Mechanism",
    "review_id": "a2bmZOOfcjS",
    "input": {
      "title": "You Are the Best Reviewer of Your Own Papers: An Owner-Assisted Scoring Mechanism",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well written and addresses an important topic, namely how to do more with the available reviewing resources at large conferences.\n- The proposed method is interesting and contains some good ideas for one way to achieve this goal: namely though the use of self assessment.\n- However, it is unclear that it is within scope for a computing conference as there is no learning and even the optimization algorithms are not detailed in full.\n- The model as it is currently established seems inadequate to deal with the full complexity of the problem.\n- And there is significant related work that is missing, specifically the large literature on impartial peer review under noise models.\n- I'll address each of these shortcomings in turn.\n- Relevance: The paper proposes an interesting model that incorporates information in a unique and creative way.\n- However, it is unclear to me that this paper fits within the conference call as it does not address learning, optimization, or even computation in a direct way.\n- Optimization algorithms are left to a reference and despite the availability of real-world conference data (e.g., PrefLib or the ICLR data) there's no empirical or numerical experiments.\n- To be more precise: while it is true that none of these datasets have self-reported rankings one could either run purely numerical experiments, e.g., draw from a general distribution such as a Mallows model and then run the suggested algorithm or one could impute the required orders and draw samples from the existing datasets.\n- All the papers I suggested below have experiments with various adaptations such as this and given the bounds I would have liked to see evidence that this proposed method performs well in practice for some set of assumptions.\n- Model Adequacy: The model detailed in the paper assumes that authors have a non-decreasing utility function over their own papers.\n- This is a fundamental assumption of the model and the strategyproofness of the mechanism rests firmly on this assumption.\n- I also find this assumption to be completely inadequate.\n- It seems more reasonable that there are only two outcomes: accept and reject, and I have a 0/1 preference over this.\n- The paper dismisses this model out of hand, which I find strange.\n- Additionally, the noise model is one of random noise, which seems reasonable, but in the literature it seems much more reasonable to use e.g., Mallows models or some kind of Random Utility Model to model the noise in these rankings.\n- I would have liked to see various noise models discussed or at least cited (see below) since there are several that are widely used.\n- On line 88 it seems that reviewers have to score all possible papers? This seems completely unfeasible and goes against the arguments above.\n- In all the work in this space (below) we assume some small set of rankings and it's not clear to me how this model would work without the assumption of full utility function elicitation (this is made worse by the lack of computational experiments noted above).\n- Finally, while it is true that some authors submit many many papers (more than they can possible read) this is being addressed through limits in the number of submissions at many conferences.\n- While you provide stats that many authors provide many papers, it seems that (from the given stats) many more authors have only one paper or perhaps two.\n- I would like to see some discussion of what happens when many of the self rankings are singletons, but this very important case is not discussed.\n- Related Work: I include a few references here but there is significant work in the mechanism design and computational social choice areas that deal with the problem of impartial peer evaluation and review.\n- While the paper current includes references to some work on de-biasing evaluations the much more relevant work on mechanism design (which is what this paper is) is missing.\n- Aziz, H., Lev, O., Mattei, N., Rosenschein, J.S. and Walsh, T., 2019. Strategyproof peer selection using randomization, partitioning, and apportionment. Artificial Intelligence, 275, pp.295-309.\n- Noothigattu, R., Shah, N. and Procaccia, A., 2021. Loss functions, axioms, and peer review. Journal of Artificial Intelligence Research, 70, pp.1481-1515.\n- Jecmen, S., Zhang, H., Liu, R., Shah, N., Conitzer, V. and Fang, F., 2020. Mitigating Manipulation in Peer Review via Randomized Reviewer Assignments. Advances in Neural Information Processing Systems, 33, pp.12533-12545.\n- Mattei, N., Turrini, P. and Zhydkov, S., PEERNOMINATION: Relaxing Exactness for Increased Accuracy in Peer Selection. IJCAI 2020.\n- In all the paper contains a nice idea: use self reporting data in a clever way to improve peer review.\n- However, in its current form it does not do enough to show that this method is applicable to the real problem or demonstrate effectiveness of the method.\n- Finally important related work is missing.\n- The authors have answered many of my questions on the paper and I have raised my score on this submission.\n- I am now convinced the paper is in scope for the conference but perhaps a few words as to the fit for a machine learning conference are appropriate.\n- However, I still think that a more comprehensive review of the related literature is necessary for this paper -- there are many works in this general area and situating this method is important.\n- Additionally, after discussion I still feel adding synthetic experiments would greatly improve the paper in that it would give some evidence of the quality of improvement of the bound from Theorem 2 since there is only a >= guarantee it would be good to measure this empirically on some imputed data (e.g. a Mallows model).\n- While I agree there will be improvement, some experiments demonstrating this would greatly improve the paper.\n- In general I still feel that the model for binary outcomes can and should be investigated in future work as it would greatly expand the scope of the paper's application.",
    "review_points_list": [
      "The paper is well written and addresses an important topic, namely how to do more with the available reviewing resources at large conferences.",
      "The proposed method is interesting and contains some good ideas for one way to achieve this goal: namely though the use of self assessment.",
      "However, it is unclear that it is within scope for a computing conference as there is no learning and even the optimization algorithms are not detailed in full.",
      "The model as it is currently established seems inadequate to deal with the full complexity of the problem.",
      "And there is significant related work that is missing, specifically the large literature on impartial peer review under noise models.",
      "I'll address each of these shortcomings in turn.",
      "Relevance: The paper proposes an interesting model that incorporates information in a unique and creative way.",
      "However, it is unclear to me that this paper fits within the conference call as it does not address learning, optimization, or even computation in a direct way.",
      "Optimization algorithms are left to a reference and despite the availability of real-world conference data (e.g., PrefLib or the ICLR data) there's no empirical or numerical experiments.",
      "To be more precise: while it is true that none of these datasets have self-reported rankings one could either run purely numerical experiments, e.g., draw from a general distribution such as a Mallows model and then run the suggested algorithm or one could impute the required orders and draw samples from the existing datasets.",
      "All the papers I suggested below have experiments with various adaptations such as this and given the bounds I would have liked to see evidence that this proposed method performs well in practice for some set of assumptions.",
      "Model Adequacy: The model detailed in the paper assumes that authors have a non-decreasing utility function over their own papers.",
      "This is a fundamental assumption of the model and the strategyproofness of the mechanism rests firmly on this assumption.",
      "I also find this assumption to be completely inadequate.",
      "It seems more reasonable that there are only two outcomes: accept and reject, and I have a 0/1 preference over this.",
      "The paper dismisses this model out of hand, which I find strange.",
      "Additionally, the noise model is one of random noise, which seems reasonable, but in the literature it seems much more reasonable to use e.g., Mallows models or some kind of Random Utility Model to model the noise in these rankings.",
      "I would have liked to see various noise models discussed or at least cited (see below) since there are several that are widely used.",
      "On line 88 it seems that reviewers have to score all possible papers? This seems completely unfeasible and goes against the arguments above.",
      "In all the work in this space (below) we assume some small set of rankings and it's not clear to me how this model would work without the assumption of full utility function elicitation (this is made worse by the lack of computational experiments noted above).",
      "Finally, while it is true that some authors submit many many papers (more than they can possible read) this is being addressed through limits in the number of submissions at many conferences.",
      "While you provide stats that many authors provide many papers, it seems that (from the given stats) many more authors have only one paper or perhaps two.",
      "I would like to see some discussion of what happens when many of the self rankings are singletons, but this very important case is not discussed.",
      "Related Work: I include a few references here but there is significant work in the mechanism design and computational social choice areas that deal with the problem of impartial peer evaluation and review.",
      "While the paper current includes references to some work on de-biasing evaluations the much more relevant work on mechanism design (which is what this paper is) is missing.",
      "Aziz, H., Lev, O., Mattei, N., Rosenschein, J.S. and Walsh, T., 2019. Strategyproof peer selection using randomization, partitioning, and apportionment. Artificial Intelligence, 275, pp.295-309.",
      "Noothigattu, R., Shah, N. and Procaccia, A., 2021. Loss functions, axioms, and peer review. Journal of Artificial Intelligence Research, 70, pp.1481-1515.",
      "Jecmen, S., Zhang, H., Liu, R., Shah, N., Conitzer, V. and Fang, F., 2020. Mitigating Manipulation in Peer Review via Randomized Reviewer Assignments. Advances in Neural Information Processing Systems, 33, pp.12533-12545.",
      "Mattei, N., Turrini, P. and Zhydkov, S., PEERNOMINATION: Relaxing Exactness for Increased Accuracy in Peer Selection. IJCAI 2020.",
      "In all the paper contains a nice idea: use self reporting data in a clever way to improve peer review.",
      "However, in its current form it does not do enough to show that this method is applicable to the real problem or demonstrate effectiveness of the method.",
      "Finally important related work is missing.",
      "The authors have answered many of my questions on the paper and I have raised my score on this submission.",
      "I am now convinced the paper is in scope for the conference but perhaps a few words as to the fit for a machine learning conference are appropriate.",
      "However, I still think that a more comprehensive review of the related literature is necessary for this paper -- there are many works in this general area and situating this method is important.",
      "Additionally, after discussion I still feel adding synthetic experiments would greatly improve the paper in that it would give some evidence of the quality of improvement of the bound from Theorem 2 since there is only a >= guarantee it would be good to measure this empirically on some imputed data (e.g. a Mallows model).",
      "While I agree there will be improvement, some experiments demonstrating this would greatly improve the paper.",
      "In general I still feel that the model for binary outcomes can and should be investigated in future work as it would greatly expand the scope of the paper's application."
    ]
  },
  {
    "paper_id": "2211.10000v1",
    "submission_id": "uXc42E9ZPFs",
    "submission_title": "Language models enable zero-shot prediction of the effects of mutations on protein function",
    "review_id": "XTIV6V2OKRp",
    "input": {
      "title": "Language models enable zero-shot prediction of the effects of mutations on protein function",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- My primary negative critique of this paper is its lack of novelty.\n- It has been previously established in the literature by many papers that the functional effect of mutations can be predicted in a zero-shot setting by scoring variants using the likelihood of a generative model.\n- Further, the two models considered in this paper have been introduced in recent prior work.\n- Those papers are really great; I found them rigorous and well written and would have advocated for their acceptance to NeurIPS.\n- I feel that the scale of contributions of the current paper is smaller than that of a typical NeurIPS paper, though, and its content would be better placed as an additional section of experiments in, for example, the MSA transformer paper.\n- One argument for a paradigm shift due to your approach is that practitioners don't have to train a new model for a protein family of interest and don't have to perform multiple sequence alignment of homologous sequences.\n- Instead, the user can just do forward passes in an existing model.\n- However, it's rare for practitioners to be considering a large number of families at once.\n- The paper is well written and cites relevant recent work.\n- The experimental results could have been analyzed in more detail.\n- This paper is part of a really important line of work on deep learning + proteins.\n- My hesitation is around whether this paper should appear as a stand-alone paper at NeurIPS, not whether the results are of interest to the community.\n- I disagree with your definition of zero-shot in the paragraph starting on line 75.\n- To me, any method is zero-shot if it doesn't rely on experimental data as input.\n- Why is a method that relies on querying a sequence database to retrieve homologous sequences qualitatively different than your approach?\n- Doesn't the training set for ESM-1v or MSATransformer include the same 'weak supervision' that the traditional approach relies on?\n- I suppose you could argue that your method could be applied to predict the functional effect of mutations on sequences that are very different than anything that appears in nature, where there is no associated protein family that could be retrieved by a database search.\n- This is zero-shot in a different sense and not evaluated in the experiments.\n- In Eq (1) uses P(x_t | x_{-t}), but ignores P(x_{-t} | x_t).\n- Why is this a reasonable assumption?\n- Surely, when making a mutation at a particular position, it effects the likelihood of the values at the other positions too.\n- Note that prior models for this task (VAEs, autoregressive models, Potts models) don't make such a simplifying assumption.\n- I see that you discuss alternatives in Appendix A.\n- Why do you think this simple approach is sufficient?\n- Following up on the previous point, does this mean that you can't capture epistasis, which is known to be prevalent in fitness landscapes?\n- For datasets with multiple mutations, you can compute the subset of examples that are epistatic (e.g., it the variant is non-functional, but combines mutations that led to a functional variant when used individually).\n- On these, how do you compare to DeepSequence, which can capture epistasis?\n- Am I correct in understanding that ESM-1v is the same as ESM-1b, but trained on slightly different data?\n- When I discuss originality above, I argue that the paper does not introduce a new model.\n- To me, changing the training data does not amount to introducing a new model with the degree of originality characteristic of a stand-alone paper.\n- I don't feel that this is a particularly important distinction between the proposed model and prior work.\n- It's not clear what an application setting would be where practitioners need to make predictions for many protein families at high throughput.\n- If the goal is just to predict the functional effects of mutations on a single parent sequence, then the speed difference across techniques will be minor.\n- The goal of this zero-shot prediction is to avoid needing to run wet-lab experiments, so any approach that can run on a computer in less than an hour is a massive speedup vs. the alternative.\n- Can you please explain why spearman correlation is a reasonable performance metric?\n- This is noisy experimental data.\n- What do you think is the upper limit on performance?\n- If you binarized the experiment measurement (e.g. whether a variants is worse than the wildtype or better), what would detection metrics like AUC or precision@k look like?\n- I'm also assuming that such labels would be very imbalanced (with more than half of the mutations leading to a decrease in function).\n- Doesn't that bias spearman rho, and make it less predictive of performance for protein design applications where the goal is to increase fitness?\n- I would have appreciated more analysis of where the method succeeds and fails.\n- What characterizes datasets where your methods outperform/underperform prior work?\n- For example, how do you compare on multi-mutant variants?\n- Again, this feels like a section that should appear in a long-form article on ESM or MSA Transformer.\n- Are these results good compared to baseline methods?\n- How does a PSSM perform on them?\n- Is the goal to show that you are outperforming a baseline, or are you just doing some sanity checks for the model?\n- I have decided to raise my review to a weak accept, after a lengthy discussion period with the authors and between the reviewers.\n- Overall, there are a number of detailed choices that were important to achieve the paper's results, and the community should know about these.\n- My principal hesitation is not around the merits of the paper's contribution, which is valuable, but in how the contribution is framed.\n- If the paper is accepted, I would really appreciate it if you considerably changed the exposition (including the title) to be more precise about what's new in the paper.\n- Specifically, I'd refer to your work and prior work (e.g., DeepSequence) both as zero-shot.\n- The title 'Language models enable zero-shot prediction of the effects of mutations on protein function' suggests that there is a new capability that they have 'enabled.'\n- This is certainly not the case.\n- Prior work uses exactly the same data (naturally-occurring sequences, but no experimentally-labeled data) and achieves comparable results.\n- When I first started working on ML for proteins, I was enthralled when I learned that both protein structure and the functional effects of mutations could be predicted by inspecting a statistical model of homologous sequences.\n- This is a remarkable result, and I'm concerned that the twitter-verse will mistakenly think that this particular paper unlocked it (it's actually been known for many years).",
    "review_points_list": [
      "My primary negative critique of this paper is its lack of novelty.",
      "It has been previously established in the literature by many papers that the functional effect of mutations can be predicted in a zero-shot setting by scoring variants using the likelihood of a generative model.",
      "Further, the two models considered in this paper have been introduced in recent prior work.",
      "Those papers are really great; I found them rigorous and well written and would have advocated for their acceptance to NeurIPS.",
      "I feel that the scale of contributions of the current paper is smaller than that of a typical NeurIPS paper, though, and its content would be better placed as an additional section of experiments in, for example, the MSA transformer paper.",
      "One argument for a paradigm shift due to your approach is that practitioners don't have to train a new model for a protein family of interest and don't have to perform multiple sequence alignment of homologous sequences.",
      "Instead, the user can just do forward passes in an existing model.",
      "However, it's rare for practitioners to be considering a large number of families at once.",
      "The paper is well written and cites relevant recent work.",
      "The experimental results could have been analyzed in more detail.",
      "This paper is part of a really important line of work on deep learning + proteins.",
      "My hesitation is around whether this paper should appear as a stand-alone paper at NeurIPS, not whether the results are of interest to the community.",
      "I disagree with your definition of zero-shot in the paragraph starting on line 75.",
      "To me, any method is zero-shot if it doesn't rely on experimental data as input.",
      "Why is a method that relies on querying a sequence database to retrieve homologous sequences qualitatively different than your approach?",
      "Doesn't the training set for ESM-1v or MSATransformer include the same 'weak supervision' that the traditional approach relies on?",
      "I suppose you could argue that your method could be applied to predict the functional effect of mutations on sequences that are very different than anything that appears in nature, where there is no associated protein family that could be retrieved by a database search.",
      "This is zero-shot in a different sense and not evaluated in the experiments.",
      "In Eq (1) uses P(x_t | x_{-t}), but ignores P(x_{-t} | x_t).",
      "Why is this a reasonable assumption?",
      "Surely, when making a mutation at a particular position, it effects the likelihood of the values at the other positions too.",
      "Note that prior models for this task (VAEs, autoregressive models, Potts models) don't make such a simplifying assumption.",
      "I see that you discuss alternatives in Appendix A.",
      "Why do you think this simple approach is sufficient?",
      "Following up on the previous point, does this mean that you can't capture epistasis, which is known to be prevalent in fitness landscapes?",
      "For datasets with multiple mutations, you can compute the subset of examples that are epistatic (e.g., it the variant is non-functional, but combines mutations that led to a functional variant when used individually).",
      "On these, how do you compare to DeepSequence, which can capture epistasis?",
      "Am I correct in understanding that ESM-1v is the same as ESM-1b, but trained on slightly different data?",
      "When I discuss originality above, I argue that the paper does not introduce a new model.",
      "To me, changing the training data does not amount to introducing a new model with the degree of originality characteristic of a stand-alone paper.",
      "I don't feel that this is a particularly important distinction between the proposed model and prior work.",
      "It's not clear what an application setting would be where practitioners need to make predictions for many protein families at high throughput.",
      "If the goal is just to predict the functional effects of mutations on a single parent sequence, then the speed difference across techniques will be minor.",
      "The goal of this zero-shot prediction is to avoid needing to run wet-lab experiments, so any approach that can run on a computer in less than an hour is a massive speedup vs. the alternative.",
      "Can you please explain why spearman correlation is a reasonable performance metric?",
      "This is noisy experimental data.",
      "What do you think is the upper limit on performance?",
      "If you binarized the experiment measurement (e.g. whether a variants is worse than the wildtype or better), what would detection metrics like AUC or precision@k look like?",
      "I'm also assuming that such labels would be very imbalanced (with more than half of the mutations leading to a decrease in function).",
      "Doesn't that bias spearman rho, and make it less predictive of performance for protein design applications where the goal is to increase fitness?",
      "I would have appreciated more analysis of where the method succeeds and fails.",
      "What characterizes datasets where your methods outperform/underperform prior work?",
      "For example, how do you compare on multi-mutant variants?",
      "Again, this feels like a section that should appear in a long-form article on ESM or MSA Transformer.",
      "Are these results good compared to baseline methods?",
      "How does a PSSM perform on them?",
      "Is the goal to show that you are outperforming a baseline, or are you just doing some sanity checks for the model?",
      "I have decided to raise my review to a weak accept, after a lengthy discussion period with the authors and between the reviewers.",
      "Overall, there are a number of detailed choices that were important to achieve the paper's results, and the community should know about these.",
      "My principal hesitation is not around the merits of the paper's contribution, which is valuable, but in how the contribution is framed.",
      "If the paper is accepted, I would really appreciate it if you considerably changed the exposition (including the title) to be more precise about what's new in the paper.",
      "Specifically, I'd refer to your work and prior work (e.g., DeepSequence) both as zero-shot.",
      "The title 'Language models enable zero-shot prediction of the effects of mutations on protein function' suggests that there is a new capability that they have 'enabled.'",
      "This is certainly not the case.",
      "Prior work uses exactly the same data (naturally-occurring sequences, but no experimentally-labeled data) and achieves comparable results.",
      "When I first started working on ML for proteins, I was enthralled when I learned that both protein structure and the functional effects of mutations could be predicted by inspecting a statistical model of homologous sequences.",
      "This is a remarkable result, and I'm concerned that the twitter-verse will mistakenly think that this particular paper unlocked it (it's actually been known for many years)."
    ]
  },
  {
    "paper_id": "2211.10000v1",
    "submission_id": "uXc42E9ZPFs",
    "submission_title": "Language models enable zero-shot prediction of the effects of mutations on protein function",
    "review_id": "DseSRk94eqb",
    "input": {
      "title": "Language models enable zero-shot prediction of the effects of mutations on protein function",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Modeling the impact of amino acid mutations on protein-protein interaction plays a crucial role in protein engineering and drug design.\n- But the structures of different families of proteins vary a lot, hindering the generalization of a machine learning model.\n- This paper found that, without any supervision from experimental data or additional training, protein language models capture the functional effects of sequence variation, achieving state-of-the-art zero-shot prediction performance.\n- However, it is somewhat expected.\n- In principle, language models learn the distribution of the protein sequences that are stable.\n- The unstable sequences are usually recognized by language models as low probabilities of existence.\n- The introduction of the used prediction models is missing.\n- It is hard to understand the acronyms without explanation.\n- The implementation details are not clear.\n- What are the hyperparameters and how do you finetune them?\n- Have the authors compared the deep learning models with the traditional evolutionary conservation profiles?",
    "review_points_list": [
      "Modeling the impact of amino acid mutations on protein-protein interaction plays a crucial role in protein engineering and drug design.",
      "But the structures of different families of proteins vary a lot, hindering the generalization of a machine learning model.",
      "This paper found that, without any supervision from experimental data or additional training, protein language models capture the functional effects of sequence variation, achieving state-of-the-art zero-shot prediction performance.",
      "However, it is somewhat expected.",
      "In principle, language models learn the distribution of the protein sequences that are stable.",
      "The unstable sequences are usually recognized by language models as low probabilities of existence.",
      "The introduction of the used prediction models is missing.",
      "It is hard to understand the acronyms without explanation.",
      "The implementation details are not clear.",
      "What are the hyperparameters and how do you finetune them?",
      "Have the authors compared the deep learning models with the traditional evolutionary conservation profiles?"
    ]
  },
  {
    "paper_id": "2211.10000v1",
    "submission_id": "uXc42E9ZPFs",
    "submission_title": "Language models enable zero-shot prediction of the effects of mutations on protein function",
    "review_id": "H4wTMBiyMse",
    "input": {
      "title": "Language models enable zero-shot prediction of the effects of mutations on protein function",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper solves the problem of functional mutation effect prediction, and does it as well as anyone else, with a very simple setup.\n- They demonstrate these results convincingly.\n- My main concern with this paper is that they achieve these results in a zero-shot manner, but don't demonstrate that fine-tuning improves performance, which is very surprising.\n- That said, I do not think that they need to completely answer the question as to why in order for this to be a complete body of work.\n- Not very original methods.\n- Not very original methods. Use of current dataset.\n- Good quality.\n- Lots of qualitative analysis.\n- Lots of baselines.\n- Baselines were tuned beyond my expectation.\n- Clear.\n- Good prose.\n- Zero-shot performance mirroring state-of-the-art in an area that has substantial impact, like pharmaceuticals, is very significant.\n- The paper describes a model that\n- - Is pretrained jointly across many protein families\n- - Learns functional effects of mutations at state-of-the-art for deep mutational scans\n- - Recapitulates substitution patterns concordant with biology\n- - Does not require MSAs at all\n- - Use UniRefXX for many values of XX\n- Quantitative evidence via deep mutational scans (DMS)\n- - 41 DMS examined\n- Spearman R used - SOTA values\n- Comparison to DeepSequence, ESM-1b, ProtBERT-BFD, UniRep, TAPE\n- Show entropy vs ground truth PSSMs\n- Show calibration of the model\n- 41 DMS examined\n- Explanations of substitution patterns like hydrophobicity and buried vs exposed via some anecdotes and statistics\n- Via an explanation of their architecture, training procedure, and inference setup\n- No fine tuning step needed\n- No family-based training objective function\n- Not trained for-purpose - should be generally useful.",
    "review_points_list": [
      "This paper solves the problem of functional mutation effect prediction, and does it as well as anyone else, with a very simple setup.",
      "They demonstrate these results convincingly.",
      "My main concern with this paper is that they achieve these results in a zero-shot manner, but don't demonstrate that fine-tuning improves performance, which is very surprising.",
      "That said, I do not think that they need to completely answer the question as to why in order for this to be a complete body of work.",
      "Not very original methods.",
      "Not very original methods. Use of current dataset.",
      "Good quality.",
      "Lots of qualitative analysis.",
      "Lots of baselines.",
      "Baselines were tuned beyond my expectation.",
      "Clear.",
      "Good prose.",
      "Zero-shot performance mirroring state-of-the-art in an area that has substantial impact, like pharmaceuticals, is very significant.",
      "The paper describes a model that",
      "- Is pretrained jointly across many protein families",
      "- Learns functional effects of mutations at state-of-the-art for deep mutational scans",
      "- Recapitulates substitution patterns concordant with biology",
      "- Does not require MSAs at all",
      "- Use UniRefXX for many values of XX",
      "Quantitative evidence via deep mutational scans (DMS)",
      "- 41 DMS examined",
      "Spearman R used - SOTA values",
      "Comparison to DeepSequence, ESM-1b, ProtBERT-BFD, UniRep, TAPE",
      "Show entropy vs ground truth PSSMs",
      "Show calibration of the model",
      "41 DMS examined",
      "Explanations of substitution patterns like hydrophobicity and buried vs exposed via some anecdotes and statistics",
      "Via an explanation of their architecture, training procedure, and inference setup",
      "No fine tuning step needed",
      "No family-based training objective function",
      "Not trained for-purpose - should be generally useful."
    ]
  },
  {
    "paper_id": "2211.10000v1",
    "submission_id": "uXc42E9ZPFs",
    "submission_title": "Language models enable zero-shot prediction of the effects of mutations on protein function",
    "review_id": "sUIrRbGvpcQ",
    "input": {
      "title": "Language models enable zero-shot prediction of the effects of mutations on protein function",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The method is well motivated, simple, effective, and likely to lead to fruitful future research.\n- The method is carefully evaluated against several baselines.\n- The datasets are standard benchmarks for evaluating protein function prediction.\n- The models are variants on standard BERT models, with evaluations to select the right pretraining dataset and compare model sizes.\n- It performs about as well as methods that use a full MSA while only requiring a single sequence.\n- The paper is technically sound and carefully evaluated.\n- It answered questions I had while reading it with experiments (and a thorough appendix).\n- Proper validation sets are used.\n- Baselines are well tuned (even outperforming results in source publication).\n- Results are reported using sound statistics.\n- The ESM-1v model is evaluated at several different scales and across many pre-training datasets.\n- Several alternatives are considered for the primary choices made in the paper (e.g. how to score the effects of mutations given the model, which pre-training dataset to use, how to ...\n- Good discussion of related work, in both ML + protein and NLP literature.\n- Extends the model analysis beyond the task at hand to how the models do at modeling the stability of residues located in different regions of the folded protein.\n- The paper is clearly written, with sufficient references to related work and background.\n- Figures clarify content of the text (such as the overall task, the pipeline for each baseline and the proposed method, and visualizations of relationship between position and model entropy).\n- I believe a practitioner familiar with the data and BERT models could reproduce the results as described.\n- I believe other researchers are likely to build on the methods outlined in the paper.\n- While it does not always exceed the baselines, the method generally performs near or better than existing methods despite only needing a single protein sequence (instead of a full MSA).\n- It is also the first paper I have seen that explicitly evaluates scaling on protein datasets (which is why I would like to see more discussion of this point).\n- Consider saying 'masked language models' in the title to point at the specific model class used.\n- What methods are appropriate for handing Methionine in the first position ('care must be used when applying the model to a subsequence')\n- Any theories as to why uniref90 performs the best?\n- Does the pretraining only use the cluster centers from each cluster? Consider adding a section to appendix expanding on the pretraining details, even if it is explained in a referenced paper\n- How large was the dataset? Roughly how many epochs was 170k steps of 1 million tokens\n- Add figure or table including other pretraining metrics alongside just the plot of rho with respect to model size/update steps. What is the per amino acid accuracy? Perplexity? table 12 has some of this for the large model, but the other model information is also useful.\n- Generally suggest trying to characterize relationship between pretraining performance and downstream performance on your task as measured by rho.\n- I'm sure I've seen similar methods to 'spiked unsupervised fine-tuning' used in NLP literature to regularize/combat forgetting, but I'm struggling to find a reference\u2026 I will see if I can find something for the discussion period.\n- Define mt=mutated, wt=wild type before equation\n- Should the conditioning be x^{mt}_{-t} and x^{wt}_{-t}?\n- Consider describing more about what fitness landscape means (fitness of the region around the protein in sequence space).\n- The #s don't add up:\"among the 15% predicted positions, 10% are randomly, 10% retain \u2026\"\n- Add comma after 'in biology'\n- Define MSA when it is first used\n- You do not describe what ESM-1v before referring to it\n- Misspelled marginal\n- Label the y axis\n- The bottom of the figure is cut off\n- Add reference to appendix section where you describe sampling for the MSA",
    "review_points_list": [
      "The method is well motivated, simple, effective, and likely to lead to fruitful future research.",
      "The method is carefully evaluated against several baselines.",
      "The datasets are standard benchmarks for evaluating protein function prediction.",
      "The models are variants on standard BERT models, with evaluations to select the right pretraining dataset and compare model sizes.",
      "It performs about as well as methods that use a full MSA while only requiring a single sequence.",
      "The paper is technically sound and carefully evaluated.",
      "It answered questions I had while reading it with experiments (and a thorough appendix).",
      "Proper validation sets are used.",
      "Baselines are well tuned (even outperforming results in source publication).",
      "Results are reported using sound statistics.",
      "The ESM-1v model is evaluated at several different scales and across many pre-training datasets.",
      "Several alternatives are considered for the primary choices made in the paper (e.g. how to score the effects of mutations given the model, which pre-training dataset to use, how to ...",
      "Good discussion of related work, in both ML + protein and NLP literature.",
      "Extends the model analysis beyond the task at hand to how the models do at modeling the stability of residues located in different regions of the folded protein.",
      "The paper is clearly written, with sufficient references to related work and background.",
      "Figures clarify content of the text (such as the overall task, the pipeline for each baseline and the proposed method, and visualizations of relationship between position and model entropy).",
      "I believe a practitioner familiar with the data and BERT models could reproduce the results as described.",
      "I believe other researchers are likely to build on the methods outlined in the paper.",
      "While it does not always exceed the baselines, the method generally performs near or better than existing methods despite only needing a single protein sequence (instead of a full MSA).",
      "It is also the first paper I have seen that explicitly evaluates scaling on protein datasets (which is why I would like to see more discussion of this point).",
      "Consider saying 'masked language models' in the title to point at the specific model class used.",
      "What methods are appropriate for handing Methionine in the first position ('care must be used when applying the model to a subsequence')",
      "Any theories as to why uniref90 performs the best?",
      "Does the pretraining only use the cluster centers from each cluster? Consider adding a section to appendix expanding on the pretraining details, even if it is explained in a referenced paper",
      "How large was the dataset? Roughly how many epochs was 170k steps of 1 million tokens",
      "Add figure or table including other pretraining metrics alongside just the plot of rho with respect to model size/update steps. What is the per amino acid accuracy? Perplexity? table 12 has some of this for the large model, but the other model information is also useful.",
      "Generally suggest trying to characterize relationship between pretraining performance and downstream performance on your task as measured by rho.",
      "I'm sure I've seen similar methods to 'spiked unsupervised fine-tuning' used in NLP literature to regularize/combat forgetting, but I'm struggling to find a reference\u2026 I will see if I can find something for the discussion period.",
      "Define mt=mutated, wt=wild type before equation",
      "Should the conditioning be x^{mt}_{-t} and x^{wt}_{-t}?",
      "Consider describing more about what fitness landscape means (fitness of the region around the protein in sequence space).",
      "The #s don't add up:\"among the 15% predicted positions, 10% are randomly, 10% retain \u2026\"",
      "Add comma after 'in biology'",
      "Define MSA when it is first used",
      "You do not describe what ESM-1v before referring to it",
      "Misspelled marginal",
      "Label the y axis",
      "The bottom of the figure is cut off",
      "Add reference to appendix section where you describe sampling for the MSA"
    ]
  },
  {
    "paper_id": "2501.10258v1",
    "submission_id": "wTLc2HcWLIM",
    "submission_title": "Adaptive First-Order Methods Revisited: Convex Minimization without Lipschitz Requirements",
    "review_id": "d3VPAjb__uT",
    "input": {
      "title": "Adaptive First-Order Methods Revisited: Convex Minimization without Lipschitz Requirements",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well-written and easy to follow. It was a pleasure to read.\n- The authors did a good job explaining the problem, the motivating limitations from the literature, and the connections to other methods.\n- The use of examples and the clarifying remarks were very insightful.\n- The proposed method combines Mirror descent with a generalized version of the adaptive step-size rule popularized by AdaGrad.\n- The method is simple and somewhat natural.\n- The core innovation is the analysis of these algorithmic solutions under weaker conditions.\n- The theoretical analysis appears to be mathematically sound.\n- However, I did not check all the details.\n- The column 'Order-optimal' in Table 1 is slightly misleading.\n- This column is not comparable among the rows because the classes of functions are different.\n- Consider dropping the column or including the class explicitly.\n- I would like to see how AdaMir performs against other methods in the literature;\n- the paper would greatly benefit from a few numerical experiments.\n- What does 'partial' mean in Table 1?\n- L98: adaptiving -> adapting.\n- L121: Move the footnote to the previous sentence where you make the claim.\n- L131: Delete one 'sample.'\n- L134: Clarify this is the dual norm on V^*.\n- L229: Typo double in the inline equation.\n- L259: It is odd to present all the other statements explicitly and use the big-O notation for this one. Consider writing an explicit bound.\n- L301: I cannot find (SI) defined anywhere.\n- I am assuming you refer to (12)?",
    "review_points_list": [
      "The paper is well-written and easy to follow. It was a pleasure to read.",
      "The authors did a good job explaining the problem, the motivating limitations from the literature, and the connections to other methods.",
      "The use of examples and the clarifying remarks were very insightful.",
      "The proposed method combines Mirror descent with a generalized version of the adaptive step-size rule popularized by AdaGrad.",
      "The method is simple and somewhat natural.",
      "The core innovation is the analysis of these algorithmic solutions under weaker conditions.",
      "The theoretical analysis appears to be mathematically sound.",
      "However, I did not check all the details.",
      "The column 'Order-optimal' in Table 1 is slightly misleading.",
      "This column is not comparable among the rows because the classes of functions are different.",
      "Consider dropping the column or including the class explicitly.",
      "I would like to see how AdaMir performs against other methods in the literature;",
      "the paper would greatly benefit from a few numerical experiments.",
      "What does 'partial' mean in Table 1?",
      "L98: adaptiving -> adapting.",
      "L121: Move the footnote to the previous sentence where you make the claim.",
      "L131: Delete one 'sample.'",
      "L134: Clarify this is the dual norm on V^*.",
      "L229: Typo double in the inline equation.",
      "L259: It is odd to present all the other statements explicitly and use the big-O notation for this one. Consider writing an explicit bound.",
      "L301: I cannot find (SI) defined anywhere.",
      "I am assuming you refer to (12)?"
    ]
  },
  {
    "paper_id": "2501.10258v1",
    "submission_id": "wTLc2HcWLIM",
    "submission_title": "Adaptive First-Order Methods Revisited: Convex Minimization without Lipschitz Requirements",
    "review_id": "OOjEhQCkDRw",
    "input": {
      "title": "Adaptive First-Order Methods Revisited: Convex Minimization without Lipschitz Requirements",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well written, clear to read and the theory seems to be sound. I did not check the proofs though.\n- Authors provide a good introduction to various concepts involved in the paper, for example, Bregman distances, relative smoothness and many others.\n- AdaMir combines the best of two worlds, adaptive gradient methods and Mirror Descent based methods.\n- In the deterministic setting, the ergodic convergence rates of AdaMir for both RC and RS settings are given in Theorem 1.\n- Notably, optimal rates are obtained in both the settings.\n- The stochastic setting is also considered, for which convergence rates are provided for AdaMir.\n- Brief discussion on non-convex setting is also provided.\n- The paper considers many settings which contributed to too much packed content in the paper.\n- I wish authors focussed on just online setting itself, while relegating the stochastic setting to the supplementary material.\n- No experiments were provided in the main paper.\n- I would suggest moving the experiment from the supplement to the main paper.\n- Example 1, 2, 3 can be moved to supplementary material.\n- I think it is better to focus more on the AdaMir algorithm.\n- The authors use a strongly convex h, which makes the definition of \u03b4 not so appealing.\n- In my opinion, the main novelty lies in the definition of \u03b4 which makes use of two Bregman distance evaluations.\n- However, I think the novelty in the rest of paper is not significant.\n- More discussion on remark starting at line 118 is needed.\n- A closely related work seems to be [45].\n- I think more discussion on this is needed preferably before just before the AdaMir algorithm.\n- Also, discussion on regret bounds based on Proposition 3 is missing (please refer to [45]).\n- What is the connection of your Definition of a Bregman function to the other standard definition using Legendre functions?\n- There is no numerical evidence for the proposed method.\n- In line 334, change 'eay' to 'easy'.\n- Typo in equation in line 229.",
    "review_points_list": [
      "The paper is well written, clear to read and the theory seems to be sound. I did not check the proofs though.",
      "Authors provide a good introduction to various concepts involved in the paper, for example, Bregman distances, relative smoothness and many others.",
      "AdaMir combines the best of two worlds, adaptive gradient methods and Mirror Descent based methods.",
      "In the deterministic setting, the ergodic convergence rates of AdaMir for both RC and RS settings are given in Theorem 1.",
      "Notably, optimal rates are obtained in both the settings.",
      "The stochastic setting is also considered, for which convergence rates are provided for AdaMir.",
      "Brief discussion on non-convex setting is also provided.",
      "The paper considers many settings which contributed to too much packed content in the paper.",
      "I wish authors focussed on just online setting itself, while relegating the stochastic setting to the supplementary material.",
      "No experiments were provided in the main paper.",
      "I would suggest moving the experiment from the supplement to the main paper.",
      "Example 1, 2, 3 can be moved to supplementary material.",
      "I think it is better to focus more on the AdaMir algorithm.",
      "The authors use a strongly convex h, which makes the definition of \u03b4 not so appealing.",
      "In my opinion, the main novelty lies in the definition of \u03b4 which makes use of two Bregman distance evaluations.",
      "However, I think the novelty in the rest of paper is not significant.",
      "More discussion on remark starting at line 118 is needed.",
      "A closely related work seems to be [45].",
      "I think more discussion on this is needed preferably before just before the AdaMir algorithm.",
      "Also, discussion on regret bounds based on Proposition 3 is missing (please refer to [45]).",
      "What is the connection of your Definition of a Bregman function to the other standard definition using Legendre functions?",
      "There is no numerical evidence for the proposed method.",
      "In line 334, change 'eay' to 'easy'.",
      "Typo in equation in line 229."
    ]
  },
  {
    "paper_id": "2501.10258v1",
    "submission_id": "wTLc2HcWLIM",
    "submission_title": "Adaptive First-Order Methods Revisited: Convex Minimization without Lipschitz Requirements",
    "review_id": "RZ1uDMJ6Pf8",
    "input": {
      "title": "Adaptive First-Order Methods Revisited: Convex Minimization without Lipschitz Requirements",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper provides a detailed literature review on the considered problem.\n- The study is well motivated and the results obtained are clearly stated and discussed.\n- Please be clear about the $O(1/T^\text{\u03b1}) $ convergence rates appeared in the paper.\n- For Nesterov\u2019s accelerated gradient, the $O(1/T^2)$ rate is on the objective function value at the last iterate, while for some other methods mentioned in the paper, $O(1/T^2)$ rate is for ergodic averaged point.",
    "review_points_list": [
      "The paper provides a detailed literature review on the considered problem.",
      "The study is well motivated and the results obtained are clearly stated and discussed.",
      "Please be clear about the $O(1/T^\text{\u03b1}) $ convergence rates appeared in the paper.",
      "For Nesterov\u2019s accelerated gradient, the $O(1/T^2)$ rate is on the objective function value at the last iterate, while for some other methods mentioned in the paper, $O(1/T^2)$ rate is for ergodic averaged point."
    ]
  },
  {
    "paper_id": "2105.13504v2",
    "submission_id": "yITJ6t31eAE",
    "submission_title": "Lattice partition recovery with dyadic CART",
    "review_id": "aeNtCPKp8Zl",
    "input": {
      "title": "Lattice partition recovery with dyadic CART",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The ideas were mostly comprehensible, but I felt that a lot of the definitions would have benefited from more straightforward explanations than were given in Section 1.1.\n- I appreciate that while the ideas are simple, the lattice- and graph-based nature of the problem makes it challenging to keep notation succinct.\n- The descriptions made them feel more dense than necessary for a reader without extensive familiarity with this area of research.\n- My suggestion would be that more diagrams like Figures 1 and 2 to explain notions like induced partitions, dyadic splits and the like would be disproportionately helpful.\n- There were certainly useful discussions in the paper, for example, the discussions in lines 186\u2013193 and 267\u2013276 are appreciated.\n- The notation itself was consistent and clear throughout, so nothing was ambiguous or notationally confusing, it was just that some of the ideas came across as requiring a lot of abstract setup.\n- The definitions of $\\\text{kappa}$ and $\\\text{Delta}$ should be separated from the rest of Definition 1, because the notion of induced partitions is a heavy (even if intuitive) concept in its own right.\n- Theorem 1 looks sound to me.\n- The assumptions in Assumption 1 have the same scaling as the Theorem 2 result, and I would have appreciated some discussion of this in the main paper (not relegated to supplementary).\n- The choice of scaling here is not, and one naturally wonders if the result of Theorem 2 follows from whatever is assumed in Assumption 1.\n- I would appreciate a discussion of how the example offered relates to Assumption 1.\n- Assumption 1 makes the recovery problem easier, so any example for a lower bound that doesn't satisfy the assumption could be too conservative, and hence not relevant to Theorem 2.\n- The experiments are straightforward I think they give some idea of what is going on.\n- However, I felt the discussion of the evaluation was overly brief.\n- What was it about setting 2 that made it more challenging under the $\\\text{dist}_1$ metric, but not the $\\\text{dist}_2$ metric?\n- I think they [standard error bars] overlap, but I didn't check carefully enough to tell for sure.\n- The noise level is reported but the 'signal level' (I suppose by this I mean $\\\text{Delta}$) was not clearly indicated.\n- I didn't peruse the supplementary material, other than to quickly check Theorem S1 and Assumption S1 and to try and get some idea of how the expressions in Assumption 1 were motivated.\n- A quick discussion on (what is known, if anything) about the relationship between the task of estimating $\\\theta^*$ and partition recovery would be useful.\n- Do better partition recoveries tend to support lower $\\\rVert \\\text{hat}\\theta - \\\theta^* \\\rVert$, or vice versa, or are they so fundamentally different that it is easy to imagine examples where one task is extremely easy and the other is very difficult?\n- I am not sufficiently familiar with the surrounding literature to provide a confident assessment of how original this is given the prior art, so the following is mostly a guess.\n- However, the authors were clear about their focus on partition recovery and the case $d \\\text{ge} 2$, and how this relates to prior work, and I'm satisfied that this is a novel contribution.\n- I think there is a lot to build on here, and I think the direction taken by the authors is a probably a good contribution to our understanding of the recovery of piecewise constant signals.\n- What is much less clear to me is the degree to which the case $d \\\text{gt} 3$ is valuable, since all of the examples of applications given are imagery based and in these contexts I'm only aware of up to 3 (spatial) or maybe at most 4 (including color) dimensions.\n- Typos:\n- Line 127: DACRT\n- Line 129: of _he_ procedure\n- Line 148: broader _then_ the ones\n- Line 239: Should (i,j) in the definition of E be c (or vice versa)?\n- Line 252: should the second $\\\text{lambda}_1$ be $\\\text{lambda}_2$?",
    "review_points_list": [
      "The ideas were mostly comprehensible, but I felt that a lot of the definitions would have benefited from more straightforward explanations than were given in Section 1.1.",
      "I appreciate that while the ideas are simple, the lattice- and graph-based nature of the problem makes it challenging to keep notation succinct.",
      "The descriptions made them feel more dense than necessary for a reader without extensive familiarity with this area of research.",
      "My suggestion would be that more diagrams like Figures 1 and 2 to explain notions like induced partitions, dyadic splits and the like would be disproportionately helpful.",
      "There were certainly useful discussions in the paper, for example, the discussions in lines 186\u2013193 and 267\u2013276 are appreciated.",
      "The notation itself was consistent and clear throughout, so nothing was ambiguous or notationally confusing, it was just that some of the ideas came across as requiring a lot of abstract setup.",
      "The definitions of $\\\text{kappa}$ and $\\\text{Delta}$ should be separated from the rest of Definition 1, because the notion of induced partitions is a heavy (even if intuitive) concept in its own right.",
      "Theorem 1 looks sound to me.",
      "The assumptions in Assumption 1 have the same scaling as the Theorem 2 result, and I would have appreciated some discussion of this in the main paper (not relegated to supplementary).",
      "The choice of scaling here is not, and one naturally wonders if the result of Theorem 2 follows from whatever is assumed in Assumption 1.",
      "I would appreciate a discussion of how the example offered relates to Assumption 1.",
      "Assumption 1 makes the recovery problem easier, so any example for a lower bound that doesn't satisfy the assumption could be too conservative, and hence not relevant to Theorem 2.",
      "The experiments are straightforward I think they give some idea of what is going on.",
      "However, I felt the discussion of the evaluation was overly brief.",
      "What was it about setting 2 that made it more challenging under the $\\\text{dist}_1$ metric, but not the $\\\text{dist}_2$ metric?",
      "I think they [standard error bars] overlap, but I didn't check carefully enough to tell for sure.",
      "The noise level is reported but the 'signal level' (I suppose by this I mean $\\\text{Delta}$) was not clearly indicated.",
      "I didn't peruse the supplementary material, other than to quickly check Theorem S1 and Assumption S1 and to try and get some idea of how the expressions in Assumption 1 were motivated.",
      "A quick discussion on (what is known, if anything) about the relationship between the task of estimating $\\\theta^*$ and partition recovery would be useful.",
      "Do better partition recoveries tend to support lower $\\\rVert \\\text{hat}\\theta - \\\theta^* \\\rVert$, or vice versa, or are they so fundamentally different that it is easy to imagine examples where one task is extremely easy and the other is very difficult?",
      "I am not sufficiently familiar with the surrounding literature to provide a confident assessment of how original this is given the prior art, so the following is mostly a guess.",
      "However, the authors were clear about their focus on partition recovery and the case $d \\\text{ge} 2$, and how this relates to prior work, and I'm satisfied that this is a novel contribution.",
      "I think there is a lot to build on here, and I think the direction taken by the authors is a probably a good contribution to our understanding of the recovery of piecewise constant signals.",
      "What is much less clear to me is the degree to which the case $d \\\text{gt} 3$ is valuable, since all of the examples of applications given are imagery based and in these contexts I'm only aware of up to 3 (spatial) or maybe at most 4 (including color) dimensions.",
      "Typos:",
      "Line 127: DACRT",
      "Line 129: of _he_ procedure",
      "Line 148: broader _then_ the ones",
      "Line 239: Should (i,j) in the definition of E be c (or vice versa)?",
      "Line 252: should the second $\\\text{lambda}_1$ be $\\\text{lambda}_2$?"
    ]
  },
  {
    "paper_id": "2105.13504v2",
    "submission_id": "yITJ6t31eAE",
    "submission_title": "Lattice partition recovery with dyadic CART",
    "review_id": "-NnHPs00kCJ",
    "input": {
      "title": "Lattice partition recovery with dyadic CART",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Overall, the big picture and the intuitions behind the results were well-explained.\n- Moreover, the empirical results look promising.\n- However, the statements of the results are heavily technical and ambiguous: for example, it is unclear how the result of Theorem 2 implies the consistency of DCARTAM: the upper bound (15) (even taking into account the inequality (14)) is not enough to prove the consistency as defined by (3).\n- There are some further remarks/suggestions:\n- - In practice, the two steps estimator requires the evaluation of (9) and (10) to be implemented, which seem to be computationally expensive.\n- It would be interesting to add a complete analysis of the complexity of this algorithm.\n- It would be interesting to illustrate the optimality of the upper bounds by numerical simulations that show the dependency on N.",
    "review_points_list": [
      "Overall, the big picture and the intuitions behind the results were well-explained.",
      "Moreover, the empirical results look promising.",
      "However, the statements of the results are heavily technical and ambiguous: for example, it is unclear how the result of Theorem 2 implies the consistency of DCARTAM: the upper bound (15) (even taking into account the inequality (14)) is not enough to prove the consistency as defined by (3).",
      "There are some further remarks/suggestions:",
      "- In practice, the two steps estimator requires the evaluation of (9) and (10) to be implemented, which seem to be computationally expensive.",
      "It would be interesting to add a complete analysis of the complexity of this algorithm.",
      "It would be interesting to illustrate the optimality of the upper bounds by numerical simulations that show the dependency on N."
    ]
  },
  {
    "paper_id": "2105.13504v2",
    "submission_id": "yITJ6t31eAE",
    "submission_title": "Lattice partition recovery with dyadic CART",
    "review_id": "Vh7rFZyqC2V",
    "input": {
      "title": "Lattice partition recovery with dyadic CART",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- There is a lot of recent research studying estimation of structured signals;\n- the model and the problem proposed in this work fit in this line of research.\n- I think it is an interesting observation that DCART tends to 'over-partition' signals.\n- However, I found the proposed fix of (roughly) merging the cells produced by DCART a bit straightforward.\n- Another weak point of this work is the gap of $k^\text{ast}$ in the upper and lower bounds.\n- I think it would be interesting to bound the error of some (possibly) inefficient estimator for this problem in order to have a better benchmark for the performance of DCART.\n- Overall, the paper is well-written and the presentation of the results and assumptions clean.\n- Since the problem is interesting and a well-known algorithm is studied, I believe that this work is above the threshold but I would not push for it to be accepted.\n- I believe it would be beneficial for the paper to add some more high-level discussion on the difference of partition estimation and recovering the whole signal, applications of partition recovery, etc.\n- Is it easier to bound the error of some inefficient estimator (for example the NP-Hard estimator of Equation (2)) for this problem?",
    "review_points_list": [
      "There is a lot of recent research studying estimation of structured signals;",
      "the model and the problem proposed in this work fit in this line of research.",
      "I think it is an interesting observation that DCART tends to 'over-partition' signals.",
      "However, I found the proposed fix of (roughly) merging the cells produced by DCART a bit straightforward.",
      "Another weak point of this work is the gap of $k^\text{ast}$ in the upper and lower bounds.",
      "I think it would be interesting to bound the error of some (possibly) inefficient estimator for this problem in order to have a better benchmark for the performance of DCART.",
      "Overall, the paper is well-written and the presentation of the results and assumptions clean.",
      "Since the problem is interesting and a well-known algorithm is studied, I believe that this work is above the threshold but I would not push for it to be accepted.",
      "I believe it would be beneficial for the paper to add some more high-level discussion on the difference of partition estimation and recovering the whole signal, applications of partition recovery, etc.",
      "Is it easier to bound the error of some inefficient estimator (for example the NP-Hard estimator of Equation (2)) for this problem?"
    ]
  },
  {
    "paper_id": "2111.12665v2",
    "submission_id": "tqo8sxHyD8",
    "submission_title": "Finite-Time Error Bounds for Distributed Linear Stochastic Approximation",
    "review_id": "Y8sw8rkhB8j",
    "input": {
      "title": "Finite-Time Error Bounds for Distributed Linear Stochastic Approximation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper studies distributed Markovian stochastic approximation algorithms with stochastic interconnection matrices, which has not yet been covered in the related literature.\n- The results are a bit different than what is known for related algorithms having doubly stochastic interconnection matrices.\n- A push-type algorithm is proposed for decentralized implementation.\n- The results are technically sound and theoretically supported.\n- The algorithm proposed is also new.\n- The paper is well written and easy to follow.\n- The results are nicely organized and the contributions relative to existing works are clear too.\n- The results are important and complement the existing distributed Markovian stochastic approximation results which have only focused on doubly stochastic interconnections among agents.\n- The tools developed for analysis may also be useful for further use.",
    "review_points_list": [
      "This paper studies distributed Markovian stochastic approximation algorithms with stochastic interconnection matrices, which has not yet been covered in the related literature.",
      "The results are a bit different than what is known for related algorithms having doubly stochastic interconnection matrices.",
      "A push-type algorithm is proposed for decentralized implementation.",
      "The results are technically sound and theoretically supported.",
      "The algorithm proposed is also new.",
      "The paper is well written and easy to follow.",
      "The results are nicely organized and the contributions relative to existing works are clear too.",
      "The results are important and complement the existing distributed Markovian stochastic approximation results which have only focused on doubly stochastic interconnections among agents.",
      "The tools developed for analysis may also be useful for further use."
    ]
  },
  {
    "paper_id": "2111.12665v2",
    "submission_id": "tqo8sxHyD8",
    "submission_title": "Finite-Time Error Bounds for Distributed Linear Stochastic Approximation",
    "review_id": "Wb2hRjBHclO",
    "input": {
      "title": "Finite-Time Error Bounds for Distributed Linear Stochastic Approximation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- As mentioned, the main contribution is a new analysis on the distributed linear stochastic approximation algorithm given in (1), encompassing constant stepsize and time varying step size, Markovian samples.\n- This technique can be interesting as it leads to a simple recursion of the iterates in (4), simplifying the subsequent analysis.\n- There are a number of drawbacks which outweigh the benefits of the current paper, as discussed below:\n- Though the paper title reads 'distributed linear stochastic approximation', the algorithm in (1) only considers a restricted setting with an identical driving matrix $A(x)$ across agents (and different $b^i(x)$ across agents).\n- This setting may be suitable for the distributed policy evaluation problem where a number of prior works have appeared, but it does not include many interesting cases for distributed linear stochastic approximation including classical ones such as linear regression.\n- In this regard, the paper may better position itself as a paper for distributed policy evaluation instead of the more general linear stochastic approximation.\n- The main theorems (Theorem 2 & 3) require Assumption 6 which is not well justified.\n- Particularly, this assumption requires the absolute probability sequence to admit a limit vector.\n- The Remark 3 which follows the assumption fails to provide a convincing case for this assumption to hold.\n- In addition, it is not clear what are the benefits of employing the absolute probability sequence technique in analyzing the convergence of distributed algorithms, e.g., when compared to the classical approach in [52] for the push-SA algorithm.\n- Some relevant work can be found in the static graph setting, e.g., J. Chen, A. Sayed, 'Distributed Pareto Optimization via Diffusion Strategies', IEEE Transactions on Signal Processing, 2013.\n- However, the presentation of the main theorems lacks useful information that a finite-time error analysis should encompass.\n- Without a more detailed description, the bound in (7) is not useful since $C_2$ can be large;\n- The result for push-SA is summarized in Theorem 5 *only* for the case of time varying step size, and it is mentioned that 'our current analysis approach cannot be directly applied for this case' which lacks further expatiation;\n- In theorem 3, how does the convergence rate of $\theta_t$ affects the finite time error bound in the constant step size case?\n- The reviewer appreciates the detailed response from the authors.\n- Unfortunately, the response has not addressed my previous concerns and therefore my previous evaluation stands.\n- In particular, the promised 'simulation based' study will not be very convincing since cases which violate Assumption 6 may still include a lot of cases.\n- Instead, it would be better to construct an analytical example to illustrate the necessity of Assumption 6.\n- My main concern is that Assumption 6 and its corresponding analysis due to the 'absolute probability sequence' is one of the main innovations claimed in the paper, yet its applications are so far only limited to the previously known cases.\n- Moreover, while it is acceptable that $C_2$ can be a large constant, it is also important to point out **how** does $C_2$ depends on the system parameters $L, \\gamma_{min}, \\gamma_{max}, A_{max}, b_{max}$.\n- The current presentation has so far eluded from discussing about that.",
    "review_points_list": [
      "As mentioned, the main contribution is a new analysis on the distributed linear stochastic approximation algorithm given in (1), encompassing constant stepsize and time varying step size, Markovian samples.",
      "This technique can be interesting as it leads to a simple recursion of the iterates in (4), simplifying the subsequent analysis.",
      "There are a number of drawbacks which outweigh the benefits of the current paper, as discussed below:",
      "Though the paper title reads 'distributed linear stochastic approximation', the algorithm in (1) only considers a restricted setting with an identical driving matrix $A(x)$ across agents (and different $b^i(x)$ across agents).",
      "This setting may be suitable for the distributed policy evaluation problem where a number of prior works have appeared, but it does not include many interesting cases for distributed linear stochastic approximation including classical ones such as linear regression.",
      "In this regard, the paper may better position itself as a paper for distributed policy evaluation instead of the more general linear stochastic approximation.",
      "The main theorems (Theorem 2 & 3) require Assumption 6 which is not well justified.",
      "Particularly, this assumption requires the absolute probability sequence to admit a limit vector.",
      "The Remark 3 which follows the assumption fails to provide a convincing case for this assumption to hold.",
      "In addition, it is not clear what are the benefits of employing the absolute probability sequence technique in analyzing the convergence of distributed algorithms, e.g., when compared to the classical approach in [52] for the push-SA algorithm.",
      "Some relevant work can be found in the static graph setting, e.g., J. Chen, A. Sayed, 'Distributed Pareto Optimization via Diffusion Strategies', IEEE Transactions on Signal Processing, 2013.",
      "However, the presentation of the main theorems lacks useful information that a finite-time error analysis should encompass.",
      "Without a more detailed description, the bound in (7) is not useful since $C_2$ can be large;",
      "The result for push-SA is summarized in Theorem 5 *only* for the case of time varying step size, and it is mentioned that 'our current analysis approach cannot be directly applied for this case' which lacks further expatiation;",
      "In theorem 3, how does the convergence rate of $\theta_t$ affects the finite time error bound in the constant step size case?",
      "The reviewer appreciates the detailed response from the authors.",
      "Unfortunately, the response has not addressed my previous concerns and therefore my previous evaluation stands.",
      "In particular, the promised 'simulation based' study will not be very convincing since cases which violate Assumption 6 may still include a lot of cases.",
      "Instead, it would be better to construct an analytical example to illustrate the necessity of Assumption 6.",
      "My main concern is that Assumption 6 and its corresponding analysis due to the 'absolute probability sequence' is one of the main innovations claimed in the paper, yet its applications are so far only limited to the previously known cases.",
      "Moreover, while it is acceptable that $C_2$ can be a large constant, it is also important to point out **how** does $C_2$ depends on the system parameters $L, \\gamma_{min}, \\gamma_{max}, A_{max}, b_{max}$.",
      "The current presentation has so far eluded from discussing about that."
    ]
  },
  {
    "paper_id": "2111.12665v2",
    "submission_id": "tqo8sxHyD8",
    "submission_title": "Finite-Time Error Bounds for Distributed Linear Stochastic Approximation",
    "review_id": "sOPAPDpWYtu",
    "input": {
      "title": "Finite-Time Error Bounds for Distributed Linear Stochastic Approximation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper relaxes the commonly adopted assumption that the interconnection matrix is doubly stochastic to a more general one.\n- The assumptions and results obtained in the work are well explained relative to existing works.\n- The motivating context concerns the application of SA approximation in reinforcement learning (RL).\n- It is suggested to briefly discuss how SA is applied in RL, for example, TD learning.\n- The paper should correct the typos mentioned.\n- Line 36 has a typo: \u2018arguably\u2019 should be replaced with \u2018inargibly\u2019.\n- Line 37 has a typo: \u2018differing\u2019 should be replaced with \u2018different\u2019.\n- Thanks for the reply! After reading other reviews and the committee discussion, I decide to change the score to weakly reject, which is in agreement with other reviewers, who raise detailed and constructive concerns.",
    "review_points_list": [
      "This paper relaxes the commonly adopted assumption that the interconnection matrix is doubly stochastic to a more general one.",
      "The assumptions and results obtained in the work are well explained relative to existing works.",
      "The motivating context concerns the application of SA approximation in reinforcement learning (RL).",
      "It is suggested to briefly discuss how SA is applied in RL, for example, TD learning.",
      "The paper should correct the typos mentioned.",
      "Line 36 has a typo: \u2018arguably\u2019 should be replaced with \u2018inargibly\u2019.",
      "Line 37 has a typo: \u2018differing\u2019 should be replaced with \u2018different\u2019.",
      "Thanks for the reply! After reading other reviews and the committee discussion, I decide to change the score to weakly reject, which is in agreement with other reviewers, who raise detailed and constructive concerns."
    ]
  },
  {
    "paper_id": "2111.12665v2",
    "submission_id": "tqo8sxHyD8",
    "submission_title": "Finite-Time Error Bounds for Distributed Linear Stochastic Approximation",
    "review_id": "NmHrEkD4Oor",
    "input": {
      "title": "Finite-Time Error Bounds for Distributed Linear Stochastic Approximation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Overall I think the results in this paper are solid and should be some interesting to the community.\n- Only convergence rate is characterized in the main theorems.\n- It would be better to see the sample complexity result (total number of samples that required to achieve $\\epsilon$-accuracy level) so that the readers can compare the contributions in this paper with the state-of-art.\n- Empirical verification is also suggested even with toy example.\n- Although it is a theoretical paper, some empirical verification is also suggested even with toy example.\n- The dependence on some conditional numbers is not clear.\n- However, those conditional numbers could affect the convergence rate significantly.\n- A detailed discussion about those numbers would make the paper more convincing.\n- In the discussion, since the area chair and reviewer AANE raised some concerns about assumptions and the author did not address these concerns convincingly, I change my score to weakly reject.",
    "review_points_list": [
      "Overall I think the results in this paper are solid and should be some interesting to the community.",
      "Only convergence rate is characterized in the main theorems.",
      "It would be better to see the sample complexity result (total number of samples that required to achieve $\\epsilon$-accuracy level) so that the readers can compare the contributions in this paper with the state-of-art.",
      "Empirical verification is also suggested even with toy example.",
      "Although it is a theoretical paper, some empirical verification is also suggested even with toy example.",
      "The dependence on some conditional numbers is not clear.",
      "However, those conditional numbers could affect the convergence rate significantly.",
      "A detailed discussion about those numbers would make the paper more convincing.",
      "In the discussion, since the area chair and reviewer AANE raised some concerns about assumptions and the author did not address these concerns convincingly, I change my score to weakly reject."
    ]
  },
  {
    "paper_id": "2112.06174v1",
    "submission_id": "x4t0fxWPNdi",
    "submission_title": "Implicit Transformer Network for Screen Content Image Continuous Super-Resolution",
    "review_id": "cuohhlswE4p",
    "input": {
      "title": "Implicit Transformer Network for Screen Content Image Continuous Super-Resolution",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The idea of integrating implicit neural representation into a transformer is interesting and its effectiveness has been validated in the extensive ablation study and comparison with SOTA methods.\n- However, there are still some issues to be clarified.\n- It is not clear what is the meaning of computing relation matrix using coordinates in transformer. Since coordinates are content-independent, it means that for images of the same size, they share the same $\textbackslash phi(q, k)$. \n- In the comparison, the proposed method shows better performance on both qualitative and quantitative comparison.\n- However, it is not clear whether comparison is fair since number of parameters and flops are not mentioned.",
    "review_points_list": [
      "The idea of integrating implicit neural representation into a transformer is interesting and its effectiveness has been validated in the extensive ablation study and comparison with SOTA methods.",
      "However, there are still some issues to be clarified.",
      "It is not clear what is the meaning of computing relation matrix using coordinates in transformer. Since coordinates are content-independent, it means that for images of the same size, they share the same $\textbackslash phi(q, k)$. ",
      "In the comparison, the proposed method shows better performance on both qualitative and quantitative comparison.",
      "However, it is not clear whether comparison is fair since number of parameters and flops are not mentioned."
    ]
  },
  {
    "paper_id": "2112.06174v1",
    "submission_id": "x4t0fxWPNdi",
    "submission_title": "Implicit Transformer Network for Screen Content Image Continuous Super-Resolution",
    "review_id": "qVEStyDxcio",
    "input": {
      "title": "Implicit Transformer Network for Screen Content Image Continuous Super-Resolution",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The method is described well.\n- The experiments show that the method can perform well in terms of quantitative analysis and qualitative comparison.\n- The qualitative comparison shows that the method is well suited for screen content compared to other SOTA methods.\n- With the help of transformers, the SR seems to improve in quality, but there is no analysis on computational complexity.\n- Normally, when the transformer is used, it can be utilized to reduce the computational load while also improving quality. Does this work also convey such characteristics?\n- The latest SOTA for SR using transformers is the CVPR 2020 paper TTSR which is not mentioned in the main paper.\n- There is no comparison with the method either nor in the related works section.\n- The latest SOTA is essential to show in the paper so that it can be compared to the latest SOTA.\n- ALthough this work is focussed on SCISR, it is still very related to SR and further uses transformers as a component to the network architecture.\n- The most similar work is arguably the TTSR which need s to be addressed.\n- Also, the authors conduct experiments on RDN, RCAN, MetaSR etc.\n- However, these are somewhat outdated SR models.\n- Therefore, it is not entirely surprising that the current model outperforms them.\n- The latest SR models that the authors should consider is definitely TTSR, but also EDVR, EDSR, IGNN, SRGAN etc.\n- I would say the experimental section is not as extensive as I would have expected.\n- Although there are not many methods combining transformers with CNNs yet for SR, it is much more relevant to compare with CNN only methods to show the effectiveness for combining an additional module; the transformer.",
    "review_points_list": [
      "The method is described well.",
      "The experiments show that the method can perform well in terms of quantitative analysis and qualitative comparison.",
      "The qualitative comparison shows that the method is well suited for screen content compared to other SOTA methods.",
      "With the help of transformers, the SR seems to improve in quality, but there is no analysis on computational complexity.",
      "Normally, when the transformer is used, it can be utilized to reduce the computational load while also improving quality. Does this work also convey such characteristics?",
      "The latest SOTA for SR using transformers is the CVPR 2020 paper TTSR which is not mentioned in the main paper.",
      "There is no comparison with the method either nor in the related works section.",
      "The latest SOTA is essential to show in the paper so that it can be compared to the latest SOTA.",
      "ALthough this work is focussed on SCISR, it is still very related to SR and further uses transformers as a component to the network architecture.",
      "The most similar work is arguably the TTSR which need s to be addressed.",
      "Also, the authors conduct experiments on RDN, RCAN, MetaSR etc.",
      "However, these are somewhat outdated SR models.",
      "Therefore, it is not entirely surprising that the current model outperforms them.",
      "The latest SR models that the authors should consider is definitely TTSR, but also EDVR, EDSR, IGNN, SRGAN etc.",
      "I would say the experimental section is not as extensive as I would have expected.",
      "Although there are not many methods combining transformers with CNNs yet for SR, it is much more relevant to compare with CNN only methods to show the effectiveness for combining an additional module; the transformer."
    ]
  },
  {
    "paper_id": "2112.06174v1",
    "submission_id": "x4t0fxWPNdi",
    "submission_title": "Implicit Transformer Network for Screen Content Image Continuous Super-Resolution",
    "review_id": "FGAxiFaBTz0",
    "input": {
      "title": "Implicit Transformer Network for Screen Content Image Continuous Super-Resolution",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- the problem of arbitrary scale super-resolution of screen content image is addressed in this work, which is a specific subarea of image super-resolution and is rarely studied by researchers.\n- The proposed ITSRN is inspired by LIIF and its performance is improved by implicit transformer and implicit positional coding.\n- In my opinion, the task is interesting and the method is novel.\n- The newly proposed datasets can benchmark this subarea and is helpful for the developing of the subarea.\n- The quality of this paper is above the bar.\n- Technical details are clear and the evaluation is convincing, extensive results are provided to show the effectiveness of implicit transformer and implicit position encoding, some design choices are also empirically verified.\n- What is the complexity of the proposed method, compared to existing state-of-the-arts. This information can help readers know better about the strength of the paper as well as its overhead.\n- As stated in line201-202, 'the 9c-dimensional output is multiplied by the corresponding feature value v, generating the coarse results I_q'. It is a little bit confusing how the multiplication is conducted, because  v is also a 9c-dimensional vector, i am guessing that I_q is a scalar or not? If yes, how to generate the 3-channel output RGB pixel value at q. Please make this more clear to readers.\n- This paper is well organized and is easy to follow.\n- The writing of this paper is good.\n- Though small ambiguity exists as stated above, codes and models are currently available for verification, which is a plus.\n- This work makes a difference to the community.\n- Firstly, the datasets can benchmark the subarea;\n- Secondly, the problem is interesting;\n- Lastly, the method is new and inspiring.",
    "review_points_list": [
      "the problem of arbitrary scale super-resolution of screen content image is addressed in this work, which is a specific subarea of image super-resolution and is rarely studied by researchers.",
      "The proposed ITSRN is inspired by LIIF and its performance is improved by implicit transformer and implicit positional coding.",
      "In my opinion, the task is interesting and the method is novel.",
      "The newly proposed datasets can benchmark this subarea and is helpful for the developing of the subarea.",
      "The quality of this paper is above the bar.",
      "Technical details are clear and the evaluation is convincing, extensive results are provided to show the effectiveness of implicit transformer and implicit position encoding, some design choices are also empirically verified.",
      "What is the complexity of the proposed method, compared to existing state-of-the-arts. This information can help readers know better about the strength of the paper as well as its overhead.",
      "As stated in line201-202, 'the 9c-dimensional output is multiplied by the corresponding feature value v, generating the coarse results I_q'. It is a little bit confusing how the multiplication is conducted, because  v is also a 9c-dimensional vector, i am guessing that I_q is a scalar or not? If yes, how to generate the 3-channel output RGB pixel value at q. Please make this more clear to readers.",
      "This paper is well organized and is easy to follow.",
      "The writing of this paper is good.",
      "Though small ambiguity exists as stated above, codes and models are currently available for verification, which is a plus.",
      "This work makes a difference to the community.",
      "Firstly, the datasets can benchmark the subarea;",
      "Secondly, the problem is interesting;",
      "Lastly, the method is new and inspiring."
    ]
  },
  {
    "paper_id": "2110.05651v2",
    "submission_id": "w0ZNeU5S-l",
    "submission_title": "Learning with Algorithmic Supervision via Continuous Relaxations",
    "review_id": "2FG8d3IbF0X",
    "input": {
      "title": "Learning with Algorithmic Supervision via Continuous Relaxations",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The explanation of their approach to relaxation of these if-else constructs is clear.\n- I like the generalised framework their approach provides.\n- The paper would go over better if it made connections to prior work and how they are specific cases of the framework provided.\n- This allows readers to ground the work in something they may have encountered before and see it more clearly as a generalisation of something they already know.\n- An example would be the Neural Turing Machine, and the various gating systems could be reframed as if-else conditions.\n- Some references of this nature: If-else: Graves, Alex, Greg Wayne, and Ivo Danihelka. 'Neural turing machines.'\n- Stick-breaking while loop - Yogatama, Dani, et al. 'Memory architectures in recurrent neural network language models.'\n- Indexing: Graves, Alex, Greg Wayne, and Ivo Danihelka. 'Neural turing machines.'\n- This work also has some connections to other work that deal with relaxation of known algorithms.\n- Another paper that creates a framework for relaxations of certain structure-based algorithms is: Mensch, Arthur, and Mathieu Blondel. 'Differentiable dynamic programming for structured prediction and attention.'\n- Specifically for the Eisner algorithm: Corro, Caio, and Ivan Titov. 'Differentiable perturb-and-parse: Semi-supervised parsing with a structured variational autoencoder.'\n- Experiments: MNIST Sorting Very surprising that relaxed bubble sort works better than the sinkhorn based method.\n- Warcraft shortest-path: Do you un-relax the algorithm during test time? Using the cost computed with the relaxed approach might result in lower costs.\n- Might be interesting to check how well do the methods generalise to untrained input sizes (e.g. longer lengths for MNIST, larger maps for shortest-path, ...)",
    "review_points_list": [
      "The explanation of their approach to relaxation of these if-else constructs is clear.",
      "I like the generalised framework their approach provides.",
      "The paper would go over better if it made connections to prior work and how they are specific cases of the framework provided.",
      "This allows readers to ground the work in something they may have encountered before and see it more clearly as a generalisation of something they already know.",
      "An example would be the Neural Turing Machine, and the various gating systems could be reframed as if-else conditions.",
      "Some references of this nature: If-else: Graves, Alex, Greg Wayne, and Ivo Danihelka. 'Neural turing machines.'",
      "Stick-breaking while loop - Yogatama, Dani, et al. 'Memory architectures in recurrent neural network language models.'",
      "Indexing: Graves, Alex, Greg Wayne, and Ivo Danihelka. 'Neural turing machines.'",
      "This work also has some connections to other work that deal with relaxation of known algorithms.",
      "Another paper that creates a framework for relaxations of certain structure-based algorithms is: Mensch, Arthur, and Mathieu Blondel. 'Differentiable dynamic programming for structured prediction and attention.'",
      "Specifically for the Eisner algorithm: Corro, Caio, and Ivan Titov. 'Differentiable perturb-and-parse: Semi-supervised parsing with a structured variational autoencoder.'",
      "Experiments: MNIST Sorting Very surprising that relaxed bubble sort works better than the sinkhorn based method.",
      "Warcraft shortest-path: Do you un-relax the algorithm during test time? Using the cost computed with the relaxed approach might result in lower costs.",
      "Might be interesting to check how well do the methods generalise to untrained input sizes (e.g. longer lengths for MNIST, larger maps for shortest-path, ...)"
    ]
  },
  {
    "paper_id": "2110.05651v2",
    "submission_id": "w0ZNeU5S-l",
    "submission_title": "Learning with Algorithmic Supervision via Continuous Relaxations",
    "review_id": "mysEcdDup3N",
    "input": {
      "title": "Learning with Algorithmic Supervision via Continuous Relaxations",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The proposed methodology is well-structured and easy to follow.\n- The authors could improve the presentation of the experimental results, making it easier to understand the significance of their findings.\n- The paper lacks a thorough discussion of the limitations of their approach.",
    "review_points_list": [
      "The proposed methodology is well-structured and easy to follow.",
      "The authors could improve the presentation of the experimental results, making it easier to understand the significance of their findings.",
      "The paper lacks a thorough discussion of the limitations of their approach."
    ]
  },
  {
    "paper_id": "2110.05651v2",
    "submission_id": "w0ZNeU5S-l",
    "submission_title": "Learning with Algorithmic Supervision via Continuous Relaxations",
    "review_id": "1ypD3JrTLRx",
    "input": {
      "title": "Learning with Algorithmic Supervision via Continuous Relaxations",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Although there are many attempts in the literature to propose discrete relaxations for deep networks, these are usually fairly ad-hoc and problem-specific.\n- This proposal focuses on generic strategies for relaxation based on a single core element, the logistic distribution.\n- This means that it is somewhat more formally satisfying than previous proposals.\n- There's also a great focus on avoiding Monte Carlo sampling, which should be very impactful in practice, although this is not explored fully.\n- Thus, I believe that this is a very well-crafted and novel solution to a very general problem.\n- The writing is of good quality, although there are instances that could be more clear, and especially a few where a formula would help make things more concrete.\n- The related work section is relatively thorough and descriptive (except for one omission), and the experiments are well described and cover a wide array of areas, although each experiment in isolation is a bit small-scale.\n- I did not identify any problems with the formulation, which was easy enough to follow.\n- One glaring omission (unless I missed it) is the probabilistic programming literature.\n- They also focus on creating programming primitives that are end-to-end differentiable and propagate distributions, similarly to the propagation of the logistic distribution here.\n- I would expect at least some mention of the core languages, e.g. Church and other works, and how they are distinguished from the present proposal.\n- The section that is the least polished is between lines 150 and 191 ('Complexity and Merging of Paths').\n- Many parts were hard to follow, although in the end they made sense.\n- It seems that a diagram illustrating the branching, nesting and merging of paths, annotated with example probabilities or logistic function visualizations, would aid understanding -- the text should make these concepts as concrete as possible.\n- The 2nd paragraph frames the issue as one of perturbing inputs vs perturbing intermediate variables, which is one aspect, but another side of it is modeling *dependencies* between variables vs considering them as independent.\n- The proposal is to model variables' distributions independently, rather than their joint distribution through a collection of path traces as is common in other works / Monte Carlo approaches.\n- A parallel to independent models such as Naive Bayes is appropriate.\n- I did not understand the argument in line 177 about optimizing an algorithm w.r.t. runtime leading to interpolations.\n- Similarly, the comparison of categorical probability distributions in lines 195-201 is also not well justified; it's also not clear where exactly it is used in experiments.\n- Lines 217-222 would benefit from a formula to make the convolution and normalization process unambiguous; in general this description is too high level.\n- The point about aliasing effects, for example, was not clear.\n- Finally, the convolution with a logistic filter is presented as a major difference w.r.t. other interpolation strategies -- however, the mentioned strategies (bilinear and bicubic) also correspond to well-defined convolution filters (e.g. triangular for bilinear).\n- This needs to be highlighted -- the similarities, not the differences.\n- The main difference would be that the logistic filter has longer tails and has potentially infinite support, while the other two filters are compact, so will not propagate gradients for far away cells.\n- All of this should be discussed more thoroughly.\n- Another part where words were used instead of a formula, creating unnecessary ambiguity, is in line 251; the description of 'we use this variable as a loss function' is puzzling.\n- The proposal for the equality operator (Eq. 9), based on a probability ratio, jumps out as not following from the initial assumptions and comes across as a bit more heuristic.\n- What is the justification for this ratio?\n- This squared hyperbolic secant function is actually the logistic distribution's PDF, so there may be some support there if this is fleshed out.\n- However, the authors could simply compose the tools they already developed to express equality.\n- Since a==b is equivalent to a<=b & a>=b and so to not(a<b)&not(a<b), the probability of equality under the logistic distribution would be simply sigma(b-a)*sigma(a-b).\n- This should have a similar shape to Eq. 9, but does not invoke new assumptions; it just reuses existing machinery.\n- The experiments are adequate, well executed and have some variety; but at least one large-scale experiment would be appreciated to show that this strategy can cope with more realistic scenarios.\n- For example, training a RNN (e.g. on a NLP task) with a stopping criterion would represent a simple application of the conditional branching, which is less complex than the tested algorithms, but at the same time it would showcase its integration with a much larger-scale model and dataset.\n- Another missing aspect is timing -- by avoiding expanding all paths, the proposal should do better than MC-based alternatives; this should be demonstrated with a fair time comparison.\n- In Eq. 7, how are infinite loops dealt with?\n- The probability of looping could never vanish (e.g. for a constant condition).\n- Have the authors considered automatically tuning beta, for example setting it such that the gradients have a minimum absolute magnitude?",
    "review_points_list": [
      "Although there are many attempts in the literature to propose discrete relaxations for deep networks, these are usually fairly ad-hoc and problem-specific.",
      "This proposal focuses on generic strategies for relaxation based on a single core element, the logistic distribution.",
      "This means that it is somewhat more formally satisfying than previous proposals.",
      "There's also a great focus on avoiding Monte Carlo sampling, which should be very impactful in practice, although this is not explored fully.",
      "Thus, I believe that this is a very well-crafted and novel solution to a very general problem.",
      "The writing is of good quality, although there are instances that could be more clear, and especially a few where a formula would help make things more concrete.",
      "The related work section is relatively thorough and descriptive (except for one omission), and the experiments are well described and cover a wide array of areas, although each experiment in isolation is a bit small-scale.",
      "I did not identify any problems with the formulation, which was easy enough to follow.",
      "One glaring omission (unless I missed it) is the probabilistic programming literature.",
      "They also focus on creating programming primitives that are end-to-end differentiable and propagate distributions, similarly to the propagation of the logistic distribution here.",
      "I would expect at least some mention of the core languages, e.g. Church and other works, and how they are distinguished from the present proposal.",
      "The section that is the least polished is between lines 150 and 191 ('Complexity and Merging of Paths').",
      "Many parts were hard to follow, although in the end they made sense.",
      "It seems that a diagram illustrating the branching, nesting and merging of paths, annotated with example probabilities or logistic function visualizations, would aid understanding -- the text should make these concepts as concrete as possible.",
      "The 2nd paragraph frames the issue as one of perturbing inputs vs perturbing intermediate variables, which is one aspect, but another side of it is modeling *dependencies* between variables vs considering them as independent.",
      "The proposal is to model variables' distributions independently, rather than their joint distribution through a collection of path traces as is common in other works / Monte Carlo approaches.",
      "A parallel to independent models such as Naive Bayes is appropriate.",
      "I did not understand the argument in line 177 about optimizing an algorithm w.r.t. runtime leading to interpolations.",
      "Similarly, the comparison of categorical probability distributions in lines 195-201 is also not well justified; it's also not clear where exactly it is used in experiments.",
      "Lines 217-222 would benefit from a formula to make the convolution and normalization process unambiguous; in general this description is too high level.",
      "The point about aliasing effects, for example, was not clear.",
      "Finally, the convolution with a logistic filter is presented as a major difference w.r.t. other interpolation strategies -- however, the mentioned strategies (bilinear and bicubic) also correspond to well-defined convolution filters (e.g. triangular for bilinear).",
      "This needs to be highlighted -- the similarities, not the differences.",
      "The main difference would be that the logistic filter has longer tails and has potentially infinite support, while the other two filters are compact, so will not propagate gradients for far away cells.",
      "All of this should be discussed more thoroughly.",
      "Another part where words were used instead of a formula, creating unnecessary ambiguity, is in line 251; the description of 'we use this variable as a loss function' is puzzling.",
      "The proposal for the equality operator (Eq. 9), based on a probability ratio, jumps out as not following from the initial assumptions and comes across as a bit more heuristic.",
      "What is the justification for this ratio?",
      "This squared hyperbolic secant function is actually the logistic distribution's PDF, so there may be some support there if this is fleshed out.",
      "However, the authors could simply compose the tools they already developed to express equality.",
      "Since a==b is equivalent to a<=b & a>=b and so to not(a<b)&not(a<b), the probability of equality under the logistic distribution would be simply sigma(b-a)*sigma(a-b).",
      "This should have a similar shape to Eq. 9, but does not invoke new assumptions; it just reuses existing machinery.",
      "The experiments are adequate, well executed and have some variety; but at least one large-scale experiment would be appreciated to show that this strategy can cope with more realistic scenarios.",
      "For example, training a RNN (e.g. on a NLP task) with a stopping criterion would represent a simple application of the conditional branching, which is less complex than the tested algorithms, but at the same time it would showcase its integration with a much larger-scale model and dataset.",
      "Another missing aspect is timing -- by avoiding expanding all paths, the proposal should do better than MC-based alternatives; this should be demonstrated with a fair time comparison.",
      "In Eq. 7, how are infinite loops dealt with?",
      "The probability of looping could never vanish (e.g. for a constant condition).",
      "Have the authors considered automatically tuning beta, for example setting it such that the gradients have a minimum absolute magnitude?"
    ]
  },
  {
    "paper_id": "2110.05651v2",
    "submission_id": "w0ZNeU5S-l",
    "submission_title": "Learning with Algorithmic Supervision via Continuous Relaxations",
    "review_id": "RomgUBuZaT",
    "input": {
      "title": "Learning with Algorithmic Supervision via Continuous Relaxations",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This submission is out of my expertise. I suppose it came to me regarding weak supervision but I am not familiar with differentiable algorithms.\n- I asked the AC to remove me from the reviews but.. no response.\n- I will try to review this submission to my understanding.\n- The authors propose continuous relaxations of different algorithmic concepts: comparators, conditional statements, loops, and indexing.\n- The proposed method estimates expectation by sampling-free closed form solution.\n- I cannot consider originality due to my lack of expertise.\n- Eq. 1-5 supports choosing logistic distributions for relaxation.\n- Relaxed comparators are reasonable (Eq. 8-10).\n- Relaxed indexing is somewhat vague because not every array has semantic relationship between neighboring elements (L227-229).\n- The latter case should be covered in the experiments or the reason for not covering should be described.\n- Most parts are clear to understand.\n- Although the proposed method has some pitfalls (e.g., x<x evaluates to 50% and the relaxed indexing is meaningful only if the array is ordered),\n- I suppose providing sampling-free closed form solution is an important contribution to the literature.",
    "review_points_list": [
      "This submission is out of my expertise. I suppose it came to me regarding weak supervision but I am not familiar with differentiable algorithms.",
      "I asked the AC to remove me from the reviews but.. no response.",
      "I will try to review this submission to my understanding.",
      "The authors propose continuous relaxations of different algorithmic concepts: comparators, conditional statements, loops, and indexing.",
      "The proposed method estimates expectation by sampling-free closed form solution.",
      "I cannot consider originality due to my lack of expertise.",
      "Eq. 1-5 supports choosing logistic distributions for relaxation.",
      "Relaxed comparators are reasonable (Eq. 8-10).",
      "Relaxed indexing is somewhat vague because not every array has semantic relationship between neighboring elements (L227-229).",
      "The latter case should be covered in the experiments or the reason for not covering should be described.",
      "Most parts are clear to understand.",
      "Although the proposed method has some pitfalls (e.g., x<x evaluates to 50% and the relaxed indexing is meaningful only if the array is ordered),",
      "I suppose providing sampling-free closed form solution is an important contribution to the literature."
    ]
  },
  {
    "paper_id": "2110.12567v1",
    "submission_id": "th788unrdTj",
    "submission_title": "Alignment Attention by Matching Key and Query Distributions",
    "review_id": "WbDxO2aJTRA",
    "input": {
      "title": "Alignment Attention by Matching Key and Query Distributions",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well written.\n- The paper gives extensive experiments to prove the effectiveness of the proposed approach in terms of various aspects, i.e., accuracy, uncertainty estimation, generalization across domains, and robustness to adversarial attacks.\n- The proposed approach achieves state-of-the-art results on several tasks while remaining efficient in memory and computation cost.\n- The contributions are limited.\n- The idea of alignment learning has been explored in literature.\n- The main contribution of this paper is the methodological contribution, i.e., the alignment attention model, which can align the query and key distributions.\n- However, the motivation is unclear.\n- The motivation and the studied problem are unclear.\n- What problems of the conventional self-attention model can be solved by the proposed approach?\n- What are the problems that will cause if the distributions between query and key are not aligned?\n- Personally, it is unclear what problems of the conventional self-attention model can be solved by the proposed approach?\n- In other words,  what are the problems that will cause if the distributions between query and key are not aligned?\n- In L44-45, the authors claim that 'misalignment could lead to an undesired dependence between the attention weights of a token and its position in the input feature space', however, there is no evidence/experimental analysis that can support this claim.\n- How to prove it?\n- Although the extensive experiments have indeed demonstrated the effectiveness of the proposed approach, I would like to know why performing the alignment of query and key distributions can improve the performance.\n- In the discriminator-based modules, i.e., L137, why do you adopt the complex highway architecture to construct the discriminator?\n- What are the performances of a single MLP (i.e., FC-Relu-FC) or a fully connected layer (i.e., FC)?\n- Besides, to train the discriminator, what are the output dimension in the discriminator and the adopted loss, e.g., BCE/MSE?\n- In Section 2.3, what are the performances of adopting the widely-used distance losses, e.g., KL Loss, to perform the alignment.\n- In Equation (2), what are the performances of exchanging query and key distributions?\n- If the approach brings errors, and what type of errors does it bring, and why?\n- More importantly, are there errors caused by the approach when the model well aligns the distributions of query and key?\n- The margins of the gains in all Tables are small and there appears to be no statistical significance testing.\n- Statistical significant test and error ranges are highly appreciated.\n- In all Tables, I encourage the authors to list several performances of recently published models to help the readers better understand the proposed approach.\n- For the results of all base models in all experiments, it is better to clarify whether the results are reproduced by yourself or copied directly from the original paper.\n- L48: 'emprical' -> 'empirical'; L180: 'is' -> 'are'; L269: 'with maximum' -> 'with a maximum'.",
    "review_points_list": [
      "The paper is well written.",
      "The paper gives extensive experiments to prove the effectiveness of the proposed approach in terms of various aspects, i.e., accuracy, uncertainty estimation, generalization across domains, and robustness to adversarial attacks.",
      "The proposed approach achieves state-of-the-art results on several tasks while remaining efficient in memory and computation cost.",
      "The contributions are limited.",
      "The idea of alignment learning has been explored in literature.",
      "The main contribution of this paper is the methodological contribution, i.e., the alignment attention model, which can align the query and key distributions.",
      "However, the motivation is unclear.",
      "The motivation and the studied problem are unclear.",
      "What problems of the conventional self-attention model can be solved by the proposed approach?",
      "What are the problems that will cause if the distributions between query and key are not aligned?",
      "Personally, it is unclear what problems of the conventional self-attention model can be solved by the proposed approach?",
      "In other words,  what are the problems that will cause if the distributions between query and key are not aligned?",
      "In L44-45, the authors claim that 'misalignment could lead to an undesired dependence between the attention weights of a token and its position in the input feature space', however, there is no evidence/experimental analysis that can support this claim.",
      "How to prove it?",
      "Although the extensive experiments have indeed demonstrated the effectiveness of the proposed approach, I would like to know why performing the alignment of query and key distributions can improve the performance.",
      "In the discriminator-based modules, i.e., L137, why do you adopt the complex highway architecture to construct the discriminator?",
      "What are the performances of a single MLP (i.e., FC-Relu-FC) or a fully connected layer (i.e., FC)?",
      "Besides, to train the discriminator, what are the output dimension in the discriminator and the adopted loss, e.g., BCE/MSE?",
      "In Section 2.3, what are the performances of adopting the widely-used distance losses, e.g., KL Loss, to perform the alignment.",
      "In Equation (2), what are the performances of exchanging query and key distributions?",
      "If the approach brings errors, and what type of errors does it bring, and why?",
      "More importantly, are there errors caused by the approach when the model well aligns the distributions of query and key?",
      "The margins of the gains in all Tables are small and there appears to be no statistical significance testing.",
      "Statistical significant test and error ranges are highly appreciated.",
      "In all Tables, I encourage the authors to list several performances of recently published models to help the readers better understand the proposed approach.",
      "For the results of all base models in all experiments, it is better to clarify whether the results are reproduced by yourself or copied directly from the original paper.",
      "L48: 'emprical' -> 'empirical'; L180: 'is' -> 'are'; L269: 'with maximum' -> 'with a maximum'."
    ]
  },
  {
    "paper_id": "2110.12567v1",
    "submission_id": "th788unrdTj",
    "submission_title": "Alignment Attention by Matching Key and Query Distributions",
    "review_id": "Ln751qD3nuA",
    "input": {
      "title": "Alignment Attention by Matching Key and Query Distributions",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper rethinks the dominant self-attention mechanism in both deep neural networks and points out the alignments of query and key distributions in the current attention mechanism are largely unexplored.\n- The motivation of align the projection of both query and key tokens is strong and meaningful as decreasing the risk of misaligned interactions between queries and keys.\n- The paper attempts to take distribution matching into consideration of attention mechanism.\n- The authors proposed three alignment methods attempting to align the attention and finally adopted adversarial training and conditional transport methods to align the distributions.\n- The analyses of methods are theoretical and insightful.\n- The authors conducted extensive experiments in natural language understanding, GNN and VQA domains.\n- The evaluations are not only in-domain dataset, but also out-domain ones to illustrate the generalization across domains.\n- Adversarial attacks are taken into consideration to show the robustness of alignment attention.\n- The experiments are very meticulous and rational to show the effectiveness of alignment attention as a plugin-and-play component.\n- As is known, the multi-head attention mechanism is widely applied in vision tasks like classification, detection and segmentation.\n- The authors have conducted detailed ablations to show effectiveness in NLP, GNN and VQA covering language, graph and multi-modal domains.\n- I suggest supplements of some vision tasks to finalize the ablations would make the paper more completed \n- Do we really need alignment between key and query? As key and query are linear projections of input, the distribution of key and query should be well aligned.\n- Thus I do not think the alignment story is reasonable and suggest weak rejection.",
    "review_points_list": [
      "The paper rethinks the dominant self-attention mechanism in both deep neural networks and points out the alignments of query and key distributions in the current attention mechanism are largely unexplored.",
      "The motivation of align the projection of both query and key tokens is strong and meaningful as decreasing the risk of misaligned interactions between queries and keys.",
      "The paper attempts to take distribution matching into consideration of attention mechanism.",
      "The authors proposed three alignment methods attempting to align the attention and finally adopted adversarial training and conditional transport methods to align the distributions.",
      "The analyses of methods are theoretical and insightful.",
      "The authors conducted extensive experiments in natural language understanding, GNN and VQA domains.",
      "The evaluations are not only in-domain dataset, but also out-domain ones to illustrate the generalization across domains.",
      "Adversarial attacks are taken into consideration to show the robustness of alignment attention.",
      "The experiments are very meticulous and rational to show the effectiveness of alignment attention as a plugin-and-play component.",
      "As is known, the multi-head attention mechanism is widely applied in vision tasks like classification, detection and segmentation.",
      "The authors have conducted detailed ablations to show effectiveness in NLP, GNN and VQA covering language, graph and multi-modal domains.",
      "I suggest supplements of some vision tasks to finalize the ablations would make the paper more completed ",
      "Do we really need alignment between key and query? As key and query are linear projections of input, the distribution of key and query should be well aligned.",
      "Thus I do not think the alignment story is reasonable and suggest weak rejection."
    ]
  },
  {
    "paper_id": "2110.12567v1",
    "submission_id": "th788unrdTj",
    "submission_title": "Alignment Attention by Matching Key and Query Distributions",
    "review_id": "WpMqUpLg-v",
    "input": {
      "title": "Alignment Attention by Matching Key and Query Distributions",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I recommend accepting the paper.\n- In general, this paper is well-written and easy to follow.\n- It aims at studying the interactions between the keys and queries for attention modules.\n- A variety of experiments on different problem settings with different proposed alignment methods are performed, and, the proposed method consistently outperforms the baseline, which proves that explicitly regularizing the key and query distributions can help to improve the feature learning for the attention-based methods.\n- I summarize the strengths and weaknesses as follows:\n- This paper proposes a plug-and-play alignment module that can be applied to various attention-based models.\n- This paper proves that explicitly regularizing the distributions of the key and query feature can help the feature learning of the self-attention module.\n- Three alignment methods are introduced to regularizing the distributions of the keys and queries.\n- The experimental results are convincing.\n- Experiments are performed in different language understanding settings.\n- It shows that the proposed alignment can bring consistent improvements no matter which alignment method is adopted.\n- It lacks the experimental results showing that after being trained with the alignment loss, the distribution of the keys and queries are well-aligned.\n- In the baseline attention module, the keys and queries will be dot-producted, which means they should be of the same feature domain.\n- Thus, it has implicitly introduced the regularization of their alignments.\n- In comparison, the novel part of the proposed method is explicitly modeling the regularization.\n- However, it lacks a detailed explanation on why explicitly align the keys and queries can bring improvements over the baselines.\n- Typos: Line-104 the tensor dimension should be [B, H, w, d]",
    "review_points_list": [
      "I recommend accepting the paper.",
      "In general, this paper is well-written and easy to follow.",
      "It aims at studying the interactions between the keys and queries for attention modules.",
      "A variety of experiments on different problem settings with different proposed alignment methods are performed, and, the proposed method consistently outperforms the baseline, which proves that explicitly regularizing the key and query distributions can help to improve the feature learning for the attention-based methods.",
      "I summarize the strengths and weaknesses as follows:",
      "This paper proposes a plug-and-play alignment module that can be applied to various attention-based models.",
      "This paper proves that explicitly regularizing the distributions of the key and query feature can help the feature learning of the self-attention module.",
      "Three alignment methods are introduced to regularizing the distributions of the keys and queries.",
      "The experimental results are convincing.",
      "Experiments are performed in different language understanding settings.",
      "It shows that the proposed alignment can bring consistent improvements no matter which alignment method is adopted.",
      "It lacks the experimental results showing that after being trained with the alignment loss, the distribution of the keys and queries are well-aligned.",
      "In the baseline attention module, the keys and queries will be dot-producted, which means they should be of the same feature domain.",
      "Thus, it has implicitly introduced the regularization of their alignments.",
      "In comparison, the novel part of the proposed method is explicitly modeling the regularization.",
      "However, it lacks a detailed explanation on why explicitly align the keys and queries can bring improvements over the baselines.",
      "Typos: Line-104 the tensor dimension should be [B, H, w, d]"
    ]
  },
  {
    "paper_id": "2105.14937v2",
    "submission_id": "wfGbrrWgXDm",
    "submission_title": "Safe Pontryagin Differentiable Programming",
    "review_id": "jqyn-2jeJjU",
    "input": {
      "title": "Safe Pontryagin Differentiable Programming",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- There is value in the clear manner in which the authors combine different methods with a machine learning audience in mind, and the authors' description of using log-barrier functions to enforce 'safety' (even if this idea has been presented in the past).\n- The results up to the end of Section 4, including Theorem 1, are directly from: Jin, Wang, Yang, and Mou, 'Pontryagin Differentiable Programming: An End-to-End Learning and Control Framework', NeurIPS 2020.\n- The use of log-barrier functions to travel within the interior of the constraint set is the primary characteristic of Interior Point Methods (IPMs).\n- Viewing this as a notion of 'safe learning' has been done in: Usmanova, Krause, and Kamgarpour, 'Safe non-smooth black-box optimization with application to policy search', L4DC 2020.\n- Liu, Ding, and Liu, 'IPO: Interior-Point Policy Optimization under Constraints', AAAI 2020.\n- Neither of these papers are cited by the authors.\n- The authors strongly overclaim originality in this regard;\n- The authors do not discuss how the approximation of the inner trajectory optimization affects the quality of the outer solution;\n- Finding a feasible initial point is a key challenge when using IPMs.\n- Given this, it is disappointing that the authors did not address the issue of finding a feasible initialization of the parameters theta in the main paper.\n- In Section 7 ('Problem II: Safe Motion Planning'), this point is exacerbated by the authors' choice to experimentally compare their method with the ALTRO solver for trajectory optimization.\n- The authors state: '... solving a constrained optimal control ... is difficult since the popular trajectory optimization methods, such as iLQR and DDP, are designed only for unconstrained systems'\n- There is an entire field of literature and academic community dedicated to trajectory optimization under constraints.\n- Overall, I think the idea of using log-barrier functions to enforce 'safety' in an Interior Point Method (IPM)-style of optimization is a useful perspective for the machine learning community.\n- The authors did well in communicating this idea through their current work.\n- The authors need to spend more time evaluating and communicating the limitations of their method.\n- Much of this could be connected to fundamental limitations of IPMs.\n- Fair experimental comparisons to the state-of-the-art in trajectory optimization, optimal control, and sensitivity analysis would also help improve the quality of this paper.\n- The authors should make an effort to discuss how the approximation of the inner trajectory optimization affects the quality of the outer solution -- an important aspect that the authors seem to have overlooked.",
    "review_points_list": [
      "There is value in the clear manner in which the authors combine different methods with a machine learning audience in mind, and the authors' description of using log-barrier functions to enforce 'safety' (even if this idea has been presented in the past).",
      "The results up to the end of Section 4, including Theorem 1, are directly from: Jin, Wang, Yang, and Mou, 'Pontryagin Differentiable Programming: An End-to-End Learning and Control Framework', NeurIPS 2020.",
      "The use of log-barrier functions to travel within the interior of the constraint set is the primary characteristic of Interior Point Methods (IPMs).",
      "Viewing this as a notion of 'safe learning' has been done in: Usmanova, Krause, and Kamgarpour, 'Safe non-smooth black-box optimization with application to policy search', L4DC 2020.",
      "Liu, Ding, and Liu, 'IPO: Interior-Point Policy Optimization under Constraints', AAAI 2020.",
      "Neither of these papers are cited by the authors.",
      "The authors strongly overclaim originality in this regard;",
      "The authors do not discuss how the approximation of the inner trajectory optimization affects the quality of the outer solution;",
      "Finding a feasible initial point is a key challenge when using IPMs.",
      "Given this, it is disappointing that the authors did not address the issue of finding a feasible initialization of the parameters theta in the main paper.",
      "In Section 7 ('Problem II: Safe Motion Planning'), this point is exacerbated by the authors' choice to experimentally compare their method with the ALTRO solver for trajectory optimization.",
      "The authors state: '... solving a constrained optimal control ... is difficult since the popular trajectory optimization methods, such as iLQR and DDP, are designed only for unconstrained systems'",
      "There is an entire field of literature and academic community dedicated to trajectory optimization under constraints.",
      "Overall, I think the idea of using log-barrier functions to enforce 'safety' in an Interior Point Method (IPM)-style of optimization is a useful perspective for the machine learning community.",
      "The authors did well in communicating this idea through their current work.",
      "The authors need to spend more time evaluating and communicating the limitations of their method.",
      "Much of this could be connected to fundamental limitations of IPMs.",
      "Fair experimental comparisons to the state-of-the-art in trajectory optimization, optimal control, and sensitivity analysis would also help improve the quality of this paper.",
      "The authors should make an effort to discuss how the approximation of the inner trajectory optimization affects the quality of the outer solution -- an important aspect that the authors seem to have overlooked."
    ]
  },
  {
    "paper_id": "2105.14937v2",
    "submission_id": "wfGbrrWgXDm",
    "submission_title": "Safe Pontryagin Differentiable Programming",
    "review_id": "5VUGFbP9kiP",
    "input": {
      "title": "Safe Pontryagin Differentiable Programming",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I found this paper studies a very interesting and important research problem in control learning.\n- The proposed approach will be very potential for many robot learning problems.\n- The experiments on many robotic tasks are very convincing and non-trivial.\n- Could the authors comment on how to improve the solving time of the forward pass?\n- Each iteration, e.g. T=100, might take approximately 1s. If this can be improved, I believe Safe PDP could become more useful, e.g. integrated into an end-to-end task network.\n- It might be interesting if the implementation can be leveraged to exploit GPUs, similar to the way OptNet and cvxpylayers do.\n- If possible for future work, it might be very interesting to see Safe PDP can be used as a layer in an end-to-end network.\n- Reference [1] might be related.",
    "review_points_list": [
      "I found this paper studies a very interesting and important research problem in control learning.",
      "The proposed approach will be very potential for many robot learning problems.",
      "The experiments on many robotic tasks are very convincing and non-trivial.",
      "Could the authors comment on how to improve the solving time of the forward pass?",
      "Each iteration, e.g. T=100, might take approximately 1s. If this can be improved, I believe Safe PDP could become more useful, e.g. integrated into an end-to-end task network.",
      "It might be interesting if the implementation can be leveraged to exploit GPUs, similar to the way OptNet and cvxpylayers do.",
      "If possible for future work, it might be very interesting to see Safe PDP can be used as a layer in an end-to-end network.",
      "Reference [1] might be related."
    ]
  },
  {
    "paper_id": "2105.14937v2",
    "submission_id": "wfGbrrWgXDm",
    "submission_title": "Safe Pontryagin Differentiable Programming",
    "review_id": "pPD2ln4FoX",
    "input": {
      "title": "Safe Pontryagin Differentiable Programming",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper provides a novel and interesting extension of PDP for safety-critical settings.\n- The approach is well-motivated, the theory is well-grounded with reasonable assumptions, and the authors do a good job explaining the intuition and implications of the theoretical results even without including the full proofs in the main paper.\n- The empirical evaluation does a good job showing the efficacy and generality of the proposed method.\n- Overall, I think this is a very solid contribution and is well-suited for NeurIPS.\n- One suggestion for improvement is that non-safe PDP methods should be compared against in the experiments, in order to enable a better discussion of the salient tradeoffs.\n- Another suggestion is that the nascent literature on safe control via neural networks + differentiable optimization layers should also be discussed and ideally compared against in the experiments.\n- These methods do attempt to address similar settings as in the present work, and therefore can potentially provide some 'safe' baselines.\n- Pham, Tu-Hoa, Giovanni De Magistris, and Ryuki Tachibana. 'OptLayer - Practical constrained optimization for deep reinforcement learning in the real world.' 2018 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2018.\n- Donti, P. L., Roderick, M., Fazlyab, M., & Kolter, J. Z. (2021). Enforcing robust control guarantees within neural network policies. ICLR 2021.\n- Chen, B., Donti, P., Baker, K., Kolter, J. Z., & Berges, M. (2021). Enforcing Policy Feasibility Constraints through Differentiable Projection for Energy Optimization. ACM e-Energy 2021.\n- As an additional question: In the experiments for Problem I, are the controllers evaluated on the true f, or the learned f? This should be made clearer, as evaluating on the learned f could lead to potential over-stating of the results.\n- Minor points, questions, and typo corrections (not affecting my score):\n- Line 113: 'arbitrarily' --> 'arbitrary'\n- Equation 1: Should the dynamics and path constraints have some notion of '$\forall t$' somewhere?\n- Line 160: Since challenge 1 already seems to address how to obtain $\frac{\nabla \text{xi}_{\theta}}{\nabla \theta}$ efficiently (with $\text{O}(T)$ complexity), I was initially confused by the implicit claim in challenge 2 that  $\frac{\nabla \text{xi}_{\theta}}{\nabla \theta}$ is potentially expensive to obtain (and therefore needs to be cheaply obtained via an approximation).\n- Line 160-169: These points should generally be checked for grammar and typos.\n- Line 239: 'motive' --> 'motivate'\n- Line 248, Theorem 2: 'differentiability' is misspelled\n- Line 291, Theorem 3: 'minimizer' is misspelled\n- Line 329: 'exiting' --> 'existing'",
    "review_points_list": [
      "This paper provides a novel and interesting extension of PDP for safety-critical settings.",
      "The approach is well-motivated, the theory is well-grounded with reasonable assumptions, and the authors do a good job explaining the intuition and implications of the theoretical results even without including the full proofs in the main paper.",
      "The empirical evaluation does a good job showing the efficacy and generality of the proposed method.",
      "Overall, I think this is a very solid contribution and is well-suited for NeurIPS.",
      "One suggestion for improvement is that non-safe PDP methods should be compared against in the experiments, in order to enable a better discussion of the salient tradeoffs.",
      "Another suggestion is that the nascent literature on safe control via neural networks + differentiable optimization layers should also be discussed and ideally compared against in the experiments.",
      "These methods do attempt to address similar settings as in the present work, and therefore can potentially provide some 'safe' baselines.",
      "Pham, Tu-Hoa, Giovanni De Magistris, and Ryuki Tachibana. 'OptLayer - Practical constrained optimization for deep reinforcement learning in the real world.' 2018 IEEE International Conference on Robotics and Automation (ICRA). IEEE, 2018.",
      "Donti, P. L., Roderick, M., Fazlyab, M., & Kolter, J. Z. (2021). Enforcing robust control guarantees within neural network policies. ICLR 2021.",
      "Chen, B., Donti, P., Baker, K., Kolter, J. Z., & Berges, M. (2021). Enforcing Policy Feasibility Constraints through Differentiable Projection for Energy Optimization. ACM e-Energy 2021.",
      "As an additional question: In the experiments for Problem I, are the controllers evaluated on the true f, or the learned f? This should be made clearer, as evaluating on the learned f could lead to potential over-stating of the results.",
      "Minor points, questions, and typo corrections (not affecting my score):",
      "Line 113: 'arbitrarily' --> 'arbitrary'",
      "Equation 1: Should the dynamics and path constraints have some notion of '$\forall t$' somewhere?",
      "Line 160: Since challenge 1 already seems to address how to obtain $\frac{\nabla \text{xi}_{\theta}}{\nabla \theta}$ efficiently (with $\text{O}(T)$ complexity), I was initially confused by the implicit claim in challenge 2 that  $\frac{\nabla \text{xi}_{\theta}}{\nabla \theta}$ is potentially expensive to obtain (and therefore needs to be cheaply obtained via an approximation).",
      "Line 160-169: These points should generally be checked for grammar and typos.",
      "Line 239: 'motive' --> 'motivate'",
      "Line 248, Theorem 2: 'differentiability' is misspelled",
      "Line 291, Theorem 3: 'minimizer' is misspelled",
      "Line 329: 'exiting' --> 'existing'"
    ]
  },
  {
    "paper_id": "2403.14685v1",
    "submission_id": "yqj6q_eNTJd",
    "submission_title": "ActCooLR \u2013 High-Level Learning Rate Schedules using Activation Pattern Temperature",
    "review_id": "hSj6Rq2Wlf",
    "input": {
      "title": "ActCooLR \u2013 High-Level Learning Rate Schedules using Activation Pattern Temperature",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The idea of defining and estimating the notion of temperature and linking it to the learning rate is interesting, and the text provides several experiments that explore the development of the temperature throughout the training of several networks.\n- I think there are several aspects of the text that would benefit from further insight in order to understand the potential utility of the temperature measure.\n- How the APT is computed is not clear from the 'computation' paragraph, could the authors provide an algorithm?\n- Except the first few epochs, the APT seems to track the LR very closely (as seen in Fig. 1) and the APT distribution seems to change very little (Fig. 2).\n- Are the changes in APT distributions in early training understood or can they be explored more, and can these changes give insights into the early training process?\n- Beyond that early training, APT seems very closely related to LR, what additional insights about the training development can I get from APT over LR?\n- How does the APT relate to the gradient norms? Or how does it affect parameter trajectories?\n- What is the benefit of using an APT scheduler instead of an LR scheduler?\n- It would seem to require the same amount of schedule design, but more computation to eventually determine the LR is needed with APT.\n- How does designing a temperature schedule, i.e., a schedule damping of non-linear network changes, make the training process easier, it seems as abstract as an LR schedule?\n- How do you know when you are in a chaotic vs non-chaotic non-linear regime, and how can a reader see that controlling APT better navigates these regimes?\n- Table 1 - why are different method comparisons used for every experiment? It makes it challenging to compare methods across experiments.\n- The authors state that only tracking the nonlinear behavior is enough to provide the information needed for step-size control. It was not clear to me how the conclusion was drawn.\n- Are there toy experiments that could show this?\n- I believe the authors have provided detailed answers to all of my questions, and I believe these answers are sufficient and provide more clarification for me.\n- I believe that ensuring this information is clearly discussed in the paper would be an important update for the text.\n- I think the paper would benefit from a deeper mathematical/theoretical exploration of the ideas presented, but the current empirical analysis is still of value.\n- I have updated my scores accordingly.",
    "review_points_list": [
      "The idea of defining and estimating the notion of temperature and linking it to the learning rate is interesting, and the text provides several experiments that explore the development of the temperature throughout the training of several networks.",
      "I think there are several aspects of the text that would benefit from further insight in order to understand the potential utility of the temperature measure.",
      "How the APT is computed is not clear from the 'computation' paragraph, could the authors provide an algorithm?",
      "Except the first few epochs, the APT seems to track the LR very closely (as seen in Fig. 1) and the APT distribution seems to change very little (Fig. 2).",
      "Are the changes in APT distributions in early training understood or can they be explored more, and can these changes give insights into the early training process?",
      "Beyond that early training, APT seems very closely related to LR, what additional insights about the training development can I get from APT over LR?",
      "How does the APT relate to the gradient norms? Or how does it affect parameter trajectories?",
      "What is the benefit of using an APT scheduler instead of an LR scheduler?",
      "It would seem to require the same amount of schedule design, but more computation to eventually determine the LR is needed with APT.",
      "How does designing a temperature schedule, i.e., a schedule damping of non-linear network changes, make the training process easier, it seems as abstract as an LR schedule?",
      "How do you know when you are in a chaotic vs non-chaotic non-linear regime, and how can a reader see that controlling APT better navigates these regimes?",
      "Table 1 - why are different method comparisons used for every experiment? It makes it challenging to compare methods across experiments.",
      "The authors state that only tracking the nonlinear behavior is enough to provide the information needed for step-size control. It was not clear to me how the conclusion was drawn.",
      "Are there toy experiments that could show this?",
      "I believe the authors have provided detailed answers to all of my questions, and I believe these answers are sufficient and provide more clarification for me.",
      "I believe that ensuring this information is clearly discussed in the paper would be an important update for the text.",
      "I think the paper would benefit from a deeper mathematical/theoretical exploration of the ideas presented, but the current empirical analysis is still of value.",
      "I have updated my scores accordingly."
    ]
  },
  {
    "paper_id": "2403.14685v1",
    "submission_id": "yqj6q_eNTJd",
    "submission_title": "ActCooLR \u2013 High-Level Learning Rate Schedules using Activation Pattern Temperature",
    "review_id": "G_REkDwD0o",
    "input": {
      "title": "ActCooLR \u2013 High-Level Learning Rate Schedules using Activation Pattern Temperature",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The main idea presented in the paper, measuring the rate of change to a different linear regime (per linear-ReLU layer) is original and interesting.\n- However, the paper does not yet provide enough theoretical insight or compelling practical methods to warrant being presented to a wide audience.\n- The method, as presented, is only applicable to networks with piece-wise-linear non-linearities, and the adaptive learning-rate introduced does not achieve better results than the alternatives.\n- The paper starts with a good introduction to related work and the problem of hyperparameter scheduling.\n- But the quality of the exposition deteriorates later on in the paper.\n- The reasons why the APT measure is denominated a temperature is not clearly explained given that it is introduced as a log-probability in equation 4.\n- There are several hints in the paper that the authors will connect this measure to temperatures in simulated annealing but this connection is never explicitly presented.\n- Why is APT calculated per layer, and not for the whole network or per unit?\n- This is not even discussed in the main paper.\n- The sequences of theta and M are mentioned to be Markov chains, but this is not necessary for the rest of the exposition.\n- Same when in line 193 the authors mention there are hidden variables responsible for the course of APT, this is rather mysterious and not necessary for the exposition.\n- The figure captions are incomplete and it is necessary to read the main text to understand what is being presented.\n- Sometimes the axis labels used are difficult to understand (e.g. Figure 1 for the validation errors, why use 10^{-0.1} - 10^{-1} instead of 0.8 - 0.1?\n- They introduce Hypothesis 1, and then they support it by saying it fits in practice.\n- This gives a veneer of formality that is not really necessary.\n- Simply saying they are fitting the APT vs learning rate function with a logistic would be clearer.\n- ActCooLR does not obtain better final performance than the alternatives (which are simpler to implement and more general).\n- I would like to end encouraging the authors to pursue the ideas further, as they are interesting but the paper is not yet conference-ready.\n- Some of the ideas left for future work in the paper, like using a different learning-rates per layer, may push the final accuracy and make it a practical alternative for applications.",
    "review_points_list": [
      "The main idea presented in the paper, measuring the rate of change to a different linear regime (per linear-ReLU layer) is original and interesting.",
      "However, the paper does not yet provide enough theoretical insight or compelling practical methods to warrant being presented to a wide audience.",
      "The method, as presented, is only applicable to networks with piece-wise-linear non-linearities, and the adaptive learning-rate introduced does not achieve better results than the alternatives.",
      "The paper starts with a good introduction to related work and the problem of hyperparameter scheduling.",
      "But the quality of the exposition deteriorates later on in the paper.",
      "The reasons why the APT measure is denominated a temperature is not clearly explained given that it is introduced as a log-probability in equation 4.",
      "There are several hints in the paper that the authors will connect this measure to temperatures in simulated annealing but this connection is never explicitly presented.",
      "Why is APT calculated per layer, and not for the whole network or per unit?",
      "This is not even discussed in the main paper.",
      "The sequences of theta and M are mentioned to be Markov chains, but this is not necessary for the rest of the exposition.",
      "Same when in line 193 the authors mention there are hidden variables responsible for the course of APT, this is rather mysterious and not necessary for the exposition.",
      "The figure captions are incomplete and it is necessary to read the main text to understand what is being presented.",
      "Sometimes the axis labels used are difficult to understand (e.g. Figure 1 for the validation errors, why use 10^{-0.1} - 10^{-1} instead of 0.8 - 0.1?",
      "They introduce Hypothesis 1, and then they support it by saying it fits in practice.",
      "This gives a veneer of formality that is not really necessary.",
      "Simply saying they are fitting the APT vs learning rate function with a logistic would be clearer.",
      "ActCooLR does not obtain better final performance than the alternatives (which are simpler to implement and more general).",
      "I would like to end encouraging the authors to pursue the ideas further, as they are interesting but the paper is not yet conference-ready.",
      "Some of the ideas left for future work in the paper, like using a different learning-rates per layer, may push the final accuracy and make it a practical alternative for applications."
    ]
  },
  {
    "paper_id": "2403.14685v1",
    "submission_id": "yqj6q_eNTJd",
    "submission_title": "ActCooLR \u2013 High-Level Learning Rate Schedules using Activation Pattern Temperature",
    "review_id": "KL_RWCtJa-",
    "input": {
      "title": "ActCooLR \u2013 High-Level Learning Rate Schedules using Activation Pattern Temperature",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is elegantly written, very engaging throughout.\n- One impression I get after the first read is that it is more about the temperature concept, aka, APT, than the learning rate scheduler ActCooLR.\n- The title seems to suggest otherwise.\n- One suggestion would be to modify the title to truthfully reflect the content.\n- Probably one remark that would be raised by reviewers, and all readers in general, is that the eventually devised LR scheduler doesn't really work -- on all the experiments it didn't show a superiority over other contemporary methods.\n- I am a strong believer that the merit of a scientific work does not solely depend on the positivity of results.\n- I do believe the APT method, the relationship between LR and APT, and the empirical analysis provide great insight to the community that's actively trying to uncover the mystery of training dynamics.",
    "review_points_list": [
      "The paper is elegantly written, very engaging throughout.",
      "One impression I get after the first read is that it is more about the temperature concept, aka, APT, than the learning rate scheduler ActCooLR.",
      "The title seems to suggest otherwise.",
      "One suggestion would be to modify the title to truthfully reflect the content.",
      "Probably one remark that would be raised by reviewers, and all readers in general, is that the eventually devised LR scheduler doesn't really work -- on all the experiments it didn't show a superiority over other contemporary methods.",
      "I am a strong believer that the merit of a scientific work does not solely depend on the positivity of results.",
      "I do believe the APT method, the relationship between LR and APT, and the empirical analysis provide great insight to the community that's actively trying to uncover the mystery of training dynamics."
    ]
  },
  {
    "paper_id": "2403.14685v1",
    "submission_id": "yqj6q_eNTJd",
    "submission_title": "ActCooLR \u2013 High-Level Learning Rate Schedules using Activation Pattern Temperature",
    "review_id": "FbtlUmb0h9r",
    "input": {
      "title": "ActCooLR \u2013 High-Level Learning Rate Schedules using Activation Pattern Temperature",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I enjoyed the originality and clarity of this paper.\n- There are however a few points that can be improved, and I am not exactly convinced that introducing the APT gives a useful tool to analyze training dynamics, or in other word that this contribution is significant enough for a publication at NeurIPS.\n- What new insight can APT give that other quantities in the literature cannot?\n- Additionally, how can we use the APT to design better neural networks?\n- How did you come up with the formula in eq. 5?\n- Can you make this statement more precise? At first read it looks that you can anticipate on the future (i.e. the new) optimal values for mu?\n- Are you using momentum in the experiments in figure 2? If so, how does it affect the actual step size in parameter space after applying momentum?\n- In Figure 3., you are using momentum. It seems that in this case, the actual APT is not fully determined by the learning rate, but also by the additional momentum term in the update. Can you please discuss how momentum interacts with the APT?\n- I question the choice of a log scale in Fig. 1 right for the APT plot. Aren't we looking at the log of a quantity that is already a log (the temperature)?\n- On the same figure, I find it a little bit weird to use a log scale for the validation error, whereas I have always seen linear scales in other works.\n- Most of the change in accuracy typically occurs during a few training epochs in the beginning, can you maybe reflect that by plotting epochs on a log scale in Figure 2 e.g.?\n- In Figure 3, can you use a log scale for the learning rate, as it typically ranges over several orders of magnitude?",
    "review_points_list": [
      "I enjoyed the originality and clarity of this paper.",
      "There are however a few points that can be improved, and I am not exactly convinced that introducing the APT gives a useful tool to analyze training dynamics, or in other word that this contribution is significant enough for a publication at NeurIPS.",
      "What new insight can APT give that other quantities in the literature cannot?",
      "Additionally, how can we use the APT to design better neural networks?",
      "How did you come up with the formula in eq. 5?",
      "Can you make this statement more precise? At first read it looks that you can anticipate on the future (i.e. the new) optimal values for mu?",
      "Are you using momentum in the experiments in figure 2? If so, how does it affect the actual step size in parameter space after applying momentum?",
      "In Figure 3., you are using momentum. It seems that in this case, the actual APT is not fully determined by the learning rate, but also by the additional momentum term in the update. Can you please discuss how momentum interacts with the APT?",
      "I question the choice of a log scale in Fig. 1 right for the APT plot. Aren't we looking at the log of a quantity that is already a log (the temperature)?",
      "On the same figure, I find it a little bit weird to use a log scale for the validation error, whereas I have always seen linear scales in other works.",
      "Most of the change in accuracy typically occurs during a few training epochs in the beginning, can you maybe reflect that by plotting epochs on a log scale in Figure 2 e.g.?",
      "In Figure 3, can you use a log scale for the learning rate, as it typically ranges over several orders of magnitude?"
    ]
  },
  {
    "paper_id": "2111.00190v1",
    "submission_id": "wGRNAqVBQT2",
    "submission_title": "Leveraging SE(3) Equivariance for Self-supervised Category-Level Object  Pose Estimation from Point Clouds",
    "review_id": "fYbkd2Vlk79",
    "input": {
      "title": "Leveraging SE(3) Equivariance for Self-supervised Category-Level Object  Pose Estimation from Point Clouds",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Clear writing.\n- Experiments on multiple datasets, including both synthetic and real ones.\n- Detailed analysis of failure cases and limitations.\n- The authors miss some important related works.\n- Although relying on multi-view supervision, there is a line of previous works focusing on learning-shape-from-x without GT labels, e.g. [1], [2], [3].\n- Especially, [3] has proposed a quite similar framework, like disentangling canonical shapes and poses, self-supervised losses, as well as selecting the best hypothesis during inference.\n- The major differences are the type of supervision (multi-view) and the network design (PointNet + regression).\n- It also presents many observations mentioned in this paper.\n- For example, symmetric objects like cars are difficult for such self-supervised frameworks.\n- The authors could provide more ablation studies to verify the design choices, which is kind of missing now.\n- Although Sec 2.4 in Supp has presented some results, can the authors analyze the impact of equivariant networks on the shape and pose separately?\n- For example, KPConv (or EPN) for shapes and EPN (or KPConv) for poses.\n- Compared to [3], one key improvement of this paper is to introduce SE(3)-equivariant networks to generate consistent canonical shapes.\n- Another question is how important it is to predict multiple hypotheses for 6D poses.\n- Can the authors study the impact of the number of hypotheses (predefined groups)?\n- And can the authors directly regress poses rather than using any hypothesis?\n- The second car in Figure 2 looks strange.\n- The blue point cloud (canonical shape) in the 3rd column looks different from that in the 2nd column.\n- How stable is the training process?\n- It seems that the network can easily get stuck in local minima (imperfect shapes will lead to wrong poses, and imperfect poses can also lead to imperfect shapes.\n- This phenomenon might be most obvious for cars.)\n- Can the authors report the result of multiple trials of experiments to show the variance of the method?\n- L152: there are two 'j-th', and I think one should be 'j'-th'.\n- L203-L204:  $g_x=\the author of the paperelta g_{x_0} \the author of the papercdot g_x$\n- Weakly-supervised 3d shape completion in the wild",
    "review_points_list": [
      "Clear writing.",
      "Experiments on multiple datasets, including both synthetic and real ones.",
      "Detailed analysis of failure cases and limitations.",
      "The authors miss some important related works.",
      "Although relying on multi-view supervision, there is a line of previous works focusing on learning-shape-from-x without GT labels, e.g. [1], [2], [3].",
      "Especially, [3] has proposed a quite similar framework, like disentangling canonical shapes and poses, self-supervised losses, as well as selecting the best hypothesis during inference.",
      "The major differences are the type of supervision (multi-view) and the network design (PointNet + regression).",
      "It also presents many observations mentioned in this paper.",
      "For example, symmetric objects like cars are difficult for such self-supervised frameworks.",
      "The authors could provide more ablation studies to verify the design choices, which is kind of missing now.",
      "Although Sec 2.4 in Supp has presented some results, can the authors analyze the impact of equivariant networks on the shape and pose separately?",
      "For example, KPConv (or EPN) for shapes and EPN (or KPConv) for poses.",
      "Compared to [3], one key improvement of this paper is to introduce SE(3)-equivariant networks to generate consistent canonical shapes.",
      "Another question is how important it is to predict multiple hypotheses for 6D poses.",
      "Can the authors study the impact of the number of hypotheses (predefined groups)?",
      "And can the authors directly regress poses rather than using any hypothesis?",
      "The second car in Figure 2 looks strange.",
      "The blue point cloud (canonical shape) in the 3rd column looks different from that in the 2nd column.",
      "How stable is the training process?",
      "It seems that the network can easily get stuck in local minima (imperfect shapes will lead to wrong poses, and imperfect poses can also lead to imperfect shapes.",
      "This phenomenon might be most obvious for cars.)",
      "Can the authors report the result of multiple trials of experiments to show the variance of the method?",
      "L152: there are two 'j-th', and I think one should be 'j'-th'.",
      "L203-L204:  $g_x=\the author of the paperelta g_{x_0} \the author of the papercdot g_x$",
      "Weakly-supervised 3d shape completion in the wild"
    ]
  },
  {
    "paper_id": "2111.00190v1",
    "submission_id": "wGRNAqVBQT2",
    "submission_title": "Leveraging SE(3) Equivariance for Self-supervised Category-Level Object  Pose Estimation from Point Clouds",
    "review_id": "uu1jPeNeN44",
    "input": {
      "title": "Leveraging SE(3) Equivariance for Self-supervised Category-Level Object  Pose Estimation from Point Clouds",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is difficult to digest due to the writing due to a large number of typos. For example, on lines 65-68, features for 6D pose estimation can be equivariant rather than the problem itself.\n- The design of canonical reconstruction and using residual pose predictions for progressive alignment to canonical space is not novel in the field.\n- The proposed method can be considered to combine two branches of canonical reconstruction and pose estimation in a self-supervised manner.\n- However, due to lack of canonical reference, ideally canonical reconstruction can be affected by intra-class shape variations and inaccurate pose predictions.\n- The authors are suggested to explain its effects on pose estimation and do some ablation studies, which are missing in the paper.",
    "review_points_list": [
      "The paper is difficult to digest due to the writing due to a large number of typos. For example, on lines 65-68, features for 6D pose estimation can be equivariant rather than the problem itself.",
      "The design of canonical reconstruction and using residual pose predictions for progressive alignment to canonical space is not novel in the field.",
      "The proposed method can be considered to combine two branches of canonical reconstruction and pose estimation in a self-supervised manner.",
      "However, due to lack of canonical reference, ideally canonical reconstruction can be affected by intra-class shape variations and inaccurate pose predictions.",
      "The authors are suggested to explain its effects on pose estimation and do some ablation studies, which are missing in the paper."
    ]
  },
  {
    "paper_id": "2312.08662v1",
    "submission_id": "zOngaSKrElL",
    "submission_title": "Self-Supervised Bug Detection and Repair",
    "review_id": "txs8Uob9F3k",
    "input": {
      "title": "Self-Supervised Bug Detection and Repair",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper is well-organized and the analysis of the experimental results seems very sufficient.\n- Furthermore, it provides a novel approach with self-supervised techniques to detect and repair bugs.\n- Compared with current approaches that mostly based on a supervised learning approach for vulnerability-related tasks, the approach is interesting.\n- Specifically, it contains two different models, the first one is the detector model to detect buggy code, and the second one is the bug selector model to introduce some bugs in the original code by the self-defined rewrite rules.\n- It further contains some operations for data augmentation.",
    "review_points_list": [
      "This paper is well-organized and the analysis of the experimental results seems very sufficient.",
      "Furthermore, it provides a novel approach with self-supervised techniques to detect and repair bugs.",
      "Compared with current approaches that mostly based on a supervised learning approach for vulnerability-related tasks, the approach is interesting.",
      "Specifically, it contains two different models, the first one is the detector model to detect buggy code, and the second one is the bug selector model to introduce some bugs in the original code by the self-defined rewrite rules.",
      "It further contains some operations for data augmentation."
    ]
  },
  {
    "paper_id": "2312.08662v1",
    "submission_id": "zOngaSKrElL",
    "submission_title": "Self-Supervised Bug Detection and Repair",
    "review_id": "T2lxXLtZ_--",
    "input": {
      "title": "Self-Supervised Bug Detection and Repair",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The idea of using a localization+repair model as both a bug injector and a bug fixer is neat and unusual.\n- Augmentation with buggy or 'semantics-preserving' rewrites is otherwise not that new (e.g., the Ramakrishnan et al., and Vasic et al. papers cited used semantics-preserving rewrites as well, but also 'Generating Adversarial Computer Programs using Optimized Obfuscations' from ICLR21).\n- The submission is well described, but the actual benefit of the learned bug selector is not adequately evaluated in my opinion.\n- Baselines are well studied.\n- The submission is reasonably well written, but it leaves important information in the appendix.\n- The training regime is very very briefly described in the main paper.\n- The evaluation is very well presented.\n- The idea of a form of 'curriculum training' where hard-to-fix bugs are injected into the training dataset is neat and seems important for this (and many) code-understanding model.\n- The results seem positive and advance the state of the art.\n- A new dataset of simple Python bugs from actual open-source projects is a valuable contribution and is likely to be used by many future papers in this space.\n- New previously-undiscovered bugs were found in open-source projects!\n- This was a fun paper to read!\n- The teacher/learner formulation was interesting, reminiscent of adversarial training, and not often used in this space (there are a handful of adversarial robustness papers for code, but that's about it).\n- As such, this was an intriguing approach.\n- What's more, results matter: the authors found a few real bugs in open-source software, some of which were confirmed.\n- To my knowledge, similar neural bug-finding systems haven't revealed many real bugs, and tend to focus on synthetic datasets, so this is a great new result from this work.\n- My main concern is that, although the experimental results seem positive and encouraging, why exactly they look like that is not very clear from the experimental evaluation or the design.\n- In part, that's because the bug fixer and the bug injector are operating asynchronously, rather than in controlled fixed-length generations.\n- The authors don't provide justification for this design choice.\n- It's not clear how the bug injector's performance changes over time, or how diverse the samples it generates are.\n- Are they harder over time? Or is this just a matter of adding more noise to the training data for the bug fixer?\n- For example, the difference between the Random Selector and PyBugLab on table 1 is quite small.\n- If we could compare the two on the same number of generations of the same length for the fixer and injector, perhaps we could draw some solid conclusions.\n- Given how close the results are, and given that we see no confidence intervals from multiple experiment repetitions, it's very hard to believe that this is a repeatable, stable result.\n- While we're at it, what exactly is the difference between the Random Selector and Supervised rows of Table 1?\n- Isn't that just changing the initial data generator to create more buggy examples than bug-free examples?\n- Does this serve any other purpose?\n- I'd recommend that the authors make the experiment a bit more controllable, and show how the bug fixer's performance on the test dataset evolves over time with the learned injector, the random injector, and the original dataset.\n- Another related question is why we don't see a line in that table for the semantic rewrites.\n- This seems to be a standard tool, and appears to be working well, so it would be useful to understand how the no-injector model, or the random-injector model would work with the static, ahead-of-time data augmentation.\n- So overall, it's not obvious to me that the learned bug injector actually does something, and if it does, whether it's big.\n- Maybe it's the data augmentation (semantics preserving or synthetic bug injection) that does the trick.\n- I'd like to understand better the the contribution of the learned bug injector is significant.\n- A related concern is sample efficiency.\n- Because the training mechanism is rather ambiguous due to its asynchronous execution, we don't really know what the training dataset size is, or how many actual samples the bug detector saw before converging to its best behavior.\n- Would training it longer but with less fancy an augmentation mechanism have achieved similar results?\n- A smaller concern is about the actual model architecture.\n- Having to manually define scoring functions per concrete rewrite seems super awkward and unscalable.\n- This is most glaring in the case of literal repair, where to limit the number of candidate rewrites that must be scored, the possible repairs is limited to just a few (-2, -1, ...).\n- I wonder if a generative rewrite approach (perhaps like AnyCodeGen from ICML 20 or 'Generative code modelling with graphs' from ICLR19) might be a more scalable approach, perhaps harder to train of course.\n- I liked the augmentation approach used, and it seems to help.\n- However, calling it 'semantics preserving' is a bit of a misnomer.\n- Python has very intrusive reflection capabilities.\n- Changing docstrings and renaming variables changes the semantics of the program.\n- For example, if you rename variables in this program, you will cause an assertion error:\n- MY_VARIABLE = 42\n- def f():\n- assert globals()['MY_VARIABLE'] == 42\n- Certainly there are good reasons not to write such a Python program, but the fact remains that your rewrites are not semantics preserving.\n- Please don't call them that.\n- Why isn't your 'semantics-preserving rewrite' also an operation that the bug selector can train on and introduce in the same way as the bug injections?\n- Arguably, such a rewrite might also throw off the detector, so trying to find such hard rewrites would be valuable for the selector.\n- Why are the two (bug injections, benign rewrites) treated differently?\n- I found the comparisons to strong baselines well done.\n- I was particularly impressed with the validation against the original datasets for the GREAT re-implementation (in the appendix).\n- I was originally concerned with your finding that the GNN does better than GREAT, despite the findings in that paper.\n- It was good to read the steps you took to ensure you weren't misrepresenting GREAT (although of course, it's still a mystery).\n- A brief mention in the main paper that you did all that would have been nice, since without at least a pointer, the reader is left suspicious.\n- The comparison to the CuBERT baseline was also helpful in contextualizing the benefits of your approach.\n- I was curious why you didn't also show the performance of your model on the CuBERT benchmarks (for the same tasks you chose).\n- For the same number of total samples seen by the bug detector (ignoring the selector), how do the various approaches compare?\n- Is augmentation with semantics-preserving rewrites by itself able to give better results?\n- Why are rewrites and bug injections treated differently? Aren't they both types of augmentation?",
    "review_points_list": [
      "The idea of using a localization+repair model as both a bug injector and a bug fixer is neat and unusual.",
      "Augmentation with buggy or 'semantics-preserving' rewrites is otherwise not that new (e.g., the Ramakrishnan et al., and Vasic et al. papers cited used semantics-preserving rewrites as well, but also 'Generating Adversarial Computer Programs using Optimized Obfuscations' from ICLR21).",
      "The submission is well described, but the actual benefit of the learned bug selector is not adequately evaluated in my opinion.",
      "Baselines are well studied.",
      "The submission is reasonably well written, but it leaves important information in the appendix.",
      "The training regime is very very briefly described in the main paper.",
      "The evaluation is very well presented.",
      "The idea of a form of 'curriculum training' where hard-to-fix bugs are injected into the training dataset is neat and seems important for this (and many) code-understanding model.",
      "The results seem positive and advance the state of the art.",
      "A new dataset of simple Python bugs from actual open-source projects is a valuable contribution and is likely to be used by many future papers in this space.",
      "New previously-undiscovered bugs were found in open-source projects!",
      "This was a fun paper to read!",
      "The teacher/learner formulation was interesting, reminiscent of adversarial training, and not often used in this space (there are a handful of adversarial robustness papers for code, but that's about it).",
      "As such, this was an intriguing approach.",
      "What's more, results matter: the authors found a few real bugs in open-source software, some of which were confirmed.",
      "To my knowledge, similar neural bug-finding systems haven't revealed many real bugs, and tend to focus on synthetic datasets, so this is a great new result from this work.",
      "My main concern is that, although the experimental results seem positive and encouraging, why exactly they look like that is not very clear from the experimental evaluation or the design.",
      "In part, that's because the bug fixer and the bug injector are operating asynchronously, rather than in controlled fixed-length generations.",
      "The authors don't provide justification for this design choice.",
      "It's not clear how the bug injector's performance changes over time, or how diverse the samples it generates are.",
      "Are they harder over time? Or is this just a matter of adding more noise to the training data for the bug fixer?",
      "For example, the difference between the Random Selector and PyBugLab on table 1 is quite small.",
      "If we could compare the two on the same number of generations of the same length for the fixer and injector, perhaps we could draw some solid conclusions.",
      "Given how close the results are, and given that we see no confidence intervals from multiple experiment repetitions, it's very hard to believe that this is a repeatable, stable result.",
      "While we're at it, what exactly is the difference between the Random Selector and Supervised rows of Table 1?",
      "Isn't that just changing the initial data generator to create more buggy examples than bug-free examples?",
      "Does this serve any other purpose?",
      "I'd recommend that the authors make the experiment a bit more controllable, and show how the bug fixer's performance on the test dataset evolves over time with the learned injector, the random injector, and the original dataset.",
      "Another related question is why we don't see a line in that table for the semantic rewrites.",
      "This seems to be a standard tool, and appears to be working well, so it would be useful to understand how the no-injector model, or the random-injector model would work with the static, ahead-of-time data augmentation.",
      "So overall, it's not obvious to me that the learned bug injector actually does something, and if it does, whether it's big.",
      "Maybe it's the data augmentation (semantics preserving or synthetic bug injection) that does the trick.",
      "I'd like to understand better the the contribution of the learned bug injector is significant.",
      "A related concern is sample efficiency.",
      "Because the training mechanism is rather ambiguous due to its asynchronous execution, we don't really know what the training dataset size is, or how many actual samples the bug detector saw before converging to its best behavior.",
      "Would training it longer but with less fancy an augmentation mechanism have achieved similar results?",
      "A smaller concern is about the actual model architecture.",
      "Having to manually define scoring functions per concrete rewrite seems super awkward and unscalable.",
      "This is most glaring in the case of literal repair, where to limit the number of candidate rewrites that must be scored, the possible repairs is limited to just a few (-2, -1, ...).",
      "I wonder if a generative rewrite approach (perhaps like AnyCodeGen from ICML 20 or 'Generative code modelling with graphs' from ICLR19) might be a more scalable approach, perhaps harder to train of course.",
      "I liked the augmentation approach used, and it seems to help.",
      "However, calling it 'semantics preserving' is a bit of a misnomer.",
      "Python has very intrusive reflection capabilities.",
      "Changing docstrings and renaming variables changes the semantics of the program.",
      "For example, if you rename variables in this program, you will cause an assertion error:",
      "MY_VARIABLE = 42",
      "def f():",
      "assert globals()['MY_VARIABLE'] == 42",
      "Certainly there are good reasons not to write such a Python program, but the fact remains that your rewrites are not semantics preserving.",
      "Please don't call them that.",
      "Why isn't your 'semantics-preserving rewrite' also an operation that the bug selector can train on and introduce in the same way as the bug injections?",
      "Arguably, such a rewrite might also throw off the detector, so trying to find such hard rewrites would be valuable for the selector.",
      "Why are the two (bug injections, benign rewrites) treated differently?",
      "I found the comparisons to strong baselines well done.",
      "I was particularly impressed with the validation against the original datasets for the GREAT re-implementation (in the appendix).",
      "I was originally concerned with your finding that the GNN does better than GREAT, despite the findings in that paper.",
      "It was good to read the steps you took to ensure you weren't misrepresenting GREAT (although of course, it's still a mystery).",
      "A brief mention in the main paper that you did all that would have been nice, since without at least a pointer, the reader is left suspicious.",
      "The comparison to the CuBERT baseline was also helpful in contextualizing the benefits of your approach.",
      "I was curious why you didn't also show the performance of your model on the CuBERT benchmarks (for the same tasks you chose).",
      "For the same number of total samples seen by the bug detector (ignoring the selector), how do the various approaches compare?",
      "Is augmentation with semantics-preserving rewrites by itself able to give better results?",
      "Why are rewrites and bug injections treated differently? Aren't they both types of augmentation?"
    ]
  },
  {
    "paper_id": "2312.08662v1",
    "submission_id": "zOngaSKrElL",
    "submission_title": "Self-Supervised Bug Detection and Repair",
    "review_id": "uokunvYoEee",
    "input": {
      "title": "Self-Supervised Bug Detection and Repair",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I think that the self-supervised learning approach and the resulting models it produces is valuable for automated bug detection and repair.\n- The evaluation of the models on the real-life bugs is also valuable.\n- The evidence that the tool can find bugs in open-source packages is also positive.\n- The paper should compare their model not just with a baseline, but also with other bug detection and repair models.\n- When run on the real-life software, the tool suffers high false positive rate.\n- For the tool to be useful, this needs to be addressed in future work.\n- Line 30 - what do you mean by 'shows improved performance over training with randomly inserted bugs'?\n- Line 33 - Please state what are the false positive rates.\n- Line 127 - 'other' is repeated.\n- Line 274 - should be 'seems to be'.\n- Line 382 - what limitations did you identify? It is not clear what you mean.",
    "review_points_list": [
      "I think that the self-supervised learning approach and the resulting models it produces is valuable for automated bug detection and repair.",
      "The evaluation of the models on the real-life bugs is also valuable.",
      "The evidence that the tool can find bugs in open-source packages is also positive.",
      "The paper should compare their model not just with a baseline, but also with other bug detection and repair models.",
      "When run on the real-life software, the tool suffers high false positive rate.",
      "For the tool to be useful, this needs to be addressed in future work.",
      "Line 30 - what do you mean by 'shows improved performance over training with randomly inserted bugs'?",
      "Line 33 - Please state what are the false positive rates.",
      "Line 127 - 'other' is repeated.",
      "Line 274 - should be 'seems to be'.",
      "Line 382 - what limitations did you identify? It is not clear what you mean."
    ]
  },
  {
    "paper_id": "2301.11099v1",
    "submission_id": "yJqcM36Qvnu",
    "submission_title": "Federated Graph Classification over Non-IID Graphs",
    "review_id": "A_AegsimizI",
    "input": {
      "title": "Federated Graph Classification over Non-IID Graphs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors recognize an important problem in the non-iidness that occurs in graph datasets within the same domain and naturally across domains.\n- The paper is mostly well written and easy to follow, although a few sections could benefit from clear phrasing.\n- It's unclear what the comparison of random graphs to real-world graphs is meant to illustrate beyond the fact that real-world graphs illustrate certain common properties across domains.\n- The motivation for clustering is entirely dependent on a robust metric of homogeneity.\n- On the one hand, statistical structural properties might be similar between graphs on different clients. But how much do these statistical properties matter?\n- What is the correlation between the expressivity of a GNN trained on different graphs and the statistical similarity between those graphs?\n- From Table 1 we notice that real-world graphs tend to share certain general properties across different graphs, datasets and even domains.\n- This is probably a bit strong claim to be made from the Table 1.\n- The information presented in Table 1 is inadequate to make this claim.\n- At the very least, more datasets need to be investigated.\n- Table 1 in itself doesn't seem like a strong enough motivation for clustering.\n- Graph Clustered Federated Learning needs to be motivated with a real-world use case that satisfies these properties.\n- Where do real-world scenarios with different clients containing heterogeneous features in their graphs/nodes show up?\n- Why would an IMDB-BINARY type dataset ever be split between clients that cannot share data with each other?\n- Or when would a client working on molecular data ever collaborate with a social media company working on social networks?\n- Recent work motivated federated graph learning in the context of molecular graphs, but the features that are used in such a setting are often atom properties which would be fairly homogenous between graphs and clients.\n- So the motivation needs to be better.\n- The technical novelty is limited.\n- Section 4.3 seems more like an application of CFL than a novel approach to clustered federated learning.\n- Moreover, the approach seems general and doesn't seem specific to exploiting any GNN-related specifics.\n- Observations on gradient norm and why GCFL cannot adjust itself make sense, still a general phenomenon in FL.\n- Using DTW is simple and neat, but experimentally, improvement seems not significant.\n- Have you ever tried different window lengths?\n- In the single dataset to number of clients setting, how is the dataset partitioned in a non-iid fashion between clients?\n- The baselines are not strong enough.\n- What is the motivation for the self-train baseline?\n- How does GCFL compare to just CFL being applied?\n- The claim that GCFL can help clients that are training on disparate graphs collaborate needs to be better justified.\n- Maybe I misunderstood, but it seems that the authors are suggesting that the semantic information in the graphs on each client is irrelevant?\n- I am not sure if a client training on social network data can collaborate with a client training on some other GCN models.\n- Hence, collaboration across domains may not be that trivial, in my view.\n- The experiments section needs to be reinforced with more combinations of datasets from different domains to convince readers that such a non-intuitive result holds true in practice.\n- Why is the model used for analysis SGC but the model used in experiments GIN?\n- I understand that it is for the sake of simplicity, but the models are quite different.\n- Do the proofs hold up if the model being analyzed was GIN?\n- Some intuition on this, even if not a full proof, would definitely clear things up.",
    "review_points_list": [
      "The authors recognize an important problem in the non-iidness that occurs in graph datasets within the same domain and naturally across domains.",
      "The paper is mostly well written and easy to follow, although a few sections could benefit from clear phrasing.",
      "It's unclear what the comparison of random graphs to real-world graphs is meant to illustrate beyond the fact that real-world graphs illustrate certain common properties across domains.",
      "The motivation for clustering is entirely dependent on a robust metric of homogeneity.",
      "On the one hand, statistical structural properties might be similar between graphs on different clients. But how much do these statistical properties matter?",
      "What is the correlation between the expressivity of a GNN trained on different graphs and the statistical similarity between those graphs?",
      "From Table 1 we notice that real-world graphs tend to share certain general properties across different graphs, datasets and even domains.",
      "This is probably a bit strong claim to be made from the Table 1.",
      "The information presented in Table 1 is inadequate to make this claim.",
      "At the very least, more datasets need to be investigated.",
      "Table 1 in itself doesn't seem like a strong enough motivation for clustering.",
      "Graph Clustered Federated Learning needs to be motivated with a real-world use case that satisfies these properties.",
      "Where do real-world scenarios with different clients containing heterogeneous features in their graphs/nodes show up?",
      "Why would an IMDB-BINARY type dataset ever be split between clients that cannot share data with each other?",
      "Or when would a client working on molecular data ever collaborate with a social media company working on social networks?",
      "Recent work motivated federated graph learning in the context of molecular graphs, but the features that are used in such a setting are often atom properties which would be fairly homogenous between graphs and clients.",
      "So the motivation needs to be better.",
      "The technical novelty is limited.",
      "Section 4.3 seems more like an application of CFL than a novel approach to clustered federated learning.",
      "Moreover, the approach seems general and doesn't seem specific to exploiting any GNN-related specifics.",
      "Observations on gradient norm and why GCFL cannot adjust itself make sense, still a general phenomenon in FL.",
      "Using DTW is simple and neat, but experimentally, improvement seems not significant.",
      "Have you ever tried different window lengths?",
      "In the single dataset to number of clients setting, how is the dataset partitioned in a non-iid fashion between clients?",
      "The baselines are not strong enough.",
      "What is the motivation for the self-train baseline?",
      "How does GCFL compare to just CFL being applied?",
      "The claim that GCFL can help clients that are training on disparate graphs collaborate needs to be better justified.",
      "Maybe I misunderstood, but it seems that the authors are suggesting that the semantic information in the graphs on each client is irrelevant?",
      "I am not sure if a client training on social network data can collaborate with a client training on some other GCN models.",
      "Hence, collaboration across domains may not be that trivial, in my view.",
      "The experiments section needs to be reinforced with more combinations of datasets from different domains to convince readers that such a non-intuitive result holds true in practice.",
      "Why is the model used for analysis SGC but the model used in experiments GIN?",
      "I understand that it is for the sake of simplicity, but the models are quite different.",
      "Do the proofs hold up if the model being analyzed was GIN?",
      "Some intuition on this, even if not a full proof, would definitely clear things up."
    ]
  },
  {
    "paper_id": "2301.11099v1",
    "submission_id": "yJqcM36Qvnu",
    "submission_title": "Federated Graph Classification over Non-IID Graphs",
    "review_id": "zbL4mRXhJBH",
    "input": {
      "title": "Federated Graph Classification over Non-IID Graphs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- It looks like the objective of GCFL is closer to personalized federated learning instead of standard federated learning. Can the authors clarify on this?\n- The overall technical novelty is somewhat limited. For example, how is the proposed framework different from recent works such as FedCG (Cluster-driven Graph Federated Learning over Multiple Domains), in CVPR'21 workshop?\n- The columns in tables 3&4 can use more explanations, such as the min gain and ratio columns. As they appear now, it requires more thinking to exactly appreciate how they show the advantages of the proposed methods.\n- How do hyper-parameters like \u00ce\u00b5_1 and \u00ce\u00b5_2 influence the performance of the framework?\n- Some minor concerns are as follows:",
    "review_points_list": [
      "It looks like the objective of GCFL is closer to personalized federated learning instead of standard federated learning. Can the authors clarify on this?",
      "The overall technical novelty is somewhat limited. For example, how is the proposed framework different from recent works such as FedCG (Cluster-driven Graph Federated Learning over Multiple Domains), in CVPR'21 workshop?",
      "The columns in tables 3&4 can use more explanations, such as the min gain and ratio columns. As they appear now, it requires more thinking to exactly appreciate how they show the advantages of the proposed methods.",
      "How do hyper-parameters like \u00ce\u00b5_1 and \u00ce\u00b5_2 influence the performance of the framework?",
      "Some minor concerns are as follows:"
    ]
  },
  {
    "paper_id": "2301.11099v1",
    "submission_id": "yJqcM36Qvnu",
    "submission_title": "Federated Graph Classification over Non-IID Graphs",
    "review_id": "JLFcczs0JVY",
    "input": {
      "title": "Federated Graph Classification over Non-IID Graphs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper does not try to sell a bunch of fancy or complicated architectures.\n- Instead, it tells a real scientific story, where every major step including the problem setting, usage of GNN, utilization of clustered FL (and the small improvement) are well motivated and justified through real data analysis and observations.\n- This has been taken for granted in recent works especially related to graph federated learning.\n- In terms of weaknesses, I find certain low-level technical details to be confusing, such as why agglomerative clustering is used for splitting the clusters?\n- Is it following the design of existing clustered FL ?  Is it really ideal?\n- Overall, this paper is well-organized and easy to follow.\n- It provides enough information even for non-expert readers.\n- This paper properly justifies the need of graph classification with federated learning and demonstrates its benefit in different settings (one-dataset, cross-dataset, cross-domain).\n- An easy-to-implement framework composed of GNN and clustered FL is proposed and shown to be effective.\n- Though there exist some issues such as model efficiency, privacy, etc. that should be further studied, this work can serve as a good starting point for research on graph federated learning.",
    "review_points_list": [
      "This paper does not try to sell a bunch of fancy or complicated architectures.",
      "Instead, it tells a real scientific story, where every major step including the problem setting, usage of GNN, utilization of clustered FL (and the small improvement) are well motivated and justified through real data analysis and observations.",
      "This has been taken for granted in recent works especially related to graph federated learning.",
      "In terms of weaknesses, I find certain low-level technical details to be confusing, such as why agglomerative clustering is used for splitting the clusters?",
      "Is it following the design of existing clustered FL ?  Is it really ideal?",
      "Overall, this paper is well-organized and easy to follow.",
      "It provides enough information even for non-expert readers.",
      "This paper properly justifies the need of graph classification with federated learning and demonstrates its benefit in different settings (one-dataset, cross-dataset, cross-domain).",
      "An easy-to-implement framework composed of GNN and clustered FL is proposed and shown to be effective.",
      "Though there exist some issues such as model efficiency, privacy, etc. that should be further studied, this work can serve as a good starting point for research on graph federated learning."
    ]
  },
  {
    "paper_id": "2109.01556v1",
    "submission_id": "ycmcCSoNBx8",
    "submission_title": "Pareto-Optimal Learning-Augmented Algorithms for Online Conversion Problems",
    "review_id": "gu8wmbRTkpw",
    "input": {
      "title": "Pareto-Optimal Learning-Augmented Algorithms for Online Conversion Problems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The algorithm developed in the paper is a so-called online threshold-based algorithm.\n- The challenge lies in defining this threshold function.\n- The algorithm designed in the paper is elegant and the authors put quite a lot of effort into conveying the intuition behind their ideas.\n- They also provide tight lower bounds implying that their algorithm achieves Pareto optimal tradeoffs between robustness and consistency.\n- Parsing the experimental results was quite difficult, and despite going over the section several times, I still cannot say what the actual performance of the algorithms is on these experiments.\n- I would recommend to at least give more descriptive names to the variables and to extend the captions.\n- The paper is presenting interesting and -- to the best of my knowledge -- original results.\n- I did not carefully check all the calculations but at least at an intuitive level it all checks out.\n- - your use of $\thea$ is a bit confusing.\n- In general $\thea$ is used for arbitrarily small values, whereas you use it for the prediction error, which is commonly denoted with $\thea$ and can be quite large in the worst case.",
    "review_points_list": [
      "The algorithm developed in the paper is a so-called online threshold-based algorithm.",
      "The challenge lies in defining this threshold function.",
      "The algorithm designed in the paper is elegant and the authors put quite a lot of effort into conveying the intuition behind their ideas.",
      "They also provide tight lower bounds implying that their algorithm achieves Pareto optimal tradeoffs between robustness and consistency.",
      "Parsing the experimental results was quite difficult, and despite going over the section several times, I still cannot say what the actual performance of the algorithms is on these experiments.",
      "I would recommend to at least give more descriptive names to the variables and to extend the captions.",
      "The paper is presenting interesting and -- to the best of my knowledge -- original results.",
      "I did not carefully check all the calculations but at least at an intuitive level it all checks out.",
      "- your use of $\thea$ is a bit confusing.",
      "In general $\thea$ is used for arbitrarily small values, whereas you use it for the prediction error, which is commonly denoted with $\thea$ and can be quite large in the worst case."
    ]
  },
  {
    "paper_id": "2109.01556v1",
    "submission_id": "ycmcCSoNBx8",
    "submission_title": "Pareto-Optimal Learning-Augmented Algorithms for Online Conversion Problems",
    "review_id": "Lj7HCRxDeGd",
    "input": {
      "title": "Pareto-Optimal Learning-Augmented Algorithms for Online Conversion Problems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Learning-augmented online algorithms have been a very active research area in recent years, and this paper finds optimal bounds for the conversion problem in this setting, which was not analyzed in this setting before.\n- The paper shows that some naive algorithms fail, and the constructed algorithms are non-trivial.\n- There is a chance that the techniques in this paper could also be used to derive more fine-grained results for conversion problems, i.e., to establish bounds that show how fast the competitive ratio degrades as the prediction error increases.\n- The authors also say that their lower bound technique could be useful for other problems, though to me it would seem that the main steps for the lower bound is to identify an appropriate family of worst-case inputs (which is a very simple one here), and turning it into a lower bound proof is then usually a matter of calculation (which is non-trivial here though).\n- The authors emphasize that tight lower bounds on the pareto-optimal trade-off of consistency and robustness were  previously known only for the ski rental problem.\n- One reason is also that for many problems it is simply not necessary to make such a trade-off: E.g. for caching, MTS, load balancing etc one can use predictions to improve performance with good predictions without having to make any (or only insignificant) sacrifices in the worst-case performance.\n- This is different for the conversion problem, where bad predictions come at a higher cost.\n- I am a bit unsure about how convincing I find the overall motivation for the setting of this problem: Since even in the classical online setting it is assumed already that upper and lower bounds U and L on the conversion rate are known, essentially these are already predictions, so in some sense one could say this paper adds a third prediction to a setting where there were already two.\n- In terms of writing, I found this paper relatively hard to read, and I think much of it could be improved by changing the order in which things are presented.\n- For example, the text at the beginning of section 3.2 is hard to understand for someone that has not read Definition 3.2, Lemma 3.3 and Theorem 3.4 yet.\n- The intuition for the algorithms is also hard to appreciate because it is only given much later than when the algorithms were defined.\n- For example, reading the definition of the six constants in (9) and (10) without any intuition is not particularly enjoyable.\n- Also, no real intuition for Theorem 3.4 is given.\n- In the experimental setup, some things are unclear to me: How do you choose U and L in the experiments?\n- Are the experiments for the 1-max search algorithm or the one-way trading algorithm?\n- Why not both?\n- Is the adjustment of the error level between 0 and 1 for Figure 3a or also the other figures, and do you actually use 0 somewhere or just 0.6 and 1?\n- Overall, I think this is a borderline paper.",
    "review_points_list": [
      "Learning-augmented online algorithms have been a very active research area in recent years, and this paper finds optimal bounds for the conversion problem in this setting, which was not analyzed in this setting before.",
      "The paper shows that some naive algorithms fail, and the constructed algorithms are non-trivial.",
      "There is a chance that the techniques in this paper could also be used to derive more fine-grained results for conversion problems, i.e., to establish bounds that show how fast the competitive ratio degrades as the prediction error increases.",
      "The authors also say that their lower bound technique could be useful for other problems, though to me it would seem that the main steps for the lower bound is to identify an appropriate family of worst-case inputs (which is a very simple one here), and turning it into a lower bound proof is then usually a matter of calculation (which is non-trivial here though).",
      "The authors emphasize that tight lower bounds on the pareto-optimal trade-off of consistency and robustness were  previously known only for the ski rental problem.",
      "One reason is also that for many problems it is simply not necessary to make such a trade-off: E.g. for caching, MTS, load balancing etc one can use predictions to improve performance with good predictions without having to make any (or only insignificant) sacrifices in the worst-case performance.",
      "This is different for the conversion problem, where bad predictions come at a higher cost.",
      "I am a bit unsure about how convincing I find the overall motivation for the setting of this problem: Since even in the classical online setting it is assumed already that upper and lower bounds U and L on the conversion rate are known, essentially these are already predictions, so in some sense one could say this paper adds a third prediction to a setting where there were already two.",
      "In terms of writing, I found this paper relatively hard to read, and I think much of it could be improved by changing the order in which things are presented.",
      "For example, the text at the beginning of section 3.2 is hard to understand for someone that has not read Definition 3.2, Lemma 3.3 and Theorem 3.4 yet.",
      "The intuition for the algorithms is also hard to appreciate because it is only given much later than when the algorithms were defined.",
      "For example, reading the definition of the six constants in (9) and (10) without any intuition is not particularly enjoyable.",
      "Also, no real intuition for Theorem 3.4 is given.",
      "In the experimental setup, some things are unclear to me: How do you choose U and L in the experiments?",
      "Are the experiments for the 1-max search algorithm or the one-way trading algorithm?",
      "Why not both?",
      "Is the adjustment of the error level between 0 and 1 for Figure 3a or also the other figures, and do you actually use 0 somewhere or just 0.6 and 1?",
      "Overall, I think this is a borderline paper."
    ]
  },
  {
    "paper_id": "2109.01556v1",
    "submission_id": "ycmcCSoNBx8",
    "submission_title": "Pareto-Optimal Learning-Augmented Algorithms for Online Conversion Problems",
    "review_id": "4ZO9xKKckoy",
    "input": {
      "title": "Pareto-Optimal Learning-Augmented Algorithms for Online Conversion Problems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper considers the online conversion problem and designs a pareto optimal family of algorithms that utilizes predictions about the maximum conversion rate.\n- I\u2019m a bit unsure about the novelty of this section since OTA\u2019s have been known for online knapsack and one-way trading (essentially fractional online knapsack) from prior work.\n- Even the general framework described here also appears in [15] almost verbatim (see algorithm 1 there).\n- The paper also presents an interesting notion of \u201cgeneralized competitive ratio\u201d that gives a more fine-grained view into the worst-case behavior of the algorithm on different types of instances.\n- Overall, the paper is interesting and designs a non-trivial learning-augmented algorithm for a well-studied online problem.\n- Technically, however, the paper feels a bit lacking and in particular adds limited novelty over prior work in [15], [18], [*]\n- It\u2019s great that the paper also demonstrates tight lower bounds and shows that the proposed algorithm is pareto-optimal.\n- The connection with prior work needs to be established better.\n- For instance, the online conversion problem defined here is the fractional version of the online knapsack problem in [18].\n- Line 46: \u201cmetrical task systems\u201d\n- Some discussion of how the predicted value can be learned and why the absolute value of the prediction and the actual max conversion rate is the appropriate notion of error in this context would be useful.\n- The references are out-of-date.\n- For instance, [3], [11] have appeared at NeurIPS 2020 and ICML 2018 respectively.\n- [*] Data-driven Competitive Algorithms for Online Knapsack and Set Cover. Ali Zeynali, Bo Sun, Mohammad Hajiesmaili, Adam Wierman. AAAI 2021.",
    "review_points_list": [
      "The paper considers the online conversion problem and designs a pareto optimal family of algorithms that utilizes predictions about the maximum conversion rate.",
      "I\u2019m a bit unsure about the novelty of this section since OTA\u2019s have been known for online knapsack and one-way trading (essentially fractional online knapsack) from prior work.",
      "Even the general framework described here also appears in [15] almost verbatim (see algorithm 1 there).",
      "The paper also presents an interesting notion of \u201cgeneralized competitive ratio\u201d that gives a more fine-grained view into the worst-case behavior of the algorithm on different types of instances.",
      "Overall, the paper is interesting and designs a non-trivial learning-augmented algorithm for a well-studied online problem.",
      "Technically, however, the paper feels a bit lacking and in particular adds limited novelty over prior work in [15], [18], [*]",
      "It\u2019s great that the paper also demonstrates tight lower bounds and shows that the proposed algorithm is pareto-optimal.",
      "The connection with prior work needs to be established better.",
      "For instance, the online conversion problem defined here is the fractional version of the online knapsack problem in [18].",
      "Line 46: \u201cmetrical task systems\u201d",
      "Some discussion of how the predicted value can be learned and why the absolute value of the prediction and the actual max conversion rate is the appropriate notion of error in this context would be useful.",
      "The references are out-of-date.",
      "For instance, [3], [11] have appeared at NeurIPS 2020 and ICML 2018 respectively.",
      "[*] Data-driven Competitive Algorithms for Online Knapsack and Set Cover. Ali Zeynali, Bo Sun, Mohammad Hajiesmaili, Adam Wierman. AAAI 2021."
    ]
  },
  {
    "paper_id": "2106.00225v4",
    "submission_id": "xfDXF0I_bt",
    "submission_title": "Locally Valid and Discriminative Prediction Intervals for Deep Learning Models",
    "review_id": "ObIPRYwAcnp",
    "input": {
      "title": "Locally Valid and Discriminative Prediction Intervals for Deep Learning Models",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- A question of conditional validity for the conformal framework has received a lot of attention over the past years.\n- On the theory and clarity side, the paper contains significant flaws.\n- I believe that even formalizing the problem, e.g., validity in section 2.2 requires revisiting.\n- The writing can also be improved substantially as the paper contains a large number of typos.\n- Examples include (there are many more):\n- 1. Links to the equations are entered manually instead of using hyperlinks (line 87 --> \"E.q. 2\", lines 101 and 103).\n- 2. Line 112 --> missing fullstop.\n- 3. I believe that the citation given on line 93 is incorrect.\n- 4. Equations are parts of the sentences (punctuation is needed).\n- 5. In general, it is important to differentiate between confidence and prediction intervals not to introduce confusion.\n- Authors focus on the latter while referring to the former.\n- Finally, regarding the empirical evaluation, I am not convinced that presented simulations illustrate the conditional validity of the proposed procedure.\n- Conditional validity is easy to study at least through simulated examples (see, for example, Romano et al. \"Classification with Valid and Adaptive Coverage\", which is in the classification setting but might point out relevant ideas).\n- Unfortunately, the current work seems not to be ready to be accepted to the conference.",
    "review_points_list": [
      "A question of conditional validity for the conformal framework has received a lot of attention over the past years.",
      "On the theory and clarity side, the paper contains significant flaws.",
      "I believe that even formalizing the problem, e.g., validity in section 2.2 requires revisiting.",
      "The writing can also be improved substantially as the paper contains a large number of typos.",
      "Examples include (there are many more):",
      "1. Links to the equations are entered manually instead of using hyperlinks (line 87 --> \"E.q. 2\", lines 101 and 103).",
      "2. Line 112 --> missing fullstop.",
      "3. I believe that the citation given on line 93 is incorrect.",
      "4. Equations are parts of the sentences (punctuation is needed).",
      "5. In general, it is important to differentiate between confidence and prediction intervals not to introduce confusion.",
      "Authors focus on the latter while referring to the former.",
      "Finally, regarding the empirical evaluation, I am not convinced that presented simulations illustrate the conditional validity of the proposed procedure.",
      "Conditional validity is easy to study at least through simulated examples (see, for example, Romano et al. \"Classification with Valid and Adaptive Coverage\", which is in the classification setting but might point out relevant ideas).",
      "Unfortunately, the current work seems not to be ready to be accepted to the conference."
    ]
  },
  {
    "paper_id": "2106.00225v4",
    "submission_id": "xfDXF0I_bt",
    "submission_title": "Locally Valid and Discriminative Prediction Intervals for Deep Learning Models",
    "review_id": "TSgO2umePU6",
    "input": {
      "title": "Locally Valid and Discriminative Prediction Intervals for Deep Learning Models",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I like the combination of kernel regression and split conformal inference.\n- Overall, I found the method compelling and backed by a solid theoretical argument, though I found the experimental results somewhat limited, both in terms of the interval construct methods that were evaluated, deep learning models, and datasets.\n- There also is a semantic confusion (see above) around confidence vs prediction intervals that warrants addressing.\n- The method relies on the assumption that neural nets (i.e. the embedding function) learns a mapping such that 'similar' inputs end up mapping near to each other in this new space.\n- I believe there is a lot of evidence in the literature for this assumption but it is worth making this assumption explicit.\n- The work is original and combines two ideas to produce a novel uncertainty quantification procedure for deep learning models.\n- Note, however, very similar ideas have been explore for non-deep learning models in the statistical literature, e.g. https://www.tandfonline.com/doi/abs/10.1080/01621459.2012.751873\n- The experiments are of high quality and I offer some suggestions for strengthening them below:\n- The investigation into conditional coverage is limited to tail coverage and, given it is listed as one of the central contributions of the paper, I would like to see more empirical evaluations where other, non-tail subsamples are evaluated.\n- Given the close relationship between kernel methods and Gaussian Processes, it would be nice to include a GP in this comparison. Given the size of some of the datasets, I appreciate GPs could be expensive but it would be nice to see the comparison of how a 90% posterior interval from a GP performs.\n- Evaluations on other kinds of architectures (e.g. CNNs) would also greatly strengthen the results.\n- Prior evaluations of marginal coverage properties of Bayesian and non-Bayesian deep learning models should be acknowledged: https://arxiv.org/abs/2010.03039\n- The work is clearly presented and I found text and experiments easy to follow.\n- The work addresses an important topic and will be of interest to applied and theoretical researchers.",
    "review_points_list": [
      "I like the combination of kernel regression and split conformal inference.",
      "Overall, I found the method compelling and backed by a solid theoretical argument, though I found the experimental results somewhat limited, both in terms of the interval construct methods that were evaluated, deep learning models, and datasets.",
      "There also is a semantic confusion (see above) around confidence vs prediction intervals that warrants addressing.",
      "The method relies on the assumption that neural nets (i.e. the embedding function) learns a mapping such that 'similar' inputs end up mapping near to each other in this new space.",
      "I believe there is a lot of evidence in the literature for this assumption but it is worth making this assumption explicit.",
      "The work is original and combines two ideas to produce a novel uncertainty quantification procedure for deep learning models.",
      "Note, however, very similar ideas have been explore for non-deep learning models in the statistical literature, e.g. https://www.tandfonline.com/doi/abs/10.1080/01621459.2012.751873",
      "The experiments are of high quality and I offer some suggestions for strengthening them below:",
      "The investigation into conditional coverage is limited to tail coverage and, given it is listed as one of the central contributions of the paper, I would like to see more empirical evaluations where other, non-tail subsamples are evaluated.",
      "Given the close relationship between kernel methods and Gaussian Processes, it would be nice to include a GP in this comparison. Given the size of some of the datasets, I appreciate GPs could be expensive but it would be nice to see the comparison of how a 90% posterior interval from a GP performs.",
      "Evaluations on other kinds of architectures (e.g. CNNs) would also greatly strengthen the results.",
      "Prior evaluations of marginal coverage properties of Bayesian and non-Bayesian deep learning models should be acknowledged: https://arxiv.org/abs/2010.03039",
      "The work is clearly presented and I found text and experiments easy to follow.",
      "The work addresses an important topic and will be of interest to applied and theoretical researchers."
    ]
  },
  {
    "paper_id": "2106.00225v4",
    "submission_id": "xfDXF0I_bt",
    "submission_title": "Locally Valid and Discriminative Prediction Intervals for Deep Learning Models",
    "review_id": "9OPwNSfZogn",
    "input": {
      "title": "Locally Valid and Discriminative Prediction Intervals for Deep Learning Models",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The empirical study done by the paper is extensive and has not been done before.\n- However, the paper significantly overstates the novelty in terms of theory and methodology.\n- The main algorithm and theoretical results heavily rely on the work of Guan [2019, 2021], as can be verified by looking at the proof in Appendix A.\n- The authors should transparently discuss the relationship to Guan's work, starting with a citation in the abstract.\n- I strongly suggest that the authors correct me if I am missing some important theory developed in this paper which was not present in Guan's work, in which case I will reconsider my assessment.\n- Strong empirics:\n- As far as I know Guan's proposed method of localization, although having very nice theoretical properties, has not been empirically validated in an extensive study.\n- This paper provides such a study for real world datasets for deep learning models.\n- Section 4 confirms that the localization framework leads to discriminative prediction intervals that are marginally valid as well as have better conditional performance.\n- The authors have considered many standard real world datasets, compared their approach to multiple other UQ methods (conformal and non-conformal), and used multiple meaningful evaluation metrics.\n- The authors comment also on the time required for training and prediction of their method vs other methods.\n- Methodology:\n- This paper discusses learning an adaptive kernel based on the Nadaraya-Watson estimator.\n- Guan's paper considered the localization function or kernel as fixed; thus learning the kernel using data is a new methodological contribution.\n- Once the kernel is learnt, from what I can tell the conformalization technique is exactly the same as Guan's paper, and so are the theoretical guarantees.\n- Is there further development regarding the conformal methodology or theory itself which I have missed?\n- Writing:\n- The writing is clear and easy to follow.\n- However, I feel that there are two significant issues which make the writing unscholarly to the extent that it has affected my overall score.\n- The paper seems to significantly downplay the dependence of their methodology and theory on Guan's paper.\n- The first mention of Guan's paper appear in passing in Section 2.2, which I found very strange.\n- Lines 54-56: ... most conformal methods are only marginally valid [24, 37, 19, 4]. We however seek to construct a CI conditioning on the input.\n- Is there a reason for not discussing the work of Guan [12] in this context? To a reader, it appears that this paper proposes a new solution to the conditional validity problem, whereas in fact the solution used is exactly the same as the one proposed by Guan.\n- Similarly lines 58-66 incorrectly suggest that the method proposed by the authors is new and this problem has not been solved before.\n- Line 286 'This paper introduces LVD, the first locally valid and discriminative CI estimator for DL' also suggests that the conformal methodology is new.\n- The authors should clarify the reason for using the term 'confidence intervals' instead of 'prediction intervals'.\n- Additionally minor comments on writing and related works:\n- The abstract is quite long, and contains many finer details and terminologies.\n- These can be postponed to the introduction or discussion sections.\n- I suggest streamlining the abstract and focusing on the 'big picture' to reach a wider audience.\n- Line 39 'Post-hoc methods are ideal because ...'.\n- While this is common, I believe it is not a necessary property of post-hoc methods.\n- Line 50 'Such methods usually use the prediction errors from a hold-out set to ...'.\n- Such 'split' conformal methods are currently popular due to their efficiency and validity despite their simplicity.\n- However the statement of the authors is a misrepresentation of the well-developed body of conformal prediction.\n- The paper [1] is highly relevant and should be cited somewhere.\n- Eq. (4): Should X have a \tilde above it?\n- Line 112: Missing period \u2018.\u2019 after closing parenthesis.\n- Line 146: The definition of R_i may be somewhat abrupt for readers unfamiliar with conformal prediction",
    "review_points_list": [
      "The empirical study done by the paper is extensive and has not been done before.",
      "However, the paper significantly overstates the novelty in terms of theory and methodology.",
      "The main algorithm and theoretical results heavily rely on the work of Guan [2019, 2021], as can be verified by looking at the proof in Appendix A.",
      "The authors should transparently discuss the relationship to Guan's work, starting with a citation in the abstract.",
      "I strongly suggest that the authors correct me if I am missing some important theory developed in this paper which was not present in Guan's work, in which case I will reconsider my assessment.",
      "Strong empirics:",
      "As far as I know Guan's proposed method of localization, although having very nice theoretical properties, has not been empirically validated in an extensive study.",
      "This paper provides such a study for real world datasets for deep learning models.",
      "Section 4 confirms that the localization framework leads to discriminative prediction intervals that are marginally valid as well as have better conditional performance.",
      "The authors have considered many standard real world datasets, compared their approach to multiple other UQ methods (conformal and non-conformal), and used multiple meaningful evaluation metrics.",
      "The authors comment also on the time required for training and prediction of their method vs other methods.",
      "Methodology:",
      "This paper discusses learning an adaptive kernel based on the Nadaraya-Watson estimator.",
      "Guan's paper considered the localization function or kernel as fixed; thus learning the kernel using data is a new methodological contribution.",
      "Once the kernel is learnt, from what I can tell the conformalization technique is exactly the same as Guan's paper, and so are the theoretical guarantees.",
      "Is there further development regarding the conformal methodology or theory itself which I have missed?",
      "Writing:",
      "The writing is clear and easy to follow.",
      "However, I feel that there are two significant issues which make the writing unscholarly to the extent that it has affected my overall score.",
      "The paper seems to significantly downplay the dependence of their methodology and theory on Guan's paper.",
      "The first mention of Guan's paper appear in passing in Section 2.2, which I found very strange.",
      "Lines 54-56: ... most conformal methods are only marginally valid [24, 37, 19, 4]. We however seek to construct a CI conditioning on the input.",
      "Is there a reason for not discussing the work of Guan [12] in this context? To a reader, it appears that this paper proposes a new solution to the conditional validity problem, whereas in fact the solution used is exactly the same as the one proposed by Guan.",
      "Similarly lines 58-66 incorrectly suggest that the method proposed by the authors is new and this problem has not been solved before.",
      "Line 286 'This paper introduces LVD, the first locally valid and discriminative CI estimator for DL' also suggests that the conformal methodology is new.",
      "The authors should clarify the reason for using the term 'confidence intervals' instead of 'prediction intervals'.",
      "Additionally minor comments on writing and related works:",
      "The abstract is quite long, and contains many finer details and terminologies.",
      "These can be postponed to the introduction or discussion sections.",
      "I suggest streamlining the abstract and focusing on the 'big picture' to reach a wider audience.",
      "Line 39 'Post-hoc methods are ideal because ...'.",
      "While this is common, I believe it is not a necessary property of post-hoc methods.",
      "Line 50 'Such methods usually use the prediction errors from a hold-out set to ...'.",
      "Such 'split' conformal methods are currently popular due to their efficiency and validity despite their simplicity.",
      "However the statement of the authors is a misrepresentation of the well-developed body of conformal prediction.",
      "The paper [1] is highly relevant and should be cited somewhere.",
      "Eq. (4): Should X have a \tilde above it?",
      "Line 112: Missing period \u2018.\u2019 after closing parenthesis.",
      "Line 146: The definition of R_i may be somewhat abrupt for readers unfamiliar with conformal prediction"
    ]
  },
  {
    "paper_id": "2106.00225v4",
    "submission_id": "xfDXF0I_bt",
    "submission_title": "Locally Valid and Discriminative Prediction Intervals for Deep Learning Models",
    "review_id": "HQYzh3FgTD",
    "input": {
      "title": "Locally Valid and Discriminative Prediction Intervals for Deep Learning Models",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- On the whole I was quite impressed with this paper.\n- The authors write clearly throughout.\n- Experimental setup is reasonable, and Figure 1 in particular provides a succinct picture for their motivation.\n- I was left with a few questions and suggestions:\n- 1/ How does the smoothness requirement affect the confidence interval estimates? It would be interesting to repeat the procedure of say Table 3 and 4 as an ablation study to determine its necessity.\n- 2/ It would be helpful to explicitly define Mean Absolute Deviation (MAD) in Section 4.2.\n- 3/ Pearce et al. ICML 2018 directly measures the Mean Prediction Interval Width instead of the MAD, as a measure of discrimination. I'd be curious to see that added as a sub-table of Table 4 (perhaps in the Appendix), to compare the two evaluation metrics.\n- Miscellaneous comments, typos: 1/ It looks like references 18, 19 are duplicates of each other.\n- 2/ Line 221: \"Conforamlized Quantile Regression\".\n- Update: I thank the authors for their response, and for pointing me to Tables 7-10 in the Appendix in particular. After reading through their response, and the other reviewers' comments, I maintain my recommendation that the paper be accepted.",
    "review_points_list": [
      "On the whole I was quite impressed with this paper.",
      "The authors write clearly throughout.",
      "Experimental setup is reasonable, and Figure 1 in particular provides a succinct picture for their motivation.",
      "I was left with a few questions and suggestions:",
      "1/ How does the smoothness requirement affect the confidence interval estimates? It would be interesting to repeat the procedure of say Table 3 and 4 as an ablation study to determine its necessity.",
      "2/ It would be helpful to explicitly define Mean Absolute Deviation (MAD) in Section 4.2.",
      "3/ Pearce et al. ICML 2018 directly measures the Mean Prediction Interval Width instead of the MAD, as a measure of discrimination. I'd be curious to see that added as a sub-table of Table 4 (perhaps in the Appendix), to compare the two evaluation metrics.",
      "Miscellaneous comments, typos: 1/ It looks like references 18, 19 are duplicates of each other.",
      "2/ Line 221: \"Conforamlized Quantile Regression\".",
      "Update: I thank the authors for their response, and for pointing me to Tables 7-10 in the Appendix in particular. After reading through their response, and the other reviewers' comments, I maintain my recommendation that the paper be accepted."
    ]
  },
  {
    "paper_id": "1708.07106v1",
    "submission_id": "xZvuqfT6Otj",
    "submission_title": "Fixes That Fail: Self-Defeating Improvements in Machine-Learning Systems",
    "review_id": "1eZkHm9LUhW",
    "input": {
      "title": "Fixes That Fail: Self-Defeating Improvements in Machine-Learning Systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- well motivated and important topic\n- well-written; intuitive and clean formulation of the problem\n- good visualization of the formulation on toy examples\n- case study demonstrates the existence of the studied problem in practice\n- only one case study is conducted\n- no systematic method is presented to determine which component of the error is the cause of a certain 'self-defeating improvement'\n- this paper is a pleasure to read and believes it will encourage more exploration on this important topic\n- One minor weakness is that the paper only conducts one case study so I am not sure how common the studied 'self-defeating improvement' is in real-world ML systems\n- I wonder if it is possible to distinguish between downstream approximation error and downstream estimation error?\n- Is there a possible systematic way to decompose the error based on the formulation in real-world application like the one in the case study?\n- Regarding fairness in the final bullet point in Conclusion and Future Work, it might worth looking into 'Fairness Under Composition' by Cynthia Dwork and Christina Ilvento\n- Is it possible to also make a visualization for the upstream error similar to Figure 2 and Figure 3?\n- For Figure 4(a), I am a bit confused here. Are the ground-truth for u, v, and w different? Are you using the same color code here as in Figure 2 and Figure 3?",
    "review_points_list": [
      "well motivated and important topic",
      "well-written; intuitive and clean formulation of the problem",
      "good visualization of the formulation on toy examples",
      "case study demonstrates the existence of the studied problem in practice",
      "only one case study is conducted",
      "no systematic method is presented to determine which component of the error is the cause of a certain 'self-defeating improvement'",
      "this paper is a pleasure to read and believes it will encourage more exploration on this important topic",
      "One minor weakness is that the paper only conducts one case study so I am not sure how common the studied 'self-defeating improvement' is in real-world ML systems",
      "I wonder if it is possible to distinguish between downstream approximation error and downstream estimation error?",
      "Is there a possible systematic way to decompose the error based on the formulation in real-world application like the one in the case study?",
      "Regarding fairness in the final bullet point in Conclusion and Future Work, it might worth looking into 'Fairness Under Composition' by Cynthia Dwork and Christina Ilvento",
      "Is it possible to also make a visualization for the upstream error similar to Figure 2 and Figure 3?",
      "For Figure 4(a), I am a bit confused here. Are the ground-truth for u, v, and w different? Are you using the same color code here as in Figure 2 and Figure 3?"
    ]
  },
  {
    "paper_id": "1708.07106v1",
    "submission_id": "xZvuqfT6Otj",
    "submission_title": "Fixes That Fail: Self-Defeating Improvements in Machine-Learning Systems",
    "review_id": "AJPbJJaAQ3J",
    "input": {
      "title": "Fixes That Fail: Self-Defeating Improvements in Machine-Learning Systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Point 1\n- Point 2\n- Point 3",
    "review_points_list": [
      "Point 1",
      "Point 2",
      "Point 3"
    ]
  },
  {
    "paper_id": "1708.07106v1",
    "submission_id": "xZvuqfT6Otj",
    "submission_title": "Fixes That Fail: Self-Defeating Improvements in Machine-Learning Systems",
    "review_id": "lISCOhlOKmr",
    "input": {
      "title": "Fixes That Fail: Self-Defeating Improvements in Machine-Learning Systems",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper explores a relatively less studied problem which will be more relevant as the number of more complex (and modular) machine learning systems increase.\n- The main contribution of the current paper is demonstrating the problem, and providing an analysis of sources of the self-defeating improvements.\n- I think raising awareness and promoting discussion are reasonable contributions. However, paper would be stronger if included some concrete discussion towards solutions (e.g., diagnostics for detecting the problems, or suggestions to avoid them).\n- It is not clear to me whether the case study is a constructed demonstration, or an example that the authors happened to observe in a real study.\n- Although the authors state in the checklist that they did not report variation (error bars) because it was low, I think it would still help reader decide the extent of the differences if the variation was presented in Table 1 and Table 3. Some of the scores in Table 1 are particularly close.\n- The paper is rather dense. In particular, the description of the case study is difficult to understand people outside the field without consulting quite a few additional sources. I think it is important for the current paper to aim for a broader audience.\n- Part of the motivation and problem setting subsection (line 102) is already stated in the introduction, which, I think, is a better place for motivation anyway.\n- Footnote marks should follow punctuation.",
    "review_points_list": [
      "The paper explores a relatively less studied problem which will be more relevant as the number of more complex (and modular) machine learning systems increase.",
      "The main contribution of the current paper is demonstrating the problem, and providing an analysis of sources of the self-defeating improvements.",
      "I think raising awareness and promoting discussion are reasonable contributions. However, paper would be stronger if included some concrete discussion towards solutions (e.g., diagnostics for detecting the problems, or suggestions to avoid them).",
      "It is not clear to me whether the case study is a constructed demonstration, or an example that the authors happened to observe in a real study.",
      "Although the authors state in the checklist that they did not report variation (error bars) because it was low, I think it would still help reader decide the extent of the differences if the variation was presented in Table 1 and Table 3. Some of the scores in Table 1 are particularly close.",
      "The paper is rather dense. In particular, the description of the case study is difficult to understand people outside the field without consulting quite a few additional sources. I think it is important for the current paper to aim for a broader audience.",
      "Part of the motivation and problem setting subsection (line 102) is already stated in the introduction, which, I think, is a better place for motivation anyway.",
      "Footnote marks should follow punctuation."
    ]
  },
  {
    "paper_id": "2010.10549v2",
    "submission_id": "yrqn9rQO2YT",
    "submission_title": "Instance-Dependent Bounds for Zeroth-order Lipschitz Optimization with Error Certificates",
    "review_id": "9OzAD6ZnIDM",
    "input": {
      "title": "Instance-Dependent Bounds for Zeroth-order Lipschitz Optimization with Error Certificates",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper considers the version of zeroth-order lipschitz optimization with certification.\n- Considering certification is novel, but its motivation needs further justification.\n- For example, is the goal of certification only to certify the $eps-optim...\n- ...or to certify every point generated by the algorithm?\n- If we only want to provide certification for the $eps-optim... point, then bandit optimization algorithms can do as well...\n- The goal to certify the output of the algorithm generated in every round, in the contrary, seems extravagant since we don't care about certification when the output is far away from optimal.\n- It's not too surprising that one can get instance-dependent bounds, since certification essentially requires 'exploring every corner of X' at a high level.\n- My main concern is on the constant $c$ and its dependence on $d$.\n- Roughly speaking, $c$ is the product of two terms, where the first is $L^d/v_1$ and the second is $(1-Lip(f)/L)^d$.\n- The second term is exponentially small (in $d$), which is problematic (it hurts the tightness of the upper bound) even if $d$ is seen as a constant.\n- The first term is either exponentially large or exponentially small in $d$, depending on whether $L$ is above a constant threshold.\n- This seems unnatural as one can easily scale the function to be $l$-lipschitz for arbitrary $l$, and finding an $eps... point will suffice.\n- Moreover, $\u03b3 isn't completely independent of $d either, because the value of $\u03b3 would be not mild at all for large $d whereas the same value might be mild for low dimension.\n- This paper is overall well-written, except that the end of Section 4 ($L=Lip(f)$ case) should be written in a separate section with more details.\n- Adding proof sketches instead of putting technical proofs in the main text would improve readability.\n- This work solves an existing open problem.\n- Though whether the proposed algorithm could be useful in practice is unclear, it's of importance from a theoretical perspective.",
    "review_points_list": [
      "This paper considers the version of zeroth-order lipschitz optimization with certification.",
      "Considering certification is novel, but its motivation needs further justification.",
      "For example, is the goal of certification only to certify the $eps-optim...",
      "...or to certify every point generated by the algorithm?",
      "If we only want to provide certification for the $eps-optim... point, then bandit optimization algorithms can do as well...",
      "The goal to certify the output of the algorithm generated in every round, in the contrary, seems extravagant since we don't care about certification when the output is far away from optimal.",
      "It's not too surprising that one can get instance-dependent bounds, since certification essentially requires 'exploring every corner of X' at a high level.",
      "My main concern is on the constant $c$ and its dependence on $d$.",
      "Roughly speaking, $c$ is the product of two terms, where the first is $L^d/v_1$ and the second is $(1-Lip(f)/L)^d$.",
      "The second term is exponentially small (in $d$), which is problematic (it hurts the tightness of the upper bound) even if $d$ is seen as a constant.",
      "The first term is either exponentially large or exponentially small in $d$, depending on whether $L$ is above a constant threshold.",
      "This seems unnatural as one can easily scale the function to be $l$-lipschitz for arbitrary $l$, and finding an $eps... point will suffice.",
      "Moreover, $\u03b3 isn't completely independent of $d either, because the value of $\u03b3 would be not mild at all for large $d whereas the same value might be mild for low dimension.",
      "This paper is overall well-written, except that the end of Section 4 ($L=Lip(f)$ case) should be written in a separate section with more details.",
      "Adding proof sketches instead of putting technical proofs in the main text would improve readability.",
      "This work solves an existing open problem.",
      "Though whether the proposed algorithm could be useful in practice is unclear, it's of importance from a theoretical perspective."
    ]
  },
  {
    "paper_id": "2010.10549v2",
    "submission_id": "yrqn9rQO2YT",
    "submission_title": "Instance-Dependent Bounds for Zeroth-order Lipschitz Optimization with Error Certificates",
    "review_id": "G6eSf6OQ0z1",
    "input": {
      "title": "Instance-Dependent Bounds for Zeroth-order Lipschitz Optimization with Error Certificates",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper studies the complexity of certifiable zeroth-order optimization of Lipschitz functions.\n- Given oracle access to evaluations of a $L$-Lipschitz function $f$ over a known compact domain $\text{X}$ and an error parameter, $\text{epsilon} > 0$, the goal is to find a point $\text{x\u0302}$ satisfying $f (\text{x\u0302}) \text{\u2265} \text{max}_x f (x) - \text{epsilon}$\n- The paper characterizes the optimal oracle complexity of the problem in an instance dependent sense where the number of queries made to the oracle depend on the behavior of the particular function.\n- They show that the number of queries that necessarily must be made to the oracle is $\text{\u222b}_{\text{X}} d \textbf{x} / (\text{max}(f) - f(\textbf{x})  + \text{epsilon})^d$ up to constant factors depending (exponentially) on the dimension.\n- The right notion of complexity in the instance dependent setting is a little tricky as the optimal algorithm in the instance dependent setting would be one that simply outputs the optimizer of the particular function in question.\n- However, if one additionally imposes the requirement of certification which is essentially that the algorithm must output a correct answer for \textit{any} Lipschitz function over $\text{X}$, one obtains nontrivial bounds.\n- There seem to be two main technical contributions in the paper.\n- Firstly, noting that a modification of the Deterministic Optimistic Optimization algorithm by Munos (2011) obtains a sample complexity of:\n- They show that under reasonable assumptions on $\text{X}$, the integral is a dimension-dependent constant factor approximation of the integral characterizing the optimal upper and lower bounds.\n- Secondly, they show any certified algorithm must incur an oracle complexity of:\n- providing some justification on why $1 - \text{Lip} (f) / L$ factor in the lower bound may be inherent.\n- In proving the lower bound, they show that any algorithm making fewer than the number characterized by the lower bound for some function $f$ must make an error on a related function $f'$ constructed by perturbing $f$ using a precisely constructed bump function around a close-to-optimal point of $f$.\n- The construction itself is fairly intuitive but yields near-optimal results.\n- Overall, the paper makes progress on a natural question relating to a fundamental problem that is of interest to the NeurIPS community.\n- The proofs themselves are quite natural and intuitive though one small caveat is that the assumption on $\text{X}$ (Assumption 4) while seemingly reasonable is a little difficult to reason about.\n- Additional exposition on the types of sets for which it may (or may not) hold would be quite helpful.\n- After reviewing the authors response, I am convinced of the technical quality of the results in the paper and the assumptions underlying them.\n- I will retain my recommendation to accept the paper.",
    "review_points_list": [
      "The paper studies the complexity of certifiable zeroth-order optimization of Lipschitz functions.",
      "Given oracle access to evaluations of a $L$-Lipschitz function $f$ over a known compact domain $\text{X}$ and an error parameter, $\text{epsilon} > 0$, the goal is to find a point $\text{x\u0302}$ satisfying $f (\text{x\u0302}) \text{\u2265} \text{max}_x f (x) - \text{epsilon}$",
      "The paper characterizes the optimal oracle complexity of the problem in an instance dependent sense where the number of queries made to the oracle depend on the behavior of the particular function.",
      "They show that the number of queries that necessarily must be made to the oracle is $\text{\u222b}_{\text{X}} d \textbf{x} / (\text{max}(f) - f(\textbf{x})  + \text{epsilon})^d$ up to constant factors depending (exponentially) on the dimension.",
      "The right notion of complexity in the instance dependent setting is a little tricky as the optimal algorithm in the instance dependent setting would be one that simply outputs the optimizer of the particular function in question.",
      "However, if one additionally imposes the requirement of certification which is essentially that the algorithm must output a correct answer for \textit{any} Lipschitz function over $\text{X}$, one obtains nontrivial bounds.",
      "There seem to be two main technical contributions in the paper.",
      "Firstly, noting that a modification of the Deterministic Optimistic Optimization algorithm by Munos (2011) obtains a sample complexity of:",
      "They show that under reasonable assumptions on $\text{X}$, the integral is a dimension-dependent constant factor approximation of the integral characterizing the optimal upper and lower bounds.",
      "Secondly, they show any certified algorithm must incur an oracle complexity of:",
      "providing some justification on why $1 - \text{Lip} (f) / L$ factor in the lower bound may be inherent.",
      "In proving the lower bound, they show that any algorithm making fewer than the number characterized by the lower bound for some function $f$ must make an error on a related function $f'$ constructed by perturbing $f$ using a precisely constructed bump function around a close-to-optimal point of $f$.",
      "The construction itself is fairly intuitive but yields near-optimal results.",
      "Overall, the paper makes progress on a natural question relating to a fundamental problem that is of interest to the NeurIPS community.",
      "The proofs themselves are quite natural and intuitive though one small caveat is that the assumption on $\text{X}$ (Assumption 4) while seemingly reasonable is a little difficult to reason about.",
      "Additional exposition on the types of sets for which it may (or may not) hold would be quite helpful.",
      "After reviewing the authors response, I am convinced of the technical quality of the results in the paper and the assumptions underlying them.",
      "I will retain my recommendation to accept the paper."
    ]
  },
  {
    "paper_id": "2010.10549v2",
    "submission_id": "yrqn9rQO2YT",
    "submission_title": "Instance-Dependent Bounds for Zeroth-order Lipschitz Optimization with Error Certificates",
    "review_id": "m7SRTZwxyiN",
    "input": {
      "title": "Instance-Dependent Bounds for Zeroth-order Lipschitz Optimization with Error Certificates",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Overall this is a nice paper and I enjoyed reading it.\n- This paper provides a complete characterization for the instance-dependent complexity of zeroth-order Lipschitz optimization, solving a long-standing conjecture for over 30 years.\n- If I have to list some weaknesses, perhaps the main weakness is that the current paper may owe a lot to Bouttier et al. (2020) which obtained the crucial quantity S_C(f, \u03b5).\n- Based on this quantity the remaining steps are actually not so hard, including its relationship to the integral, and the lower bound argument.\n- Therefore, I suggest the authors to discuss more on the importance of error certification, as well as the main novelty/difference/challenge in the current DOO algorithm compared with the previous ones.\n- This would make the contribution of the current paper more convincing.\n- Some additional comments: \n- Perhaps it would be nice to add that error certification makes the instance-dependent complexity meaningful.\n- Without error certification, the complexity lower bound must be in a local minimax sense instead of strictly pointwise.\n- In the lower bound, does any result change if the points could be queried randomly?\n- The pigeonhole principle always becomes a little bit shaky to apply when things are not deterministic.\n- Some discussions would be appreciated.\n- Also, if the oracle is actually noisy, do the authors have any intuition/evidence whether the sample complexity is roughly the same, or changes dramatically?\n- Some discussions would also be appreciated.\n- Line 66-68: check for language issues.\n- Post-rebuttal feedback:\n- Thanks to the authors for the detailed response.\n- Please add the discussions on the random query model and noisy oracles if space permits.\n- I am happy to keep my score and recommend acceptance.",
    "review_points_list": [
      "Overall this is a nice paper and I enjoyed reading it.",
      "This paper provides a complete characterization for the instance-dependent complexity of zeroth-order Lipschitz optimization, solving a long-standing conjecture for over 30 years.",
      "If I have to list some weaknesses, perhaps the main weakness is that the current paper may owe a lot to Bouttier et al. (2020) which obtained the crucial quantity S_C(f, \u03b5).",
      "Based on this quantity the remaining steps are actually not so hard, including its relationship to the integral, and the lower bound argument.",
      "Therefore, I suggest the authors to discuss more on the importance of error certification, as well as the main novelty/difference/challenge in the current DOO algorithm compared with the previous ones.",
      "This would make the contribution of the current paper more convincing.",
      "Some additional comments: ",
      "Perhaps it would be nice to add that error certification makes the instance-dependent complexity meaningful.",
      "Without error certification, the complexity lower bound must be in a local minimax sense instead of strictly pointwise.",
      "In the lower bound, does any result change if the points could be queried randomly?",
      "The pigeonhole principle always becomes a little bit shaky to apply when things are not deterministic.",
      "Some discussions would be appreciated.",
      "Also, if the oracle is actually noisy, do the authors have any intuition/evidence whether the sample complexity is roughly the same, or changes dramatically?",
      "Some discussions would also be appreciated.",
      "Line 66-68: check for language issues.",
      "Post-rebuttal feedback:",
      "Thanks to the authors for the detailed response.",
      "Please add the discussions on the random query model and noisy oracles if space permits.",
      "I am happy to keep my score and recommend acceptance."
    ]
  },
  {
    "paper_id": "2010.10549v2",
    "submission_id": "yrqn9rQO2YT",
    "submission_title": "Instance-Dependent Bounds for Zeroth-order Lipschitz Optimization with Error Certificates",
    "review_id": "U4gAqh2zVbV",
    "input": {
      "title": "Instance-Dependent Bounds for Zeroth-order Lipschitz Optimization with Error Certificates",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper resolves an interesting open question from 1991.\n- The problem of finding global optima with zero-order methods is very important in many areas, e.g., in hyperparameter tuning.\n- The techniques developed to prove the results are very interesting.\n- The use of the notion of certified algorithms is a very clever way to be able to accurately prove lower bounds for this problem.\n- It would be nice to have some better understanding of the expression of \u03c3. For example, when the domain is [0, 1]^d, a trivial brute force algorithm would need (L/\u03b5)^d steps to get a certified \u03b5-approximately optimal solution.\n- How is this bound compared to the per-instance optimal bound? It is clear that the per-instance bound is smaller but is which cases it is significantly smaller? For example if L is O(1) are the two bounds of the same order.\n- The term \"constant\" in many lemmas and theorems is misleading. In many cases the constants C, c, or c' dependent at least exponentially to the dimension d of the problem which is a very important parameter.\n- I understand that these constants do not dependent on f and \u03b5 but d is an important parameter as well and the authors should be more careful when they use the term constant that has some dependence on d.\n- The use of the term \"sample complexity\" is a bit misleading, a believe a better wording would be \"query complexity\".\n- In lines 244-250 it is mentioned that Assumption 4 is satisfied for many natural domain sets. Is it satisfied in general for convex sets X or there is a counter-example?\n- In the proof of Theorem 2 in line 302 the notation K is confusing because K has been used so far for the expansion of the tree in the algorithm.\n- The fact that the exact knowledge of the Lipschitzness is fundamental for the lower bound is a bit confusing. It is possible that the exact knowledge of the Lipschitz constant can be used to get an improved algorithm for any function f?\n- The results provided in this paper seem to be important and significant and for this reason I recommend acceptance.\n- After reading the authors response and the other reviews I keep my score.",
    "review_points_list": [
      "The paper resolves an interesting open question from 1991.",
      "The problem of finding global optima with zero-order methods is very important in many areas, e.g., in hyperparameter tuning.",
      "The techniques developed to prove the results are very interesting.",
      "The use of the notion of certified algorithms is a very clever way to be able to accurately prove lower bounds for this problem.",
      "It would be nice to have some better understanding of the expression of \u03c3. For example, when the domain is [0, 1]^d, a trivial brute force algorithm would need (L/\u03b5)^d steps to get a certified \u03b5-approximately optimal solution.",
      "How is this bound compared to the per-instance optimal bound? It is clear that the per-instance bound is smaller but is which cases it is significantly smaller? For example if L is O(1) are the two bounds of the same order.",
      "The term \"constant\" in many lemmas and theorems is misleading. In many cases the constants C, c, or c' dependent at least exponentially to the dimension d of the problem which is a very important parameter.",
      "I understand that these constants do not dependent on f and \u03b5 but d is an important parameter as well and the authors should be more careful when they use the term constant that has some dependence on d.",
      "The use of the term \"sample complexity\" is a bit misleading, a believe a better wording would be \"query complexity\".",
      "In lines 244-250 it is mentioned that Assumption 4 is satisfied for many natural domain sets. Is it satisfied in general for convex sets X or there is a counter-example?",
      "In the proof of Theorem 2 in line 302 the notation K is confusing because K has been used so far for the expansion of the tree in the algorithm.",
      "The fact that the exact knowledge of the Lipschitzness is fundamental for the lower bound is a bit confusing. It is possible that the exact knowledge of the Lipschitz constant can be used to get an improved algorithm for any function f?",
      "The results provided in this paper seem to be important and significant and for this reason I recommend acceptance.",
      "After reading the authors response and the other reviews I keep my score."
    ]
  },
  {
    "paper_id": "2010.10549v2",
    "submission_id": "yrqn9rQO2YT",
    "submission_title": "Instance-Dependent Bounds for Zeroth-order Lipschitz Optimization with Error Certificates",
    "review_id": "Fx3nH8W9cao",
    "input": {
      "title": "Instance-Dependent Bounds for Zeroth-order Lipschitz Optimization with Error Certificates",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well-organized.\n- The authors present the Certified DOO algorithm and the upper bound of sample complexity of the Certified DOO algorithm.\n- And the novel technique, which the authors used to prove an instance-dependent lower bound of certified algorithms, could likely follow up to prove other learning settings.\n- With noticing that the Certified DOO algorithm is highly dependent on the information of the feasible set,\n- There is a question that I am interested in: can we design algorithms without knowing the information of the feasible set K in advance, i.e., the oracle will return - \n if x \n K.\n- Thanks for the authors' nice response.\n- I would like to keep my ratings for this good paper,",
    "review_points_list": [
      "The paper is well-organized.",
      "The authors present the Certified DOO algorithm and the upper bound of sample complexity of the Certified DOO algorithm.",
      "And the novel technique, which the authors used to prove an instance-dependent lower bound of certified algorithms, could likely follow up to prove other learning settings.",
      "With noticing that the Certified DOO algorithm is highly dependent on the information of the feasible set,",
      "There is a question that I am interested in: can we design algorithms without knowing the information of the feasible set K in advance, i.e., the oracle will return - \n if x \n K.",
      "Thanks for the authors' nice response.",
      "I would like to keep my ratings for this good paper,"
    ]
  },
  {
    "paper_id": "2010.10549v2",
    "submission_id": "yrqn9rQO2YT",
    "submission_title": "Instance-Dependent Bounds for Zeroth-order Lipschitz Optimization with Error Certificates",
    "review_id": "-qZt-k5Jgr",
    "input": {
      "title": "Instance-Dependent Bounds for Zeroth-order Lipschitz Optimization with Error Certificates",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I believe this work is a nice complement to the instance-dependent sample complexity of zeroth-order optimization.\n- The presentation is good with clear upper and lower bounds.\n- I'm confused about the gap in the dependence of dimension $d$ in the upper and lower bounds.\n- Theorem 3 suggests that the constant $c$ in lower bound is $c'(1-Lip(f)/L)^d$, and claims that the results are direct corollary of Theorem 2 and Proposition 1.\n- However, in theorem 2 the constant $c$ has a extra dependence of $2^{-7d}$, which can be huge when the dimension is large and suggests another mismatch of order $2^{-d}$ in the upper and lower bounds.\n- Is there any other technique applied to mitigate this factor in the lower bound?\n- Otherwise, the authors shall state this gap clearly in the introduction and theorem instead of hiding it in the constant $c'.\n- Based on the dependence of smoothness in the lower bound in Theorem 2, the adaptivity to all range of smoothness seems to be a natural and important question towards fully instance-dependent optimal bound.\n- It is mentioned in line 89 that 'our lower bound suggests that no adaptivity could be possible for certified algorithm'.\n- This is not clear from Proposition 2 and 3, since Proposition 2 seems to suggest that there exists algorithm that can achieve constant sample size when $f$ is exactly $L$-Lipschitz.\n- Could the author elaborate on this point?\n- The mismatch between one dimension and high dimension is quite interesting.\n- In Proposition 3, the authors suggest that in one dimension, the term $S_c$ is again a valid lower bound.\n- Does this mean that the problem when we know exactly the smoothness of the function in one dimension can be harder than that in high dimension?\n- Does this also imply that there exists algorithm that is adaptive to smoothness in one dimension?\n- It would be great if some intuitive explanation can be added on why the discrepancy between one dimension and high dimension happens.\n- Besides the concerns mentioned above, I think understanding exactly the instance-dependent optimal zeroth-order optimization is a good contribution.\n- I'm happy to adjust the points accordingly if my questions are resolved.\n- The authors have resolved most of the questions listed above.\n- Although the exponential gap in dimension is still tricky, I acknowledge that this is an open problem left and this work makes a first step towards understanding the instance-dependent optimal zeroth-order optimization in high dimension.\n- I have adjusted my score accordingly.",
    "review_points_list": [
      "I believe this work is a nice complement to the instance-dependent sample complexity of zeroth-order optimization.",
      "The presentation is good with clear upper and lower bounds.",
      "I'm confused about the gap in the dependence of dimension $d$ in the upper and lower bounds.",
      "Theorem 3 suggests that the constant $c$ in lower bound is $c'(1-Lip(f)/L)^d$, and claims that the results are direct corollary of Theorem 2 and Proposition 1.",
      "However, in theorem 2 the constant $c$ has a extra dependence of $2^{-7d}$, which can be huge when the dimension is large and suggests another mismatch of order $2^{-d}$ in the upper and lower bounds.",
      "Is there any other technique applied to mitigate this factor in the lower bound?",
      "Otherwise, the authors shall state this gap clearly in the introduction and theorem instead of hiding it in the constant $c'.",
      "Based on the dependence of smoothness in the lower bound in Theorem 2, the adaptivity to all range of smoothness seems to be a natural and important question towards fully instance-dependent optimal bound.",
      "It is mentioned in line 89 that 'our lower bound suggests that no adaptivity could be possible for certified algorithm'.",
      "This is not clear from Proposition 2 and 3, since Proposition 2 seems to suggest that there exists algorithm that can achieve constant sample size when $f$ is exactly $L$-Lipschitz.",
      "Could the author elaborate on this point?",
      "The mismatch between one dimension and high dimension is quite interesting.",
      "In Proposition 3, the authors suggest that in one dimension, the term $S_c$ is again a valid lower bound.",
      "Does this mean that the problem when we know exactly the smoothness of the function in one dimension can be harder than that in high dimension?",
      "Does this also imply that there exists algorithm that is adaptive to smoothness in one dimension?",
      "It would be great if some intuitive explanation can be added on why the discrepancy between one dimension and high dimension happens.",
      "Besides the concerns mentioned above, I think understanding exactly the instance-dependent optimal zeroth-order optimization is a good contribution.",
      "I'm happy to adjust the points accordingly if my questions are resolved.",
      "The authors have resolved most of the questions listed above.",
      "Although the exponential gap in dimension is still tricky, I acknowledge that this is an open problem left and this work makes a first step towards understanding the instance-dependent optimal zeroth-order optimization in high dimension.",
      "I have adjusted my score accordingly."
    ]
  },
  {
    "paper_id": "2010.10549v2",
    "submission_id": "yrqn9rQO2YT",
    "submission_title": "Instance-Dependent Bounds for Zeroth-order Lipschitz Optimization with Error Certificates",
    "review_id": "-cemEFnjnJV",
    "input": {
      "title": "Instance-Dependent Bounds for Zeroth-order Lipschitz Optimization with Error Certificates",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- i think that this result should be advertised less as resolving the open problem of finding the number of sample complexity queries of any optimal algorithm.\n- Indeed it should be made more explicit that: (i) the authors relate the sample complexity bound on the PS algorithm established earlier by Bouttier et al, and (ii) show that the DOO algorithm can be made certifiable.\n- i feel like these points are not established clearly in the abstract.\n- It should be mentioned that the constants c and C in the upper and lower bounds depend exponentially on d and are not absolute constants.\n- Theorem 2 of Bouttier et al (2020) proves that the term $S_C (f,\newlinepsilon)$ is an upper bound to the sample complexity for a different algorithm than the one considered in the paper which is less computationally efficient.\n- It might help to clarify this again in the discussion above eq. (5) / in section 2.\n- In the intuition for proposition 2, I find it hard to understand how the learner can *find* two points at which the respective values of f are maximally distant.\n- Even given two such points, the general intuition for this result is not clear to me.\n- I find it hard to understand the message in propositions 2 and 3.\n- Shouldn\u2019t the certification problem in, say, 2 dimensions be harder than in 1 dimension?\n- One can always embed a 1-d Lipschitz function into 2-d as: $f_2 ( x ) = f_1 ( \neqangle x , e_1 \rangle )$.\n- Is there any intuition as to what to expect in the case when any of the assumptions such as 2 and 3 are relaxed?\n- Is there a fundamental difficulty in the absence of either of these assumptions?",
    "review_points_list": [
      "i think that this result should be advertised less as resolving the open problem of finding the number of sample complexity queries of any optimal algorithm.",
      "Indeed it should be made more explicit that: (i) the authors relate the sample complexity bound on the PS algorithm established earlier by Bouttier et al, and (ii) show that the DOO algorithm can be made certifiable.",
      "i feel like these points are not established clearly in the abstract.",
      "It should be mentioned that the constants c and C in the upper and lower bounds depend exponentially on d and are not absolute constants.",
      "Theorem 2 of Bouttier et al (2020) proves that the term $S_C (f,\newlinepsilon)$ is an upper bound to the sample complexity for a different algorithm than the one considered in the paper which is less computationally efficient.",
      "It might help to clarify this again in the discussion above eq. (5) / in section 2.",
      "In the intuition for proposition 2, I find it hard to understand how the learner can *find* two points at which the respective values of f are maximally distant.",
      "Even given two such points, the general intuition for this result is not clear to me.",
      "I find it hard to understand the message in propositions 2 and 3.",
      "Shouldn\u2019t the certification problem in, say, 2 dimensions be harder than in 1 dimension?",
      "One can always embed a 1-d Lipschitz function into 2-d as: $f_2 ( x ) = f_1 ( \neqangle x , e_1 \rangle )$.",
      "Is there any intuition as to what to expect in the case when any of the assumptions such as 2 and 3 are relaxed?",
      "Is there a fundamental difficulty in the absence of either of these assumptions?"
    ]
  },
  {
    "paper_id": "2107.07630v3",
    "submission_id": "x_JOyw5CLP",
    "submission_title": "Evaluation of Human-AI Teams for Learned and Rule-Based Agents in Hanabi",
    "review_id": "DP-pLuI8tG",
    "input": {
      "title": "Evaluation of Human-AI Teams for Learned and Rule-Based Agents in Hanabi",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper has several key strengths:\n- - Topic relevance: The paper investigates an important (at least in near term) question around how human-AI collaboration is experienced by humans.\n- - Rigor: Overall the empirical analysis is well-described and uses statistical tests where appropriate.\n- The paper has some modest weaknesses:\n- - Limited generality: Any human study will have necessarily limited generalization to other problem domains. The value in this work is the insight into the problem and as a good demonstration of appropriate methodology for others to apply to other domains.\n- - Scale: The study is limited to 29 participants, which is modest for the variety of questions to be addressed. Regardless of statistical power it would be more compelling to see a larger scale replication of this work, particularly including a more balanced sample of participant skill levels.\n- - Representativeness: Results reporting do not give a sense as to whether the sample should be considered 'representative'. Or what a representative population might be for something like Hanabi. This makes it hard to assess the whether the outcomes would transfer to the general population of human-AI teaming for Hanabi.\n- - Missing results: Many negative results are not included in the main text. That is fine, but it would help to include these in the appendices. The narrative of the results may change depending on what other measures of cooperation and task load (TLX) were *not* significantly different.",
    "review_points_list": [
      "The paper has several key strengths:",
      "- Topic relevance: The paper investigates an important (at least in near term) question around how human-AI collaboration is experienced by humans.",
      "- Rigor: Overall the empirical analysis is well-described and uses statistical tests where appropriate.",
      "The paper has some modest weaknesses:",
      "- Limited generality: Any human study will have necessarily limited generalization to other problem domains. The value in this work is the insight into the problem and as a good demonstration of appropriate methodology for others to apply to other domains.",
      "- Scale: The study is limited to 29 participants, which is modest for the variety of questions to be addressed. Regardless of statistical power it would be more compelling to see a larger scale replication of this work, particularly including a more balanced sample of participant skill levels.",
      "- Representativeness: Results reporting do not give a sense as to whether the sample should be considered 'representative'. Or what a representative population might be for something like Hanabi. This makes it hard to assess the whether the outcomes would transfer to the general population of human-AI teaming for Hanabi.",
      "- Missing results: Many negative results are not included in the main text. That is fine, but it would help to include these in the appendices. The narrative of the results may change depending on what other measures of cooperation and task load (TLX) were *not* significantly different."
    ]
  },
  {
    "paper_id": "2107.07630v3",
    "submission_id": "x_JOyw5CLP",
    "submission_title": "Evaluation of Human-AI Teams for Learned and Rule-Based Agents in Hanabi",
    "review_id": "OKQa1dxlgYh",
    "input": {
      "title": "Evaluation of Human-AI Teams for Learned and Rule-Based Agents in Hanabi",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well written and deals with an important problem, which is to understand how humans perceive their interaction with RL-based agents in cooperative settings.\n- The game of Hanabi is a great choice for studying this problem as it is one of the standard benchmark problems for evaluating RL algorithms in cooperative settings.\n- The choice of the agents used in the study is also good: Smart Bot (SB) and Other-Play (OP), which are the current state-of-the-art rule-based and RL-based algorithms for playing Hanabi.\n- The results of the study show an interesting trend: objective metric of number of points scored is similar for both agents, but subjective metrics such as whether the agent 'understands' the human player's intention mostly favor the rule-based agent.\n- I have played Hanabi with older RL agents such as policies trained with DQN Rainbow and I know that it can be frustrating to play with RL agents.\n- However, I have not played with agents trained with the newer OP algorithm.\n- When I read the OP paper I had thought that it would be fun to play with OP agents because humans were shown to score much higher with OP agents (while I can score around 5 or 6 with DQN Rainbow, the OP paper showed that experienced players can score ~15).\n- This submission is telling me that 'hey, you might score ~15 with OP agents, but you will still prefer to play the SB agent.'\n- I think this is an interesting result that needs to be investigate more carefully.\n- The research community needs to get to the bottom of this result and understand what is going on.\n- After my initial excitement with the result, I started to be concerned with its validity for the authors enlisted a small number of people to perform their study.\n- A careful analysis show that the results might be too preliminary and we would need a larger study to confirm the trend observed in the current submission (see details below).\n- Participants of the study played 3 games with each agent (either SB or OP and then with the other agent).\n- The results suggest (according to the paper) that there is a learning effect, which is expected: participants score higher as they play the second block of games.\n- The experimental design deals with learning effects by controlling the number of people that gets to play each agent first.\n- It would be helpful to know exactly how many of the 29 participants played OP first and how many played SB first.\n- Small variations in the distribution could affect the results due to the strong learning effect of the design.\n- A cleaner approach is to use a between-subjects design, where each participant plays either SB or OP.\n- Then the learning effect won't be carried across different treatments of the study.\n- I am also concerned with the incentive design of the study.\n- Each participant received a 10 USD gift card and the highest-scoring participant received an additional 50 USD gift card.\n- I wonder if a different compensation model (e.g., participants receive more if score higher in the game, independently of the other participants' scores) would change the results.\n- Figure 1 shows that the distributions of scores of OP and SB are different.\n- In particular, there is a peak for the OP results for the score of 24 (maximum is 25).\n- I wonder how people who played those matches ranked OP compared to SB.\n- Would the participants who scored higher with OP than with SB still prefer to play with SB -- even if OP gives them a higher monetary reward?\n- A careful analysis of the distributions shown in Figure 1 also shows that the number of participants enlisted in the study is probably too small to support significant conclusions.\n- For example, no participant scored 15 with SB and I don't see why 15 would be too different from 14 or 16.\n- The lack of scores 15 makes the distribution look bimodal, but I suspect this is just the effect of a small number of participants.\n- The distinction between experienced and inexperienced players seems to play an important role in these user studies (e.g., the one presented in the OP paper).\n- However, no one has proposed an effective metric of experience for Hanabi that allows others to reproduce the results.\n- There could even be a cultural effect of how people regard their own experience in the game.\n- Perhaps one can formulate a Hanabi test to allow for a concrete evaluation of one's experience?\n- In short, the results presented in this paper are interesting, but perhaps too preliminary for publication.\n- I suggest that the study is repeated with a between-subject design, a more lenient reward function to make people prefer higher scores, and with many more participants.\n- It would also be helpful to report demographic data about the participants and also the effect size of the comparisons.",
    "review_points_list": [
      "The paper is well written and deals with an important problem, which is to understand how humans perceive their interaction with RL-based agents in cooperative settings.",
      "The game of Hanabi is a great choice for studying this problem as it is one of the standard benchmark problems for evaluating RL algorithms in cooperative settings.",
      "The choice of the agents used in the study is also good: Smart Bot (SB) and Other-Play (OP), which are the current state-of-the-art rule-based and RL-based algorithms for playing Hanabi.",
      "The results of the study show an interesting trend: objective metric of number of points scored is similar for both agents, but subjective metrics such as whether the agent 'understands' the human player's intention mostly favor the rule-based agent.",
      "I have played Hanabi with older RL agents such as policies trained with DQN Rainbow and I know that it can be frustrating to play with RL agents.",
      "However, I have not played with agents trained with the newer OP algorithm.",
      "When I read the OP paper I had thought that it would be fun to play with OP agents because humans were shown to score much higher with OP agents (while I can score around 5 or 6 with DQN Rainbow, the OP paper showed that experienced players can score ~15).",
      "This submission is telling me that 'hey, you might score ~15 with OP agents, but you will still prefer to play the SB agent.'",
      "I think this is an interesting result that needs to be investigate more carefully.",
      "The research community needs to get to the bottom of this result and understand what is going on.",
      "After my initial excitement with the result, I started to be concerned with its validity for the authors enlisted a small number of people to perform their study.",
      "A careful analysis show that the results might be too preliminary and we would need a larger study to confirm the trend observed in the current submission (see details below).",
      "Participants of the study played 3 games with each agent (either SB or OP and then with the other agent).",
      "The results suggest (according to the paper) that there is a learning effect, which is expected: participants score higher as they play the second block of games.",
      "The experimental design deals with learning effects by controlling the number of people that gets to play each agent first.",
      "It would be helpful to know exactly how many of the 29 participants played OP first and how many played SB first.",
      "Small variations in the distribution could affect the results due to the strong learning effect of the design.",
      "A cleaner approach is to use a between-subjects design, where each participant plays either SB or OP.",
      "Then the learning effect won't be carried across different treatments of the study.",
      "I am also concerned with the incentive design of the study.",
      "Each participant received a 10 USD gift card and the highest-scoring participant received an additional 50 USD gift card.",
      "I wonder if a different compensation model (e.g., participants receive more if score higher in the game, independently of the other participants' scores) would change the results.",
      "Figure 1 shows that the distributions of scores of OP and SB are different.",
      "In particular, there is a peak for the OP results for the score of 24 (maximum is 25).",
      "I wonder how people who played those matches ranked OP compared to SB.",
      "Would the participants who scored higher with OP than with SB still prefer to play with SB -- even if OP gives them a higher monetary reward?",
      "A careful analysis of the distributions shown in Figure 1 also shows that the number of participants enlisted in the study is probably too small to support significant conclusions.",
      "For example, no participant scored 15 with SB and I don't see why 15 would be too different from 14 or 16.",
      "The lack of scores 15 makes the distribution look bimodal, but I suspect this is just the effect of a small number of participants.",
      "The distinction between experienced and inexperienced players seems to play an important role in these user studies (e.g., the one presented in the OP paper).",
      "However, no one has proposed an effective metric of experience for Hanabi that allows others to reproduce the results.",
      "There could even be a cultural effect of how people regard their own experience in the game.",
      "Perhaps one can formulate a Hanabi test to allow for a concrete evaluation of one's experience?",
      "In short, the results presented in this paper are interesting, but perhaps too preliminary for publication.",
      "I suggest that the study is repeated with a between-subject design, a more lenient reward function to make people prefer higher scores, and with many more participants.",
      "It would also be helpful to report demographic data about the participants and also the effect size of the comparisons."
    ]
  },
  {
    "paper_id": "2107.07630v3",
    "submission_id": "x_JOyw5CLP",
    "submission_title": "Evaluation of Human-AI Teams for Learned and Rule-Based Agents in Hanabi",
    "review_id": "-Z4ae1cE8as",
    "input": {
      "title": "Evaluation of Human-AI Teams for Learned and Rule-Based Agents in Hanabi",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This work is the first to study the human teammate's subjective evaluation of different types of AI agents for the card game Hanabi.\n- The user study is carefully designed and controlled to offer a comprehensive analysis of the two selected candidate AI agents.\n- The results of the user study are presented in detail with clarity and the claims are supported with statistical analysis.\n- The findings imply that human subjective evaluations are also important metrics for designing AI agents since the task performance is not indicative of subjective evaluations.\n- One concern for this paper is that the selection of candidate AI agents for testing is too limited (one from each category) and therefore the results may not generalize across different agents within the same game.\n- The selection of candidate AI agents was not optimal.\n- Especially that RL training is an unstable process and the paper only tested one policy trained by RL to represent the full range of learning-based agents.\n- The findings do not seem to be too surprising since the rule-based AI agent is designed with hard-coded human knowledge and therefore are expected to play smoothly with human teammates\n- the RL-based policy was trained to optimize for zero-short coordination but the test scenarios in this user study is few-shot coordination.\n- Moreover, the RL agent was not explicitly designed to perform well with experienced human teammates who have developed their conventions for communication.\n- While I agree with the implication from the findings of this paper that human experiences/evaluations are important metrics on their own, I do not think this directly indicates that subjective metrics should be incorporated into RL training to achieve good human evaluations.\n- Experiments and comparisons with RL agents trained or fine-tuned with human teammates are needed to show whether it is necessary to directly optimize for human subjective evaluations.",
    "review_points_list": [
      "This work is the first to study the human teammate's subjective evaluation of different types of AI agents for the card game Hanabi.",
      "The user study is carefully designed and controlled to offer a comprehensive analysis of the two selected candidate AI agents.",
      "The results of the user study are presented in detail with clarity and the claims are supported with statistical analysis.",
      "The findings imply that human subjective evaluations are also important metrics for designing AI agents since the task performance is not indicative of subjective evaluations.",
      "One concern for this paper is that the selection of candidate AI agents for testing is too limited (one from each category) and therefore the results may not generalize across different agents within the same game.",
      "The selection of candidate AI agents was not optimal.",
      "Especially that RL training is an unstable process and the paper only tested one policy trained by RL to represent the full range of learning-based agents.",
      "The findings do not seem to be too surprising since the rule-based AI agent is designed with hard-coded human knowledge and therefore are expected to play smoothly with human teammates",
      "the RL-based policy was trained to optimize for zero-short coordination but the test scenarios in this user study is few-shot coordination.",
      "Moreover, the RL agent was not explicitly designed to perform well with experienced human teammates who have developed their conventions for communication.",
      "While I agree with the implication from the findings of this paper that human experiences/evaluations are important metrics on their own, I do not think this directly indicates that subjective metrics should be incorporated into RL training to achieve good human evaluations.",
      "Experiments and comparisons with RL agents trained or fine-tuned with human teammates are needed to show whether it is necessary to directly optimize for human subjective evaluations."
    ]
  },
  {
    "paper_id": "2107.07630v3",
    "submission_id": "x_JOyw5CLP",
    "submission_title": "Evaluation of Human-AI Teams for Learned and Rule-Based Agents in Hanabi",
    "review_id": "OQhwV-6wL4",
    "input": {
      "title": "Evaluation of Human-AI Teams for Learned and Rule-Based Agents in Hanabi",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Much work has been done in multiagent RL, and recently it has started to look into human-AI teaming as well, but so far the focus has primarily been on optimizing the reward obtained, with at best qualitative evaluations of other factors.\n- These other factors seem very important for the deployment of human-AI teaming in the real world, so it is good to see a paper explicitly aim to quantify and analyze these factors.\n- The survey design and analysis seem sensible (though I do not know much about these topics, and might be missing something).\n- The paper is very clear; I especially appreciated the abstract, which laid out exactly what I should expect from the paper.\n- The one critique of the paper is that it could have been more ambitious and had a broader scope.\n- Alternatives include StarCraft and Overcooked; the authors could adapt the existing website for Overcooked in which humans can play against trained agents.\n- An agent that is trained to play with humans is less likely to fall into such a trap.\n- It would also be interesting to learn more about qualitative reasons for participant\u2019s responses -- it seems there were multiple free response questions.\n- Did participants mostly not answer these? If they did, what did they tend to say?\n- Given that this is (to my knowledge) the first paper studying other aspects besides reward in human-AI teaming for agents based on deep reinforcement learning, it might have been nice to mention other qualitative results that have been informally reported, such as in the cooperative matches for OpenAI Five and Capture the Flag, in which some bots and humans play together on a team.\n- This could capture a broader range of qualitative effects that we may expect to see in human-AI teaming.",
    "review_points_list": [
      "Much work has been done in multiagent RL, and recently it has started to look into human-AI teaming as well, but so far the focus has primarily been on optimizing the reward obtained, with at best qualitative evaluations of other factors.",
      "These other factors seem very important for the deployment of human-AI teaming in the real world, so it is good to see a paper explicitly aim to quantify and analyze these factors.",
      "The survey design and analysis seem sensible (though I do not know much about these topics, and might be missing something).",
      "The paper is very clear; I especially appreciated the abstract, which laid out exactly what I should expect from the paper.",
      "The one critique of the paper is that it could have been more ambitious and had a broader scope.",
      "Alternatives include StarCraft and Overcooked; the authors could adapt the existing website for Overcooked in which humans can play against trained agents.",
      "An agent that is trained to play with humans is less likely to fall into such a trap.",
      "It would also be interesting to learn more about qualitative reasons for participant\u2019s responses -- it seems there were multiple free response questions.",
      "Did participants mostly not answer these? If they did, what did they tend to say?",
      "Given that this is (to my knowledge) the first paper studying other aspects besides reward in human-AI teaming for agents based on deep reinforcement learning, it might have been nice to mention other qualitative results that have been informally reported, such as in the cooperative matches for OpenAI Five and Capture the Flag, in which some bots and humans play together on a team.",
      "This could capture a broader range of qualitative effects that we may expect to see in human-AI teaming."
    ]
  },
  {
    "paper_id": "2404.10393v2",
    "submission_id": "w6iVxEdh6bi",
    "submission_title": "Offline RL Without Off-Policy Evaluation",
    "review_id": "Bcfu567bjR6",
    "input": {
      "title": "Offline RL Without Off-Policy Evaluation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is very simple. This is a virtue of the paper, I don't expect papers to be complex to be good.\n- The paper has little novelty in it. This would not bother me in general, but I also feel that the authors did not delve deep into the phenomenon described in the paper, neither theoretically nor empirically.\n- The paper was not informative. The paper felt more like a survey to me. I did not feel I learned any new ideas after reading it.\n- There is little to no theoretical analysis in the paper. The work seems rushed and incomplete. Empirical evaluation is lacking.\n- Either the authors add strong empirical evidence, or they provide new theoretical insights.\n- The fact that overestimation of Q-values affects performance has already been proven theoretically as well as empirically.\n- Are the authors providing another method for overcoming overestimation?\n- If so, why are they not comparing their work to the vast array of current work, such as the following simple paper that uses BC with TD3 (without any special tricks) to achieve sota performance?\n- https://arxiv.org/pdf/2106.06860.pdf\n- While this work is attempting to deliver a very simple idea, the overall organization and flow of the paper make the paper very hard to follow.\n- I think that the solution of one step gradients could be useful as a regularization technique, and in that sense the paper could help practitioners.\n- Nevertheless, I do not believe a 'trick for practitioners' is enough to pass the bar to a top-tier conference.",
    "review_points_list": [
      "The paper is very simple. This is a virtue of the paper, I don't expect papers to be complex to be good.",
      "The paper has little novelty in it. This would not bother me in general, but I also feel that the authors did not delve deep into the phenomenon described in the paper, neither theoretically nor empirically.",
      "The paper was not informative. The paper felt more like a survey to me. I did not feel I learned any new ideas after reading it.",
      "There is little to no theoretical analysis in the paper. The work seems rushed and incomplete. Empirical evaluation is lacking.",
      "Either the authors add strong empirical evidence, or they provide new theoretical insights.",
      "The fact that overestimation of Q-values affects performance has already been proven theoretically as well as empirically.",
      "Are the authors providing another method for overcoming overestimation?",
      "If so, why are they not comparing their work to the vast array of current work, such as the following simple paper that uses BC with TD3 (without any special tricks) to achieve sota performance?",
      "https://arxiv.org/pdf/2106.06860.pdf",
      "While this work is attempting to deliver a very simple idea, the overall organization and flow of the paper make the paper very hard to follow.",
      "I think that the solution of one step gradients could be useful as a regularization technique, and in that sense the paper could help practitioners.",
      "Nevertheless, I do not believe a 'trick for practitioners' is enough to pass the bar to a top-tier conference."
    ]
  },
  {
    "paper_id": "2404.10393v2",
    "submission_id": "w6iVxEdh6bi",
    "submission_title": "Offline RL Without Off-Policy Evaluation",
    "review_id": "lKYnD1OgMz6",
    "input": {
      "title": "Offline RL Without Off-Policy Evaluation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors evaluate 3 different, typically iterative algorithms while performing only a single step of policy improvement on D4RL, observing improvements in around half of the tasks.\n- In case of one of these algorithms (reverse KL regularization), implement 3 versions: one-step, multi-step, and iterative, observing best results in one-step version ~half of the times again\n- Provide some intuition (based on representing errors as auxiliary, hurtful rewards) about the reason for multi-step/iterative algorithms to do poorly in offline rl\n- Show examples of MDPs where multi-step is bound to fail and one where it's necessary to solve the MDP (in the appendix).\n- Argue for some theoretical guarantees of performance of single-step methods (in the appendix).\n- Show some empirical evidence relating overestimation with regularization in their algorithm\n- I share the authors' intuition regarding the statement of the paper: doing multiple steps of improvement can be hurtful due to accumulation of errors and a single step can be a useful baseline/practice\n- Having said that, I cast a weak vote to reject the paper due to perceived lack of novelty\n- The paper doesn't on its own introduce a novel algorithm, the (simple) idea it tests is literally just doing a single step of known improvement operators (as opposed to multi-step).\n- Authors mention that these papers 'propose complicated variants of the one-step approach'. While I can agree the methods in either of these papers are more complex, the results are also better (CG evaluates on different dataset, so hard to say) and they both provide ablation studies showing the behavior of the one-step approach with a simple, single improvement step\n- If we consider these two papers as prior work, the proposed method is basically a simplified version of CG/GN that doesn't work as well\n- After having read these two papers, I don't think I gained much new insights (basically only point 5 above) from reading the paper under review\n- At the same time, I consider the presentation of this particular idea as a useful contribution to the community\n- Minor notes: I'm not sure what is meant by 'removes the policy correction network' in BCQ; I didn't find it in Fujimoto et al.\n- I don't find the abstraction of OAMPI particularly useful, as it doesn't capture well all 3 types of algorithms that you have (one-step, multi-step, and iterative).\n- You state that '$\beta$ are likely to have larger magnitude the further we go from the support of the dataset.' This matches my intuition, but I think it should be possible to give more formal reasoning why this would be so.\n- You say 'In the example, like in the D4RL benchmark, we see that one step outperforms multiple steps of improvement.' This is not substantiated by the data, where the results were half-half.\n- In sec. 6.1/2, it's not clear what algorithms are tested\n- You write 'As shown in Figure 2, we often observe that the iterative algorithm': which iterative algorithm? It looks like one particular algorithm (with different alpha) was used and it's not clear whether the results would transfer to other ones.\n- In sec. 4.3 'incentivising $\beta$ to cover $\beta$\n- The authors' idea is not particularly novel.\n- The paper does not introduce a novel algorithm.\n- The results are not surprising.\n- The presentation is clear and well-organized.\n- The authors show that their algorithm is more efficient and effective than existing methods.\n- The authors provide some empirical evidence.\n- The authors do not provide enough details about the implementation of their algorithm.\n- The authors do not provide enough details about the experimental results.\n- The authors do not provide enough details about the methodology.\n- The authors do not provide enough details about the limitations of their algorithm.\n- The authors do not provide enough details about the future work.\n- The authors do not provide enough details.\n- The authors do not provide enough details about the results.\n- The authors do not provide enough details about the methodology.\n- The authors do not provide enough details about the implementation.\n- The authors do not provide enough details about the limitations.\n- The authors do not provide enough details about the future work.",
    "review_points_list": [
      "The authors evaluate 3 different, typically iterative algorithms while performing only a single step of policy improvement on D4RL, observing improvements in around half of the tasks.",
      "In case of one of these algorithms (reverse KL regularization), implement 3 versions: one-step, multi-step, and iterative, observing best results in one-step version ~half of the times again",
      "Provide some intuition (based on representing errors as auxiliary, hurtful rewards) about the reason for multi-step/iterative algorithms to do poorly in offline rl",
      "Show examples of MDPs where multi-step is bound to fail and one where it's necessary to solve the MDP (in the appendix).",
      "Argue for some theoretical guarantees of performance of single-step methods (in the appendix).",
      "Show some empirical evidence relating overestimation with regularization in their algorithm",
      "I share the authors' intuition regarding the statement of the paper: doing multiple steps of improvement can be hurtful due to accumulation of errors and a single step can be a useful baseline/practice",
      "Having said that, I cast a weak vote to reject the paper due to perceived lack of novelty",
      "The paper doesn't on its own introduce a novel algorithm, the (simple) idea it tests is literally just doing a single step of known improvement operators (as opposed to multi-step).",
      "Authors mention that these papers 'propose complicated variants of the one-step approach'. While I can agree the methods in either of these papers are more complex, the results are also better (CG evaluates on different dataset, so hard to say) and they both provide ablation studies showing the behavior of the one-step approach with a simple, single improvement step",
      "If we consider these two papers as prior work, the proposed method is basically a simplified version of CG/GN that doesn't work as well",
      "After having read these two papers, I don't think I gained much new insights (basically only point 5 above) from reading the paper under review",
      "At the same time, I consider the presentation of this particular idea as a useful contribution to the community",
      "Minor notes: I'm not sure what is meant by 'removes the policy correction network' in BCQ; I didn't find it in Fujimoto et al.",
      "I don't find the abstraction of OAMPI particularly useful, as it doesn't capture well all 3 types of algorithms that you have (one-step, multi-step, and iterative).",
      "You state that '$\beta$ are likely to have larger magnitude the further we go from the support of the dataset.' This matches my intuition, but I think it should be possible to give more formal reasoning why this would be so.",
      "You say 'In the example, like in the D4RL benchmark, we see that one step outperforms multiple steps of improvement.' This is not substantiated by the data, where the results were half-half.",
      "In sec. 6.1/2, it's not clear what algorithms are tested",
      "You write 'As shown in Figure 2, we often observe that the iterative algorithm': which iterative algorithm? It looks like one particular algorithm (with different alpha) was used and it's not clear whether the results would transfer to other ones.",
      "In sec. 4.3 'incentivising $\beta$ to cover $\beta$",
      "The authors' idea is not particularly novel.",
      "The paper does not introduce a novel algorithm.",
      "The results are not surprising.",
      "The presentation is clear and well-organized.",
      "The authors show that their algorithm is more efficient and effective than existing methods.",
      "The authors provide some empirical evidence.",
      "The authors do not provide enough details about the implementation of their algorithm.",
      "The authors do not provide enough details about the experimental results.",
      "The authors do not provide enough details about the methodology.",
      "The authors do not provide enough details about the limitations of their algorithm.",
      "The authors do not provide enough details about the future work.",
      "The authors do not provide enough details.",
      "The authors do not provide enough details about the results.",
      "The authors do not provide enough details about the methodology.",
      "The authors do not provide enough details about the implementation.",
      "The authors do not provide enough details about the limitations.",
      "The authors do not provide enough details about the future work."
    ]
  },
  {
    "paper_id": "2404.10393v2",
    "submission_id": "w6iVxEdh6bi",
    "submission_title": "Offline RL Without Off-Policy Evaluation",
    "review_id": "Q4pvJ2Ta8Ub",
    "input": {
      "title": "Offline RL Without Off-Policy Evaluation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper presents a very interesting finding that doing one step improvement of policy using on-policy Q-estimate is a surprisingly strong baseline of offline reinforcement learning(RL).\n- Offline RL is a promising approach for the tasks when, despite having plenty of recorded data, there is no way of evaluation of the RL method in control setting.\n- Additionally, it could be useful to improve sample efficiency.\n- Simplicity of the approach and new insights into the dynamics of learning for offline RL: the main point of the paper is that there exists a baseline which is simpler than the existing methods and still performs competitively on much of the D4RL benchmark suite.\n- The proposed method could be of impact as it defines a new benchmark method for offline RL.\n- While the study has multiple limitations, such as that the analysis is mostly empirical and does not strictly answer when exactly this improvements happen, the reviewer has the opinion that these limitations of the study are clearly defined in the paper, and the reported results are novel and valuable enough as they show the previously overlooked simpler benchmark method.\n- Results of one-step algorithms on the D4RL benchmark. The first column gives the best results across several iterative algorithms considered in Fu et al. [2020].\n- Would it be possible to give results on separate state-of-the-art algorithms considered in Fu et al; also, is it possible to report confidence intervals for Fu et al\u2019s experiments?\n- Update: the score is updated reflecting the contribution of the paper in providing simpler and better performing baselines",
    "review_points_list": [
      "The paper presents a very interesting finding that doing one step improvement of policy using on-policy Q-estimate is a surprisingly strong baseline of offline reinforcement learning(RL).",
      "Offline RL is a promising approach for the tasks when, despite having plenty of recorded data, there is no way of evaluation of the RL method in control setting.",
      "Additionally, it could be useful to improve sample efficiency.",
      "Simplicity of the approach and new insights into the dynamics of learning for offline RL: the main point of the paper is that there exists a baseline which is simpler than the existing methods and still performs competitively on much of the D4RL benchmark suite.",
      "The proposed method could be of impact as it defines a new benchmark method for offline RL.",
      "While the study has multiple limitations, such as that the analysis is mostly empirical and does not strictly answer when exactly this improvements happen, the reviewer has the opinion that these limitations of the study are clearly defined in the paper, and the reported results are novel and valuable enough as they show the previously overlooked simpler benchmark method.",
      "Results of one-step algorithms on the D4RL benchmark. The first column gives the best results across several iterative algorithms considered in Fu et al. [2020].",
      "Would it be possible to give results on separate state-of-the-art algorithms considered in Fu et al; also, is it possible to report confidence intervals for Fu et al\u2019s experiments?",
      "Update: the score is updated reflecting the contribution of the paper in providing simpler and better performing baselines"
    ]
  },
  {
    "paper_id": "2404.10393v2",
    "submission_id": "w6iVxEdh6bi",
    "submission_title": "Offline RL Without Off-Policy Evaluation",
    "review_id": "tWRznRz4Xi_",
    "input": {
      "title": "Offline RL Without Off-Policy Evaluation",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well written and the claims and empirical evidence are adequate and clearly marked, which makes it easier to assess its contributions.\n- The results are also interesting and add to the current understanding of offline RL.\n- The notion of proposing simple, improved baselines for offline RL is also interesting and helps increase applicability of offline RL methods.\n- A more detailed assessment of the related work can help clarify the novelty of the contributions.\n- The paper does not contain a discussion of the broader societal impact of its results.\n- The paper seems correct, though I think it could be more emphatic that the issue identified in Sec 6.3 is one potential issue with iterative and multi-step methods, but perhaps not the only one.\n- The paper is clearly written.\n- In a recent paper, Gulcehre et al. (https://arxiv.org/pdf/2103.09575.pdf) seem to arrive at similar conclusions about one-step methods, but they additionally prescribe a regularization term to discourage the improved policy from selecting actions (at respective states) absent from the training data.\n- The example you proposed for Figure 4 and Appendix A can be useful for validating the claim from Gulcehre et al. as to why they prescribe the ranking regularization.\n- I do not agree with the assessment in lines 86-95. YOEO fits the bill of a one-step method (and in fact the authors state that they want to propose an alternative to multi-step and iterative algorithms) and has some improvements over multistep and iterative methods.\n- Moreover, the Niekum et al. make some of the core points this paper makes as well (see their Sec. 4), so I think it is important to acknowledge that.\n- This will help the reader understand the contributions better in light of existing work.\n- I find there is enough information for reproducing the results.\n- Thank you for your submission. I have a few miscellaneous comments.\n- OAMPI is similar to MPI, so maybe cite https://www.jstor.org/stable/2630487 and possibly also GPI in Sutton & Barto's book.\n- I would also suggest calling the evaluation step $mathcal{E}$.\n- Some of this taxonomy is also used by Levine et al. (https://arxiv.org/pdf/2005.01643.pdf) so perhaps point to their work as well.\n- To me the Q ``without a stop gradient'' in eq. 2 is confusing, even though later you say that in practice a target network is used.\n- Fitted Q evaluation/iteration (https://www.jmlr.org/papers/volume6/ernst05a/ernst05a.pdf) aims to solve an optimization problem with fixed next-state value estimates, not to optimize your eq. 2.\n- I find the interpretation and example in Section 6.3 enlightening.\n- In fact, it made me wonder whether one can leverage methods such as generalized policy evaluation (https://www.pnas.org/content/pnas/117/48/30079.full.pdf) and generalized policy improvement as an extension to one-step baselines.\n- l. 66 he learned -> the learned\n- l. 89 paraterizations -> parametrizations\n- l. 167 suite [Fu et al., 2020]\n- l. 323 effects -> affects (maybe)",
    "review_points_list": [
      "The paper is well written and the claims and empirical evidence are adequate and clearly marked, which makes it easier to assess its contributions.",
      "The results are also interesting and add to the current understanding of offline RL.",
      "The notion of proposing simple, improved baselines for offline RL is also interesting and helps increase applicability of offline RL methods.",
      "A more detailed assessment of the related work can help clarify the novelty of the contributions.",
      "The paper does not contain a discussion of the broader societal impact of its results.",
      "The paper seems correct, though I think it could be more emphatic that the issue identified in Sec 6.3 is one potential issue with iterative and multi-step methods, but perhaps not the only one.",
      "The paper is clearly written.",
      "In a recent paper, Gulcehre et al. (https://arxiv.org/pdf/2103.09575.pdf) seem to arrive at similar conclusions about one-step methods, but they additionally prescribe a regularization term to discourage the improved policy from selecting actions (at respective states) absent from the training data.",
      "The example you proposed for Figure 4 and Appendix A can be useful for validating the claim from Gulcehre et al. as to why they prescribe the ranking regularization.",
      "I do not agree with the assessment in lines 86-95. YOEO fits the bill of a one-step method (and in fact the authors state that they want to propose an alternative to multi-step and iterative algorithms) and has some improvements over multistep and iterative methods.",
      "Moreover, the Niekum et al. make some of the core points this paper makes as well (see their Sec. 4), so I think it is important to acknowledge that.",
      "This will help the reader understand the contributions better in light of existing work.",
      "I find there is enough information for reproducing the results.",
      "Thank you for your submission. I have a few miscellaneous comments.",
      "OAMPI is similar to MPI, so maybe cite https://www.jstor.org/stable/2630487 and possibly also GPI in Sutton & Barto's book.",
      "I would also suggest calling the evaluation step $mathcal{E}$.",
      "Some of this taxonomy is also used by Levine et al. (https://arxiv.org/pdf/2005.01643.pdf) so perhaps point to their work as well.",
      "To me the Q ``without a stop gradient'' in eq. 2 is confusing, even though later you say that in practice a target network is used.",
      "Fitted Q evaluation/iteration (https://www.jmlr.org/papers/volume6/ernst05a/ernst05a.pdf) aims to solve an optimization problem with fixed next-state value estimates, not to optimize your eq. 2.",
      "I find the interpretation and example in Section 6.3 enlightening.",
      "In fact, it made me wonder whether one can leverage methods such as generalized policy evaluation (https://www.pnas.org/content/pnas/117/48/30079.full.pdf) and generalized policy improvement as an extension to one-step baselines.",
      "l. 66 he learned -> the learned",
      "l. 89 paraterizations -> parametrizations",
      "l. 167 suite [Fu et al., 2020]",
      "l. 323 effects -> affects (maybe)"
    ]
  },
  {
    "paper_id": "2201.06133v1",
    "submission_id": "x5hh6N9bUUb",
    "submission_title": "Stochastic Solutions for Linear Inverse Problems using the Prior Implicit in a Denoiser",
    "review_id": "q07hpzwJ_id",
    "input": {
      "title": "Stochastic Solutions for Linear Inverse Problems using the Prior Implicit in a Denoiser",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper introduces an original way to solve linear inverse problems and demonstrates with simulations that it works well, both computationally and in terms of imaging quality.\n- The idea is well explained, the paper is well written, and the experiments support the claims.\n- I would be happy to see the paper at the conference.\n- The paper uses as an denoiser the bias-free CNN from [36], and writes it obtains similar results with other bias-free denoisers. I would be curious to also see results for other standard CNN-denoisers, in particular for U-net, because U-net or similar encoder-decoder architectures work very well for denoising and other inverse problem.\n- I would also be interesting to show results for standard CNN denoisers that are not bias-free, and potentially add a brief discussion whether bias-freeness is important or not for this method to work.\n- For the numbers in Table 1 ``ours - avg``, it would be great to also give confidence intervals or a standard deviation, to get intuition on the variation across samples.\n- Another interesting baseline that is also easy to train for table 3 is a U-net trained end-to-end for compressive sensing. Runtimes for CS would also be great to add.\n- Can the method also give realistic samples of high-resolution images? I didn't understand from the paper what the resolution of the images in figure 4 or 5 is.",
    "review_points_list": [
      "The paper introduces an original way to solve linear inverse problems and demonstrates with simulations that it works well, both computationally and in terms of imaging quality.",
      "The idea is well explained, the paper is well written, and the experiments support the claims.",
      "I would be happy to see the paper at the conference.",
      "The paper uses as an denoiser the bias-free CNN from [36], and writes it obtains similar results with other bias-free denoisers. I would be curious to also see results for other standard CNN-denoisers, in particular for U-net, because U-net or similar encoder-decoder architectures work very well for denoising and other inverse problem.",
      "I would also be interesting to show results for standard CNN denoisers that are not bias-free, and potentially add a brief discussion whether bias-freeness is important or not for this method to work.",
      "For the numbers in Table 1 ``ours - avg``, it would be great to also give confidence intervals or a standard deviation, to get intuition on the variation across samples.",
      "Another interesting baseline that is also easy to train for table 3 is a U-net trained end-to-end for compressive sensing. Runtimes for CS would also be great to add.",
      "Can the method also give realistic samples of high-resolution images? I didn't understand from the paper what the resolution of the images in figure 4 or 5 is."
    ]
  },
  {
    "paper_id": "2201.06133v1",
    "submission_id": "x5hh6N9bUUb",
    "submission_title": "Stochastic Solutions for Linear Inverse Problems using the Prior Implicit in a Denoiser",
    "review_id": "3B06cJO3i2Z",
    "input": {
      "title": "Stochastic Solutions for Linear Inverse Problems using the Prior Implicit in a Denoiser",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This work is novel in relating the MSE denoisers to priors in an explicit way by using the classic result.\n- The difference between PnP/RED and the proposed method is clearly stated.\n- However, I found a concurrent paper [1] that seems to propose a similar method.\n- I believe a discussion between your and their methods can avoid future confusion.\n- Moreover, investigations on the relationship between denoisers and explicit regularizers have also been conducted for MMSE denoisers within the PnP framework [2].\n- This paper conducts adequate experiments to support their claims.\n- The results are technically sound and convincible.\n- For questions please see my comments below.\n- Also, the limitations of the proposed method are well-discussed.\n- Since I am not very familiar with the score-match field, the paper is a little bit difficult for me to follow.\n- A supplement with some introductory details (e.g. derivation of Langevin process) will be welcome for readers like me.\n- This paper provides interesting insights from a Bayesian perspective, which can be useful for the theoretical studies of PnP/RED.",
    "review_points_list": [
      "This work is novel in relating the MSE denoisers to priors in an explicit way by using the classic result.",
      "The difference between PnP/RED and the proposed method is clearly stated.",
      "However, I found a concurrent paper [1] that seems to propose a similar method.",
      "I believe a discussion between your and their methods can avoid future confusion.",
      "Moreover, investigations on the relationship between denoisers and explicit regularizers have also been conducted for MMSE denoisers within the PnP framework [2].",
      "This paper conducts adequate experiments to support their claims.",
      "The results are technically sound and convincible.",
      "For questions please see my comments below.",
      "Also, the limitations of the proposed method are well-discussed.",
      "Since I am not very familiar with the score-match field, the paper is a little bit difficult for me to follow.",
      "A supplement with some introductory details (e.g. derivation of Langevin process) will be welcome for readers like me.",
      "This paper provides interesting insights from a Bayesian perspective, which can be useful for the theoretical studies of PnP/RED."
    ]
  },
  {
    "paper_id": "2201.06133v1",
    "submission_id": "x5hh6N9bUUb",
    "submission_title": "Stochastic Solutions for Linear Inverse Problems using the Prior Implicit in a Denoiser",
    "review_id": "AitVFp3zrKG",
    "input": {
      "title": "Stochastic Solutions for Linear Inverse Problems using the Prior Implicit in a Denoiser",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is nicely motivated, well-written and clear.\n- The overall topic is highly relevant and the numerical results are encouraging.\n- Despite the detailed explanation given in lines 255 to 272, the difference to [20] did not become perfectly clear to me from an algorithmic perspective and thus raises questions about the originality of the research in my opinion.\n- The authors state that their method is not based on Langevin dynamics.\n- The update equation for y in eq.(4) is, however, identical to the update equation of x in [20] except for the way the scaling factors / step sizes are computed.\n- Both approaches update the variable with the help of (differently weighted) combinations of the denoiser residual and random noise.\n- I believe it is crucial to discuss the difference of the proposed approach with respect to Langevin dynamics in more detail.\n- The Langevin dynamics of [20] could be used / compared to in the numerical results.\n- As the paper is validated empirically (with no convergence proof of the proposed scheme), I believe it is crucial to describe why the two approaches are different despite their very similar appearance of the algorithm.\n- I am attaching some related works below, which could be of interest.\n- Typos: - line 118: maniofld >> manifold - line 126- 127: residual of the denoising function proportional to the gradient of p(y) >> residual of the denoising function proportional to the gradient of log p(y)\n- I would like to thank the authors for their explanation which helped me understand the difference to Langevin dynamics better.\n- Due to the large algorithmic similarity to Langevin dynamics I would have still appreciated a comparison to (or at least a small test on) using an algorithm like [20] in the same fashion the authors are solving inverse problems based on the idea of algorithm 1.\n- This would contribute to my understanding whether it is the use of stochasticity or the specific way it is introduced (i.e. controlling the amount of noise via the magnitude of the residual predicted by the denoiser) that leads to the superior results.\n- Although it at least seems like [20] could easily be adapted to solve inverse problems the same way as proposed in this paper, I understand that [20] addressed generative tasks only (counting inpainting as a generative task).\n- I will therefore raise my score to 7.",
    "review_points_list": [
      "The paper is nicely motivated, well-written and clear.",
      "The overall topic is highly relevant and the numerical results are encouraging.",
      "Despite the detailed explanation given in lines 255 to 272, the difference to [20] did not become perfectly clear to me from an algorithmic perspective and thus raises questions about the originality of the research in my opinion.",
      "The authors state that their method is not based on Langevin dynamics.",
      "The update equation for y in eq.(4) is, however, identical to the update equation of x in [20] except for the way the scaling factors / step sizes are computed.",
      "Both approaches update the variable with the help of (differently weighted) combinations of the denoiser residual and random noise.",
      "I believe it is crucial to discuss the difference of the proposed approach with respect to Langevin dynamics in more detail.",
      "The Langevin dynamics of [20] could be used / compared to in the numerical results.",
      "As the paper is validated empirically (with no convergence proof of the proposed scheme), I believe it is crucial to describe why the two approaches are different despite their very similar appearance of the algorithm.",
      "I am attaching some related works below, which could be of interest.",
      "Typos: - line 118: maniofld >> manifold - line 126- 127: residual of the denoising function proportional to the gradient of p(y) >> residual of the denoising function proportional to the gradient of log p(y)",
      "I would like to thank the authors for their explanation which helped me understand the difference to Langevin dynamics better.",
      "Due to the large algorithmic similarity to Langevin dynamics I would have still appreciated a comparison to (or at least a small test on) using an algorithm like [20] in the same fashion the authors are solving inverse problems based on the idea of algorithm 1.",
      "This would contribute to my understanding whether it is the use of stochasticity or the specific way it is introduced (i.e. controlling the amount of noise via the magnitude of the residual predicted by the denoiser) that leads to the superior results.",
      "Although it at least seems like [20] could easily be adapted to solve inverse problems the same way as proposed in this paper, I understand that [20] addressed generative tasks only (counting inpainting as a generative task).",
      "I will therefore raise my score to 7."
    ]
  },
  {
    "paper_id": "2201.06133v1",
    "submission_id": "x5hh6N9bUUb",
    "submission_title": "Stochastic Solutions for Linear Inverse Problems using the Prior Implicit in a Denoiser",
    "review_id": "FpBuYOPRkz",
    "input": {
      "title": "Stochastic Solutions for Linear Inverse Problems using the Prior Implicit in a Denoiser",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The idea is quite interesting, i.e., building a plug-and-play denoiser to inverse problems.\n- The proposed approach is not very clearly explained.\n- There are many incorrect or unclear claims, which are detailed in the below box.\n- The paper is not very well organized, e.g., methodology and experiments are mixed in one section.\n- The authors' contribution in methodology is not clearly separated from existing works.",
    "review_points_list": [
      "The idea is quite interesting, i.e., building a plug-and-play denoiser to inverse problems.",
      "The proposed approach is not very clearly explained.",
      "There are many incorrect or unclear claims, which are detailed in the below box.",
      "The paper is not very well organized, e.g., methodology and experiments are mixed in one section.",
      "The authors' contribution in methodology is not clearly separated from existing works."
    ]
  },
  {
    "paper_id": "2110.02370v1",
    "submission_id": "urueR03mkng",
    "submission_title": "Leveraging the Inductive Bias of Large Language Models for Abstract Textual Reasoning",
    "review_id": "88JFRyvQiC",
    "input": {
      "title": "Leveraging the Inductive Bias of Large Language Models for Abstract Textual Reasoning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The objective of the paper is clearly clarified.\n- The writing is easy to follow.\n- The findings in the experiments are interesting.\n- It is a good paper to study how well pre-trained LM can perform on reasoning-required tasks and its generalization capabilities on different aspects.\n- I appreciate this work\n- I think the datasets built within this paper is limited to specific domains and scenarios.\n- It will be better if the paper can cover results on other open domain datasets as well\n- such as commonsense QA, mathematical reasoning, etc",
    "review_points_list": [
      "The objective of the paper is clearly clarified.",
      "The writing is easy to follow.",
      "The findings in the experiments are interesting.",
      "It is a good paper to study how well pre-trained LM can perform on reasoning-required tasks and its generalization capabilities on different aspects.",
      "I appreciate this work",
      "I think the datasets built within this paper is limited to specific domains and scenarios.",
      "It will be better if the paper can cover results on other open domain datasets as well",
      "such as commonsense QA, mathematical reasoning, etc"
    ]
  },
  {
    "paper_id": "2110.02370v1",
    "submission_id": "urueR03mkng",
    "submission_title": "Leveraging the Inductive Bias of Large Language Models for Abstract Textual Reasoning",
    "review_id": "2cw6WK-gV-k",
    "input": {
      "title": "Leveraging the Inductive Bias of Large Language Models for Abstract Textual Reasoning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Synthetically generated tasks are equally valuable.\n- Using synthetic environments that are controllable can help researchers better understand the problem.\n- It may be meaningful to have synthetic environments before stepping into natural language data.\n- The tasks in the work are not oversimplified as shown in the figures.\n- Using natural language data might not be ideal when strong pre-trained language models still struggle on toy-ish tasks.\n- Many examples in the NLP community use synthetic datasets as starting points for research directions.\n- Back-translating the templated descriptions could be an interesting experiment.\n- The work provides well-designed experiments with convincing results exploring an interesting direction.\n- The community needs works that help understand the capabilities and limitations of language models.\n- The experiment designs and presentations, especially the heatmaps, are commendable.\n- Pointed out a typo on L217: 'There are 3 groups of columns.'",
    "review_points_list": [
      "Synthetically generated tasks are equally valuable.",
      "Using synthetic environments that are controllable can help researchers better understand the problem.",
      "It may be meaningful to have synthetic environments before stepping into natural language data.",
      "The tasks in the work are not oversimplified as shown in the figures.",
      "Using natural language data might not be ideal when strong pre-trained language models still struggle on toy-ish tasks.",
      "Many examples in the NLP community use synthetic datasets as starting points for research directions.",
      "Back-translating the templated descriptions could be an interesting experiment.",
      "The work provides well-designed experiments with convincing results exploring an interesting direction.",
      "The community needs works that help understand the capabilities and limitations of language models.",
      "The experiment designs and presentations, especially the heatmaps, are commendable.",
      "Pointed out a typo on L217: 'There are 3 groups of columns.'"
    ]
  },
  {
    "paper_id": "2110.02370v1",
    "submission_id": "urueR03mkng",
    "submission_title": "Leveraging the Inductive Bias of Large Language Models for Abstract Textual Reasoning",
    "review_id": "Fqli0Wb1kzN",
    "input": {
      "title": "Leveraging the Inductive Bias of Large Language Models for Abstract Textual Reasoning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- While I think that the exact settings in this work are somewhat original, Clark et al. 2020 (RuleTaker) also consider reasoning abilities of transformers on synthetic tasks and look at various generalization abilities.\n- Similarly, Banerjee et al. 2020 also look at how well transformers can be trained to do various reasoning tasks in blocks worlds.\n- In the authors\u2019 opinion, what are some major differences between these works and this paper?\n- I think some of the experiments are inconclusive in determining whether the model has truly learnt the underlying rule.\n- For example, in the containers experiment the model just needs to track the state of 2 containers (which can be easily detected based on the language context) to correctly answer.\n- So, even if the model can generalize to more objects and containers, it is not really impressive since the model can learn to ignore all other containers except the two containers whose states were altered.\n- Indeed, if we look at the navigation results, we see poorer extrapolation since the task is harder.\n- In Section 4.4, we cannot immediately conclude that the model is leveraging previous knowledge.\n- The model could just as well be learning superficial features from the container and navigation tasks that help on the hard object tasks.\n- One way to check for this confounder would be to just do some steps of pre-training on the Nav and Cont tasks and see if that by itself explains the fast learning on HardObj.\n- If not, we can then conclude that perhaps the model is leveraging previously acquired knowledge to do well on a composition.\n- I really liked the experiment in Section 4.5.\n- Although, I wonder if the decrease in performance has a simpler explanation like gibberish words like 'sixnqkxb' contain more sub-words and are hence harder to reason / track.\n- I think the paper is decently written.\n- Some style suggestions:\n- Table-2 could be converted into a barplot (moving numbers into appendix) since it\u2019s really hard to parse so many numbers.\n- And it\u2019s generally good to bold the best numbers for a quick read.\n- In Figure-7, it is unclear what the x axis refers to.",
    "review_points_list": [
      "While I think that the exact settings in this work are somewhat original, Clark et al. 2020 (RuleTaker) also consider reasoning abilities of transformers on synthetic tasks and look at various generalization abilities.",
      "Similarly, Banerjee et al. 2020 also look at how well transformers can be trained to do various reasoning tasks in blocks worlds.",
      "In the authors\u2019 opinion, what are some major differences between these works and this paper?",
      "I think some of the experiments are inconclusive in determining whether the model has truly learnt the underlying rule.",
      "For example, in the containers experiment the model just needs to track the state of 2 containers (which can be easily detected based on the language context) to correctly answer.",
      "So, even if the model can generalize to more objects and containers, it is not really impressive since the model can learn to ignore all other containers except the two containers whose states were altered.",
      "Indeed, if we look at the navigation results, we see poorer extrapolation since the task is harder.",
      "In Section 4.4, we cannot immediately conclude that the model is leveraging previous knowledge.",
      "The model could just as well be learning superficial features from the container and navigation tasks that help on the hard object tasks.",
      "One way to check for this confounder would be to just do some steps of pre-training on the Nav and Cont tasks and see if that by itself explains the fast learning on HardObj.",
      "If not, we can then conclude that perhaps the model is leveraging previously acquired knowledge to do well on a composition.",
      "I really liked the experiment in Section 4.5.",
      "Although, I wonder if the decrease in performance has a simpler explanation like gibberish words like 'sixnqkxb' contain more sub-words and are hence harder to reason / track.",
      "I think the paper is decently written.",
      "Some style suggestions:",
      "Table-2 could be converted into a barplot (moving numbers into appendix) since it\u2019s really hard to parse so many numbers.",
      "And it\u2019s generally good to bold the best numbers for a quick read.",
      "In Figure-7, it is unclear what the x axis refers to."
    ]
  },
  {
    "paper_id": "2106.04110v1",
    "submission_id": "vBYwwBxVcsE",
    "submission_title": "A self consistent theory of Gaussian Processes captures feature learning effects in finite CNNs",
    "review_id": "h0Y22yAP1zJ",
    "input": {
      "title": "A self consistent theory of Gaussian Processes captures feature learning effects in finite CNNs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The view of trained NNs as GP regression with modified targets is novel, as far as I can tell, as are the insights developed on toy CNN models.\n- The paper is clear in how it uses and extends previous work in my opinion.\n- I enjoyed reading this paper, and believe it is of high quality.\n- The approach is non-rigorous but I believe technically sound, and the insights that the authors obtain (e.g. the main equations 8 and 16) are interesting.\n- The choice of toy models is also made well, in that they are simple enough to obtain analytic results but also complicated enough to lead to profound results of benefits of feature learning (in terms of sample complexity).\n- The paper is well written and organised, particularly with regards to relation to previous work.\n- The paper examines a key question which is of feature learning in wide NNs, which will be of interest to the general NeurIPS community.\n- The new results about trained NNs being GP regression with shifted targets is certainly surprising to me, and I can see these techniques being built upon in future work.\n- The comment on line 20 about 'DNNs map to Bayesian inference on GPs governed by the NTK' is incorrect. https://arxiv.org/abs/2007.05864 shows you need to add in extra randomness to the initialised NN to obtain a Bayesian interpretation to trained NNs in the NTK regime.\n- where -> were in line 332\n- There is another concurrent paper to [41] in line 77, https://arxiv.org/abs/2106.06615, which provides similar results.",
    "review_points_list": [
      "The view of trained NNs as GP regression with modified targets is novel, as far as I can tell, as are the insights developed on toy CNN models.",
      "The paper is clear in how it uses and extends previous work in my opinion.",
      "I enjoyed reading this paper, and believe it is of high quality.",
      "The approach is non-rigorous but I believe technically sound, and the insights that the authors obtain (e.g. the main equations 8 and 16) are interesting.",
      "The choice of toy models is also made well, in that they are simple enough to obtain analytic results but also complicated enough to lead to profound results of benefits of feature learning (in terms of sample complexity).",
      "The paper is well written and organised, particularly with regards to relation to previous work.",
      "The paper examines a key question which is of feature learning in wide NNs, which will be of interest to the general NeurIPS community.",
      "The new results about trained NNs being GP regression with shifted targets is certainly surprising to me, and I can see these techniques being built upon in future work.",
      "The comment on line 20 about 'DNNs map to Bayesian inference on GPs governed by the NTK' is incorrect. https://arxiv.org/abs/2007.05864 shows you need to add in extra randomness to the initialised NN to obtain a Bayesian interpretation to trained NNs in the NTK regime.",
      "where -> were in line 332",
      "There is another concurrent paper to [41] in line 77, https://arxiv.org/abs/2106.06615, which provides similar results."
    ]
  },
  {
    "paper_id": "2106.04110v1",
    "submission_id": "vBYwwBxVcsE",
    "submission_title": "A self consistent theory of Gaussian Processes captures feature learning effects in finite CNNs",
    "review_id": "_ipd6w_N9v6",
    "input": {
      "title": "A self consistent theory of Gaussian Processes captures feature learning effects in finite CNNs",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The overall quality of the paper is good: I found it technically solid, clearly written, original (at least to my knowledge), and all claims are well supported.\n- The organisation of the paper is fine but could be improved (see my comments below).\n- Other works from the literature (see e.g. https://arxiv.org/abs/1906.08034) distinguish lazy and feature learning regimes in the infinite-$C$ limit, according to the scaling of the network's parameters with $C$. In this paper, feature learning appears to be solely a finite size effect (the parameters\u2019 scaling with $C$ gives the lazy learning regime in the infinite-$C$ limit).\n- I wonder if the self consistent theory developed here would work for different scalings of the parameters with $C$, and in which case, as I presume the cumulants too will scale differently with $C$.\n- I would appreciate if the authors could comment on this point.\n- The authors use a saddle point (SP) method in a somewhat non standard way, as explained in the first paragraph of Appendix A.4.\n- I think the paper would gain in clarity with a sentence in the main text that spells out this point.\n- I would also suggest to state more clearly that the approximation assumes $n$ large, with $n$ the training set size, in the paragraph where the SP method is introduced.\n- A further improvement would be to comment on the error induced by this approximation when $n$ is finite, as e.g. to explain the mismatches observed in figure 1 (increasing as $n$ decreases).\n- With the SP method, the authors are able to find the expression for the posterior covariance matrix by expanding the action to quadratic orders.\n- This coincides with the posterior covariance of a GP with a kernel given by $K + \text{Delta} K$ (with $\text{Delta} K$ properly defined in eq. (9)).\n- As far as I understand, the term $\text{Delta} K$ makes this kernel different from the one appearing in the predictive mean with shifted targets.\n- If this is the case, the predictions for finitely sized DNNs cannot be really described as equivalent to a GP regression with shifted targets (while the equivalence in the infinite-$C$ limit is exact).\n- If so, this should be stated clearly in the paper, as to avoid misinterpretations.\n- Although section 4.4 provides a valid and interesting investigation of the feature learning transition in the CNN model, it is not completely clear to me how the proposed analysis fits with the rest of the paper, i.e. if/how the self-consistent shifted target approach is relevant for the task.\n- I would recommend the authors to make this clearer in the main text; as of now, it appears to be more of a stand alone section (also, it is not immediately obvious why the feature-to-lazy learning transition observed in this specific model is of interest, nor is it clear if the same method could be applied to different architectures).\n- The discussion of the FCN architecture presented in the main text is limited to the equation for the target shift, while the rest of it is left to Appendix I.\n- Even there, there is no figure showing a comparison between theoretical predictions and empirical results.",
    "review_points_list": [
      "The overall quality of the paper is good: I found it technically solid, clearly written, original (at least to my knowledge), and all claims are well supported.",
      "The organisation of the paper is fine but could be improved (see my comments below).",
      "Other works from the literature (see e.g. https://arxiv.org/abs/1906.08034) distinguish lazy and feature learning regimes in the infinite-$C$ limit, according to the scaling of the network's parameters with $C$. In this paper, feature learning appears to be solely a finite size effect (the parameters\u2019 scaling with $C$ gives the lazy learning regime in the infinite-$C$ limit).",
      "I wonder if the self consistent theory developed here would work for different scalings of the parameters with $C$, and in which case, as I presume the cumulants too will scale differently with $C$.",
      "I would appreciate if the authors could comment on this point.",
      "The authors use a saddle point (SP) method in a somewhat non standard way, as explained in the first paragraph of Appendix A.4.",
      "I think the paper would gain in clarity with a sentence in the main text that spells out this point.",
      "I would also suggest to state more clearly that the approximation assumes $n$ large, with $n$ the training set size, in the paragraph where the SP method is introduced.",
      "A further improvement would be to comment on the error induced by this approximation when $n$ is finite, as e.g. to explain the mismatches observed in figure 1 (increasing as $n$ decreases).",
      "With the SP method, the authors are able to find the expression for the posterior covariance matrix by expanding the action to quadratic orders.",
      "This coincides with the posterior covariance of a GP with a kernel given by $K + \text{Delta} K$ (with $\text{Delta} K$ properly defined in eq. (9)).",
      "As far as I understand, the term $\text{Delta} K$ makes this kernel different from the one appearing in the predictive mean with shifted targets.",
      "If this is the case, the predictions for finitely sized DNNs cannot be really described as equivalent to a GP regression with shifted targets (while the equivalence in the infinite-$C$ limit is exact).",
      "If so, this should be stated clearly in the paper, as to avoid misinterpretations.",
      "Although section 4.4 provides a valid and interesting investigation of the feature learning transition in the CNN model, it is not completely clear to me how the proposed analysis fits with the rest of the paper, i.e. if/how the self-consistent shifted target approach is relevant for the task.",
      "I would recommend the authors to make this clearer in the main text; as of now, it appears to be more of a stand alone section (also, it is not immediately obvious why the feature-to-lazy learning transition observed in this specific model is of interest, nor is it clear if the same method could be applied to different architectures).",
      "The discussion of the FCN architecture presented in the main text is limited to the equation for the target shift, while the rest of it is left to Appendix I.",
      "Even there, there is no figure showing a comparison between theoretical predictions and empirical results."
    ]
  },
  {
    "paper_id": "2110.05960v1",
    "submission_id": "zEuLFJCRk4X",
    "submission_title": "Imitating Deep Learning Dynamics via  Locally Elastic Stochastic Differential Equations",
    "review_id": "6PwELcNBrLj",
    "input": {
      "title": "Imitating Deep Learning Dynamics via  Locally Elastic Stochastic Differential Equations",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The paper is well written and clear.\n- The greatest contribution is the finding that such a simple model is able to describe the feature evolution of neural networks, as shown in experiments.\n- This work shows, with its limitations, that the phenomenological approach can in some settings produce results that closely resemble the real NN.\n- It opens up several questions that I hope can be answered in future works: When is this model valid?\n- Can we somehow infer the drift terms from the neural network weights, and then design architectures that favor separation?\n- When presenting the experiments, the plots for $\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{hat{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{alpha}$ and $\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{hat{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{beta}$ are very noisy and it is unclear what the decay of this quantities is.\n- If possible, it would be interesting to denoise the plots and show them in a log-log scale, to see whether indeed the separation results claimed in Theorem 3.1 translate to real NN.\n- Typos: The paper needs to be proofread for typos.\n- I point out some.\n- In line 133 $c_x, c_y$ should be $c_1, c_2$.\n- In line 184, \u201csemi-positive definite\u201d should be \u201cpositive semi-definite\u201d.\n- In line 188, I believe that the sentence should be \u201cthe features are asymptotically pairwise separable with probability 0,\u201d as the current sentence means that the features are asymptotically pairwise separable with probability 1.",
    "review_points_list": [
      "The paper is well written and clear.",
      "The greatest contribution is the finding that such a simple model is able to describe the feature evolution of neural networks, as shown in experiments.",
      "This work shows, with its limitations, that the phenomenological approach can in some settings produce results that closely resemble the real NN.",
      "It opens up several questions that I hope can be answered in future works: When is this model valid?",
      "Can we somehow infer the drift terms from the neural network weights, and then design architectures that favor separation?",
      "When presenting the experiments, the plots for $\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{hat{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{alpha}$ and $\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{hat{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{\text{beta}$ are very noisy and it is unclear what the decay of this quantities is.",
      "If possible, it would be interesting to denoise the plots and show them in a log-log scale, to see whether indeed the separation results claimed in Theorem 3.1 translate to real NN.",
      "Typos: The paper needs to be proofread for typos.",
      "I point out some.",
      "In line 133 $c_x, c_y$ should be $c_1, c_2$.",
      "In line 184, \u201csemi-positive definite\u201d should be \u201cpositive semi-definite\u201d.",
      "In line 188, I believe that the sentence should be \u201cthe features are asymptotically pairwise separable with probability 0,\u201d as the current sentence means that the features are asymptotically pairwise separable with probability 1."
    ]
  },
  {
    "paper_id": "2110.05960v1",
    "submission_id": "zEuLFJCRk4X",
    "submission_title": "Imitating Deep Learning Dynamics via  Locally Elastic Stochastic Differential Equations",
    "review_id": "0g2HB2RmLkR",
    "input": {
      "title": "Imitating Deep Learning Dynamics via  Locally Elastic Stochastic Differential Equations",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The authors seek to understand how neural networks are able to achieve linear separability explaining the recent empirical phenomenon of neural collapse.\n- They conjecture that this is caused by the network possessing local elasticity.\n- They construct a SDE in feature space that under certain assumptions will provably lead to feature separability when local elasticity is met.\n- It was not clear why the SDE they use should reflect the actual feature dynamics of a real neural network.\n- The authors did not provide a clear theoretical explanation for their model.\n- The authors did not spend enough time focusing on assumptions applied in their theory or limitations of their empirical approach to \"validating\" the theory.\n- Future work and related work should be expanded, with particular emphasis on how this model could inform algorithmic improvement or answer open questions.\n- Equation (1) is the basis of your analysis, but you made very little effort to build it up or discuss the assumptions applied.\n- The authors did not discuss the relationship between equation (2) and an Ornstein-Uhlenbeck process.\n- The potentially anisotropic diffusion \u03a3t kind of came out of nowhere.\n- The authors did not discuss what is being generalized here.\n- The analysis and experiments assume a batch size of 1, but how would the results change for a realistic scenario with mini batches?\n- Could you please provide more intuition for the expressions in equation (11)?\n- To estimate \u03b1(t) and \u03b2(t), 'each experiment is repeated for ntrial = 100 independent runs'.\n- The estimated \u03b1(t) and \u03b2(t) are then used to simulate your SDE and these dynamics are displayed over one of the trials of training in figure 5?\n- The model does not suggest hyperparameter settings or architecture design that would facilitate separability.\n- The SDE in feature space is used to model the feature dynamics rather than the parameter dynamics.\n- The authors did not provide a clear explanation for why is depth needed or non-linearities to achieve feature separability.",
    "review_points_list": [
      "The authors seek to understand how neural networks are able to achieve linear separability explaining the recent empirical phenomenon of neural collapse.",
      "They conjecture that this is caused by the network possessing local elasticity.",
      "They construct a SDE in feature space that under certain assumptions will provably lead to feature separability when local elasticity is met.",
      "It was not clear why the SDE they use should reflect the actual feature dynamics of a real neural network.",
      "The authors did not provide a clear theoretical explanation for their model.",
      "The authors did not spend enough time focusing on assumptions applied in their theory or limitations of their empirical approach to \"validating\" the theory.",
      "Future work and related work should be expanded, with particular emphasis on how this model could inform algorithmic improvement or answer open questions.",
      "Equation (1) is the basis of your analysis, but you made very little effort to build it up or discuss the assumptions applied.",
      "The authors did not discuss the relationship between equation (2) and an Ornstein-Uhlenbeck process.",
      "The potentially anisotropic diffusion \u03a3t kind of came out of nowhere.",
      "The authors did not discuss what is being generalized here.",
      "The analysis and experiments assume a batch size of 1, but how would the results change for a realistic scenario with mini batches?",
      "Could you please provide more intuition for the expressions in equation (11)?",
      "To estimate \u03b1(t) and \u03b2(t), 'each experiment is repeated for ntrial = 100 independent runs'.",
      "The estimated \u03b1(t) and \u03b2(t) are then used to simulate your SDE and these dynamics are displayed over one of the trials of training in figure 5?",
      "The model does not suggest hyperparameter settings or architecture design that would facilitate separability.",
      "The SDE in feature space is used to model the feature dynamics rather than the parameter dynamics.",
      "The authors did not provide a clear explanation for why is depth needed or non-linearities to achieve feature separability."
    ]
  },
  {
    "paper_id": "2110.05960v1",
    "submission_id": "zEuLFJCRk4X",
    "submission_title": "Imitating Deep Learning Dynamics via  Locally Elastic Stochastic Differential Equations",
    "review_id": "azoxhcmhl0z",
    "input": {
      "title": "Imitating Deep Learning Dynamics via  Locally Elastic Stochastic Differential Equations",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- This paper provides a new way to understand the training process of deep neural networks.\n- The dynamics of features, rather than the parameters, is considered.\n- Due to the stochastic nature of the training, the dynamics of features is formulated as SDEs.\n- The work is not purely theoretical, since its modeling and analysis is built on the local elasticity assumption, which is observed in practice but not proven theoretically.\n- However, considering the local elasticity is a special property for nonlinear machine learning models, such as deep neural network, and does not appear for linear models, the LE-SDEs still provide some insights to the interaction between different data during the training process of neural networks.\n- Numerical experiments also show that the class means given by LE-SDEs with properly calculated coefficients match the real class means well.\n- My major concern about the work lies on the linear formulation of the LE-SDE.\n- By the formulation, the influence of one data to other data is linear.\n- However, no explanation or justification is provided for this linear formulation.\n- Does it come from the stochastic gradient descent update, or come from the choices of features?\n- Will the linear formulation still work if other optimization algorithms are used, or other quantities in the neural network are picked as features?\n- The authors should discuss the rationality and potential limitation of the linear formulation.\n- The paper is generally well written and easy to read.\n- Though, there are still some typos and seemingly wrong expressions (perhaps I'm wrong).\n- To mention one, in the equations between line 121 and 122, \u03b1 and \u03b2 are fixed in the expressions, regardless of the classes L_m.\n- I believe this is not the right formulation.",
    "review_points_list": [
      "This paper provides a new way to understand the training process of deep neural networks.",
      "The dynamics of features, rather than the parameters, is considered.",
      "Due to the stochastic nature of the training, the dynamics of features is formulated as SDEs.",
      "The work is not purely theoretical, since its modeling and analysis is built on the local elasticity assumption, which is observed in practice but not proven theoretically.",
      "However, considering the local elasticity is a special property for nonlinear machine learning models, such as deep neural network, and does not appear for linear models, the LE-SDEs still provide some insights to the interaction between different data during the training process of neural networks.",
      "Numerical experiments also show that the class means given by LE-SDEs with properly calculated coefficients match the real class means well.",
      "My major concern about the work lies on the linear formulation of the LE-SDE.",
      "By the formulation, the influence of one data to other data is linear.",
      "However, no explanation or justification is provided for this linear formulation.",
      "Does it come from the stochastic gradient descent update, or come from the choices of features?",
      "Will the linear formulation still work if other optimization algorithms are used, or other quantities in the neural network are picked as features?",
      "The authors should discuss the rationality and potential limitation of the linear formulation.",
      "The paper is generally well written and easy to read.",
      "Though, there are still some typos and seemingly wrong expressions (perhaps I'm wrong).",
      "To mention one, in the equations between line 121 and 122, \u03b1 and \u03b2 are fixed in the expressions, regardless of the classes L_m.",
      "I believe this is not the right formulation."
    ]
  },
  {
    "paper_id": "2104.08977v2",
    "submission_id": "u9RvlvaBC7",
    "submission_title": "Off-Policy Risk Assessment in Contextual Bandits",
    "review_id": "qwpbiUF9ILK",
    "input": {
      "title": "Off-Policy Risk Assessment in Contextual Bandits",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I like the problem this paper studies since it has some practical applicability and the method is easy to use with a solid statistical guarantee.\n- I will view the significance level as high, as this more broad class of objectives characterizes lots of useful and popular metrics people care about.\n- Regarding to the originality, I think it is a medium-low.\n- The method proposed is based on CDF estimate and then a plug-in in any risk functionals, this kind of approach has been used in the previous literature as well, though not explicitly stated, see the algorithms [1].\n- Though this paper discusses its difference with a concurrent work [2], there is still some literature that utilizes this kind of approach [1], it would be great if the authors could comment on this.\n- The quality of this paper is good.\n- The motivation is clear, and the assumption of Lipschitz risk functional is well-motivated and justified.\n- I like Section 4.1, but it might be shortened, and leave some space for experiments.\n- The method is clearly introduced.\n- Theoretically, this paper gives the first uniform concentration for CDF estimates in bandits, which also directly translates to a $O(1/\\sqrt{n})$ rate for the Lipschitz objective.\n- For the empirical study side, it seems all the examinations are about, first estimating CDF using different approaches, then a direct plug-in.\n- I am wondering if there any other baselines in the literature that says do OPE for CVaR, variance, etc.\n- If not, it would be great to state them clearly.\n- If yes, it would be great to include them as baselines.\n- I would view the current experiments as ablation studies, rather than a comparison with existing methods.\n- Some specific comments:\n- [1]. How to estimate the Lipschitz constant when it is not obvious from the context?\n- [2]. It seems the requirement of the Lipschitz property is to derive the uniform convergence rate theoretically.\n- [3]. I am wondering how this method (probably empirically) applies to some metrics that not satisfy this requirement, say VaR?\n- It would be great to comment on the necessity of this assumption.\n- Some typos: line 6, it would be great to define CPT when use it the first time; line 52, is scales; line 35, off-hig evaluation; line 90, steps generates;\n- I enjoy reading the paper and it writes well!\n- ref: [1]. Being Optimistic to Be Conservative: Quickly Learning a CVaR Policy [2]. Universal off-policy evaluation",
    "review_points_list": [
      "I like the problem this paper studies since it has some practical applicability and the method is easy to use with a solid statistical guarantee.",
      "I will view the significance level as high, as this more broad class of objectives characterizes lots of useful and popular metrics people care about.",
      "Regarding to the originality, I think it is a medium-low.",
      "The method proposed is based on CDF estimate and then a plug-in in any risk functionals, this kind of approach has been used in the previous literature as well, though not explicitly stated, see the algorithms [1].",
      "Though this paper discusses its difference with a concurrent work [2], there is still some literature that utilizes this kind of approach [1], it would be great if the authors could comment on this.",
      "The quality of this paper is good.",
      "The motivation is clear, and the assumption of Lipschitz risk functional is well-motivated and justified.",
      "I like Section 4.1, but it might be shortened, and leave some space for experiments.",
      "The method is clearly introduced.",
      "Theoretically, this paper gives the first uniform concentration for CDF estimates in bandits, which also directly translates to a $O(1/\\sqrt{n})$ rate for the Lipschitz objective.",
      "For the empirical study side, it seems all the examinations are about, first estimating CDF using different approaches, then a direct plug-in.",
      "I am wondering if there any other baselines in the literature that says do OPE for CVaR, variance, etc.",
      "If not, it would be great to state them clearly.",
      "If yes, it would be great to include them as baselines.",
      "I would view the current experiments as ablation studies, rather than a comparison with existing methods.",
      "Some specific comments:",
      "[1]. How to estimate the Lipschitz constant when it is not obvious from the context?",
      "[2]. It seems the requirement of the Lipschitz property is to derive the uniform convergence rate theoretically.",
      "[3]. I am wondering how this method (probably empirically) applies to some metrics that not satisfy this requirement, say VaR?",
      "It would be great to comment on the necessity of this assumption.",
      "Some typos: line 6, it would be great to define CPT when use it the first time; line 52, is scales; line 35, off-hig evaluation; line 90, steps generates;",
      "I enjoy reading the paper and it writes well!",
      "ref: [1]. Being Optimistic to Be Conservative: Quickly Learning a CVaR Policy [2]. Universal off-policy evaluation"
    ]
  },
  {
    "paper_id": "2104.08977v2",
    "submission_id": "u9RvlvaBC7",
    "submission_title": "Off-Policy Risk Assessment in Contextual Bandits",
    "review_id": "RjyFrwrp-Km",
    "input": {
      "title": "Off-Policy Risk Assessment in Contextual Bandits",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- my main concern for this work is that it seems to be a straightforward combination of the well-known properties of the IS estimator and the AIPW estimator and a new class of estimands.\n- The authors introduce a new class of estimands that are (Lipschitz) functionals of the CDF, so to estimate these estimands well it suffices to estimate the CDFs well.\n- Establishing the concentration results for CDF estimates is also a straightforward adaptation of the results in the offline policy evaluation literature.\n- I feel there is a lack of technical novelty. Please correct me if I missed something.\n- I think the paper can be improved if stronger results can be shown.\n- Is it possible to provide (asymptotic) confidence intervals for the estimands?\n- Is it possible to establish optimality for the current results?\n- Line 125: \u2018its value\u2019 should be \u2018the difference between the function values evaluated at Z and Z\u2019\u2019?\n- The definition of u^+(z) should depend on c as well?\n- Line 351: might be improved",
    "review_points_list": [
      "my main concern for this work is that it seems to be a straightforward combination of the well-known properties of the IS estimator and the AIPW estimator and a new class of estimands.",
      "The authors introduce a new class of estimands that are (Lipschitz) functionals of the CDF, so to estimate these estimands well it suffices to estimate the CDFs well.",
      "Establishing the concentration results for CDF estimates is also a straightforward adaptation of the results in the offline policy evaluation literature.",
      "I feel there is a lack of technical novelty. Please correct me if I missed something.",
      "I think the paper can be improved if stronger results can be shown.",
      "Is it possible to provide (asymptotic) confidence intervals for the estimands?",
      "Is it possible to establish optimality for the current results?",
      "Line 125: \u2018its value\u2019 should be \u2018the difference between the function values evaluated at Z and Z\u2019\u2019?",
      "The definition of u^+(z) should depend on c as well?",
      "Line 351: might be improved"
    ]
  },
  {
    "paper_id": "2104.08977v2",
    "submission_id": "u9RvlvaBC7",
    "submission_title": "Off-Policy Risk Assessment in Contextual Bandits",
    "review_id": "D2iYpa16K4g",
    "input": {
      "title": "Off-Policy Risk Assessment in Contextual Bandits",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- I am satisfied with the novelty of the paper\n- I am satisfied with the quality of the paper\n- I think the paper is well written\n- I would recommend acceptance of the submission\n- The paper provides the first DKW-style proof of uniform convergence of weighted empirical CDF if the importance ratio is bounded\n- The proof looks standard but is new and I think it is an important complement to DKW-style inequalities\n- The proof is sound to me\n- I have the same concern of theorem 5.2 as the authors also mention in line 271\n- The error for DR does not depend on $\\hat{G} - G$ and cannot improve over IS also seems weird to me\n- A better bound on that would definitely improves the paper's quality\n- The paper is well written and inspiring\n- The background on Lipschitz risk functionals bring up a wide range of risk functionals that we can directly utilized given the estimation of the CDF\n- The main proof in Section 5 discusses two important estimator: IS and DR, both are provided with sufficient background the theoretical results\n- In line 229, 'DI' should replace with 'DM'",
    "review_points_list": [
      "I am satisfied with the novelty of the paper",
      "I am satisfied with the quality of the paper",
      "I think the paper is well written",
      "I would recommend acceptance of the submission",
      "The paper provides the first DKW-style proof of uniform convergence of weighted empirical CDF if the importance ratio is bounded",
      "The proof looks standard but is new and I think it is an important complement to DKW-style inequalities",
      "The proof is sound to me",
      "I have the same concern of theorem 5.2 as the authors also mention in line 271",
      "The error for DR does not depend on $\\hat{G} - G$ and cannot improve over IS also seems weird to me",
      "A better bound on that would definitely improves the paper's quality",
      "The paper is well written and inspiring",
      "The background on Lipschitz risk functionals bring up a wide range of risk functionals that we can directly utilized given the estimation of the CDF",
      "The main proof in Section 5 discusses two important estimator: IS and DR, both are provided with sufficient background the theoretical results",
      "In line 229, 'DI' should replace with 'DM'"
    ]
  },
  {
    "paper_id": "2104.08977v2",
    "submission_id": "u9RvlvaBC7",
    "submission_title": "Off-Policy Risk Assessment in Contextual Bandits",
    "review_id": "afPVTpxak2Z",
    "input": {
      "title": "Off-Policy Risk Assessment in Contextual Bandits",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The work provides a general way of performing high-confidence off-policy value estimation which is applicable to a large class of evaluation metrics.\n- These metrics, characterised as being Lipschitz functionals of CDF, are understudied in the machine learning literature and are practically relevant for policy evaluation in high-risk applications.\n- The proposed approach that starts from bounding errors in estimating CDF and carrying this over to bounding errors in risk measure-based value is novel.\n- The method guarantees good value estimates for any set of risk measures simultaneously, given they satisfy Lipschitz property.\n- Experimental evaluation adequately verifies the theoretical results on realistic datasets.\n- The advantage of the approach is its generality for all Lipschitz risk measures.\n- But familiarity with applications of such measures and their relative merits is assumed.\n- Although many examples of such measures are presented (beyond mean, variance, and CVaR), some more details on strengths of each and applications in which they are appropriate will help to provide more guidance on use of such risk measures by the machine learning community.\n- Experimental evaluation does not seem to be suited to ideal settings where risk measures are useful, e.g. continuous-valued rewards with a skewed distribution and a large range (max-min is high).\n- For binary rewards, as in the experiments, Lipschitz constant determined by max reward D is relatively small.\n- While classification datasets are easier to convert to a bandit task, alternatives based on semi-synthetic datasets with simulated continuous-valued outcomes could be explored. This may provide understanding of usefulness of the confidence intervals when Lipschitz constants are large.\n- Does the approach assume non-negative rewards (for applying Lemma 4.1)? Is this without any loss of generality?\n- How does the bounds from the presented approach compare with existing ones for mean, variance, and CVaR?\n- Does the experiments provide a sense of how tight are the confidence intervals for different risk measures and datasets?\n- In case of unknown behaviour policy, doubly robust estimators have another advantage (in addition to being consistent under misspecification of either action or reward models) of having root n convergence rates under mild misspecification. Does this property follows as well for the proposed doubly robust estimator, both for CDF and policy value?",
    "review_points_list": [
      "The work provides a general way of performing high-confidence off-policy value estimation which is applicable to a large class of evaluation metrics.",
      "These metrics, characterised as being Lipschitz functionals of CDF, are understudied in the machine learning literature and are practically relevant for policy evaluation in high-risk applications.",
      "The proposed approach that starts from bounding errors in estimating CDF and carrying this over to bounding errors in risk measure-based value is novel.",
      "The method guarantees good value estimates for any set of risk measures simultaneously, given they satisfy Lipschitz property.",
      "Experimental evaluation adequately verifies the theoretical results on realistic datasets.",
      "The advantage of the approach is its generality for all Lipschitz risk measures.",
      "But familiarity with applications of such measures and their relative merits is assumed.",
      "Although many examples of such measures are presented (beyond mean, variance, and CVaR), some more details on strengths of each and applications in which they are appropriate will help to provide more guidance on use of such risk measures by the machine learning community.",
      "Experimental evaluation does not seem to be suited to ideal settings where risk measures are useful, e.g. continuous-valued rewards with a skewed distribution and a large range (max-min is high).",
      "For binary rewards, as in the experiments, Lipschitz constant determined by max reward D is relatively small.",
      "While classification datasets are easier to convert to a bandit task, alternatives based on semi-synthetic datasets with simulated continuous-valued outcomes could be explored. This may provide understanding of usefulness of the confidence intervals when Lipschitz constants are large.",
      "Does the approach assume non-negative rewards (for applying Lemma 4.1)? Is this without any loss of generality?",
      "How does the bounds from the presented approach compare with existing ones for mean, variance, and CVaR?",
      "Does the experiments provide a sense of how tight are the confidence intervals for different risk measures and datasets?",
      "In case of unknown behaviour policy, doubly robust estimators have another advantage (in addition to being consistent under misspecification of either action or reward models) of having root n convergence rates under mild misspecification. Does this property follows as well for the proposed doubly robust estimator, both for CDF and policy value?"
    ]
  },
  {
    "paper_id": "2506.06324v1",
    "submission_id": "vLyI__SoeAe",
    "submission_title": "Co-Adaptation of Algorithmic and Implementational Innovations in Inference-based Deep Reinforcement Learning",
    "review_id": "NYspl1Sk5v",
    "input": {
      "title": "Co-Adaptation of Algorithmic and Implementational Innovations in Inference-based Deep Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Your task is to split the provided Review into individual review points or pieces.\n- Each point should be a distinct comment, observation, strength, weakness, or question.\n- Your response should be in JSON format with a 'review_points' key containing an array of strings.\n- Please provide the split Review in JSON format.\n- This was an interesting paper.\n- The authors' theoretical framework casting MPO, AWR, SAC, and other algorithms as special cases of a more unified control-as-inference objective was rather enlightening.\n- Unclear whether 'Implementational Details' are possible transferable implementational choices or different algorithms\n- The authors ablated the different implementational choices individually, but concern is that there may be co-dependencies between different implementational choices\n- Co-dependencies between implementational choices may fail to capture the actual effects\n- The four implementational choices do not seem to depend in any way on the fact that MPO, AWR, and SAC can be treated in a unified, inference-based manner",
    "review_points_list": [
      "Your task is to split the provided Review into individual review points or pieces.",
      "Each point should be a distinct comment, observation, strength, weakness, or question.",
      "Your response should be in JSON format with a 'review_points' key containing an array of strings.",
      "Please provide the split Review in JSON format.",
      "This was an interesting paper.",
      "The authors' theoretical framework casting MPO, AWR, SAC, and other algorithms as special cases of a more unified control-as-inference objective was rather enlightening.",
      "Unclear whether 'Implementational Details' are possible transferable implementational choices or different algorithms",
      "The authors ablated the different implementational choices individually, but concern is that there may be co-dependencies between different implementational choices",
      "Co-dependencies between implementational choices may fail to capture the actual effects",
      "The four implementational choices do not seem to depend in any way on the fact that MPO, AWR, and SAC can be treated in a unified, inference-based manner"
    ]
  },
  {
    "paper_id": "2506.06324v1",
    "submission_id": "vLyI__SoeAe",
    "submission_title": "Co-Adaptation of Algorithmic and Implementational Innovations in Inference-based Deep Reinforcement Learning",
    "review_id": "RHZ2J1NlZzQ",
    "input": {
      "title": "Co-Adaptation of Algorithmic and Implementational Innovations in Inference-based Deep Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- The control as inference framework has been used by the authors of MPO and SAC in their respective papers, and isn't a new way of looking at these algorithms.\n- More specifically, the EM class formulation closely follows a similar characterization in the MPO paper.\n- Nevertheless presenting these together as part of the same framework seems new (where KL control is shown to be almost a sub-problem for EM control).\n- The paper cites a lot of the previous work dealing with meta-analysis of RL algorithms which point out that performance is often dependent on the specific code implementation used.\n- The mathematical formulation seems technically sound and well supported (and are based on prior work in the field).\n- The experimental evaluation includes 5 openAI gym mujoco environments and is quite exhaustive as it includes ablations over a number of different design choices, such as network size, activations and normalization etc, in order to study which low-level code optimizations are important.\n- The paper is well written and easy to follow and understand.\n- The authors first present their unified control as inference framework, then clearly show how MPO, AWR, SAC fall into it.\n- The experimental evaluation is well organized for analysis into each separate ablation axis.\n- Irreproducibility is a well known issue for RL, especially the dependence of algorithm performance on the specific implementation used.\n- This work takes a step towards addressing this issue.\n- The exhaustive experimental evaluation might be useful to other researchers, where the authors analyze what aspects of the different algorithms are critical.\n- They find that certain choices that are important for SAC (clipped double Q and squashed tanh), do not improve performance of other algorithms.\n- Further they also find useful design choices in MPO (ELU and LayerNorm) which improve performance of SAC.\n- That said, some of these observations might be specific to the gym environments tested, and may not transfer.",
    "review_points_list": [
      "The control as inference framework has been used by the authors of MPO and SAC in their respective papers, and isn't a new way of looking at these algorithms.",
      "More specifically, the EM class formulation closely follows a similar characterization in the MPO paper.",
      "Nevertheless presenting these together as part of the same framework seems new (where KL control is shown to be almost a sub-problem for EM control).",
      "The paper cites a lot of the previous work dealing with meta-analysis of RL algorithms which point out that performance is often dependent on the specific code implementation used.",
      "The mathematical formulation seems technically sound and well supported (and are based on prior work in the field).",
      "The experimental evaluation includes 5 openAI gym mujoco environments and is quite exhaustive as it includes ablations over a number of different design choices, such as network size, activations and normalization etc, in order to study which low-level code optimizations are important.",
      "The paper is well written and easy to follow and understand.",
      "The authors first present their unified control as inference framework, then clearly show how MPO, AWR, SAC fall into it.",
      "The experimental evaluation is well organized for analysis into each separate ablation axis.",
      "Irreproducibility is a well known issue for RL, especially the dependence of algorithm performance on the specific implementation used.",
      "This work takes a step towards addressing this issue.",
      "The exhaustive experimental evaluation might be useful to other researchers, where the authors analyze what aspects of the different algorithms are critical.",
      "They find that certain choices that are important for SAC (clipped double Q and squashed tanh), do not improve performance of other algorithms.",
      "Further they also find useful design choices in MPO (ELU and LayerNorm) which improve performance of SAC.",
      "That said, some of these observations might be specific to the gym environments tested, and may not transfer."
    ]
  },
  {
    "paper_id": "2506.06324v1",
    "submission_id": "vLyI__SoeAe",
    "submission_title": "Co-Adaptation of Algorithmic and Implementational Innovations in Inference-based Deep Reinforcement Learning",
    "review_id": "yt8jMT4R5St",
    "input": {
      "title": "Co-Adaptation of Algorithmic and Implementational Innovations in Inference-based Deep Reinforcement Learning",
      "paper_content_placeholder": "TODO: Load paper content from extracted_files"
    },
    "output": "- Overall, the structure is great and I like the ablation study.\n- Furthermore, I have learned new things via the EM vs direct minimization taxonomy.\n- That being said, I think that the writing could be improved.\n- I find the technical presentation is not solid enough.\n- Not that the authors should go with a measure-theoretic presentation, but the paper would gain clarity if the notation is improved.\n- Don't get me wrong, I'm not complaining about the choice of symbol, but rather the symbol-to-meaning mapping which I find deficient.\n- For the kind of paper that the authors are aiming for, the background section needs to be near-perfect and crystal clear.\n- Regarding the main contribution, the co-adaptation claim, I think that it should be de-emphasized.\n- Just in terms of space in the text, pages 1-6 are dedicated to the presentation of SAC, MPO and AWR under a unified narrative.\n- The co-adaptation findings are only developped in pages 7-9 and the overall takeaway seems to be that pretty much everything should stay the same for MPO and AWR but SAC is a bit more tolerant and can do better with a few tweaks taken from the other methods.\n- The expression 'co-adaptation' is interesting, and I can see how it expresses the idea that you are trying to convey.\n- That being said, I wonder if there would be another way to describe the issue without introducing new terminology (in this case borrowing from biology).",
    "review_points_list": [
      "Overall, the structure is great and I like the ablation study.",
      "Furthermore, I have learned new things via the EM vs direct minimization taxonomy.",
      "That being said, I think that the writing could be improved.",
      "I find the technical presentation is not solid enough.",
      "Not that the authors should go with a measure-theoretic presentation, but the paper would gain clarity if the notation is improved.",
      "Don't get me wrong, I'm not complaining about the choice of symbol, but rather the symbol-to-meaning mapping which I find deficient.",
      "For the kind of paper that the authors are aiming for, the background section needs to be near-perfect and crystal clear.",
      "Regarding the main contribution, the co-adaptation claim, I think that it should be de-emphasized.",
      "Just in terms of space in the text, pages 1-6 are dedicated to the presentation of SAC, MPO and AWR under a unified narrative.",
      "The co-adaptation findings are only developped in pages 7-9 and the overall takeaway seems to be that pretty much everything should stay the same for MPO and AWR but SAC is a bit more tolerant and can do better with a few tweaks taken from the other methods.",
      "The expression 'co-adaptation' is interesting, and I can see how it expresses the idea that you are trying to convey.",
      "That being said, I wonder if there would be another way to describe the issue without introducing new terminology (in this case borrowing from biology)."
    ]
  }
]